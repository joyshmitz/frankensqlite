<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="color-scheme" content="light" />
    <title>FrankenSQLite Spec Evolution</title>

    <!-- Typography -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Fraunces:opsz,wght@9..144,350..900&family=Manrope:wght@200..800&display=swap"
      rel="stylesheet"
    />

    <!-- Tailwind (CDN) -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            fontFamily: {
              display: ["Fraunces", "ui-serif", "Georgia", "serif"],
              sans: ["Manrope", "ui-sans-serif", "system-ui", "sans-serif"],
              mono: [
                "ui-monospace",
                "SFMono-Regular",
                "SF Mono",
                "Menlo",
                "Monaco",
                "Consolas",
                "Liberation Mono",
                "Courier New",
                "monospace",
              ],
            },
            boxShadow: {
              glow: "0 0 0 1px rgba(15, 23, 42, 0.06), 0 10px 30px rgba(2, 6, 23, 0.10)",
              glowLg:
                "0 0 0 1px rgba(15, 23, 42, 0.06), 0 24px 60px rgba(2, 6, 23, 0.16)",
            },
          },
        },
      };
    </script>

    <!-- Code highlighting -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/diff2html/bundles/css/diff2html.min.css"
    />

    <style>
      :root {
        /* Surfaces */
        --bg0: #fbfbfe;
        --bg1: #f6f7ff;
        --card: rgba(255, 255, 255, 0.82);
        --card2: rgba(255, 255, 255, 0.7);
        --stroke: rgba(2, 6, 23, 0.10);
        --stroke2: rgba(2, 6, 23, 0.07);

        /* Ink */
        --ink0: #0b1220;
        --ink1: rgba(2, 6, 23, 0.80);
        --ink2: rgba(2, 6, 23, 0.62);
        --ink3: rgba(2, 6, 23, 0.46);

        /* Brand-ish gradient */
        --a0: rgba(37, 99, 235, 0.14);
        --a1: rgba(219, 39, 119, 0.10);
        --a2: rgba(20, 184, 166, 0.10);
        --a3: rgba(217, 119, 6, 0.10);

        /* Category colors (10 buckets) */
        --c1: #2563eb; /* logic/math */
        --c2: #d97706; /* sqlite legacy */
        --c3: #059669; /* asupersync */
        --c4: #dc2626; /* architecture mistakes */
        --c5: #64748b; /* scrivening */
        --c6: #db2777; /* background/context */
        --c7: #0ea5e9; /* standard eng perf */
        --c8: #7c3aed; /* alien math */
        --c9: #16a34a; /* clarification */
        --c10: #0f172a; /* other */

        --ring: rgba(37, 99, 235, 0.35);
      }

      html,
      body {
        height: 100%;
      }

      body {
        font-family: Manrope, system-ui, -apple-system, Segoe UI, sans-serif;
        color: var(--ink0);
        background: radial-gradient(1200px 700px at 10% -10%, var(--a0), transparent 60%),
          radial-gradient(900px 600px at 95% 5%, var(--a1), transparent 58%),
          radial-gradient(1100px 700px at 40% 110%, var(--a2), transparent 60%),
          radial-gradient(1100px 650px at 100% 85%, var(--a3), transparent 56%),
          linear-gradient(180deg, var(--bg0), var(--bg1));
        background-attachment: fixed;
      }

      /* Subtle noise */
      body::before {
        content: "";
        position: fixed;
        inset: 0;
        pointer-events: none;
        opacity: 0.035;
        mix-blend-mode: multiply;
        background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='320' height='320'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='.9' numOctaves='3' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='320' height='320' filter='url(%23n)' opacity='.35'/%3E%3C/svg%3E");
      }

      .glass {
        background: var(--card);
        border: 1px solid var(--stroke);
        backdrop-filter: blur(14px);
        -webkit-backdrop-filter: blur(14px);
      }

      .glass-2 {
        background: var(--card2);
        border: 1px solid var(--stroke2);
        backdrop-filter: blur(14px);
        -webkit-backdrop-filter: blur(14px);
      }

      .focus-ring:focus {
        outline: none;
        box-shadow: 0 0 0 4px var(--ring);
      }

      @media (prefers-reduced-motion: reduce) {
        * {
          animation: none !important;
          transition: none !important;
          scroll-behavior: auto !important;
        }
      }

      .enter {
        animation: enter 700ms cubic-bezier(0.2, 1, 0.2, 1) both;
      }
      @keyframes enter {
        from {
          opacity: 0;
          transform: translateY(10px);
        }
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      .chip {
        border: 1px solid var(--stroke2);
        background: rgba(255, 255, 255, 0.7);
      }

      .codebox {
        background: rgba(15, 23, 42, 0.03);
        border: 1px solid rgba(2, 6, 23, 0.10);
      }

      .mono {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono",
          "Courier New", monospace;
      }

      /* Mobile bottom sheet */
      .sheet {
        transform: translateY(12px);
        opacity: 0;
        transition: transform 200ms ease, opacity 200ms ease;
      }
      .sheet.open {
        transform: translateY(0);
        opacity: 1;
      }

      /* ECharts container should not shrink weirdly */
      .chart {
        min-height: 280px;
      }

      /* Markdown rendering (hand-rolled; avoids tailwind/typography plugin dependency) */
      .md {
        color: rgba(2, 6, 23, 0.82);
        font-size: 15px;
        line-height: 1.75;
      }
      .md h1,
      .md h2,
      .md h3,
      .md h4 {
        font-family: Fraunces, ui-serif, Georgia, serif;
        color: rgba(2, 6, 23, 0.92);
        letter-spacing: -0.01em;
      }
      .md h1 {
        font-size: 28px;
        line-height: 1.15;
        margin: 18px 0 10px;
      }
      .md h2 {
        font-size: 22px;
        line-height: 1.2;
        margin: 18px 0 8px;
      }
      .md h3 {
        font-size: 18px;
        line-height: 1.25;
        margin: 14px 0 6px;
      }
      .md p {
        margin: 10px 0;
      }
      .md ul,
      .md ol {
        margin: 10px 0 10px 18px;
      }
      .md li {
        margin: 4px 0;
      }
      .md code {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono",
          "Courier New", monospace;
        font-size: 0.92em;
        padding: 0.12em 0.36em;
        border: 1px solid rgba(2, 6, 23, 0.10);
        border-radius: 10px;
        background: rgba(15, 23, 42, 0.04);
      }
      .md pre code {
        display: block;
        padding: 0;
        border: none;
        background: transparent;
        font-size: 12px;
        line-height: 1.6;
      }
      .md pre {
        margin: 12px 0;
        padding: 12px 14px;
        border-radius: 18px;
        overflow: auto;
        border: 1px solid rgba(2, 6, 23, 0.10);
        background: rgba(15, 23, 42, 0.03);
      }
      .md a {
        color: rgb(37, 99, 235);
        text-decoration: none;
      }
      .md a:hover {
        text-decoration: underline;
      }
      .md table {
        width: 100%;
        border-collapse: collapse;
        margin: 12px 0;
        font-size: 13px;
      }
      .md th,
      .md td {
        border: 1px solid rgba(2, 6, 23, 0.10);
        padding: 8px 10px;
        vertical-align: top;
      }
      .md th {
        background: rgba(15, 23, 42, 0.03);
        font-weight: 800;
      }
      .md blockquote {
        margin: 12px 0;
        padding: 10px 12px;
        border-left: 3px solid rgba(37, 99, 235, 0.35);
        background: rgba(37, 99, 235, 0.06);
        border-radius: 14px;
      }

      /* Bottom timeline dock */
      .dock {
        background: rgba(255, 255, 255, 0.78);
        border-top: 1px solid rgba(2, 6, 23, 0.10);
        backdrop-filter: blur(16px);
        -webkit-backdrop-filter: blur(16px);
      }
      .dock-canvas {
        width: 100%;
        height: 40px;
        display: block;
      }
      .dock-slider {
        width: 100%;
      }
    </style>
  </head>

  <body>
    <div class="mx-auto max-w-[1200px] px-4 pb-40 pt-10 sm:px-6 lg:px-8">
      <!-- Top -->
      <header class="enter">
        <div
          class="glass shadow-glow rounded-3xl px-5 py-6 sm:px-7 sm:py-7 lg:px-10 lg:py-10"
        >
          <div class="flex flex-col gap-6 lg:flex-row lg:items-end lg:justify-between">
            <div class="max-w-[70ch]">
              <div class="flex flex-wrap items-center gap-2">
                <span
                  class="chip inline-flex items-center gap-2 rounded-full px-3 py-1 text-xs font-semibold text-slate-700"
                >
                  <span
                    class="inline-block h-2 w-2 rounded-full"
                    style="background: linear-gradient(90deg, var(--c1), var(--c6))"
                  ></span>
                  Single-file visualization
                </span>
                <span
                  id="metaSpan"
                  class="chip inline-flex items-center rounded-full px-3 py-1 text-xs font-semibold text-slate-700"
                ></span>
              </div>

              <h1 class="mt-4 font-display text-4xl leading-[1.05] sm:text-5xl">
                Evolution of the FrankenSQLite Spec
              </h1>
              <p class="mt-4 text-base leading-relaxed text-slate-700 sm:text-lg">
                A commit-by-commit atlas of how
                <span class="mono">COMPREHENSIVE_SPEC_FOR_FRANKENSQLITE_V1.md</span>
                changed from inception. Every change is bucketed into 10 categories with
                multi-label support, confidence, and diff excerpts.
              </p>
            </div>

            <div class="flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-center lg:justify-end">
              <button
                id="btnFilters"
                class="focus-ring inline-flex items-center justify-center gap-2 rounded-2xl border border-slate-900/10 bg-white/60 px-4 py-2.5 text-sm font-semibold text-slate-900 shadow-sm transition hover:bg-white"
                type="button"
              >
                Filters
              </button>
              <a
                id="btnOpenSpec"
                class="focus-ring inline-flex items-center justify-center gap-2 rounded-2xl border border-slate-900/10 bg-white/60 px-4 py-2.5 text-sm font-semibold text-slate-900 shadow-sm transition hover:bg-white"
                href="COMPREHENSIVE_SPEC_FOR_FRANKENSQLITE_V1.md"
              >
                Open Spec
              </a>
              <button
                id="btnGalaxy"
                class="focus-ring inline-flex items-center justify-center gap-2 rounded-2xl bg-slate-900 px-4 py-2.5 text-sm font-semibold text-white shadow-sm transition hover:bg-slate-800"
                type="button"
              >
                Galaxy Brain
              </button>
            </div>
          </div>

          <div class="mt-7 grid grid-cols-2 gap-3 sm:grid-cols-4 lg:grid-cols-5">
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Commits</div>
              <div id="kpiCommits" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Change Groups</div>
              <div id="kpiGroups" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Lines Changed</div>
              <div id="kpiLines" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Primary Mode</div>
              <div id="kpiMode" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 hidden rounded-2xl p-4 shadow-sm lg:block">
              <div class="text-xs font-semibold text-slate-500">Data Integrity</div>
              <div id="kpiIntegrity" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
          </div>
        </div>
      </header>

      <!-- Main layout -->
      <div class="mt-8 grid grid-cols-1 gap-6 lg:grid-cols-[360px_1fr]">
        <!-- Sidebar (desktop) -->
        <aside class="enter hidden lg:block">
          <div class="glass shadow-glow rounded-3xl p-5">
            <div class="flex items-center justify-between">
              <div class="text-sm font-bold text-slate-900">Filters</div>
              <button
                id="btnReset"
                class="focus-ring rounded-xl border border-slate-900/10 bg-white/60 px-3 py-1.5 text-xs font-semibold text-slate-900 hover:bg-white"
                type="button"
              >
                Reset
              </button>
            </div>

            <div class="mt-4">
              <label class="text-xs font-semibold text-slate-600">Search</label>
              <input
                id="q"
                class="focus-ring mt-2 w-full rounded-2xl border border-slate-900/10 bg-white/70 px-3.5 py-2.5 text-sm text-slate-900 placeholder:text-slate-400"
                placeholder="commit, section, keyword..."
              />
            </div>

            <div class="mt-4">
              <div class="flex items-center justify-between">
                <label class="text-xs font-semibold text-slate-600">Min Impact</label>
                <div id="impactLabel" class="mono text-xs text-slate-500">-</div>
              </div>
              <input id="impact" class="mt-2 w-full" type="range" min="0" max="200" value="0" />
            </div>

            <div class="mt-5">
              <div class="flex items-center justify-between">
                <label class="text-xs font-semibold text-slate-600">Bucket Mode</label>
                <div class="mono text-xs text-slate-500" id="bucketModeLabel">primary</div>
              </div>
              <div class="mt-2 grid grid-cols-2 gap-2">
                <button
                  id="modePrimary"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-slate-900 px-3 py-2 text-xs font-semibold text-white"
                  type="button"
                >
                  Primary (disjoint)
                </button>
                <button
                  id="modeMulti"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900"
                  type="button"
                >
                  Multi-label
                </button>
              </div>
              <p class="mt-2 text-xs leading-relaxed text-slate-500">
                Multi-label counts a change group in every bucket it matches. Primary assigns each group
                exactly one bucket for clean stacks.
              </p>
            </div>

            <div class="mt-5">
              <label class="text-xs font-semibold text-slate-600">Buckets</label>
              <div id="bucketToggles" class="mt-2 grid grid-cols-1 gap-2"></div>
            </div>

            <div class="mt-6">
              <label class="text-xs font-semibold text-slate-600">Quick Views</label>
              <div class="mt-2 grid grid-cols-1 gap-2">
                <button
                  id="viewTimeline"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Timeline + Categories
                </button>
                <button
                  id="viewCommits"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Commit Explorer
                </button>
                <button
                  id="viewAlien"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Alien Telemetry (BOCPD)
                </button>
              </div>
            </div>
          </div>
        </aside>

        <!-- Content -->
        <main class="enter">
          <!-- Timeline -->
          <section id="sectionTimeline" class="glass shadow-glow rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Timeline</div>
                <div class="mt-1 text-xs text-slate-500">
                  Dot = commit. Size = lines changed. Color = primary bucket.
                </div>
              </div>
              <div class="flex flex-wrap items-center gap-2">
                <div class="chip rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                  <span class="mono" id="rangeLabel">-</span>
                </div>
                <a
                  id="btnOpenRepo"
                  class="focus-ring chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700 hover:bg-white"
                  href="https://github.com/Dicklesworthstone/frankensqlite"
                  target="_blank"
                  rel="noreferrer"
                >
                  GitHub
                </a>
              </div>
            </div>

            <div id="timelineChart" class="chart mt-4 w-full"></div>
          </section>

          <section class="mt-6 grid grid-cols-1 gap-6 xl:grid-cols-2">
            <section class="glass shadow-glow rounded-3xl p-5">
              <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
                <div>
                  <div class="text-sm font-bold text-slate-900">Buckets Over Time</div>
                  <div class="mt-1 text-xs text-slate-500">
                    Stacked totals across time bins (or by commit). Use this for day/hour/15m/5m
                    density.
                  </div>
                </div>
                <div class="flex flex-wrap items-center gap-2">
                  <label class="chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                    Resolution
                    <select id="stackResolution" class="ml-1 rounded-xl border border-slate-900/10 bg-white/70 px-2 py-1 text-xs">
                      <option value="commit">Commit</option>
                      <option value="day">Day</option>
                      <option value="hour">Hour</option>
                      <option value="15m">15 min</option>
                      <option value="5m">5 min</option>
                    </select>
                  </label>
                  <label class="chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                    Metric
                    <select id="stackMetric" class="ml-1 rounded-xl border border-slate-900/10 bg-white/70 px-2 py-1 text-xs">
                      <option value="groups">Change groups</option>
                      <option value="lines">Lines changed (approx)</option>
                      <option value="tokens">Tokens changed (approx)</option>
                      <option value="lev">Levenshtein (hunks)</option>
                    </select>
                  </label>
                </div>
              </div>
              <div id="stackChart" class="chart mt-4 w-full"></div>
            </section>

            <section class="glass shadow-glow rounded-3xl p-5">
              <div class="flex items-end justify-between">
                <div>
                  <div class="text-sm font-bold text-slate-900">Bucket Mix</div>
                  <div class="mt-1 text-xs text-slate-500">Distribution in current filter.</div>
                </div>
              </div>
              <div id="donutChart" class="chart mt-4 w-full"></div>
            </section>
          </section>

          <!-- Doc evolution -->
          <section id="sectionDoc" class="glass shadow-glow mt-6 rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Document Evolution</div>
                <div class="mt-1 text-xs text-slate-500">
                  Scrub the timeline dock to step through history. Inspect the rendered spec and the
                  unified diff (with token + Levenshtein metrics).
                </div>
              </div>
              <div class="flex flex-wrap items-center gap-2">
                <button
                  id="docTabSpec"
                  class="focus-ring rounded-2xl bg-slate-900 px-3 py-2 text-xs font-semibold text-white hover:bg-slate-800"
                  type="button"
                >
                  Spec
                </button>
                <button
                  id="docTabDiff"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Diff
                </button>
                <button
                  id="docTabMetrics"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Metrics
                </button>
              </div>
            </div>

            <div id="docLoading" class="mt-4 rounded-3xl border border-slate-900/10 bg-white/60 p-4 text-sm text-slate-700">
              Loading spec evolution dataset... (local gzip JSON; no GitHub API)
            </div>

            <div id="docMain" class="mt-4 hidden grid-cols-1 gap-4 lg:grid lg:grid-cols-[1fr_420px]">
              <section class="glass-2 rounded-3xl p-4 lg:p-5">
                <div class="flex flex-col gap-2 sm:flex-row sm:items-center sm:justify-between">
                  <div class="min-w-0">
                    <div class="text-xs font-semibold text-slate-500">Selected commit</div>
                    <div id="docCommitTitle" class="mt-1 truncate text-sm font-semibold text-slate-900">-</div>
                  </div>
                  <div class="flex shrink-0 flex-wrap items-center gap-2">
                    <span id="docCommitMeta" class="chip mono inline-flex items-center rounded-full px-2.5 py-1 text-[11px] text-slate-700">-</span>
                    <a
                      id="docCommitLink"
                      class="focus-ring chip inline-flex items-center gap-2 rounded-2xl px-3 py-2 text-xs font-semibold text-slate-700 hover:bg-white"
                      href="#"
                      target="_blank"
                      rel="noreferrer"
                    >
                      Open commit
                    </a>
                  </div>
                </div>

                <div class="mt-4">
                  <div id="docSpecView" class="hidden">
                    <div class="flex items-center justify-between">
                      <div class="text-xs font-semibold text-slate-600">Rendered Markdown</div>
                      <button
                        id="btnRawToggle"
                        class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                        type="button"
                      >
                        Toggle Raw
                      </button>
                    </div>
                    <div id="docRendered" class="md mt-3 max-h-[70vh] overflow-auto rounded-2xl border border-slate-900/10 bg-white/70 p-4"></div>
                    <pre id="docRaw" class="codebox mono mt-3 hidden max-h-[70vh] overflow-auto rounded-2xl p-4 text-[11px] leading-relaxed text-slate-900"></pre>
                  </div>

                  <div id="docDiffView" class="hidden">
                    <div class="flex items-center justify-between">
                      <div class="text-xs font-semibold text-slate-600">Diff (parent → selected)</div>
                      <div class="flex items-center gap-2">
                        <button
                          id="btnPrettyDiff"
                          class="focus-ring rounded-xl bg-slate-900 px-3 py-1.5 text-[11px] font-semibold text-white hover:bg-slate-800"
                          type="button"
                        >
                          Pretty
                        </button>
                        <button
                          id="btnRawDiff"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                          type="button"
                        >
                          Raw
                        </button>
                      </div>
                    </div>
                    <div id="diffPretty" class="mt-3 max-h-[70vh] overflow-auto rounded-2xl border border-slate-900/10 bg-white/70 p-2"></div>
                    <pre id="diffRaw" class="codebox mono mt-3 hidden max-h-[70vh] overflow-auto rounded-2xl p-4 text-[11px] leading-relaxed text-slate-900"></pre>
                  </div>

                  <div id="docMetricsView" class="hidden">
                    <div class="text-xs font-semibold text-slate-600">Computed metrics</div>
                    <div class="mt-3 grid grid-cols-2 gap-3 sm:grid-cols-4">
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Tokens touched</div>
                        <div id="mTokens" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Levenshtein</div>
                        <div id="mLev" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Hunks</div>
                        <div id="mHunks" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Bytes touched</div>
                        <div id="mBytes" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                    </div>
                    <div class="mt-4">
                      <button
                        id="btnComputeAll"
                        class="focus-ring w-full rounded-2xl bg-slate-900 px-4 py-2.5 text-sm font-semibold text-white hover:bg-slate-800"
                        type="button"
                      >
                        Compute token + Levenshtein metrics for all commits (runs locally)
                      </button>
                      <div class="mt-2 text-xs text-slate-500">
                        This can take a bit on large diffs. The UI stays responsive; charts update
                        as metrics arrive.
                      </div>
                      <div id="computeProgress" class="mt-2 hidden text-xs font-semibold text-slate-700"></div>
                    </div>
                  </div>
                </div>
              </section>

              <aside class="glass-2 rounded-3xl p-4 lg:p-5">
                <div class="text-xs font-semibold text-slate-600">Change summary</div>
                <div id="docSummary" class="mt-3 space-y-2 text-sm text-slate-700"></div>
                <div class="mt-4 border-t border-slate-900/10 pt-4">
                  <div class="text-xs font-semibold text-slate-600">Patch notes</div>
                  <div class="mt-2 text-xs leading-relaxed text-slate-600">
                    Distances are computed per-hunk between removed and added blocks (byte-level
                    Levenshtein in WASM), then summed.
                  </div>
                </div>
              </aside>
            </div>
          </section>

          <!-- Commit explorer -->
          <section id="sectionCommits" class="glass shadow-glow mt-6 rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Commit Explorer</div>
                <div class="mt-1 text-xs text-slate-500">
                  Click a commit to expand its change groups and evidence excerpts.
                </div>
              </div>
              <div class="flex items-center gap-2">
                <div class="chip rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                  Showing <span id="showingCount" class="mono">-</span>
                </div>
              </div>
            </div>

            <div id="commitList" class="mt-4 grid grid-cols-1 gap-3"></div>
          </section>

          <!-- Alien telemetry -->
          <section id="sectionAlien" class="glass shadow-glow mt-6 rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Alien Telemetry</div>
                <div class="mt-1 text-xs text-slate-500">
                  BOCPD change-point detection over commit impact (lines changed).
                </div>
              </div>
              <div class="chip rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                Hazard <span id="hazardLabel" class="mono">-</span>
              </div>
            </div>

            <div class="mt-4 grid grid-cols-1 gap-4 lg:grid-cols-[1fr_360px]">
              <div>
                <div id="bocpdChart" class="chart w-full"></div>
              </div>
              <div class="glass-2 rounded-3xl p-5">
                <div class="text-xs font-semibold text-slate-600">Galaxy Brain Card</div>
                <div class="mt-3 codebox rounded-2xl p-3">
                  <div class="mono text-[11px] leading-relaxed text-slate-900">
                    P(r_t | x_{1:t}) ∝ Σ_{r_{t-1}} P(x_t | r_t, …) · P(r_t | r_{t-1}) · P(r_{t-1} |
                    x_{1:t-1})
                  </div>
                </div>
                <p class="mt-3 text-xs leading-relaxed text-slate-600">
                  This page runs a tiny BOCPD model locally on the commit impact series (add+del).
                  With only 101 points, it is fast and deterministic. Change points are used only as
                  a lens, not a claim of truth.
                </p>
                <div class="mt-4">
                  <label class="text-xs font-semibold text-slate-600">Hazard H</label>
                  <input
                    id="hazard"
                    class="mt-2 w-full"
                    type="range"
                    min="0.01"
                    max="0.30"
                    step="0.01"
                    value="0.10"
                  />
                </div>
              </div>
            </div>
          </section>
        </main>
      </div>
    </div>

    <!-- Mobile filter sheet -->
    <div id="overlay" class="fixed inset-0 z-40 hidden bg-slate-900/30 backdrop-blur-sm"></div>
    <div
      id="sheet"
      class="sheet fixed bottom-0 left-0 right-0 z-50 hidden rounded-t-3xl border border-slate-900/10 bg-white/90 p-5 shadow-2xl backdrop-blur-xl"
    >
      <div class="flex items-center justify-between">
        <div class="text-sm font-bold text-slate-900">Filters</div>
        <button
          id="btnCloseSheet"
          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-xs font-semibold text-slate-900 hover:bg-white"
          type="button"
        >
          Close
        </button>
      </div>
      <div class="mt-4">
        <label class="text-xs font-semibold text-slate-600">Search</label>
        <input
          id="qMobile"
          class="focus-ring mt-2 w-full rounded-2xl border border-slate-900/10 bg-white/70 px-3.5 py-2.5 text-sm text-slate-900 placeholder:text-slate-400"
          placeholder="commit, section, keyword..."
        />
      </div>
      <div class="mt-4">
        <div class="flex items-center justify-between">
          <label class="text-xs font-semibold text-slate-600">Min Impact</label>
          <div id="impactLabelMobile" class="mono text-xs text-slate-500">-</div>
        </div>
        <input id="impactMobile" class="mt-2 w-full" type="range" min="0" max="200" value="0" />
      </div>
      <div class="mt-5">
        <label class="text-xs font-semibold text-slate-600">Bucket Mode</label>
        <div class="mt-2 grid grid-cols-2 gap-2">
          <button
            id="modePrimaryMobile"
            class="focus-ring rounded-2xl border border-slate-900/10 bg-slate-900 px-3 py-2 text-xs font-semibold text-white"
            type="button"
          >
            Primary
          </button>
          <button
            id="modeMultiMobile"
            class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900"
            type="button"
          >
            Multi-label
          </button>
        </div>
      </div>
      <div class="mt-5">
        <label class="text-xs font-semibold text-slate-600">Buckets</label>
        <div id="bucketTogglesMobile" class="mt-2 grid grid-cols-1 gap-2"></div>
      </div>
      <div class="mt-6 grid grid-cols-2 gap-2">
        <button
          id="btnResetMobile"
          class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
          type="button"
        >
          Reset
        </button>
        <button
          id="btnApplyMobile"
          class="focus-ring rounded-2xl bg-slate-900 px-3 py-2 text-xs font-semibold text-white hover:bg-slate-800"
          type="button"
        >
          Apply
        </button>
      </div>
    </div>

    <!-- Timeline dock -->
    <div id="dock" class="dock fixed inset-x-0 bottom-0 z-30 px-4 py-3">
      <div class="mx-auto max-w-[1200px]">
        <div class="flex items-center justify-between gap-3">
          <div class="min-w-0">
            <div class="text-[11px] font-semibold text-slate-500">Timeline scrubber</div>
            <div id="dockTitle" class="mt-0.5 truncate text-xs font-semibold text-slate-900">-</div>
          </div>
          <div class="shrink-0 flex items-center gap-2">
            <button
              id="dockPrev"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
              type="button"
            >
              Prev
            </button>
            <button
              id="dockNext"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
              type="button"
            >
              Next
            </button>
          </div>
        </div>

        <canvas
          id="dockCanvas"
          class="dock-canvas mt-2 rounded-2xl border border-slate-900/10 bg-white/70"
        ></canvas>
        <input id="dockSlider" class="dock-slider mt-2" type="range" min="0" max="1" value="0" />
        <div class="mt-1 flex items-center justify-between text-[11px] text-slate-500">
          <div id="dockLeftLabel" class="mono">-</div>
          <div id="dockRightLabel" class="mono">-</div>
        </div>
      </div>
    </div>

    <!-- Dependencies -->
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/dist/echarts.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/dayjs@1.11.10/dayjs.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/highlight.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pako@2.1.0/dist/pako.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/markdown-it@14.1.0/dist/markdown-it.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/dompurify@3.1.0/dist/purify.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/diff2html/bundles/js/diff2html.min.js"></script>

    <script>
      // -----------------------------
      // Data: commit metadata + stats
      // -----------------------------

      const COMMIT_LOG_RAW = String.raw`c08f1602d03b1833a4f91c8f77347f8f196bac9d|c08f160|2026-02-07T01:17:42-05:00|Dicklesworthstone|Add comprehensive specification documents (8,628 + 1,206 lines)
f9d88aa96f50893f8531373d0734597ebae3c592|f9d88aa|2026-02-07T01:43:43-05:00|Dicklesworthstone|Promote SSI to V1, add intent logs, shard lock tables, expand specs
76eef31be20a6faedc62e7fecce88e78652ebdcf|76eef31|2026-02-07T02:04:31-05:00|Dicklesworthstone|docs: reconcile v1 specs (RaptorQ/SSI/K semantics)
9800b17df4a56c2dc065cf566c2810d4ed2e576c|9800b17|2026-02-07T02:45:02-05:00|Dicklesworthstone|Spec V1.3: scope doctrine, ECS substrate, multi-process MVCC, encryption
79018f161649e6d7977bc74eb849a0e22eceb286|79018f1|2026-02-07T02:56:16-05:00|Dicklesworthstone|Spec: revise WAL frame layout for true compatibility mode
5ad34871f7242de61378843c6c1e8311e35d9fa3|5ad3487|2026-02-07T03:14:56-05:00|Dicklesworthstone|Spec V1.4: Codex synthesis — RaptorQ everywhere, WAL sidecar overhaul, ECS layout, replication
7b2c677cf61adda977e71524b59d7ec234137962|7b2c677|2026-02-07T03:16:08-05:00|Dicklesworthstone|Spec V1.5: alien-artifact discipline — decision-theoretic SSI, BOCPD, monitoring stack, native mode
bf0426417685504bb2b2f5acfc4de2c2f087ef8b|bf04264|2026-02-07T03:31:40-05:00|Dicklesworthstone|Spec V1.6a: RaptorQ-native SSI witness plane — cross-process, distributed, proof-carrying
05cf07847753f444b9f74dfd0279ef96c3ff86b9|05cf078|2026-02-07T03:32:45-05:00|Dicklesworthstone|Spec V1.6b: alien-artifact discipline — formal derivations for every tunable parameter
e8ddf469d8ab8ff8eefbae92b24453e06fcf4627|e8ddf46|2026-02-07T03:33:30-05:00|Dicklesworthstone|Spec V1.6c: performance optimizations — arena allocators, CAR cache, per-invariant monitoring
480c10086fb73630744364f5fb34966de2572dc1|480c100|2026-02-07T03:35:03-05:00|Dicklesworthstone|Spec V1.6d: SSI transaction struct — TxnToken edges, eager abort, terminology scoping
0313678eff44b70cd4ea40cabc2f2222cac2ba93|0313678|2026-02-07T03:38:40-05:00|Dicklesworthstone|Spec V1.6e: SSI detection algorithm — proof-carrying commit with eager abort
b97b1abe4727a738197180c5639738c1da2f5311|b97b1ab|2026-02-07T03:39:32-05:00|Dicklesworthstone|Spec V1.6f: fixup — remove 3-way merge artifacts, restore canonical state
643c89c1c941d1e47cb6a2574e01fd7556f622ec|643c89c|2026-02-07T03:42:22-05:00|Dicklesworthstone|Spec V1.6g: final reconciliation — canonical SSI detection algorithm
0404e42c9dbdc677da9b8a5731d29290ef9f3b26|0404e42|2026-02-07T03:50:09-05:00|Dicklesworthstone|Spec V1.6h: native mode commit protocol — SSI witness-plane integration
2a6353d2f77a050454d2a6fd4b3fd6c8363064e9|2a6353d|2026-02-07T04:08:59-05:00|Dicklesworthstone|spec: align asupersync integration + preserve harness canon
3253050f2835fb305bd115bd9f5939b72cd46503|3253050|2026-02-07T04:30:26-05:00|Dicklesworthstone|docs/spec: schema epoch + align encryption
06dfe9a709d61fc899e00ee33d54dc15d003bb48|06dfe9a|2026-02-07T04:43:05-05:00|Dicklesworthstone|docs/spec: seal internal traits + clarify extensions
63f6057e8705b7105837952bc8ea977ad6f34da6|63f6057|2026-02-07T04:44:32-05:00|Dicklesworthstone|docs/spec: key ARC pages by commit_seq
2cff3a0287f1de30d2fd1185c376ac81913922c9|2cff3a0|2026-02-07T04:45:11-05:00|Dicklesworthstone|docs/spec: clarify INV-1 monitor name
4ba1ee3bce5eef69acf5e24c61e0fe5482662a79|4ba1ee3|2026-02-07T04:54:23-05:00|Dicklesworthstone|docs/spec: tighten glossary + fix merge pseudocode types
72eb835e83063d8fe19c1288a8c4624438473b2e|72eb835|2026-02-07T11:07:04-05:00|Dicklesworthstone|spec: fix cross-process cleanup + lock table semantics
0b543b5b587d72a5531a37324ad31fab0157b6ed|0b543b5|2026-02-07T11:21:20-05:00|Dicklesworthstone|docs/spec: deepen asupersync integration (regions/cancel/supervision)
d7b38efedc6f77029ce412c1eea2d0197b8b8fc6|d7b38ef|2026-02-07T11:50:08-05:00|Dicklesworthstone|Spec V1.7: deep audit fixes for Section 5 (MVCC Formal Model)
322af1706478c8da09b09af4927e6a011041c5a6|322af17|2026-02-07T11:53:09-05:00|Dicklesworthstone|Spec V1.7a + README: deep audit fixes (MVCC model alignment, SSI/ordering)
1a672dd545885d61c2531bf2be178d0edb4a5065|1a672dd|2026-02-07T12:09:27-05:00|Dicklesworthstone|Spec V1.7b: deep audit fixes for Section 7 (Checksums and Integrity)
a19a3acb957598db6e11ece9ab199ae8f34eb88e|a19a3ac|2026-02-07T12:10:44-05:00|Dicklesworthstone|docs/spec: deepen asupersync integration + witness-plane rigor
d0fda0186411a7f75bd73771f484259c29d7921a|d0fda01|2026-02-07T12:11:01-05:00|Dicklesworthstone|docs/spec: minor wording tweak
b8344dba9b295b31b843807f80c6ec10e601459b|b8344db|2026-02-07T12:11:40-05:00|Dicklesworthstone|docs/spec: tighten crate boundaries + WAL notes
5e2344ce7b5640aaad2fb48bed85838f9c9ecfef|5e2344c|2026-02-07T12:12:14-05:00|Dicklesworthstone|docs/spec: add WAL checksum algorithm + refine repair tail bounds
713e6dc4f8b202870b16e154a597bcd735d5c05b|713e6dc|2026-02-07T12:12:40-05:00|Dicklesworthstone|docs/spec: bump document version
e2dc2232567e901ce8f7192303c9da013e4c8d7c|e2dc223|2026-02-07T12:13:08-05:00|Dicklesworthstone|docs/spec: clarify fragmentation byte + add SQLite varint encoding
3c5d5a177c8fbd78fd6f11f32a02e4c3ada9e172|3c5d5a1|2026-02-07T12:13:41-05:00|Dicklesworthstone|docs/spec: fix index local-payload math + clarify affinity coercion
714570a488c9e93f3349ba527e70e744570555e9|714570a|2026-02-07T12:14:00-05:00|Dicklesworthstone|docs/spec: expand pointer-map entry type semantics
893691fc58cca08e1fba3a25a5ddf520624d6860|893691f|2026-02-07T12:14:48-05:00|Dicklesworthstone|docs/spec: add SSI invariants + correct e-process example + fix index max_local
a9aff80df7c0d04f465db40b74165a2e75ae5e29|a9aff80|2026-02-07T12:15:31-05:00|Dicklesworthstone|docs/spec: tighten budget algebra wording + fix BOCPD recursion
80bc4494162ff420cdb48c5122324d9bdc8d328b|80bc449|2026-02-07T12:16:49-05:00|Dicklesworthstone|docs/spec: refine public API facade + type-erased function state factories
a5a85e64c6356176ad86795d69e1293bd76f2601|a5a85e6|2026-02-07T12:17:16-05:00|Dicklesworthstone|docs/spec: thread Cx into rollback + clarify recursive CTE UNION semantics
7c93dbb54e2d939f820d97a469bf204829ce97c8|7c93dbb|2026-02-07T12:20:46-05:00|Dicklesworthstone|Spec audit round 2: WAL checksum inversion, WAL-index hash, ARC claim
07236c61ff86a87f22bb1aa6fd26885eb527d268|07236c6|2026-02-07T12:23:21-05:00|Dicklesworthstone|docs/spec: fix WAL checksum endianness + clarify WindowsVfs + layering notes
d9146f771541d7e134f540e11016df82cc6e17b9|d9146f7|2026-02-07T12:28:33-05:00|Dicklesworthstone|spec: harden marker stream + compaction + RaptorQ overhead
30619b34ea187d682283f8cd137d8d30e306e6bd|30619b3|2026-02-07T12:28:52-05:00|Dicklesworthstone|docs/spec: clarify R*-tree geopoly wording
7e9cace601485722e7b31411ad74796c0685bd05|7e9cace|2026-02-07T12:29:17-05:00|Dicklesworthstone|docs/spec: refine Zipf conflict probability
ff937f3d678f88eb855051dbbd32e8e5046bea0f|ff937f3|2026-02-07T12:29:51-05:00|Dicklesworthstone|docs/spec: tighten MVCC + merge modeling notes
61ee3e03f4cd5e44b189da55bb70e91cdba63a29|61ee3e0|2026-02-07T12:30:34-05:00|Dicklesworthstone|docs/spec: harden ARC eviction failure path
a90a3794616e12b083f88276e3cb47a045f3ac10|a90a379|2026-02-07T12:32:18-05:00|Dicklesworthstone|Spec V1.7c: deep audit fixes for Section 6 (Buffer Pool: ARC Cache)
246102e6b4266fa15000580a3d016d76bcb1c801|246102e|2026-02-07T12:35:11-05:00|Dicklesworthstone|Spec audit round 3: fix operator precedence tables (§10.2 and §12.15)
5ea1b6fb02945e4bc147c37ae7d054d92fdd9045|5ea1b6f|2026-02-07T12:44:12-05:00|Dicklesworthstone|Spec audit round 4: SSI pseudocode, precedence, RETURNING, merge terminology
f1f25abe3b40ad0fb8704eaee310aee17de78d25|f1f25ab|2026-02-07T12:46:31-05:00|Dicklesworthstone|Spec: harden write-merge (no raw XOR on SQLite pages)
9725f136b2450c6411f5735a1575a068f2aacc0b|9725f13|2026-02-07T12:47:33-05:00|Dicklesworthstone|Spec: clarify cross-process ordering + file format edge cases
56742886aae65bdca3a34acda8d677b52a0c241d|5674288|2026-02-07T12:47:51-05:00|Dicklesworthstone|Spec: witness hot-plane epoch advancement safety
71a41750d478e8ecad031a2f490e84a4424a839e|71a4175|2026-02-07T12:48:33-05:00|Dicklesworthstone|Spec: publish commit_seq only after durable marker
9fa8f7b6082f164d4cb1026296a360cfbafe1f73|9fa8f7b|2026-02-07T12:48:54-05:00|Dicklesworthstone|Spec: make commit_seq allocation marker-tip-derived
86d63af874d7a3dc7d522d47bf5f004f12913adb|86d63af|2026-02-07T12:49:41-05:00|Dicklesworthstone|Spec: compatibility mode legacy writer exclusion + WAL-index bridge
23f575f7d4ee20399865e33abca1f93e60eda2d7|23f575f|2026-02-07T12:49:56-05:00|Dicklesworthstone|Spec: Acquire snapshot commit_seq; tighten V1 rebase scope
6228e273d3dce6ca67c97fd43afb9018d19c6f5f|6228e27|2026-02-07T12:53:57-05:00|Dicklesworthstone|spec: fix native commit_seq gaps + witness epoch race
2e3ea218a908f4a22791b4c8b30a0dbf746f867b|2e3ea21|2026-02-07T12:58:54-05:00|Dicklesworthstone|Spec audit round 5: SharedPageLockTable key-stability, marker encoding, legacy writer exclusion
d05de23ea89da924e86232c8da519b6b58b4a0d5|d05de23|2026-02-07T12:59:44-05:00|Dicklesworthstone|Spec audit round 5b: align §5.6.3.1 rebuild prose with tombstone removal + header notes
fa1830e4593854a492d78bec24da1db90351c2f0|fa1830e|2026-02-07T13:00:08-05:00|Dicklesworthstone|Spec audit round 5c: permeation map, fragment limit, cell payload refs
70436b5c2c04e42c0aaf4b776a8f779416abdeff|70436b5|2026-02-07T13:00:29-05:00|Dicklesworthstone|Spec audit: WAL index byte order note + header layout corrections
a4e773481bd417530fe83f33868ef6ce5656e933|a4e7734|2026-02-07T13:02:16-05:00|Dicklesworthstone|Spec: add VFS shm API + clarify commit marker record
09c095901ddb1e5db47f55ddf5c616b5d51bf74e|09c0959|2026-02-07T13:02:34-05:00|Dicklesworthstone|Spec: checkpoint writer trait + replication gate
40a2ac7739778b30cb11129a782d8746bd13e6ed|40a2ac7|2026-02-07T13:03:14-05:00|Dicklesworthstone|Spec: bump audit footer to v1.18
40c6c3d152cf7d86104ad9ca19fbb850d6fdf343|40c6c3d|2026-02-07T13:04:47-05:00|Dicklesworthstone|Spec: lock-table acquire returns BUSY on insert race
8512e62aed8835864a8800ed895c91a8773dc996|8512e62|2026-02-07T13:08:08-05:00|Dicklesworthstone|spec: move compat page-FEC to sidecar + tighten UDP bounds
e31897fd92088e5305735d080e224a23b7315a11|e31897f|2026-02-07T13:08:45-05:00|Dicklesworthstone|spec: clarify checkpoint chunk MTU rationale
b03db7bc0b8a2705fe6fda19f5f149452755284c|b03db7b|2026-02-07T13:10:18-05:00|Dicklesworthstone|Spec V1.7d: deep audit fixes for Section 12 (SQL Coverage)
dd190e4f7f24aa2a8b7bb1bbc7020aead6d014c0|dd190e4|2026-02-07T13:23:44-05:00|Dicklesworthstone|Spec audit round 5+: fix GF(256) worked example, WAL checksum naming, MMR, IBLT
a664265e3f5876177b7c1410dad7119e01e7f9e9|a664265|2026-02-07T13:30:10-05:00|Dicklesworthstone|Spec+VFS: SAFE write-merge proofs + policy controller
599cafb3f29c52dd2a44f27d5632032c54a34a25|599cafb|2026-02-07T13:30:47-05:00|Dicklesworthstone|Spec: clarify forward target + symbol auth + epoch helpers
e42a43de57ff5d4ee616cd2ec3b54a0db249a3e6|e42a43d|2026-02-07T13:31:08-05:00|Dicklesworthstone|Spec: symbol auth master key derivation + VdbeOp p5 note
f158b44a5bd96ef34b378b58f61399568424f6d4|f158b44|2026-02-07T13:31:30-05:00|Dicklesworthstone|Spec: symbol auth wording + planner cost note
3cf0f13571c101725f9ef34ce2476c90478ff07d|3cf0f13|2026-02-07T13:35:09-05:00|Dicklesworthstone|Spec V1.7e: deep audit fix for Section 3 (RaptorQ MTU/sub-blocking)
0cb22962ec87cb29a29a44acfc5ec14588aadb23|0cb2296|2026-02-07T13:40:27-05:00|Dicklesworthstone|Spec: WAL lock refs + row-value expr
1680d6931f5773673fae021b7cc646e3f3faab44|1680d69|2026-02-07T13:45:48-05:00|Dicklesworthstone|Spec V1.7f: deep audit fixes for Section 4 (Asupersync e-process math)
1e2aae9940969190c6b9bebe94c94749eee91626|1e2aae9|2026-02-07T13:50:03-05:00|Dicklesworthstone|Spec: add UpdateExpression to write-merge system (§5.10)
da22f479dc2f8d1e98294750b741b3cce168fd19|da22f47|2026-02-07T13:55:11-05:00|Dicklesworthstone|Spec: formal durability+policy hardening
c25f0d00238fc36f355f818f571abc3d4a1198df|c25f0d0|2026-02-07T13:56:03-05:00|Dicklesworthstone|Spec: UpdateExpression rebase index regen
02e48a41810bdb2ad471926d9728a9a9af12b155|02e48a4|2026-02-07T14:00:52-05:00|Dicklesworthstone|Spec: fix maxLocal example + add encryption plan gates
bcd893da081fd15b1614a05c4d8b593f55cf7011|bcd893d|2026-02-07T14:16:38-05:00|Dicklesworthstone|Spec V1.7g: Section 9 deep audit — BtreeCursorOps, shm_map safety, opt-level fix
6da51572d2b5b76eb9a37ffa99da76bfb850cd83|6da5157|2026-02-07T14:16:48-05:00|Dicklesworthstone|Spec: deep audit fixes for §5.6.2 + §7.11
22e75e65b831adda852df3a11628e793aaa9e7a9|22e75e6|2026-02-07T14:27:26-05:00|Dicklesworthstone|planning: close obsolete beads; align spec/docs
2f0970b9a5d8fc755269ba848169f5a1369ec6a6|2f0970b|2026-02-07T14:27:39-05:00|Dicklesworthstone|Spec V1.7h: Section 10 deep audit — lexer DQS, cost model, UPDATE trace
5cc32a6bc813ff59db231f29db5b95a13ea94704|5cc32a6|2026-02-07T14:28:53-05:00|Dicklesworthstone|spec: tighten asupersync net + scheduler lane requirements
dc92e549d05ac8dc0c23937d6e6dfa874729fdd4|dc92e54|2026-02-07T14:31:37-05:00|Dicklesworthstone|spec: fix MVCC version-chain delta encoding
2433562451b188c9233f6fd83a9ef7573ce48f97|2433562|2026-02-07T14:33:19-05:00|Dicklesworthstone|spec: add per-source validation for WAL-FEC recovery
82dfd4bf99283e5ab283073651787b3c7975561f|82dfd4b|2026-02-07T14:33:56-05:00|Dicklesworthstone|spec: clarify WAL-FEC repair semantics + WAL checksums
ab20d7fac6f83ac527475927aa53b204c11ed7c8|ab20d7f|2026-02-07T14:34:24-05:00|Dicklesworthstone|spec: add ARC p-update online-learning note
96f32f3174453e68960d849672cb4b7a8d33d1c7|96f32f3|2026-02-07T14:34:56-05:00|Dicklesworthstone|spec: lock-table rebuild busy-wait rule + ARC p-update research note
f37158f2468145272817fd65794d78be539be19b|f37158f|2026-02-07T14:35:20-05:00|Dicklesworthstone|spec: fix UpdateExpression rebase step numbering
19fa01f6d66c19892c634a02da44f7f536b29e43|19fa01f|2026-02-07T14:42:37-05:00|Dicklesworthstone|Spec V1.7i: Section 13 deep audit — strftime specifiers, aggregate ORDER BY
a3e7ae521e6a0dcb3cf9489ac5a67b0f62aad526|a3e7ae5|2026-02-07T14:45:48-05:00|Dicklesworthstone|Spec V1.7j: Section 14 deep audit — FTS5 NOT is binary-only
56a4e91425fa5cba9aecf08f786691ef03563750|56a4e91|2026-02-07T14:46:20-05:00|Dicklesworthstone|spec: define replication changeset_bytes encoding
d2a49862864dff9799e236d2cf81b51ed268f93f|d2a4986|2026-02-07T14:48:36-05:00|Dicklesworthstone|spec: tighten crash/interop guidance (TxnSlot cleaning, WAL marks, ARC, triggers)
859e81752809cd343b00ad6499c159d2f341cc46|859e817|2026-02-07T14:50:40-05:00|Dicklesworthstone|spec: fully reset TxnSlot state/mode during cleanup
be3d256b12679a32f2fb4e44eeb82e513607b284|be3d256|2026-02-07T15:03:41-05:00|Dicklesworthstone|spec: make .db-fec checkpoint-owned + add per-source validation
65ab2f709f724750878f2cb5d045649bf0c53e89|65ab2f7|2026-02-07T15:14:48-05:00|Dicklesworthstone|spec: add auto-tuning defaults and scaling knobs
63ee097eb68a72ac23effab3979978adafb5b411|63ee097|2026-02-07T15:15:18-05:00|Dicklesworthstone|spec: fix §18 probabilistic conflict model — 10x arithmetic error + missing W²
29f7ebe942a43891f2a55fd998d02c37411efc9f|29f7ebe|2026-02-07T15:27:04-05:00|Dicklesworthstone|spec: harden rebase + safe SHM + skew-aware conflicts
6b0c12fc40c5759f5d53028ba692e8aaff80fc92|6b0c12f|2026-02-07T15:30:14-05:00|Dicklesworthstone|spec: fix §16 Phase 7 join ordering — beam search, not exhaustive
b181b6d148e02862b195824020954abadae8de88|b181b6d|2026-02-07T15:31:48-05:00|Dicklesworthstone|spec: fix §8.3 planner join ordering — beam search, not exhaustive
d302b391af5c2932c9097dd85923a8535593e45e|d302b39|2026-02-07T15:44:17-05:00|Dicklesworthstone|mvcc/spec: witness hot-index sizing manifest
017745631c79f0c9061e4fdba8d0ce09ecc6c86d|0177456|2026-02-07T15:44:51-05:00|Dicklesworthstone|spec: clarify Zipf write-set skew section
5dae90d79aef7d70300fe53a17f9e40dba24b309|5dae90d|2026-02-07T15:45:46-05:00|Dicklesworthstone|spec: tighten Zipf s_hat guidance
ca60e008352585f2501ca3f81337849396b4d140|ca60e00|2026-02-07T15:47:59-05:00|Dicklesworthstone|spec: define .db-fec physical layout + crash-consistent update
30203fb1f91acfb45c6085432a66029896e26e66|30203fb|2026-02-07T15:50:22-05:00|Dicklesworthstone|spec: reserve TxnId sentinels + guard allocation
75ac25db5853747e3f56877c943d51ce8d649a5e|75ac25d|2026-02-07T16:07:05-05:00|Dicklesworthstone|spec: harden TxnId alloc + replication changeset id + ARC singleflight
ec9adc1a8f61663d224399711d165a7dd623b919|ec9adc1|2026-02-07T16:13:12-05:00|Dicklesworthstone|spec: fix TxnId monotonicity note + clarify P_eff
e80fdde018b3ce359f49271f082366bbad19f928|e80fdde|2026-02-07T16:14:32-05:00|Dicklesworthstone|spec: deterministic RaptorQ seed for ChangesetId
fa25db0b24e84470e8271309370e0f8093463ddd|fa25db0|2026-02-07T16:21:05-05:00|Dicklesworthstone|spec: adopt NGQP beam search for V1 join ordering
1d8bbfb40fa7a1fe90e710b593dfa2b3e9113c2d|1d8bbfb|2026-02-07T16:22:50-05:00|Dicklesworthstone|spec: add TxnId CAS abort path and correct beam search complexity
4432a3daa2f875bc2d3fe47caf783b3eb286ebfe|4432a3d|2026-02-07T16:25:52-05:00|Dicklesworthstone|spec: conformance mode matrix; bump asupersync
aa8e81601a80b6910a3791490d07c5691b517850|aa8e816|2026-02-07T16:28:25-05:00|Dicklesworthstone|spec: tighten serialized FCW + schema_epoch open + rebase read footprint
0a8d8676ac74f994535eceaa1c6c47cb17868038|0a8d867|2026-02-07T16:38:09-05:00|Dicklesworthstone|spec: fix TxnSlot cleanup crash-safety and reconcile lock/VFS semantics
3d568547fd6b8036481df0d73a2c60b5bf30d5a7|3d56854|2026-02-07T16:39:53-05:00|Dicklesworthstone|spec: fix Vfs trait formatting and cleanup_txn_id comment
4c07e10c56ee30db5d03453237ae6c29c31a7cf0|4c07e10|2026-02-07T16:41:55-05:00|Dicklesworthstone|spec: clarify TxnSlot cleanup_txn_id + fix Vfs trait formatting
df0313b00f2854929c376434c56129ef6e2740e0|df0313b|2026-02-07T16:42:11-05:00|Dicklesworthstone|spec: fix ARC/CAR comment indentation
97df1f07893def20701570db65418ff75ed45656|97df1f0|2026-02-07T16:42:40-05:00|Dicklesworthstone|spec: clarify zero-copy terminology
bbc4a3114572200d7a8a674eb3a4e430ae1d0b47|bbc4a31|2026-02-07T16:45:48-05:00|Dicklesworthstone|spec: define canonical AAD encoding for page encryption
4363f50065239e47d56f12250d933f5a1ab75a00|4363f50|2026-02-07T16:51:53-05:00|Dicklesworthstone|spec: add critical implementation controls checklist
d9021cffb65692624f3990ae2544a96ae0c07021|d9021cf|2026-02-07T16:52:38-05:00|Dicklesworthstone|spec: clarify rebase rowid reuse + DatabaseId encoding
29107df6b155bb20934ef369b934699191076b32|29107df|2026-02-07T17:00:26-05:00|Dicklesworthstone|spec: harden TxnSlot cleanup and epoch reset semantics
f708f338cb6e435db3822e2aa81b2785b51bf39b|f708f33|2026-02-07T17:01:38-05:00|Dicklesworthstone|spec: clarify pipelined durability and compatibility spill semantics
a71e1d95715c1190335e8738413382b31b6d167c|a71e1d9|2026-02-07T17:07:05-05:00|Dicklesworthstone|spec: harden ECS root update; snapshot slot tid; clarify ESCAPE parsing
120eee252b4caa7fe6389602bd2c8a316c6cee2a|120eee2|2026-02-07T17:08:11-05:00|Dicklesworthstone|spec: strengthen WAL-FEC per-source validation hash to xxh3_128
	975f65c78a5745424665a95f0c222287306c9dd5|975f65c|2026-02-07T17:08:59-05:00|Dicklesworthstone|spec: clarify GF(256) elimination note; bound delta reconstruction cost
	24b6f60e9e751b699cb232759d85a06c42792019|24b6f60|2026-02-07T17:15:05-05:00|Dicklesworthstone|spec: fix GC scheduling cross-reference
	80decf6b8ba71dd4331f559a08ee0fba3fbdf4bb|80decf6|2026-02-07T17:28:31-05:00|Dicklesworthstone|spec: clarify db-fec generation digest + ESI terminology
	7cc726325faa5cad71d2132480cbb68fb046563d|7cc7263|2026-02-07T18:11:25-05:00|Dicklesworthstone|spec: harden SHM snapshot seqlock + compat db-fec freshness
	9ad50ae2a2c7fce76a75d1200e22374eb729914d|9ad50ae|2026-02-07T18:15:58-05:00|Dicklesworthstone|spec: define SHM snapshot seqlock + coordinator IPC
	19106d19e531ea75918241b2858024c34a73f037|19106d1|2026-02-07T18:20:51-05:00|Dicklesworthstone|spec: harden MVCC TxnSlot protocol, write_page idempotency, and SHM layout
	7313951174e317f889851f696de264b546e4b54e|7313951|2026-02-07T18:21:25-05:00|Dicklesworthstone|spec: define wire payload schemas, RowId allocator state, and CommitRequest type
	d329df055a1a13459d0f507bc222b05525bb7522|d329df0|2026-02-07T18:28:22-05:00|Dicklesworthstone|spec: fix snapshot seqlock + shm invariants
	351c282e9a9a2ee118496651cef7a4b33cf309f2|351c282|2026-02-07T18:41:22-05:00|Dicklesworthstone|spec: fix TxnSlot acquire pseudocode + add spec viz wasm`;
      const COMMIT_STATS_RAW = String.raw`c08f1602d03b1833a4f91c8f77347f8f196bac9d|8628|0
f9d88aa96f50893f8531373d0734597ebae3c592|431|76
76eef31be20a6faedc62e7fecce88e78652ebdcf|242|116
9800b17df4a56c2dc065cf566c2810d4ed2e576c|537|74
79018f161649e6d7977bc74eb849a0e22eceb286|246|151
5ad34871f7242de61378843c6c1e8311e35d9fa3|262|45
7b2c677cf61adda977e71524b59d7ec234137962|425|36
bf0426417685504bb2b2f5acfc4de2c2f087ef8b|290|71
05cf07847753f444b9f74dfd0279ef96c3ff86b9|217|31
e8ddf469d8ab8ff8eefbae92b24453e06fcf4627|141|20
480c10086fb73630744364f5fb34966de2572dc1|60|48
0313678eff44b70cd4ea40cabc2f2222cac2ba93|169|73
b97b1abe4727a738197180c5639738c1da2f5311|79|170
643c89c1c941d1e47cb6a2574e01fd7556f622ec|37|59
0404e42c9dbdc677da9b8a5731d29290ef9f3b26|33|16
2a6353d2f77a050454d2a6fd4b3fd6c8363064e9|643|381
3253050f2835fb305bd115bd9f5939b72cd46503|404|86
06dfe9a709d61fc899e00ee33d54dc15d003bb48|318|424
63f6057e8705b7105837952bc8ea977ad6f34da6|14|14
2cff3a0287f1de30d2fd1185c376ac81913922c9|1|1
4ba1ee3bce5eef69acf5e24c61e0fe5482662a79|18|16
72eb835e83063d8fe19c1288a8c4624438473b2e|56|16
0b543b5b587d72a5531a37324ad31fab0157b6ed|472|64
d7b38efedc6f77029ce412c1eea2d0197b8b8fc6|78|39
322af1706478c8da09b09af4927e6a011041c5a6|21|1
1a672dd545885d61c2531bf2be178d0edb4a5065|449|51
a19a3acb957598db6e11ece9ab199ae8f34eb88e|47|21
d0fda0186411a7f75bd73771f484259c29d7921a|6|3
b8344dba9b295b31b843807f80c6ec10e601459b|6|2
5e2344ce7b5640aaad2fb48bed85838f9c9ecfef|81|11
713e6dc4f8b202870b16e154a597bcd735d5c05b|18|1
e2dc2232567e901ce8f7192303c9da013e4c8d7c|40|3
3c5d5a177c8fbd78fd6f11f32a02e4c3ada9e172|18|7
714570a488c9e93f3349ba527e70e744570555e9|16|8
893691fc58cca08e1fba3a25a5ddf520624d6860|26|14
a9aff80df7c0d04f465db40b74165a2e75ae5e29|14|10
80bc4494162ff420cdb48c5122324d9bdc8d328b|33|5
a5a85e64c6356176ad86795d69e1293bd76f2601|7|5
7c93dbb54e2d939f820d97a469bf204829ce97c8|89|34
07236c61ff86a87f22bb1aa6fd26885eb527d268|43|41
d9146f771541d7e134f540e11016df82cc6e17b9|264|207
30619b34ea187d682283f8cd137d8d30e306e6bd|16|8
7e9cace601485722e7b31411ad74796c0685bd05|17|3
ff937f3d678f88eb855051dbbd32e8e5046bea0f|29|6
61ee3e03f4cd5e44b189da55bb70e91cdba63a29|15|2
a90a3794616e12b083f88276e3cb47a045f3ac10|32|8
246102e6b4266fa15000580a3d016d76bcb1c801|336|117
5ea1b6fb02945e4bc147c37ae7d054d92fdd9045|90|26
f1f25abe3b40ad0fb8704eaee310aee17de78d25|96|14
9725f136b2450c6411f5735a1575a068f2aacc0b|66|48
56742886aae65bdca3a34acda8d677b52a0c241d|14|3
71a41750d478e8ecad031a2f490e84a4424a839e|5|1
9fa8f7b6082f164d4cb1026296a360cfbafe1f73|8|3
86d63af874d7a3dc7d522d47bf5f004f12913adb|99|2
23f575f7d4ee20399865e33abca1f93e60eda2d7|17|1
6228e273d3dce6ca67c97fd43afb9018d19c6f5f|81|5
2e3ea218a908f4a22791b4c8b30a0dbf746f867b|130|93
d05de23ea89da924e86232c8da519b6b58b4a0d5|15|8
fa1830e4593854a492d78bec24da1db90351c2f0|8|7
70436b5c2c04e42c0aaf4b776a8f779416abdeff|9|3
a4e773481bd417530fe83f33868ef6ce5656e933|98|11
09c095901ddb1e5db47f55ddf5c616b5d51bf74e|18|0
40a2ac7739778b30cb11129a782d8746bd13e6ed|1|1
40c6c3d152cf7d86104ad9ca19fbb850d6fdf343|3|2
8512e62aed8835864a8800ed895c91a8773dc996|57|27
e31897fd92088e5305735d080e224a23b7315a11|1|1
b03db7bc0b8a2705fe6fda19f5f149452755284c|18|8
dd190e4f7f24aa2a8b7bb1bbc7020aead6d014c0|478|55
a664265e3f5876177b7c1410dad7119e01e7f9e9|410|93
599cafb3f29c52dd2a44f27d5632032c54a34a25|70|12
e42a43de57ff5d4ee616cd2ec3b54a0db249a3e6|15|5
f158b44a5bd96ef34b378b58f61399568424f6d4|14|6
3cf0f13571c101725f9ef34ce2476c90478ff07d|22|17
0cb22962ec87cb29a29a44acfc5ec14588aadb23|80|16
1680d6931f5773673fae021b7cc646e3f3faab44|47|28
1e2aae9940969190c6b9bebe94c94749eee91626|228|38
da22f479dc2f8d1e98294750b741b3cce168fd19|373|88
c25f0d00238fc36f355f818f571abc3d4a1198df|27|7
02e48a41810bdb2ad471926d9728a9a9af12b155|11|4
bcd893da081fd15b1614a05c4d8b593f55cf7011|379|134
6da51572d2b5b76eb9a37ffa99da76bfb850cd83|4|4
22e75e65b831adda852df3a11628e793aaa9e7a9|214|60
2f0970b9a5d8fc755269ba848169f5a1369ec6a6|8|6
5cc32a6bc813ff59db231f29db5b95a13ea94704|56|1
dc92e549d05ac8dc0c23937d6e6dfa874729fdd4|17|15
2433562451b188c9233f6fd83a9ef7573ce48f97|24|5
82dfd4bf99283e5ab283073651787b3c7975561f|30|5
ab20d7fac6f83ac527475927aa53b204c11ed7c8|26|1
96f32f3174453e68960d849672cb4b7a8d33d1c7|18|6
f37158f2468145272817fd65794d78be539be19b|9|1
19fa01f6d66c19892c634a02da44f7f536b29e43|24|8
a3e7ae521e6a0dcb3cf9489ac5a67b0f62aad526|133|68
56a4e91425fa5cba9aecf08f786691ef03563750|26|0
d2a49862864dff9799e236d2cf81b51ed268f93f|79|28
859e81752809cd343b00ad6499c159d2f341cc46|6|1
be3d256b12679a32f2fb4e44eeb82e513607b284|176|9
65ab2f709f724750878f2cb5d045649bf0c53e89|267|56
63ee097eb68a72ac23effab3979978adafb5b411|10|0
29f7ebe942a43891f2a55fd998d02c37411efc9f|262|65
6b0c12fc40c5759f5d53028ba692e8aaff80fc92|3|1
b181b6d148e02862b195824020954abadae8de88|2|2
d302b391af5c2932c9097dd85923a8535593e45e|229|45
017745631c79f0c9061e4fdba8d0ce09ecc6c86d|12|2
5dae90d79aef7d70300fe53a17f9e40dba24b309|5|1
ca60e008352585f2501ca3f81337849396b4d140|51|0
30203fb1f91acfb45c6085432a66029896e26e66|6|2
75ac25db5853747e3f56877c943d51ce8d649a5e|116|51
ec9adc1a8f61663d224399711d165a7dd623b919|16|8
e80fdde018b3ce359f49271f082366bbad19f928|12|3
fa25db0b24e84470e8271309370e0f8093463ddd|78|34
1d8bbfb40fa7a1fe90e710b593dfa2b3e9113c2d|6|2
4432a3daa2f875bc2d3fe47caf783b3eb286ebfe|119|26
aa8e81601a80b6910a3791490d07c5691b517850|45|20
0a8d8676ac74f994535eceaa1c6c47cb17868038|261|135
3d568547fd6b8036481df0d73a2c60b5bf30d5a7|16|16
4c07e10c56ee30db5d03453237ae6c29c31a7cf0|78|57
df0313b00f2854929c376434c56129ef6e2740e0|5|5
97df1f07893def20701570db65418ff75ed45656|4|0
bbc4a3114572200d7a8a674eb3a4e430ae1d0b47|3|0
4363f50065239e47d56f12250d933f5a1ab75a00|44|2
d9021cffb65692624f3990ae2544a96ae0c07021|5|4
29107df6b155bb20934ef369b934699191076b32|109|166
f708f338cb6e435db3822e2aa81b2785b51bf39b|242|100
a71e1d95715c1190335e8738413382b31b6d167c|178|105
	120eee252b4caa7fe6389602bd2c8a316c6cee2a|6|6
	975f65c78a5745424665a95f0c222287306c9dd5|17|2
	24b6f60e9e751b699cb232759d85a06c42792019|3|3
	80decf6b8ba71dd4331f559a08ee0fba3fbdf4bb|15|10
	7cc726325faa5cad71d2132480cbb68fb046563d|781|148
	9ad50ae2a2c7fce76a75d1200e22374eb729914d|160|23
	19106d19e531ea75918241b2858024c34a73f037|87|21
	7313951174e317f889851f696de264b546e4b54e|183|20
	d329df055a1a13459d0f507bc222b05525bb7522|126|43
	351c282e9a9a2ee118496651cef7a4b33cf309f2|50|45`;

      // -----------------------------
      // Data: manual classification
      // -----------------------------

      const CLASS_EARLY = [
  {
    "commit": "c08f1602d03b1833a4f91c8f77347f8f196bac9d",
    "change_groups": [
      {
        "summary": "Introduced the comprehensive V1 specification as a new, authoritative single-source document covering architecture, MVCC, RaptorQ, file format, SQL coverage, and testing.",
        "categories": [
          6,
          4,
          7,
          8,
          9
        ],
        "primary_category": 6,
        "confidence": 0.62,
        "evidence": [
          "new file mode 100644",
          "+# COMPREHENSIVE SPECIFICATION FOR FRANKENSQLITE V1"
        ],
        "changed_headings": [
          "0. How to Read This Document",
          "1. Project Identity"
        ]
      }
    ]
  },
  {
    "commit": "f9d88aa96f50893f8531373d0734597ebae3c592",
    "change_groups": [
      {
        "summary": "Promoted SSI to V1 concurrent mode and expanded MVCC structures with SIREAD tracking, sharded lock tables, and intent logs for deterministic rebase and merge policy.",
        "categories": [
          1,
          4,
          7,
          8
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "+**Layer 2 (Ship in V1): MVCC concurrent mode with SSI (Serializable by Default).**",
          "+in_flight       : RoaringBitmap"
        ],
        "changed_headings": [
          "2.4 The Solution: Layered Isolation",
          "5. MVCC Formal Model",
          "5.10 Algebraic Write Merging and Intent Logs"
        ]
      },
      {
        "summary": "Added explicit crash model and formalized Compatibility vs Native operating modes with durable marker rules.",
        "categories": [
          4,
          6,
          7
        ],
        "primary_category": 4,
        "confidence": 0.64,
        "evidence": [
          "+### 7.9 Crash Model (Explicit Contract):",
          "+### 7.10 Two Operating Modes"
        ],
        "changed_headings": [
          "7.9 Crash Model (Explicit Contract)",
          "7.10 Two Operating Modes"
        ]
      },
      {
        "summary": "Threaded `Cx` through storage and pager traits to make I/O and blocking operations cancelable and deadline-aware.",
        "categories": [
          7,
          3
        ],
        "primary_category": 7,
        "confidence": 0.58,
        "evidence": [
          "+fn open(&self, cx: &Cx, path: Option<&Path>, flags: VfsOpenFlags)",
          "+fn commit(&self, cx: &Cx, txn: Transaction) -> Result<()>"
        ],
        "changed_headings": [
          "9. Trait Hierarchy",
          "9.1 Storage Traits"
        ]
      }
    ]
  },
  {
    "commit": "76eef31be20a6faedc62e7fecce88e78652ebdcf",
    "change_groups": [
      {
        "summary": "Reframed RaptorQ decoding guarantees to avoid hard-coded probabilities and require recoverable failure handling with monitoring.",
        "categories": [
          8,
          1,
          9
        ],
        "primary_category": 8,
        "confidence": 0.67,
        "evidence": [
          "+**Decoding Failure Behavior (Normative):**",
          "+Correctness MUST NOT depend on decoding succeeding with exactly `K` symbols."
        ],
        "changed_headings": [
          "3.2 How RaptorQ Works (Essential Understanding)"
        ]
      },
      {
        "summary": "Corrected SQLite legacy behaviors and details (WAL reader limit and integer overflow semantics).",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "+caps the number of simultaneously active reader locks via `WAL_NREADER`",
          "+promote to REAL (floating point) rather than wrapping."
        ],
        "changed_headings": [
          "2.1 The Problem"
        ]
      },
      {
        "summary": "Aligned asupersync module paths and API examples; clarified feature-flag placement and harness notes.",
        "categories": [
          3,
          5,
          9
        ],
        "primary_category": 3,
        "confidence": 0.58,
        "evidence": [
          "+src/raptorq/gf256.rs        -- GF(256) arithmetic",
          "+Feature flags MUST live on a real package manifest"
        ],
        "changed_headings": [
          "3.3 Asupersync's RaptorQ Implementation",
          "8.5 Feature Flags"
        ]
      }
    ]
  },
  {
    "commit": "9800b17df4a56c2dc065cf566c2810d4ed2e576c",
    "change_groups": [
      {
        "summary": "Added non-negotiable scope doctrine, normative language rules, and a formal glossary to eliminate V1-scope escape hatches.",
        "categories": [
          6,
          5,
          9
        ],
        "primary_category": 6,
        "confidence": 0.63,
        "evidence": [
          "+### 0.1 Non-Negotiable Scope Doctrine",
          "+### 0.2 Normative Language",
          "+### 0.3 Glossary"
        ],
        "changed_headings": [
          "0.1 Non-Negotiable Scope Doctrine",
          "0.2 Normative Language",
          "0.3 Glossary"
        ]
      },
      {
        "summary": "Specified ECS substrate details and made erasure-coded page storage fully in-scope.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+### 3.5 ECS: The Erasure-Coded Stream Substrate",
          "+#### 3.5.1 ObjectId: Content-Addressed Identity"
        ],
        "changed_headings": [
          "3.5 ECS: The Erasure-Coded Stream Substrate"
        ]
      },
      {
        "summary": "Introduced multi-process MVCC shared-memory coordination and cross-process lock table protocol.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+#### 5.6.1 Shared-Memory Coordination Region",
          "+#### 5.6.3 Cross-Process Page Lock Table"
        ],
        "changed_headings": [
          "5.6.1 Shared-Memory Coordination Region",
          "5.6.3 Cross-Process Page Lock Table"
        ]
      }
    ]
  },
  {
    "commit": "79018f161649e6d7977bc74eb849a0e22eceb286",
    "change_groups": [
      {
        "summary": "Corrected WAL compatibility by moving RaptorQ repair data to a `.wal-fec` sidecar; standard WAL frames remain byte-for-byte SQLite-compatible.",
        "categories": [
          2,
          7
        ],
        "primary_category": 2,
        "confidence": 0.7,
        "evidence": [
          "+Standard SQLite WAL frames are exactly 24 bytes (header) + page_size (data).",
          "+Instead, we use a **sidecar file** (`.wal-fec`) to store repair symbols."
        ],
        "changed_headings": [
          "Concrete WAL Commit Frame Layout (Compatibility Mode)"
        ]
      }
    ]
  },
  {
    "commit": "5ad34871f7242de61378843c6c1e8311e35d9fa3",
    "change_groups": [
      {
        "summary": "Added RaptorQ Everywhere doctrine, expanded glossary/TOC, and tightened mechanical sympathy constraints.",
        "categories": [
          6,
          4,
          9
        ],
        "primary_category": 6,
        "confidence": 0.62,
        "evidence": [
          "+### 0.4 What \"RaptorQ Everywhere\" Means (No Weasel Words)",
          "+| **CommitSeq** | Monotonically increasing `u64` commit sequence number"
        ],
        "changed_headings": [
          "0.4 What \"RaptorQ Everywhere\" Means"
        ]
      },
      {
        "summary": "Overhauled WAL-FEC sidecar model and ECS/replication architecture to unify repair symbols and replication into ECS objects.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.64,
        "evidence": [
          "+.wal contains ONLY standard SQLite WAL frames (source symbols);",
          "+### 3.4.7 Replication Architecture"
        ],
        "changed_headings": [
          "3.4.7 Replication Architecture"
        ]
      }
    ]
  },
  {
    "commit": "7b2c677cf61adda977e71524b59d7ec234137962",
    "change_groups": [
      {
        "summary": "Applied alien-artifact discipline: decision-theoretic SSI policy, VOI-driven granularity investment, BOCPD monitoring, and formal durability theorems.",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.66,
        "evidence": [
          "+**Decision-Theoretic SSI Abort Policy (Alien-Artifact Discipline).**",
          "+### 4.8 Bayesian Online Change-Point Detection (BOCPD)"
        ],
        "changed_headings": [
          "4.8 Bayesian Online Change-Point Detection (BOCPD)",
          "5.7 SSI"
        ]
      },
      {
        "summary": "Added engineering guardrails: memory accounting, hash-tier strategy, and native-mode commit/recovery protocol details.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.56,
        "evidence": [
          "+### 6.9 Memory Accounting",
          "+### 7.11 Native Mode Commit Protocol"
        ],
        "changed_headings": [
          "6.9 Memory Accounting",
          "7.11 Native Mode Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "bf0426417685504bb2b2f5acfc4de2c2f087ef8b",
    "change_groups": [
      {
        "summary": "Replaced ephemeral SIREAD tables with a RaptorQ-native SSI witness plane (hot+cold planes, durable ECS evidence, cross-process support).",
        "categories": [
          4,
          7,
          8
        ],
        "primary_category": 4,
        "confidence": 0.68,
        "evidence": [
          "+| **WitnessKey** | The canonical key-space for SSI read/write evidence",
          "+SSIWitnessPlane := (see Section 5.6.4)"
        ],
        "changed_headings": [
          "5.6.4 SSI Witness Plane"
        ]
      }
    ]
  },
  {
    "commit": "05cf07847753f444b9f74dfd0279ef96c3ff86b9",
    "change_groups": [
      {
        "summary": "Replaced magic-number defaults with formal derivations and cost models for tunable parameters (delta threshold, BOCPD priors, GC scheduling, etc.).",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.7,
        "evidence": [
          "+// COST MODEL (Extreme Optimization Discipline):",
          "+P(r_t | x_{1:t}) proportional to sum_{r_{t-1}} ..."
        ],
        "changed_headings": [
          "3.4.4 Delta Threshold",
          "4.8 BOCPD",
          "5.6.5 GC Coordination"
        ]
      }
    ]
  },
  {
    "commit": "e8ddf469d8ab8ff8eefbae92b24453e06fcf4627",
    "change_groups": [
      {
        "summary": "Introduced performance-oriented data structures (VersionArena, AppendOnlyVec, CAR cache) and per-invariant monitoring calibration.",
        "categories": [
          7,
          8
        ],
        "primary_category": 7,
        "confidence": 0.63,
        "evidence": [
          "+VersionArena",
          "+CommitLog := AppendOnlyVec<CommitRecord>",
          "+CAR (Clock with Adaptive Replacement)"
        ],
        "changed_headings": [
          "5.5 MVCC Data Structures",
          "6. ARC Cache",
          "4.3 E-process Calibration"
        ]
      }
    ]
  },
  {
    "commit": "480c10086fb73630744364f5fb34966de2572dc1",
    "change_groups": [
      {
        "summary": "Updated SSI transaction struct to use TxnToken edges and added eager abort semantics plus witness-plane-aware commit-time detection pseudocode.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.62,
        "evidence": [
          "+marked_for_abort : bool",
          "+**Commit-time detection + proof emission pseudocode (witness plane):**"
        ],
        "changed_headings": [
          "5.7 SSI Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "0313678eff44b70cd4ea40cabc2f2222cac2ba93",
    "change_groups": [
      {
        "summary": "Clarified SSI detection algorithm as a two-pass pivot/completion check with eager abort marking.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.6,
        "evidence": [
          "+The on_commit(T) pseudocode specifies the two-pass check:",
          "+on_commit(T):"
        ],
        "changed_headings": [
          "5.7 SSI Algorithm"
        ]
      },
      {
        "summary": "Adjusted object identity and Cx capability descriptions (ObjectId truncation and richer capability mechanics).",
        "categories": [
          4,
          3,
          9
        ],
        "primary_category": 4,
        "confidence": 0.52,
        "evidence": [
          "+| **ObjectId** | Content-addressed identifier: 128-bit `Trunc128(BLAKE3(...))`",
          "+**Cooperative cancellation + progress checkpoints**"
        ],
        "changed_headings": [
          "0.3 Glossary",
          "4.2 Asupersync Integration"
        ]
      }
    ]
  },
  {
    "commit": "b97b1abe4727a738197180c5639738c1da2f5311",
    "change_groups": [
      {
        "summary": "Removed merge artifacts by restoring canonical ObjectId size and concise Cx glossary/API examples.",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.66,
        "evidence": [
          "-| **ObjectId** | Content-addressed identifier: 128-bit `Trunc128(...)",
          "+| **ObjectId** | Content-addressed identifier: `BLAKE3(canonical_encoding(object))`, 32 bytes."
        ],
        "changed_headings": [
          "0.3 Glossary"
        ]
      }
    ]
  },
  {
    "commit": "643c89c1c941d1e47cb6a2574e01fd7556f622ec",
    "change_groups": [
      {
        "summary": "Restored canonical SSI detection algorithm and in-process edge representation after merge artifacts.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.64,
        "evidence": [
          "+has_incoming_rw : bool",
          "+**Detection algorithm pseudocode:**"
        ],
        "changed_headings": [
          "5.7 SSI Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "0404e42c9dbdc677da9b8a5731d29290ef9f3b26",
    "change_groups": [
      {
        "summary": "Integrated SSI witness-plane evidence into native-mode commit protocol, adding CommitProof and new ordering constraints.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.63,
        "evidence": [
          "+`proof_object_id`",
          "+**Critical ordering:** Marker publication MUST happen AFTER capsule durability and AFTER `CommitProof` durability is satisfied."
        ],
        "changed_headings": [
          "7.11 Native Mode Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "2a6353d2f77a050454d2a6fd4b3fd6c8363064e9",
    "change_groups": [
      {
        "summary": "Aligned asupersync integration terminology, witness-plane naming, and ObjectId truncation details.",
        "categories": [
          3,
          9,
          4
        ],
        "primary_category": 3,
        "confidence": 0.6,
        "evidence": [
          "+| **ObjectId** | Content-addressed identifier: `Trunc128(BLAKE3(\"fsqlite:ecs:v1\" || canonical_object_header || payload_hash))`",
          "+| **SIREAD witness (legacy term)** | ... represented by `ReadWitness` objects"
        ],
        "changed_headings": [
          "0.3 Glossary"
        ]
      }
    ]
  },
  {
    "commit": "3253050f2835fb305bd115bd9f5939b72cd46503",
    "change_groups": [
      {
        "summary": "Added systematic symbol fast-path flags and tiered storage semantics for ECS objects.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+flags       : u8,           -- bitflags (see below)",
          "+**Systematic read fast path (hybrid decode):**"
        ],
        "changed_headings": [
          "3.5.2 Symbol Record Envelope",
          "3.5.11 Tiered Storage (\"Bottomless\", Native Mode)"
        ]
      },
      {
        "summary": "Introduced SchemaEpoch into MVCC snapshot to forbid intent replay across schema changes.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.56,
        "evidence": [
          "+SchemaEpoch := u64",
          "+schema_epoch    : SchemaEpoch"
        ],
        "changed_headings": [
          "5.1 Core Types"
        ]
      }
    ]
  },
  {
    "commit": "06dfe9a709d61fc899e00ee33d54dc15d003bb48",
    "change_groups": [
      {
        "summary": "Updated core MVCC types to CommitSeq-based snapshots and formalized SSI witness plane in place of SIREAD tables.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.62,
        "evidence": [
          "+CommitSeq   := u64",
          "+SSIWitnessPlane := (see Section 5.6.4)"
        ],
        "changed_headings": [
          "5.1 Core Types"
        ]
      }
    ]
  },
  {
    "commit": "63f6057e8705b7105837952bc8ea977ad6f34da6",
    "change_groups": [
      {
        "summary": "Changed MVCC ARC cache keys from TxnId to CommitSeq and updated invariants accordingly.",
        "categories": [
          7,
          1
        ],
        "primary_category": 7,
        "confidence": 0.62,
        "evidence": [
          "-Standard ARC keys on page number. Our variant keys on `(PageNumber, TxnId)`",
          "+Standard ARC keys on page number. Our variant keys on `(PageNumber, CommitSeq)`"
        ],
        "changed_headings": [
          "6.2 MVCC-Aware ARC Data Structures"
        ]
      }
    ]
  },
  {
    "commit": "2cff3a0287f1de30d2fd1185c376ac81913922c9",
    "change_groups": [
      {
        "summary": "Clarified the INV-1 monitor label to include CommitSeq monotonicity.",
        "categories": [
          9,
          5
        ],
        "primary_category": 9,
        "confidence": 0.8,
        "evidence": [
          "+EProcess::new(\"INV-1: TxnId/CommitSeq Monotonicity\", EProcessConfig {"
        ],
        "changed_headings": [
          "4.3 E-process Monitoring"
        ]
      }
    ]
  },
  {
    "commit": "4ba1ee3bce5eef69acf5e24c61e0fe5482662a79",
    "change_groups": [
      {
        "summary": "Tightened glossary entries and fixed algebraic merge pseudocode types plus MVCC module descriptions.",
        "categories": [
          9,
          5,
          1
        ],
        "primary_category": 9,
        "confidence": 0.62,
        "evidence": [
          "+| **CommitMarker** | The durable \"this commit exists\" record in Native mode: `(commit_seq, commit_time_unix_ns, capsule_object_id, proof_object_id, prev_marker, integrity_hash)`.",
          "+page_T2_committed: &PageData"
        ],
        "changed_headings": [
          "0.3 Glossary",
          "5.10 Algebraic Write Merge"
        ]
      }
    ]
  },
  {
    "commit": "72eb835e83063d8fe19c1288a8c4624438473b2e",
    "change_groups": [
      {
        "summary": "Corrected cross-process TxnSlot cleanup to defend against PID reuse and formalized lock-table tombstone semantics.",
        "categories": [
          7,
          1
        ],
        "primary_category": 7,
        "confidence": 0.65,
        "evidence": [
          "+pid_birth       : AtomicU64",
          "+TOMBSTONE := 0xFFFF_FFFF is reserved."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "5.6.3 Cross-Process Page Lock Table"
        ]
      }
    ]
  },
  {
    "commit": "0b543b5b587d72a5531a37324ad31fab0157b6ed",
    "change_groups": [
      {
        "summary": "Expanded asupersync integration glossary with Budget/Outcome/Region semantics and structured concurrency behavior.",
        "categories": [
          3,
          6
        ],
        "primary_category": 3,
        "confidence": 0.6,
        "evidence": [
          "+| **Budget** | Asupersync resource budget (product semiring) carried by `Cx`",
          "+| **Region** | Asupersync structured concurrency scope"
        ],
        "changed_headings": [
          "0.3 Glossary"
        ]
      },
      {
        "summary": "Corrected RaptorQ failure probability claims and clarified rules of thumb using RFC 6330 Annex B data.",
        "categories": [
          1,
          8
        ],
        "primary_category": 1,
        "confidence": 0.6,
        "evidence": [
          "+**Caution on failure probability claims:**",
          "+Decoding with **exactly K** received symbols: ~99% success (P_fail < 0.01)."
        ],
        "changed_headings": [
          "3.1 RaptorQ Foundation"
        ]
      }
    ]
  },
  {
    "commit": "d7b38efedc6f77029ce412c1eea2d0197b8b8fc6",
    "change_groups": [
      {
        "summary": "Deep audit fixes to MVCC formal model: CommitLog definition, SSI inequality correction, padding alignment, and cost model adjustments.",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.66,
        "evidence": [
          "+CommitLog := AppendOnlyVec<CommitRecord>",
          "+_padding        : [u8; 64]"
        ],
        "changed_headings": [
          "5.1 Core Types",
          "5.6 Shared Memory"
        ]
      }
    ]
  },
  {
    "commit": "322af1706478c8da09b09af4927e6a011041c5a6",
    "change_groups": [
      {
        "summary": "Added normative memory-ordering rules for CommitSeq visibility and clarified SSI pivot abort overapproximation.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.64,
        "evidence": [
          "+MUST be incremented with `Release` ordering AFTER all version chain updates",
          "+**Note (deliberate overapproximation):**"
        ],
        "changed_headings": [
          "5.4 Visibility",
          "5.7 SSI Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "1a672dd545885d61c2531bf2be178d0edb4a5065",
    "change_groups": [
      {
        "summary": "Corrected checksum/format details: WAL magic endianness, integrity check scoping, and symbol overhead interpretation.",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.62,
        "evidence": [
          "+0x377F0682 (bit 0 = 0) = little-endian word order",
          "+loss_fraction_max approx max(0, (R - slack) / (K_source + R))"
        ],
        "changed_headings": [
          "11. Checksums and Integrity"
        ]
      },
      {
        "summary": "Added family-wise error control for multiple e-process monitors using e-value aggregation.",
        "categories": [
          8
        ],
        "primary_category": 8,
        "confidence": 0.56,
        "evidence": [
          "+E_global(t) := prod_i E_i(t)^{w_i}",
          "+sum_i alpha_i <= alpha_total"
        ],
        "changed_headings": [
          "4.3 E-process Monitoring"
        ]
      }
    ]
  },
  {
    "commit": "a19a3acb957598db6e11ece9ab199ae8f34eb88e",
    "change_groups": [
      {
        "summary": "Fixed crate layering to avoid dependency cycles and clarified mvcc/wal relationships.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+fsqlite-mvcc moved from Layer 6 to Layer 3.",
          "+Checkpoint now receives `&dyn CheckpointPageWriter` at runtime"
        ],
        "changed_headings": [
          "8. Architecture: Crate Map and Dependencies"
        ]
      },
      {
        "summary": "Corrected SQLite expression precedence and VDBE p5 flag semantics.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.58,
        "evidence": [
          "+**IMPORTANT:** `NOT` is NOT at the same precedence as unary `~`/`+`/`-`.",
          "+upper 8 bits MUST be zero."
        ],
        "changed_headings": [
          "12. SQL Coverage",
          "VDBE Opcode Layout"
        ]
      }
    ]
  },
  {
    "commit": "d0fda0186411a7f75bd73771f484259c29d7921a",
    "change_groups": [
      {
        "summary": "Minor wording adjustments clarifying wal/pager dependency and header naming.",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.72,
        "evidence": [
          "+Does NOT depend on `fsqlite-pager`",
          "+| `sqliteInt.h` | Main internal header"
        ],
        "changed_headings": [
          "Crate Descriptions",
          "C SQLite Reference Extraction"
        ]
      }
    ]
  },
  {
    "commit": "b8344dba9b295b31b843807f80c6ec10e601459b",
    "change_groups": [
      {
        "summary": "Clarified crate boundaries and added WAL header notes for SQLite format.",
        "categories": [
          4,
          2
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+does not depend on `fsqlite-wal`.",
          "+Format version: 3007000 (constant for all WAL1 databases;"
        ],
        "changed_headings": [
          "Crate Descriptions",
          "WAL Header"
        ]
      }
    ]
  },
  {
    "commit": "5e2344ce7b5640aaad2fb48bed85838f9c9ecfef",
    "change_groups": [
      {
        "summary": "Specified the exact SQLite WAL checksum algorithm and clarified wal-index layout details.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.64,
        "evidence": [
          "+fn wal_checksum(data: &[u8], mut s0: u32, mut s1: u32, native: bool) -> (u32, u32)",
          "+WalIndexHdr (first copy):"
        ],
        "changed_headings": [
          "11.9.1 WAL Checksum Algorithm",
          "11.10 WAL Index (wal-index / SHM)"
        ]
      },
      {
        "summary": "Refined repair tail bounds with concrete orders of magnitude for small K.",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.54,
        "evidence": [
          "+K=4, R=1 (n=5): P(loss) approx C(5,2) p^2 approx 1e-7"
        ],
        "changed_headings": [
          "Durability Bound"
        ]
      }
    ]
  },
  {
    "commit": "713e6dc4f8b202870b16e154a597bcd735d5c05b",
    "change_groups": [
      {
        "summary": "Added explicit SQLite page header field layout description.",
        "categories": [
          2,
          6
        ],
        "primary_category": 2,
        "confidence": 0.62,
        "evidence": [
          "+**Page header field layout:**",
          "+Offset  Size  Field"
        ],
        "changed_headings": [
          "B-tree Page Header"
        ]
      },
      {
        "summary": "Updated document version metadata.",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.6,
        "evidence": [
          "-*Document version: 1.8",
          "+*Document version: 1.9"
        ],
        "changed_headings": []
      }
    ]
  },
  {
    "commit": "e2dc2232567e901ce8f7192303c9da013e4c8d7c",
    "change_groups": [
      {
        "summary": "Clarified fragmentation byte meaning and added explicit SQLite varint encoding spec.",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.65,
        "evidence": [
          "+### 11.2.1 Varint Encoding",
          "+minimum freeblock size is 4 bytes, so gaps of 1-3 bytes cannot be tracked"
        ],
        "changed_headings": [
          "11.2.1 Varint Encoding"
        ]
      }
    ]
  },
  {
    "commit": "3c5d5a177c8fbd78fd6f11f32a02e4c3ada9e172",
    "change_groups": [
      {
        "summary": "Fixed index local-payload math and clarified SQLite comparison affinity coercion rules.",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.64,
        "evidence": [
          "+index max_local = 1001.",
          "+**Comparison affinity rules** (applied before comparison; determines which operand gets type coercion)"
        ],
        "changed_headings": [
          "11.3 Cell Formats",
          "12. SQL Coverage"
        ]
      }
    ]
  },
  {
    "commit": "714570a488c9e93f3349ba527e70e744570555e9",
    "change_groups": [
      {
        "summary": "Documented SQLite pointer-map entry type semantics with explicit codes.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "+1 = PTRMAP_ROOTPAGE",
          "+5 = PTRMAP_BTREE"
        ],
        "changed_headings": [
          "Pointer Map"
        ]
      },
      {
        "summary": "Swapped raw pread usage for safe `FileExt::read_exact_at` in page read example.",
        "categories": [
          7,
          5
        ],
        "primary_category": 7,
        "confidence": 0.56,
        "evidence": [
          "+FileExt::read_exact_at is safe Rust; no `unsafe` needed.",
          "+async fn read_page(cx: &Cx, pool: &PageBufPool, file: &Arc<File>, offset: u64)"
        ],
        "changed_headings": [
          "VFS / Pager Example"
        ]
      }
    ]
  },
  {
    "commit": "893691fc58cca08e1fba3a25a5ddf520624d6860",
    "change_groups": [
      {
        "summary": "Added SSI-related invariants and clarified e-process usage versus hard invariants.",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.6,
        "evidence": [
          "+**INV-5 (Snapshot Stability)**",
          "+**Recommendation:** Use `debug_assert!` for INV-1 through INV-7"
        ],
        "changed_headings": [
          "4.3 E-process Monitoring"
        ]
      },
      {
        "summary": "Corrected index max_local formula for 4096-byte pages.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.58,
        "evidence": [
          "+index max_local = 1002.",
          "+`4084 * 64 / 255 - 23` = `1025 - 23` = 1002"
        ],
        "changed_headings": [
          "11.3 Cell Formats"
        ]
      }
    ]
  },
  {
    "commit": "a9aff80df7c0d04f465db40b74165a2e75ae5e29",
    "change_groups": [
      {
        "summary": "Corrected budget algebra terminology and fixed BOCPD recursion by marginalizing over prior run length.",
        "categories": [
          1,
          8
        ],
        "primary_category": 1,
        "confidence": 0.64,
        "evidence": [
          "+product meet-semilattice",
          "+P(r_t | x_{1:t}) proportional to sum_{r_{t-1}} ..."
        ],
        "changed_headings": [
          "0.3 Glossary",
          "4.8 BOCPD"
        ]
      },
      {
        "summary": "Threaded `Cx` through VfsFile methods to make file operations cancelable/deadline-aware.",
        "categories": [
          3,
          7
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+fn read(&mut self, cx: &Cx, buf: &mut [u8], offset: u64) -> Result<usize>;",
          "+fn sync(&mut self, cx: &Cx, flags: SyncFlags) -> Result<()>;"
        ],
        "changed_headings": [
          "9.1 Storage Traits"
        ]
      }
    ]
  },
  {
    "commit": "80bc4494162ff420cdb48c5122324d9bdc8d328b",
    "change_groups": [
      {
        "summary": "Refined public API facade with `Database` wrapper and replaced Default-based function state with `initial_state()` factories for type erasure.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+pub struct Database(Connection);",
          "+fn initial_state(&self) -> Self::State;"
        ],
        "changed_headings": [
          "Public API",
          "Scalar/Aggregate/Window Functions"
        ]
      }
    ]
  },
  {
    "commit": "a5a85e64c6356176ad86795d69e1293bd76f2601",
    "change_groups": [
      {
        "summary": "Added `Cx` parameter to rollback for cancelation-aware abort path.",
        "categories": [
          3,
          7
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+fn rollback(&self, cx: &Cx, txn: Transaction);"
        ],
        "changed_headings": [
          "MvccPager Trait"
        ]
      },
      {
        "summary": "Clarified recursive CTE semantics for UNION vs UNION ALL in SQLite.",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.58,
        "evidence": [
          "+Recursive CTEs use `UNION ALL` (keeps duplicates) or `UNION` (discards duplicates, providing implicit cycle detection)"
        ],
        "changed_headings": [
          "Recursive CTEs"
        ]
      }
    ]
  }
];
      const CLASS_MIDDLE = [
  {
    "commit": "7c93dbb54e2d939f820d97a469bf204829ce97c8",
    "change_groups": [
      {
        "summary": "Fix WAL checksum endianness semantics and clarify WAL header magic meaning, correct WAL-index hash and lock region layout, and add rollback journal format details",
        "categories": [
          1,
          2,
          4,
          9
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "WAL checksum parameter semantics corrected; bigEndCksum handling clarified",
          "WAL-index hash function corrected to multiplicative hash; lock region layout fixed",
          "Rollback journal format and checksum described"
        ],
        "changed_headings": [
          "7.1 WAL Checksum Algorithm",
          "11.9.1 WAL Checksum Algorithm",
          "11.10 WAL Index (wal-index / SHM)",
          "11.14 Rollback Journal Format"
        ]
      },
      {
        "summary": "Correct ARC competitive ratio claim",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.58,
        "evidence": [
          "ARC claim changed from competitive ratio 2 to containment/self-tuning wording"
        ],
        "changed_headings": [
          "6. Buffer Pool: ARC Cache"
        ]
      }
    ]
  },
  {
    "commit": "07236c61ff86a87f22bb1aa6fd26885eb527d268",
    "change_groups": [
      {
        "summary": "Revert WAL checksum endianness guidance to match nativeCksum derivation; update examples accordingly",
        "categories": [
          1,
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "big_end_cksum now feeds nativeCksum via target endianness; swap logic changed",
          "endianness table updated to per-reader nativeCksum outcomes"
        ],
        "changed_headings": [
          "7.1 WAL Checksum Algorithm",
          "11.9.1 WAL Checksum Algorithm"
        ]
      },
      {
        "summary": "Clarify Windows VFS inclusion and adjust layering/ARC placement notes",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.63,
        "evidence": [
          "WindowsVfs noted as in-scope; VFS locking/SHM mechanisms clarified",
          "ARC cache and MvccPager trait placement moved to pager layer"
        ],
        "changed_headings": [
          "15. VFS",
          "8. Implementation Plan"
        ]
      },
      {
        "summary": "Adjust B-tree depth capacity note",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.45,
        "evidence": [
          "B-tree depth capacity explanation rewritten"
        ],
        "changed_headings": [
          "8. Implementation Plan"
        ]
      }
    ]
  },
  {
    "commit": "d9146f771541d7e134f540e11016df82cc6e17b9",
    "change_groups": [
      {
        "summary": "Reframe GF(256) byte algebra as encoding-only; forbid raw XOR merges for structured pages and introduce SAFE/LAB_UNSAFE write-merge policy",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.74,
        "evidence": [
          "Byte-disjoint XOR merge prohibited for structured SQLite pages; SAFE merge ladder required",
          "PRAGMA fsqlite.write_merge introduced with SAFE/LAB_UNSAFE"
        ],
        "changed_headings": [
          "3.4.5 Algebraic Write Merging Over GF(256)",
          "5.10 Commit-Time Merge Policy"
        ]
      },
      {
        "summary": "Specify commit marker stream format with fixed-size records, O(1) seek, and divergence checks",
        "categories": [
          4,
          7,
          9
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "New marker segment header and record layout; fixed-size records",
          "O(1) seek and binary search by time described"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream Format (Random-Access, Auditable)"
        ]
      },
      {
        "summary": "Harden ECS compaction publication ordering and ARC eviction edge case; add RaptorQ overhead slack + adaptive tuning note",
        "categories": [
          4,
          1,
          8,
          9
        ],
        "primary_category": 4,
        "confidence": 0.67,
        "evidence": [
          "Compaction publish ordering now two-phase with durability before retiring old segments",
          "ARC T1 eviction path clarified to avoid B1 invariant violation",
          "RaptorQ overhead slack and adaptive tuning (e-process) added"
        ],
        "changed_headings": [
          "3.4.6 Erasure-Coded Page Storage",
          "3.5.4.1 Commit Marker Stream Format (Random-Access, Auditable)",
          "7.11 Publish Protocol",
          "7.9 Compaction Algorithm",
          "6.4 ARC Algorithm: REQUEST Subroutine"
        ]
      },
      {
        "summary": "Correct JSONB node types and size claim; rename R-tree to R*-Tree; tighten conflict model and retry policy",
        "categories": [
          1,
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.62,
        "evidence": [
          "JSONB node type codes updated and size claim adjusted",
          "R*-Tree naming corrected; geometry trait name fixed",
          "Conflict modeling and retry policy clarified"
        ],
        "changed_headings": [
          "JSON1/JSONB section",
          "14.4 R*-Tree",
          "18. Conflict Modeling"
        ]
      }
    ]
  },
  {
    "commit": "30619b34ea187d682283f8cd137d8d30e306e6bd",
    "change_groups": [
      {
        "summary": "Clarify geopoly as built on R*-tree and refine conflict probability interpretation with explicit examples",
        "categories": [
          9,
          1
        ],
        "primary_category": 9,
        "confidence": 0.6,
        "evidence": [
          "Geopoly extension description updated to R*-tree",
          "Birthday-paradox conflict probability explanation corrected with numeric examples"
        ],
        "changed_headings": [
          "14.4 R*-Tree",
          "18.3 Conflict Probability (Uniform)"
        ]
      }
    ]
  },
  {
    "commit": "7e9cace601485722e7b31411ad74796c0685bd05",
    "change_groups": [
      {
        "summary": "Refine Zipf conflict probability derivation with sum of squared probabilities and numerical comparison",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.74,
        "evidence": [
          "P(any conflict) expressed as exp(-C(N,2)*sum p(k)^2)",
          "Numeric comparison vs uniform added"
        ],
        "changed_headings": [
          "18.4 Non-Uniform Page Access: Zipf Distribution"
        ]
      }
    ]
  },
  {
    "commit": "ff937f3d678f88eb855051dbbd32e8e5046bea0f",
    "change_groups": [
      {
        "summary": "Clarify PageVersion hash storage and temper byte-conflict reduction claims; add retry policy",
        "categories": [
          9,
          1,
          7
        ],
        "primary_category": 9,
        "confidence": 0.62,
        "evidence": [
          "XXH3 hash belongs to CachedPage not PageVersion",
          "Byte-level conflict reduction reframed as upper bound; practical limits listed",
          "Retry policy added"
        ],
        "changed_headings": [
          "5. MVCC Formal Model",
          "18.7 Impact of Write Merging",
          "18.8 Throughput Model"
        ]
      }
    ]
  },
  {
    "commit": "61ee3e03f4cd5e44b189da55bb70e91cdba63a29",
    "change_groups": [
      {
        "summary": "Harden ARC eviction failure path to skip dirty pages on WAL flush failure",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.7,
        "evidence": [
          "flush_to_wal errors cause candidate rotation instead of eviction"
        ],
        "changed_headings": [
          "6.4 ARC Algorithm: REPLACE Subroutine"
        ]
      },
      {
        "summary": "Add math-function compile flag note and geopoly_xform function",
        "categories": [
          6,
          9
        ],
        "primary_category": 9,
        "confidence": 0.46,
        "evidence": [
          "SQLite math functions require compile flag; FrankenSQLite always includes",
          "geopoly_xform listed"
        ],
        "changed_headings": [
          "13.2 Math Functions",
          "14.4 R*-Tree"
        ]
      }
    ]
  },
  {
    "commit": "a90a3794616e12b083f88276e3cb47a045f3ac10",
    "change_groups": [
      {
        "summary": "Deep audit fixes for ARC: flush under mutex note, eviction error handling, ghost list overhead corrected, cache_size=0 semantics corrected",
        "categories": [
          1,
          2,
          4,
          9
        ],
        "primary_category": 1,
        "confidence": 0.75,
        "evidence": [
          "cache_size=0 now maps to SQLite default cache size behavior",
          "ghost list overhead recalculated; eviction path handles flush errors"
        ],
        "changed_headings": [
          "6. ARC Cache",
          "PRAGMA cache_size"
        ]
      }
    ]
  },
  {
    "commit": "246102e6b4266fa15000580a3d016d76bcb1c801",
    "change_groups": [
      {
        "summary": "Add adaptive redundancy autopilot and merge-retry loop; add witness refinement policy",
        "categories": [
          4,
          8,
          9
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "New adaptive redundancy section with e-process monitoring and policy actions",
          "Commit path restructured with coordinator conflict retry loop",
          "Witness refinement VOI policy added"
        ],
        "changed_headings": [
          "3.5.12 Adaptive Redundancy",
          "5.7 Witness Refinement Policy",
          "5.9 Commit pseudocode"
        ]
      },
      {
        "summary": "Update merge model to structured patches and operator precedence tables (ESCAPE and relational/equality split)",
        "categories": [
          1,
          2,
          9
        ],
        "primary_category": 1,
        "confidence": 0.68,
        "evidence": [
          "Physical merge retitled to structured page patches; raw XOR forbidden",
          "Precedence table split equality vs relational; ESCAPE right-associative; JSON -> operators added"
        ],
        "changed_headings": [
          "5.10 Physical Merge",
          "10.2 Pratt Parser Table",
          "12.15 Expression Grammar"
        ]
      }
    ]
  },
  {
    "commit": "5ea1b6fb02945e4bc147c37ae7d054d92fdd9045",
    "change_groups": [
      {
        "summary": "Fix SSI pseudocode edge direction and dangerous structure explanation; add claiming timestamp cleanup; cross-process note",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 1,
        "confidence": 0.74,
        "evidence": [
          "ssi_validate_and_publish scans in_edges and sets has_out_rw",
          "dangerous structure definition clarified; claiming cleanup via timeout",
          "cross-process visibility note added"
        ],
        "changed_headings": [
          "5.7 SSI",
          "5.6.2 TxnSlot",
          "SSI correctness"
        ]
      },
      {
        "summary": "Fix precedence tables and RETURNING semantics",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.65,
        "evidence": [
          "ISNULL/NOTNULL added to comparison precedence; COLLATE/unary swap fixed",
          "RETURNING reflects BEFORE but not AFTER triggers"
        ],
        "changed_headings": [
          "10.2 Pratt Parser Table",
          "12.15 Expression Grammar",
          "12.4 RETURNING"
        ]
      },
      {
        "summary": "Rename merge terminology and fix RaptorQ size unit detail",
        "categories": [
          9,
          1
        ],
        "primary_category": 9,
        "confidence": 0.42,
        "evidence": [
          "algebraic write merging renamed to safe write-merge ladder",
          "~220 MiB wording corrected"
        ],
        "changed_headings": [
          "3.1 SSI rationale",
          "3.4 RaptorQ"
        ]
      }
    ]
  },
  {
    "commit": "f1f25abe3b40ad0fb8704eaee310aee17de78d25",
    "change_groups": [
      {
        "summary": "Enforce gap-free commit_seq allocation from marker stream; tighten commit_seq publication semantics and memory ordering",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "CommitSeq derived from marker stream tip; no in-memory counter gaps",
          "commit_seq published only after durable marker; ordering clarified"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream",
          "5.6.1 SharedMemoryLayout",
          "7.11 Commit Protocol"
        ]
      },
      {
        "summary": "Clarify WAL-index layout details and rollback journal checksum loop; page size change rules",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.63,
        "evidence": [
          "WAL-index first segment layout clarified with header overlap",
          "Rollback journal checksum loop bounds clarified",
          "Page size change rules updated"
        ],
        "changed_headings": [
          "11.10 WAL Index",
          "11.14 Rollback Journal Format",
          "11.1 Database Header"
        ]
      },
      {
        "summary": "Add SSI witness rollback note for savepoints",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.4,
        "evidence": [
          "Witness registrations not rolled back on savepoint"
        ],
        "changed_headings": [
          "5.4 Savepoints"
        ]
      }
    ]
  },
  {
    "commit": "9725f136b2450c6411f5735a1575a068f2aacc0b",
    "change_groups": [
      {
        "summary": "Clarify commit_seq publication and cross-process visibility in native vs compatibility modes",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.7,
        "evidence": [
          "commit_seq described as published high-water mark; cross-process visibility split by mode"
        ],
        "changed_headings": [
          "5.6.1 SharedMemoryLayout",
          "7.11 Commit Protocol"
        ]
      },
      {
        "summary": "Define witness hot-plane epoch lock protocol to avoid false negatives",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.66,
        "evidence": [
          "epoch_lock, bucket_epoch swap discipline defined to prevent lost updates"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane"
        ]
      },
      {
        "summary": "Add DB header forward-compat rules and lock-byte page reservation; move WAL checksum impl to \u00a77.1 reference",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "Read/write version compatibility behavior specified",
          "Pending-byte page reserved; WAL checksum impl referenced"
        ],
        "changed_headings": [
          "11.1 Database Header",
          "11.13 Lock-Byte Page",
          "11.9.1 WAL Checksum Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "56742886aae65bdca3a34acda8d677b52a0c241d",
    "change_groups": [
      {
        "summary": "Restrict hot-plane epoch advancement to quiescent concurrent transactions; require epoch_lock refresh semantics",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.72,
        "evidence": [
          "Epoch advance allowed only when no active concurrent txns",
          "Bucket refresh under epoch_lock with Release semantics"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane"
        ]
      }
    ]
  },
  {
    "commit": "71a41750d478e8ecad031a2f490e84a4424a839e",
    "change_groups": [
      {
        "summary": "Publish shm.commit_seq only after marker durable (post-fsync)",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.73,
        "evidence": [
          "commit_seq publish inserted after marker fsync"
        ],
        "changed_headings": [
          "7.11 Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "9fa8f7b6082f164d4cb1026296a360cfbafe1f73",
    "change_groups": [
      {
        "summary": "Require commit_seq allocation from marker tip and align sequencer steps",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.73,
        "evidence": [
          "commit_seq allocated from marker stream tip within commit section"
        ],
        "changed_headings": [
          "7.11 Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "86d63af874d7a3dc7d522d47bf5f004f12913adb",
    "change_groups": [
      {
        "summary": "Define legacy writer exclusion for compatibility mode and hybrid SHM bridge to wal-index",
        "categories": [
          2,
          4,
          9
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "WAL_WRITE_LOCK exclusion required; concurrent mode must exclude legacy writers",
          "Hybrid protocol maintains standard wal-index and reader marks"
        ],
        "changed_headings": [
          "5.6.6 Compatibility",
          "5.6.7 Compatibility Mode Hybrid SHM"
        ]
      },
      {
        "summary": "Clarify gc_horizon derivation from published commit_seq high-water mark",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.36,
        "evidence": [
          "begin_seq derived from published commit_seq"
        ],
        "changed_headings": [
          "5.6.5 GC Horizon"
        ]
      }
    ]
  },
  {
    "commit": "23f575f7d4ee20399865e33abca1f93e60eda2d7",
    "change_groups": [
      {
        "summary": "Use Acquire load for snapshot commit_seq; constrain deterministic rebase scope and compatibility note",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 1,
        "confidence": 0.7,
        "evidence": [
          "begin snapshot uses Acquire load",
          "Rebase restricted: no splits/overflow/freelist/multi-page ops"
        ],
        "changed_headings": [
          "5.2 begin()",
          "5.10 Deterministic Rebase"
        ]
      }
    ]
  },
  {
    "commit": "6228e273d3dce6ca67c97fd43afb9018d19c6f5f",
    "change_groups": [
      {
        "summary": "Reconcile shm.commit_seq to durable tip on open; add lock-table rebuild lease protocol and epoch_lock acquisition rules",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.73,
        "evidence": [
          "commit_seq initialization/reconciliation rules added",
          "Lock table rebuild lease + quiescence; epoch_lock acquisition details"
        ],
        "changed_headings": [
          "5.6.1 SharedMemoryLayout",
          "5.6.3 SharedPageLockTable",
          "5.6.4 Hot Witness Plane"
        ]
      },
      {
        "summary": "Add ARC patent note and clarify legacy writer exclusion reminder",
        "categories": [
          9,
          2
        ],
        "primary_category": 9,
        "confidence": 0.4,
        "evidence": [
          "ARC patent expired note",
          "Legacy writer exclusion restated"
        ],
        "changed_headings": [
          "6. ARC Cache",
          "7.11 Compatibility mode verifiability"
        ]
      }
    ]
  },
  {
    "commit": "2e3ea218a908f4a22791b4c8b30a0dbf746f867b",
    "change_groups": [
      {
        "summary": "Make SharedPageLockTable key-stable (no tombstones), adjust acquire/release and rebuild rationale",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.76,
        "evidence": [
          "page_number no longer tombstoned; release only clears owner_txn",
          "Acquire CAS failure re-reads same slot; rebuild to clear keys"
        ],
        "changed_headings": [
          "5.6.3 SharedPageLockTable",
          "5.6.3.1 Table Rebuild"
        ]
      },
      {
        "summary": "Define marker stream byte-exact encoding constants and marker_id domain separation",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.69,
        "evidence": [
          "Marker header/record sizes fixed (36/88 bytes)",
          "MarkerId uses domain-separated BLAKE3"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream"
        ]
      },
      {
        "summary": "Tighten compatibility-mode legacy writer exclusion and merge terminology",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "Legacy writer exclusion required whenever fsqlite-shm used",
          "Safe write merging terminology replaces algebraic merging"
        ],
        "changed_headings": [
          "5.6.6 Compatibility",
          "5.10 Safe Write Merging"
        ]
      }
    ]
  },
  {
    "commit": "d05de23ea89da924e86232c8da519b6b58b4a0d5",
    "change_groups": [
      {
        "summary": "Align lock-table rebuild prose with key-stability and load factor accounting",
        "categories": [
          9,
          1
        ],
        "primary_category": 9,
        "confidence": 0.57,
        "evidence": [
          "Rebuild rationale now for non-deleted keys; load factor counts page_number!=0"
        ],
        "changed_headings": [
          "5.6.3.1 Table Rebuild"
        ]
      },
      {
        "summary": "Add database header constraints (usable_size >= 480) and db-size validity condition",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.66,
        "evidence": [
          "usable_size constraint added; db size valid only when version-valid-for matches change counter"
        ],
        "changed_headings": [
          "11.1 Database Header"
        ]
      }
    ]
  },
  {
    "commit": "fa1830e4593854a492d78bec24da1db90351c2f0",
    "change_groups": [
      {
        "summary": "Clarify ECS permeation map distinction between marker stream and coded objects",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.52,
        "evidence": [
          "CommitMarkerRecord separated from coded CommitCapsule/Proof"
        ],
        "changed_headings": [
          "3.5.5 RootManifest / ECS map"
        ]
      },
      {
        "summary": "Correct fragment limit semantics and cell payload local byte wording",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.65,
        "evidence": [
          "Fragment limit is threshold before insertion; cell payload references local_bytes"
        ],
        "changed_headings": [
          "11.2 B-Tree Page Layout",
          "11.3 Cell Format"
        ]
      }
    ]
  },
  {
    "commit": "70436b5c2c04e42c0aaf4b776a8f779416abdeff",
    "change_groups": [
      {
        "summary": "Specify WAL-index SHM native byte order, iVersion constraint, and WalCkptInfo layout fix",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "SHM fields are native endian; iVersion must be 3007000; WalCkptInfo 40-byte block"
        ],
        "changed_headings": [
          "11.10 WAL Index (wal-index / SHM)"
        ]
      }
    ]
  },
  {
    "commit": "a4e773481bd417530fe83f33868ef6ce5656e933",
    "change_groups": [
      {
        "summary": "Add VFS shared-memory API methods and expand trait signatures (cursor ops, virtual tables)",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "VfsFile adds shm_map/shm_lock/shm_barrier/shm_unmap",
          "BtreeCursorOps methods take &Cx and add first/last; VirtualTable lifecycle methods added"
        ],
        "changed_headings": [
          "VFS Trait Definitions",
          "BtreeCursorOps",
          "VirtualTable"
        ]
      },
      {
        "summary": "Clarify CommitMarkerRecord marker_id domain-separated hash reference",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.38,
        "evidence": [
          "marker_id comment updated to refer to domain-separated definition"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream"
        ]
      }
    ]
  },
  {
    "commit": "09c095901ddb1e5db47f55ddf5c616b5d51bf74e",
    "change_groups": [
      {
        "summary": "Define CheckpointPageWriter trait for WAL checkpoint and add replication gate acceptance criteria",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.63,
        "evidence": [
          "CheckpointPageWriter trait added in pager; replication gate added in Phase 9"
        ],
        "changed_headings": [
          "9.1 Function Traits",
          "Phase 9 Gates"
        ]
      }
    ]
  },
  {
    "commit": "40a2ac7739778b30cb11129a782d8746bd13e6ed",
    "change_groups": [
      {
        "summary": "Bump document version footer to 1.18 with summary of prior fixes",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.86,
        "evidence": [
          "Footer version line updated"
        ],
        "changed_headings": [
          "Document footer"
        ]
      }
    ]
  },
  {
    "commit": "40c6c3d152cf7d86104ad9ca19fbb850d6fdf343",
    "change_groups": [
      {
        "summary": "Lock-table acquire must return BUSY on CAS race to avoid duplicate keys",
        "categories": [
          1
        ],
        "primary_category": 1,
        "confidence": 0.69,
        "evidence": [
          "CAS failure now returns SQLITE_BUSY and forbids continued probing"
        ],
        "changed_headings": [
          "5.6.3 SharedPageLockTable"
        ]
      }
    ]
  },
  {
    "commit": "8512e62aed8835864a8800ed895c91a8773dc996",
    "change_groups": [
      {
        "summary": "Move compatibility page-FEC repair symbols to sidecar; add UDP payload limits and MTU guidance",
        "categories": [
          2,
          4,
          9
        ],
        "primary_category": 2,
        "confidence": 0.7,
        "evidence": [
          "Compatibility DB file must not append repair region; use .db-fec sidecar",
          "UDP payload <= 65507 and MTU-safe symbol sizing guidance"
        ],
        "changed_headings": [
          "3.4 Replication Packet",
          "3.4.6 Erasure-Coded Page Storage",
          "Compatibility mode verifiability"
        ]
      },
      {
        "summary": "Adjust WAL framing note, checkpoint chunk sizes, and recovery wording",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.46,
        "evidence": [
          "WAL frames are tightly packed; not sector-aligned",
          "Checkpoint chunk size guidance changed; Native mode recovery path tweak"
        ],
        "changed_headings": [
          "7. WAL Durability",
          "3.5 ECS tuning",
          "7.12 Recovery"
        ]
      },
      {
        "summary": "Clarify cross-process MVCC phase gates and compat sidecars",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.38,
        "evidence": [
          "Phase 6 covers cross-process MVCC; .db-fec referenced"
        ],
        "changed_headings": [
          "Phase gates",
          "Implementation notes"
        ]
      }
    ]
  },
  {
    "commit": "e31897fd92088e5305735d080e224a23b7315a11",
    "change_groups": [
      {
        "summary": "Clarify MTU-aware checkpoint chunk sizing rationale",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.58,
        "evidence": [
          "CheckpointChunk sizing note updated to prefer <=1366 on UDP"
        ],
        "changed_headings": [
          "3.5 ECS tuning"
        ]
      }
    ]
  },
  {
    "commit": "b03db7bc0b8a2705fe6fda19f5f149452755284c",
    "change_groups": [
      {
        "summary": "Fix SQL coverage details: join types, LIMIT comma order, MATCH semantics, DROP COLUMN behavior, json(X) error behavior",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.76,
        "evidence": [
          "JOIN types are nested-loop; LIMIT offset,count; MATCH not enforced; DROP COLUMN rewrite/failure conditions",
          "json(X) throws error on invalid JSON"
        ],
        "changed_headings": [
          "12. SQL Coverage",
          "12.1 SELECT",
          "12.2 INSERT",
          "12.8 ALTER TABLE",
          "14.1 JSON1 Functions"
        ]
      },
      {
        "summary": "Replace hash-join mention in vectorized VDBE section",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.44,
        "evidence": [
          "Vectorized VDBE applies to nested-loop joins"
        ],
        "changed_headings": [
          "21.7 Vectorized VDBE"
        ]
      }
    ]
  },
  {
    "commit": "dd190e4f7f24aa2a8b7bb1bbc7020aead6d014c0",
    "change_groups": [
      {
        "summary": "Correct GF(256) worked example and add MMR/IBLT replication enhancements",
        "categories": [
          1,
          8,
          6
        ],
        "primary_category": 1,
        "confidence": 0.72,
        "evidence": [
          "GF(256) log/exp values corrected",
          "MMR inclusion/prefix proofs added; IBLT anti-entropy described"
        ],
        "changed_headings": [
          "3.2 GF(256) Worked Example",
          "3.5.4 Marker Stream (MMR)",
          "3.5.6 Replication"
        ]
      },
      {
        "summary": "Rename WAL checksum variable names to hdr_cksum1/2 in chain description",
        "categories": [
          9,
          1
        ],
        "primary_category": 1,
        "confidence": 0.46,
        "evidence": [
          "hdr_s0/hdr_s1 renamed to hdr_cksum1/2"
        ],
        "changed_headings": [
          "7.1 WAL Checksum Chain",
          "11.9.1 WAL Checksum Chain"
        ]
      },
      {
        "summary": "Add policy controller and mixture e-process guidance; expand IntentFootprint and merge certificates",
        "categories": [
          8,
          4,
          6
        ],
        "primary_category": 8,
        "confidence": 0.66,
        "evidence": [
          "PolicyController section with expected loss and BOCPD guardrails",
          "Mixture e-processes described; IntentFootprint, commutativity rules, MergeCertificate schema added"
        ],
        "changed_headings": [
          "4.3 E-processes",
          "4.17 Policy Controller",
          "5.10 Write Merge System"
        ]
      }
    ]
  },
  {
    "commit": "a664265e3f5876177b7c1410dad7119e01e7f9e9",
    "change_groups": [
      {
        "summary": "Add policy controller, epochs, remote capability/idempotency/saga requirements, and symbol log format",
        "categories": [
          4,
          8,
          6
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "Symbol log segment format with epoch_id; RootManifest ecs_epoch added",
          "RemoteCap, idempotency, saga requirements for remote ops",
          "PolicyController section with expected loss and guardrails"
        ],
        "changed_headings": [
          "3.5.4.2 Symbol Record Logs",
          "3.5.5 RootManifest",
          "4.17 Policy Controller",
          "4.18 Epochs",
          "4.19 Remote Effects"
        ]
      },
      {
        "summary": "Revise hot witness plane to double-buffered epochs; add epoch-advance rules and candidate discovery over two epochs",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.69,
        "evidence": [
          "HotWitnessBucketEntry now has epoch_a/epoch_b buffers",
          "Candidate discovery unions both epochs; epoch advancement rule updated"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane",
          "5.7 SSI"
        ]
      },
      {
        "summary": "ARC eviction safety valve and flush_dirty_page naming; compaction saga requirement",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.58,
        "evidence": [
          "Case IV eviction adds safety valve and flush_dirty_page name",
          "Compaction must be a Saga"
        ],
        "changed_headings": [
          "6. ARC Cache",
          "7.9 Compaction"
        ]
      }
    ]
  },
  {
    "commit": "599cafb3f29c52dd2a44f27d5632032c54a34a25",
    "change_groups": [
      {
        "summary": "Clarify SQLite 3.52.0 forward target and unsafe prefetch requirement; add symbol auth guidance and epoch helper semantics",
        "categories": [
          9,
          4
        ],
        "primary_category": 9,
        "confidence": 0.57,
        "evidence": [
          "3.52.0 noted as forward target; prefetch must use helper crate due to unsafe_code forbid",
          "Symbol auth guidance refined"
        ],
        "changed_headings": [
          "1.1 What It Is",
          "1.4 Constraints",
          "3.5.2 Symbol Auth"
        ]
      },
      {
        "summary": "Add helper views for witness epoch buffers and refine epoch-advance conditions; planner NGQP note updated",
        "categories": [
          9,
          4
        ],
        "primary_category": 4,
        "confidence": 0.55,
        "evidence": [
          "readers_for_epoch/writers_for_epoch helpers defined",
          "Epoch advancement criteria specified in terms of txn states",
          "NGQP described as N3 bounded algorithm"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane",
          "10.5 Query Planning"
        ]
      }
    ]
  },
  {
    "commit": "e42a43de57ff5d4ee616cd2ec3b54a0db249a3e6",
    "change_groups": [
      {
        "summary": "Define symbol auth master key derivation and adjust VdbeOp p5 usage note",
        "categories": [
          4,
          2,
          9
        ],
        "primary_category": 4,
        "confidence": 0.64,
        "evidence": [
          "master_key derived from DEK with domain separation or lab seed",
          "P5 note updated to allow full 16 bits per opcode"
        ],
        "changed_headings": [
          "4.18 Epoch-Scoped Symbol Auth",
          "10.7 VDBE Instruction Format"
        ]
      }
    ]
  },
  {
    "commit": "f158b44a5bd96ef34b378b58f61399568424f6d4",
    "change_groups": [
      {
        "summary": "Clarify symbol auth wording and refine planner cost model with ANALYZE note",
        "categories": [
          9,
          2
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "Symbol auth description adjusted to emphasize auth_tag",
          "Cost model formulas updated; ANALYZE note added"
        ],
        "changed_headings": [
          "3.5 ECS",
          "10.5 Query Planning"
        ]
      }
    ]
  },
  {
    "commit": "3cf0f13571c101725f9ef34ce2476c90478ff07d",
    "change_groups": [
      {
        "summary": "Fix RaptorQ MTU and sub-blocking explanation; adjust symbol auth key derivation requirements",
        "categories": [
          1,
          3,
          9
        ],
        "primary_category": 1,
        "confidence": 0.72,
        "evidence": [
          "MTU-safe T corrected to 1464; sub-symbol calculation fixed",
          "Symbol auth key derivation clarified with explicit master key capability"
        ],
        "changed_headings": [
          "3.4 Replication Packet",
          "4.18 Symbol Auth"
        ]
      }
    ]
  },
  {
    "commit": "0cb22962ec87cb29a29a44acfc5ec14588aadb23",
    "change_groups": [
      {
        "summary": "Add lock references, row-value expression, and VDBE opcode examples; clarify blocking pool defaults",
        "categories": [
          7,
          9
        ],
        "primary_category": 7,
        "confidence": 0.62,
        "evidence": [
          "RowValue Expr added; UPDATE/DELETE VDBE examples added",
          "WAL_WRITE_LOCK reference updated; blocking pool defaults clarified"
        ],
        "changed_headings": [
          "10.7 VDBE Instruction Format",
          "10.6 Code Generation",
          "1.2 Innovations",
          "4.2 Blocking Pool"
        ]
      },
      {
        "summary": "Add ObjectId collision bound note; refine invariants monitor; several clarifications about WAL snapshot conflicts and risk sections",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.5,
        "evidence": [
          "ObjectId 128-bit truncation noted as ~2^64 birthday bound",
          "observe_lock_exclusivity now cross-checks lock table vs txn locks"
        ],
        "changed_headings": [
          "Glossary",
          "4.3 Invariant Monitoring",
          "7.4 Page Integrity"
        ]
      }
    ]
  },
  {
    "commit": "1680d6931f5773673fae021b7cc646e3f3faab44",
    "change_groups": [
      {
        "summary": "Fix e-process aggregation to arithmetic mean and correct INV-1 violation detection comment",
        "categories": [
          1,
          8
        ],
        "primary_category": 1,
        "confidence": 0.74,
        "evidence": [
          "E_global aggregation changed to sum of weighted e-values",
          "INV-1 comment corrected to ~20 violations for threshold"
        ],
        "changed_headings": [
          "4.3 E-processes"
        ]
      },
      {
        "summary": "Minor clarifications: WAL snapshot conflict phrasing, opcode traces illustrative, sqliteInt.h size corrected",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.45,
        "evidence": [
          "WAL snapshot conflict clarified; opcode traces labeled illustrative; sqliteInt.h size corrected"
        ],
        "changed_headings": [
          "1.2 Innovations",
          "10.6 Code Generation",
          "21. Reference Files"
        ]
      }
    ]
  },
  {
    "commit": "1e2aae9940969190c6b9bebe94c94749eee91626",
    "change_groups": [
      {
        "summary": "Introduce UpdateExpression and RebaseExpr to enable deterministic rebase of read-modify-write; refine rebase safety and commutativity rules",
        "categories": [
          4,
          1,
          8
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "UpdateExpression intent added with RebaseExpr AST",
          "Rebase safety distinguishes blocking reads vs expression reads; VDBE rules added",
          "Commutativity refined for column-disjoint UpdateExpression ops"
        ],
        "changed_headings": [
          "5.10 Deterministic Rebase",
          "5.10.1 Intent Logs",
          "5.10.7 Intent Footprints"
        ]
      },
      {
        "summary": "Require legacy WAL reader locks when updating read marks; cross-db atomic WAL transactions requirement",
        "categories": [
          2,
          4
        ],
        "primary_category": 2,
        "confidence": 0.64,
        "evidence": [
          "Readers must hold WAL_READ_LOCK when writing aReadMark",
          "Cross-database atomic WAL transactions required via 2PC"
        ],
        "changed_headings": [
          "5.6.7 Compatibility Mode Hybrid SHM",
          "12.11 ATTACH"
        ]
      }
    ]
  }
];
      const CLASS_LATE = [
  {
    "commit": "da22f479dc2f8d1e98294750b741b3cce168fd19",
    "change_groups": [
      {
        "summary": "Move WAL-FEC generation fully off the commit critical path; distinguish design-time p_design from runtime living corruption-rate monitoring.",
        "categories": [
          7,
          8,
          4
        ],
        "primary_category": 7,
        "confidence": 0.82,
        "evidence": [
          "Enqueue a background FEC job ... encoder reads source frames from .wal",
          "p_design = 10^-4; autopilot maintains living estimates + conservative bounds"
        ],
        "changed_headings": [
          "3.4.1 WAL-FEC",
          "3.5.12 Durability Autopilot"
        ]
      },
      {
        "summary": "Add rigorous durability policy math: Bayesian posterior for p (diagnostics) plus anytime-valid p_upper for guarantees; VOI-based monitoring budgeting.",
        "categories": [
          8,
          7
        ],
        "primary_category": 8,
        "confidence": 0.8,
        "evidence": [
          "p | data ~ Beta(\u03b10 + n_bad, \u03b20 + n_ok)",
          "derive p_upper via martingale inversion (anytime-valid under optional stopping)",
          "VOI(m) = E[\u0394Loss(m) | evidence] - Cost(m)"
        ],
        "changed_headings": [
          "3.5.12.2.1 Living Corruption-Rate Estimates",
          "4.16 Observability"
        ]
      },
      {
        "summary": "Reframe background compaction + retry as explicit decision policies: MDP compaction scheduling, online Zipf/s estimation, and optimal-stopping retry control; add interop notes (WAL-index locks, sqliteInt.h line count).",
        "categories": [
          8,
          7,
          2,
          4,
          5
        ],
        "primary_category": 8,
        "confidence": 0.72,
        "evidence": [
          "Model compaction scheduling as a finite-state MDP",
          "retry as expected-loss minimization; mentions Gittins-index threshold rule",
          "WAL-index lock slot mapping: aLock[0]=WAL_WRITE_LOCK ..."
        ],
        "changed_headings": [
          "7.13.1 Workload-Adaptive Compaction Policy",
          "18.4.1 Estimating Zipf s Online",
          "11.10 WAL-index"
        ]
      }
    ]
  },
  {
    "commit": "c25f0d00238fc36f355f818f571abc3d4a1198df",
    "change_groups": [
      {
        "summary": "Make UpdateExpression deterministic rebase correct: regenerate secondary-index ops from schema/row images during replay; forbid rebase for rowid/INTEGER PRIMARY KEY updates; refine commutativity check.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "Index regeneration (critical): stale IndexDelete/IndexInsert MUST be discarded",
          "No SET clause targets rowid/INTEGER PRIMARY KEY column"
        ],
        "changed_headings": [
          "5.10 Safe Write Merging",
          "UpdateExpression"
        ]
      }
    ]
  },
  {
    "commit": "02e48a41810bdb2ad471926d9728a9a9af12b155",
    "change_groups": [
      {
        "summary": "Correct the maxLocal integer-division example by showing truncation and remainder explicitly.",
        "categories": [
          1,
          5
        ],
        "primary_category": 1,
        "confidence": 0.76,
        "evidence": [
          "261376 / 255 = 1025 (truncated; remainder 1)"
        ],
        "changed_headings": [
          "B-tree local payload"
        ]
      },
      {
        "summary": "Add encryption deliverables/acceptance criteria and risk/complexity gates to the implementation phases.",
        "categories": [
          6,
          7
        ],
        "primary_category": 6,
        "confidence": 0.7,
        "evidence": [
          "Page-level encryption: XChaCha20-Poly1305 with envelope DEK/KEK",
          "Encryption acceptance: PRAGMA key/rekey + AAD swap resistance"
        ],
        "changed_headings": [
          "Implementation Plan"
        ]
      }
    ]
  },
  {
    "commit": "bcd893da081fd15b1614a05c4d8b593f55cf7011",
    "change_groups": [
      {
        "summary": "Split BtreeCursorOps into table/index-specific methods to mirror SQLite's dual B-tree APIs (table vs index move/insert semantics).",
        "categories": [
          4,
          2
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "sqlite3BtreeTableMoveTo(i64) vs sqlite3BtreeIndexMoveto(UnpackedRecord*)",
          "Replace key()/data() with payload()"
        ],
        "changed_headings": [
          "Trait Hierarchy",
          "BtreeCursorOps"
        ]
      },
      {
        "summary": "Make SHM mapping spec memory-safe: change shm_map return type to a safe ShmRegion wrapper; update unsafe-code policy boundary for VFS.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "fn shm_map(...) -> Result<ShmRegion>",
          "ShmRegion wraps mmap'd shared memory behind bounds-checked APIs"
        ],
        "changed_headings": [
          "VFS",
          "Shared Memory"
        ]
      },
      {
        "summary": "Fix release profile optimization level inconsistency (size-opt to throughput-opt) and add a release-perf profile description.",
        "categories": [
          7,
          5
        ],
        "primary_category": 7,
        "confidence": 0.74,
        "evidence": [
          "opt-level = 3  # Full optimization (database engine needs throughput)"
        ],
        "changed_headings": [
          "Release Profile"
        ]
      }
    ]
  },
  {
    "commit": "6da51572d2b5b76eb9a37ffa99da76bfb850cd83",
    "change_groups": [
      {
        "summary": "Fix TxnSlot struct sizing math so shared-memory slot stride is exactly 128 bytes.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.83,
        "evidence": [
          "_padding was 52 -> 132B total; corrected to 128B stride"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot"
        ]
      },
      {
        "summary": "Tighten group-commit and request semantics: use TxnSlot.mode via request.txn, clarify durability point for batched capsules, and fix term usage (K_source + R).",
        "categories": [
          4,
          7,
          5
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "PublishRequest has no mode field; derive mode via request.txn -> TxnSlot.mode",
          "Coordinator FSYNC_1 is the durability point for batched capsule symbols"
        ],
        "changed_headings": [
          "7.11 Group Commit"
        ]
      }
    ]
  },
  {
    "commit": "22e75e65b831adda852df3a11628e793aaa9e7a9",
    "change_groups": [
      {
        "summary": "Add RecentlyCommittedReadersIndex to preserve committed readers' SSI read evidence so incoming rw-edges aren\"t lost when TxnSlots are freed; enforce T3 rule for committed pivots.",
        "categories": [
          4,
          1,
          6,
          7
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "RecentlyCommittedReadersIndex retains committed transactions' read witness summary",
          "If entry.has_in_rw is true, committer MUST abort (T3 rule for committed pivots)"
        ],
        "changed_headings": [
          "5.6.2.1 Recently Committed Readers"
        ]
      }
    ]
  },
  {
    "commit": "2f0970b9a5d8fc755269ba848169f5a1369ec6a6",
    "change_groups": [
      {
        "summary": "Fix lexer/identifier semantics: double-quoted strings are TK_ID; DQS reinterpretation happens in name resolution, not tokenization.",
        "categories": [
          2,
          5
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "SQLite tokenize.c emits TK_ID for \"...\"; resolve.c reinterprets"
        ],
        "changed_headings": [
          "Lexer",
          "QuotedId"
        ]
      },
      {
        "summary": "Correct planner range-scan cost model by adding index-leaf scanning term; avoids preferring long-range index scans incorrectly.",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.86,
        "evidence": [
          "cost = log2(N_idx_pages) + sel*N_idx_pages + sel*N_tbl_pages"
        ],
        "changed_headings": [
          "Planner Cost Model"
        ]
      },
      {
        "summary": "Fix UPDATE VDBE trace example: MakeRecord must encode all columns (overlay updated column on full-row image).",
        "categories": [
          2,
          6
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "Overlay updated column, then MakeRecord(all columns)"
        ],
        "changed_headings": [
          "VDBE",
          "UPDATE"
        ]
      }
    ]
  },
  {
    "commit": "5cc32a6bc813ff59db231f29db5b95a13ea94704",
    "change_groups": [
      {
        "summary": "Specify required asupersync networking + deterministic VirtualTcp testing and map FrankenSQLite work onto scheduler priority lanes (cancel/timed/ready) for tail-latency control.",
        "categories": [
          3,
          7,
          6
        ],
        "primary_category": 3,
        "confidence": 0.82,
        "evidence": [
          "MUST use asupersync cancel-safe network stack; lab transport swappable to VirtualTcp",
          "Scheduler lanes: Cancel (highest), Timed (EDF), Ready (background)"
        ],
        "changed_headings": [
          "4.19.6 Networking Stack",
          "4.20 Scheduler Priority Lanes"
        ]
      }
    ]
  },
  {
    "commit": "dc92e549d05ac8dc0c23937d6e6dfa874729fdd4",
    "change_groups": [
      {
        "summary": "Correct MVCC version-chain compression: use sparse XOR deltas between adjacent versions (compression), not RaptorQ repair symbols; RaptorQ remains the durability layer for delta objects.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "V2 delta: XOR(V2,V3)",
          "RaptorQ applies at ECS object level for durability"
        ],
        "changed_headings": [
          "Version Chains",
          "Compression"
        ]
      }
    ]
  },
  {
    "commit": "2433562451b188c9233f6fd83a9ef7573ce48f97",
    "change_groups": [
      {
        "summary": "Add independent per-source hashes to WAL-FEC metadata so recovery can validate surviving source frames after the WAL checksum chain breaks.",
        "categories": [
          7,
          2,
          4
        ],
        "primary_category": 7,
        "confidence": 0.86,
        "evidence": [
          "WalFecGroupMeta.source_page_xxh3: Vec<u64> (length=K)",
          "frames at/after checksum mismatch validate via .wal-fec hashes"
        ],
        "changed_headings": [
          "3.4.1 WAL-FEC"
        ]
      }
    ]
  },
  {
    "commit": "82dfd4bf99283e5ab283073651787b3c7975561f",
    "change_groups": [
      {
        "summary": "Clarify cumulative WAL checksums: after first mismatch, frames i+1.. aren\"t WAL-validated; require random-access validation via WAL-FEC and attempt repair-before-truncate.",
        "categories": [
          2,
          7,
          4
        ],
        "primary_category": 2,
        "confidence": 0.86,
        "evidence": [
          "Because checksum is cumulative, WAL format alone cannot validate frames i+1..",
          "Attempt repair first if matching .wal-fec group exists"
        ],
        "changed_headings": [
          "7.5 WAL Checksums",
          "7.8 Error Recovery"
        ]
      },
      {
        "summary": "Correct SQLite header semantics: file change counter is updated when header page is written (not forced on every WAL commit).",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.78,
        "evidence": [
          "In WAL mode, file change counter is NOT forced on every commit"
        ],
        "changed_headings": [
          "11.1 Database Header"
        ]
      }
    ]
  },
  {
    "commit": "ab20d7fac6f83ac527475927aa53b204c11ed7c8",
    "change_groups": [
      {
        "summary": "Prevent lock-table rebuild deadlocks: transactions holding page locks must not busy-wait on rebuild-busy; abort/retry to reach lock quiescence.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "MUST NOT spin on SQLITE_BUSY while holding page locks; abort/retry"
        ],
        "changed_headings": [
          "PageLockTable Rebuild"
        ]
      },
      {
        "summary": "Add research note: view ARC p-update as online learning (OCO-style) while keeping canonical ARC update rules normative.",
        "categories": [
          8,
          7,
          6
        ],
        "primary_category": 8,
        "confidence": 0.64,
        "evidence": [
          "p_{t+1} = clamp(p_t + \u03b7_t * s_t, 0, capacity)"
        ],
        "changed_headings": [
          "6.4.1 Optional: p-Update as Online Learning"
        ]
      }
    ]
  },
  {
    "commit": "96f32f3174453e68960d849672cb4b7a8d33d1c7",
    "change_groups": [
      {
        "summary": "Harden UpdateExpression replay: enforce NOT NULL/CHECK semantics at replay time; restrict V1 to no foreign keys and rebase-safe CHECK constraints.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "Constraint checks (normative): NOT NULL + CHECK enforced during replay",
          "Foreign keys (V1 restriction): fall back to materialized Update"
        ],
        "changed_headings": [
          "UpdateExpression"
        ]
      }
    ]
  },
  {
    "commit": "f37158f2468145272817fd65794d78be539be19b",
    "change_groups": [
      {
        "summary": "Add explicit WAL-FEC invariants tying group metadata to WAL frame geometry and commit db_size.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.75,
        "evidence": [
          "k_source == end_frame_no - start_frame_no + 1"
        ],
        "changed_headings": [
          "WalFecGroupMeta"
        ]
      },
      {
        "summary": "Fix UpdateExpression rebase step numbering after inserting constraint-check step.",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.9,
        "evidence": [
          "Index regeneration step renumbered (6 -> 7)"
        ],
        "changed_headings": [
          "UpdateExpression"
        ]
      }
    ]
  },
  {
    "commit": "19fa01f6d66c19892c634a02da44f7f536b29e43",
    "change_groups": [
      {
        "summary": "Update built-in function coverage to match SQLite 3.52 target: add missing strftime specifiers and document ORDER BY inside group_concat/string_agg aggregates.",
        "categories": [
          2,
          6
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "strftime adds: %e %k %I %l %p %P %R %T %u %G %g %V",
          "group_concat(name, ', ' ORDER BY name)"
        ],
        "changed_headings": [
          "Built-in Functions"
        ]
      }
    ]
  },
  {
    "commit": "a3e7ae521e6a0dcb3cf9489ac5a67b0f62aad526",
    "change_groups": [
      {
        "summary": "Clarify Compatibility-mode I/O constraints: WAL frames are 24+page_size and break sector alignment, so O_DIRECT must not be required for .wal.",
        "categories": [
          2,
          7,
          9
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "SQLite .wal frames are 24+page_size; MUST NOT require O_DIRECT for .wal"
        ],
        "changed_headings": [
          "Mechanical Sympathy"
        ]
      },
      {
        "summary": "Tighten safety boundary: prefetch and VFS platform ops must use safe abstractions (or move behind external dependency boundary), not unsafe inside workspace crates.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.76,
        "evidence": [
          "Workspace members forbid unsafe; VFS MUST rely on safe SHM/locking APIs"
        ],
        "changed_headings": [
          "Unsafe Policy",
          "VFS"
        ]
      },
      {
        "summary": "Correct FTS5 query semantics: NOT is strictly a binary operator; unary NOT is a syntax error in FTS5 (unlike FTS3/4).",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.86,
        "evidence": [
          "FTS5 NOT: expr NOT expr (binary only); unary NOT not in fts5parse.y"
        ],
        "changed_headings": [
          "FTS5"
        ]
      }
    ]
  },
  {
    "commit": "56a4e91425fa5cba9aecf08f786691ef03563750",
    "change_groups": [
      {
        "summary": "Define replication changeset_bytes encoding as a self-delimiting header + sorted PageEntry records with per-page xxh3; receivers validate hashes before applying.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "ChangesetHeader.total_len (u64) before padding",
          "PageEntry: page_number + page_xxh3 + page_bytes"
        ],
        "changed_headings": [
          "Replication"
        ]
      }
    ]
  },
  {
    "commit": "d2a49862864dff9799e236d2cf81b51ed268f93f",
    "change_groups": [
      {
        "summary": "Harden crash cleanup and SQLite WAL-index interop: reclaim stuck CLEANING slots; enforce WAL_READ_LOCK discipline (exclusive update then shared hold) and state the 5-reader mark limitation explicitly.",
        "categories": [
          4,
          2,
          7
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "Reclaim stuck TXN_ID_CLEANING after timeout",
          "Acquire WAL_READ_LOCK(i) EXCLUSIVE to write aReadMark, then downgrade to SHARED",
          "Legacy WAL-index has only 5 reader marks/locks"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "Hybrid SHM Interop"
        ]
      },
      {
        "summary": "Fix ARC replacement liveness: track rotations per list so a pinned preferred list can\"t spin forever; add explicit fall-through path.",
        "categories": [
          1,
          7,
          4
        ],
        "primary_category": 1,
        "confidence": 0.8,
        "evidence": [
          "if rotations_t1 >= |T1| AND rotations_t2 >= |T2|: safety valve triggers"
        ],
        "changed_headings": [
          "ARC Cache"
        ]
      },
      {
        "summary": "Add deterministic safety directives: triggers must be non-recursive in Rust (explicit frame stack); correct conformal baseline sample size math under Bonferroni across M metrics.",
        "categories": [
          8,
          7,
          4
        ],
        "primary_category": 8,
        "confidence": 0.76,
        "evidence": [
          "Trigger execution MUST NOT use Rust call-stack recursion",
          "N_base >= ceil(M/alpha_total) to satisfy split conformal per-metric alpha"
        ],
        "changed_headings": [
          "Triggers",
          "Conformal No-Regression"
        ]
      }
    ]
  },
  {
    "commit": "859e81752809cd343b00ad6499c159d2f341cc46",
    "change_groups": [
      {
        "summary": "Ensure cleanup fully resets TxnSlot to a Free/Serialized state (not Aborted) when reclaiming or freeing slots.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "slot.state = Free; slot.mode = Serialized during cleanup"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot"
        ]
      }
    ]
  },
  {
    "commit": "be3d256b12679a32f2fb4e44eeb82e513607b284",
    "change_groups": [
      {
        "summary": "Specify Compatibility-mode .db-fec as a checkpoint-owned sidecar: only checkpointer mutates .db/.db-fec; enforce WAL truncation ordering; add independent per-source validation and repair writeback discipline.",
        "categories": [
          7,
          4,
          2,
          6
        ],
        "primary_category": 7,
        "confidence": 0.84,
        "evidence": [
          "V1 rule: .db-fec maintained ONLY by checkpoint subsystem",
          "WAL truncation safety: RESTART/TRUNCATE only after .db-fec updated+fsync'd",
          "DbFecGroupMeta.source_page_xxh3_128 for random-access validation"
        ],
        "changed_headings": [
          "3.4.6 .db-fec",
          "Read Path with On-the-Fly Repair"
        ]
      }
    ]
  },
  {
    "commit": "65ab2f709f724750878f2cb5d045649bf0c53e89",
    "change_groups": [
      {
        "summary": "Add out-of-the-box, bounded auto-tuning knobs and derived defaults to prevent self-DoS on many-core CPUs (bg_cpu_max, remote_max_in_flight, commit_encode_max; profile-based scaling).",
        "categories": [
          7,
          6
        ],
        "primary_category": 7,
        "confidence": 0.83,
        "evidence": [
          "PRAGMA fsqlite.auto_tune=ON (default) + PRAGMA fsqlite.profile",
          "Defaults scale sublinearly: bg_cpu_max_default = clamp(P/8,1,16)"
        ],
        "changed_headings": [
          "4.17.1 Out-of-the-Box Auto-Tuning"
        ]
      }
    ]
  },
  {
    "commit": "63ee097eb68a72ac23effab3979978adafb5b411",
    "change_groups": [
      {
        "summary": "Clarify SERIALIZABLE phantom protection: predicate/range reads must register leaf-page witnesses that intersect any phantom-producing writes.",
        "categories": [
          4,
          2,
          6
        ],
        "primary_category": 4,
        "confidence": 0.74,
        "evidence": [
          "Predicate reads MUST register witnesses (e.g., WitnessKey::Page(leaf_pgno))"
        ],
        "changed_headings": [
          "Witness Plane"
        ]
      },
      {
        "summary": "Warn against common SQLite WAL checksum mis-transcriptions that would break binary interoperability.",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "walChecksumBytes: s1 += a + s2; s2 += b + s1 (no avalanche)"
        ],
        "changed_headings": [
          "WAL Checksums"
        ]
      }
    ]
  },
  {
    "commit": "29f7ebe942a43891f2a55fd998d02c37411efc9f",
    "change_groups": [
      {
        "summary": "Place deterministic rebase outside the sequencer: committing txn must rebase before entering serialized commit section; coordinator validates certificates but must not execute B-tree/expression logic.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "Deterministic rebase MUST run before entering WriteCoordinator serialized section",
          "coordinator MUST NOT perform B-tree traversal or index-key regeneration"
        ],
        "changed_headings": [
          "5.10 Safe Write Merging"
        ]
      },
      {
        "summary": "Harden UpdateExpression index regeneration: handle partial/expression indexes, participation predicates, and enforce UNIQUE constraints during replay.",
        "categories": [
          4,
          2,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "Partial indexes: evaluate WHERE predicate; base/updated participation drives delete/insert"
        ],
        "changed_headings": [
          "UpdateExpression"
        ]
      },
      {
        "summary": "Replace Zipf-only policy input with model-free write-set skew estimation: define collision mass M2 / effective pool P_eff, add second-moment estimators and keep Zipf s_hat interpretability-only.",
        "categories": [
          8,
          7,
          9
        ],
        "primary_category": 8,
        "confidence": 0.8,
        "evidence": [
          "Collision mass M2 := \u03a3 q(pgno)^2; P_eff := 1/M2",
          "Zipf is interpretability-only; policy should prefer M2_hat/P_eff_hat"
        ],
        "changed_headings": [
          "18.4.1 Estimating Write-Set Skew Online"
        ]
      }
    ]
  },
  {
    "commit": "6b0c12fc40c5759f5d53028ba692e8aaff80fc92",
    "change_groups": [
      {
        "summary": "Correct planner join-ordering description: SQLite NGQP uses beam search (mxChoice), not an exhaustive search threshold; update the corresponding phase write-up.",
        "categories": [
          2,
          1,
          4
        ],
        "primary_category": 2,
        "confidence": 0.82,
        "evidence": [
          "wherePathSolver uses beam search; mxChoice=12/18 for 3+ tables"
        ],
        "changed_headings": [
          "Planner"
        ]
      }
    ]
  },
  {
    "commit": "b181b6d148e02862b195824020954abadae8de88",
    "change_groups": [
      {
        "summary": "Fix a second instance of the join-ordering error: beam search for all 3+ table joins, no exhaustive join enumeration path.",
        "categories": [
          2,
          1,
          5
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "No greedy/exhaustive split; beam search modeled on SQLite NGQP"
        ],
        "changed_headings": [
          "Planner"
        ]
      }
    ]
  },
  {
    "commit": "d302b391af5c2932c9097dd85923a8535593e45e",
    "change_groups": [
      {
        "summary": "Add a witness hot-index sizing manifest driven by skew: introduce deterministic second-moment (AMS F2) sketch and heavy-hitter decomposition for explainability; use M2_shard to derive S_eff under skew.",
        "categories": [
          8,
          7,
          4,
          6
        ],
        "primary_category": 8,
        "confidence": 0.82,
        "evidence": [
          "M2_shard := \u03a3 q(shard)^2; S_eff := 1/M2_shard",
          "AMS F2 sketch (normative default)"
        ],
        "changed_headings": [
          "18.4.1.3 Estimator A",
          "HotWitnessIndex"
        ]
      }
    ]
  },
  {
    "commit": "017745631c79f0c9061e4fdba8d0ce09ecc6c86d",
    "change_groups": [
      {
        "summary": "Clarify skew section naming (write-set skew, not page access) and make commit-ledger requirements explicit when contention telemetry influences commit/abort and policy actions.",
        "categories": [
          9,
          8,
          6
        ],
        "primary_category": 9,
        "confidence": 0.72,
        "evidence": [
          "Ledger must include regime_id, writers_active, M2_hat/P_eff_hat, expected losses"
        ],
        "changed_headings": [
          "18.4 Non-Uniform Write-Set Skew",
          "Evidence Ledger"
        ]
      }
    ]
  },
  {
    "commit": "5dae90d79aef7d70300fe53a17f9e40dba24b309",
    "change_groups": [
      {
        "summary": "Tighten Zipf s_hat guidance: require deterministic windowing under LabRuntime and prohibit using s_hat as a direct policy input when M2_hat is available.",
        "categories": [
          9,
          7,
          8
        ],
        "primary_category": 9,
        "confidence": 0.72,
        "evidence": [
          "s_hat MUST NOT be used as direct policy input when M2_hat is available"
        ],
        "changed_headings": [
          "Zipf s_hat"
        ]
      }
    ]
  },
  {
    "commit": "ca60e008352585f2501ca3f81337849396b4d140",
    "change_groups": [
      {
        "summary": "Define Compatibility .db-fec physical layout for O(1) seek and specify crash-consistent group updates (meta-as-commit-record discipline).",
        "categories": [
          7,
          4,
          6
        ],
        "primary_category": 7,
        "confidence": 0.82,
        "evidence": [
          "segment_off = sizeof(DbFecHeader) + SEG1_LEN + g*SEGG_LEN",
          "Write SymbolRecords first, DbFecGroupMeta last"
        ],
        "changed_headings": [
          ".db-fec physical layout"
        ]
      }
    ]
  },
  {
    "commit": "30203fb1f91acfb45c6085432a66029896e26e66",
    "change_groups": [
      {
        "summary": "Reserve TxnId sentinel values for shared-memory protocol and guard TxnId allocation from ever producing them (fail fast on overflow).",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "TxnId allocation MUST never produce u64::MAX/u64::MAX-1 sentinels"
        ],
        "changed_headings": [
          "TxnId",
          "TxnSlot"
        ]
      }
    ]
  },
  {
    "commit": "75ac25db5853747e3f56877c943d51ce8d649a5e",
    "change_groups": [
      {
        "summary": "Clarify replication identifier semantics: rename changeset_object_id to ChangesetId, validate K_source and symbol_size consistency, and truncate decoded bytes using total_len.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "ChangesetId is NOT ECS ObjectId; parse ChangesetHeader.total_len to drop padding"
        ],
        "changed_headings": [
          "Replication"
        ]
      },
      {
        "summary": "Harden TxnId allocation and witness semantics: forbid fetch_add wrap; use CAS loop to avoid publishing illegal TxnIds; tighten predicate-witness registration to include initial seek inspection.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "fetch_add forbidden; CAS loop prevents wrap into TxnId=0",
          "Register leaf-page witnesses during initial Seek*/MoveTo and OP_Next/Prev"
        ],
        "changed_headings": [
          "TxnId",
          "Witness Plane"
        ]
      },
      {
        "summary": "Make ARC cache cancel-safe and singleflight-friendly: add flush_inflight flag + protocol, define Loading watch status enum, and require cancellation to resolve latches.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.8,
        "evidence": [
          "flush_inflight: false -> true via CAS; must clear on all paths",
          "Loading state uses watch::Receiver<LoadStatus>"
        ],
        "changed_headings": [
          "ARC Cache",
          "Cancellation Safety"
        ]
      }
    ]
  },
  {
    "commit": "ec9adc1a8f61663d224399711d165a7dd623b919",
    "change_groups": [
      {
        "summary": "Update the monotonic TxnId proof text to match the CAS-loop allocator and explicitly fail closed on wrap/reserved-sentinel values.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.8,
        "evidence": [
          "Abort with FATAL_TXN_ID_OVERFLOW rather than publish illegal TxnId"
        ],
        "changed_headings": [
          "TxnId Invariants"
        ]
      },
      {
        "summary": "Clarify interpretation of P_eff: it\"s an effective collision pool for transaction write sets, not an estimate of physical page count.",
        "categories": [
          9,
          8
        ],
        "primary_category": 9,
        "confidence": 0.76,
        "evidence": [
          "P_eff plays role of \"year length\" in birthday paradox for transactions"
        ],
        "changed_headings": [
          "18.4.1.1 Collision Mass (M2)"
        ]
      }
    ]
  },
  {
    "commit": "e80fdde018b3ce359f49271f082366bbad19f928",
    "change_groups": [
      {
        "summary": "Require deterministic RaptorQ block seeding for replication changesets by deriving the seed from ChangesetId (matches asupersync determinism expectations).",
        "categories": [
          3,
          7,
          4
        ],
        "primary_category": 3,
        "confidence": 0.8,
        "evidence": [
          "seed = xxh3_64(changeset_id_bytes); decoder stores seed"
        ],
        "changed_headings": [
          "Replication"
        ]
      }
    ]
  },
  {
    "commit": "fa25db0b24e84470e8271309370e0f8093463ddd",
    "change_groups": [
      {
        "summary": "Tighten TxnSlot acquisition safety: seed claiming_timestamp via CAS after slot claim; document publish-phase CAS to detect cleanup reclaim.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "Phase 3 publish uses CAS(TXN_ID_CLAIMING -> real_txn_id); store is forbidden"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot"
        ]
      },
      {
        "summary": "Expand ARC implementation guidance and ensure REPLACE terminates: treat prefer_t1 as a hint and fall back to the other list when preferred list is exhausted.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.78,
        "evidence": [
          "prefer_t1 is a hint, not a mandate; fallback to other list to ensure termination"
        ],
        "changed_headings": [
          "ARC Cache"
        ]
      },
      {
        "summary": "Adopt NGQP-style beam search join ordering for V1 (mxChoice bounded best-first search) and remove the exhaustive/greedy split narrative.",
        "categories": [
          2,
          4,
          7
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "Maintain up to mxChoice best partial join paths; no N! exhaustive path"
        ],
        "changed_headings": [
          "Join Ordering"
        ]
      }
    ]
  },
  {
    "commit": "1d8bbfb40fa7a1fe90e710b593dfa2b3e9113c2d",
    "change_groups": [
      {
        "summary": "Make TxnSlot publish phase robust against cleanup races: publish real TxnId via CAS so a reclaimed slot can\"t be silently overwritten.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "if !slot.txn_id.CAS(TXN_ID_CLAIMING, real_txn_id): restart_slot_acquire()"
        ],
        "changed_headings": [
          "TxnSlot acquire protocol"
        ]
      },
      {
        "summary": "Correct beam-search complexity statement to reflect bounded worst-case candidate expansions (~O(mxChoice*N^2)).",
        "categories": [
          1,
          2
        ],
        "primary_category": 1,
        "confidence": 0.8,
        "evidence": [
          "Complexity: worst-case ~O(mxChoice * N^2) candidate expansions"
        ],
        "changed_headings": [
          "Join Ordering"
        ]
      }
    ]
  },
  {
    "commit": "4432a3daa2f875bc2d3fe47caf783b3eb286ebfe",
    "change_groups": [
      {
        "summary": "Make snapshots self-consistent across (commit_seq, schema_epoch) and enforce schema-epoch publication ordering to prevent mixed-schema rebase.",
        "categories": [
          4,
          1,
          7
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "load_consistent_snapshot() reads commit_seq twice around schema_epoch"
        ],
        "changed_headings": [
          "5.4 BEGIN",
          "Memory ordering"
        ]
      },
      {
        "summary": "Replace toy WAL timing constants with measured distributions (fsync dominates); require histograms and policy-driven batching; add I/O-stall semantics that prefer safety over liveness.",
        "categories": [
          7,
          6,
          4
        ],
        "primary_category": 7,
        "confidence": 0.8,
        "evidence": [
          "T_wal = T_wal_write + T_fsync + T_wal_overhead; fsync can be multi-ms",
          "Coordinator MUST record histogram of T_fsync"
        ],
        "changed_headings": [
          "Group Commit",
          "Cancellation Safety"
        ]
      },
      {
        "summary": "Add a normative conformance mode matrix: fixtures must declare required operating modes (compatibility/native) and CI must check both against Oracle and each other.",
        "categories": [
          6,
          4,
          5
        ],
        "primary_category": 6,
        "confidence": 0.8,
        "evidence": [
          "Fixture field: fsqlite_modes: [\"compatibility\",\"native\"] (default both)"
        ],
        "changed_headings": [
          "Harness",
          "Mode matrix"
        ]
      }
    ]
  },
  {
    "commit": "aa8e81601a80b6910a3791490d07c5691b517850",
    "change_groups": [
      {
        "summary": "Tighten serialized-mode correctness: add FCW freshness validation (reader-turned-writer stale snapshot must abort) and simplify commit sequencing in the COMMIT table.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "Commit (Serialized): FCW freshness validation still required; abort with SQLITE_BUSY_SNAPSHOT"
        ],
        "changed_headings": [
          "5.4 COMMIT semantics"
        ]
      },
      {
        "summary": "Harden open-sequence invariants: initialize and reconcile shm.schema_epoch from durable schema cookie/manifest and forbid shared-memory schema_epoch ahead of durable reality.",
        "categories": [
          4,
          2
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "On open: set shm.schema_epoch to durable schema cookie (offset 40)"
        ],
        "changed_headings": [
          "SharedMemoryLayout",
          "Schema epoch"
        ]
      },
      {
        "summary": "Refine rebase read-footprint semantics: footprint.reads captures non-replayable blocking reads; uniqueness checks for written keys are revalidated during replay and must not be recorded as blocking reads.",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "Do NOT include uniqueness checks in footprint.reads; re-validated during replay"
        ],
        "changed_headings": [
          "IntentFootprint"
        ]
      }
    ]
  },
  {
    "commit": "0a8d8676ac74f994535eceaa1c6c47cb17868038",
    "change_groups": [
      {
        "summary": "Make TxnSlot crash cleanup retryable: add cleanup_txn_id, broaden claiming_timestamp to sentinel states, and define release_page_locks_for(txn_id) for crashed writers.",
        "categories": [
          1,
          7,
          4
        ],
        "primary_category": 1,
        "confidence": 0.9,
        "evidence": [
          "cleanup_txn_id preserves the original TxnId under TXN_ID_CLEANING so crash cleanup can be retried safely.",
          "release_page_locks_for(txn_id) scans SharedPageLockTable and CASes owner_txn from txn_id to 0 without clearing the key.",
          "claiming_timestamp now tracks time spent in sentinel states (CLAIMING/CLEANING) for stuck-slot detection."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "5.6.3 SharedPageLockTable",
          "5.8 Conflict Detection and Resolution Detail"
        ]
      },
      {
        "summary": "Reconcile single-process vs multi-process lock semantics: SharedPageLockTable is canonical in Concurrent mode; in-process lock tables are reference-only; resolve() must materialize committed versions from durable storage when caches are stale.",
        "categories": [
          4,
          7,
          9
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "Cross-process writer exclusion is enforced via SharedPageLockTable in shm (not a per-process HashMap).",
          "InProcessPageLockTable is permitted only as a single-process reference implementation / unit-test harness.",
          "resolve(pgno, snapshot) consults WAL/marker stream to materialize committed versions when the in-process version chain cache is missing or stale."
        ],
        "changed_headings": [
          "MVCC resolve()",
          "5.4 COMMIT semantics",
          "5.6.3 SharedPageLockTable"
        ]
      },
      {
        "summary": "Tighten deterministic rebase correctness: treat existence/uniqueness probes as blocking reads for branchy conflict policies (OR IGNORE/REPLACE/UPSERT) unless the chosen branch is encoded in intent.",
        "categories": [
          4,
          2,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "For OR IGNORE/REPLACE/UPSERT, probes can change observable behavior; replay must not silently take a different branch.",
          "Until intent encodes the chosen branch, V1 deterministic rebase requires recording the probe in footprint.reads (blocking) or forbids the op."
        ],
        "changed_headings": [
          "5.10.2 Deterministic Rebase",
          "IntentFootprint"
        ]
      },
      {
        "summary": "Correct schema-cookie assumptions: the SQLite schema cookie is a 32-bit counter modulo 2^32; merge safety requires equality checks, not numeric monotonicity.",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.78,
        "evidence": [
          "SQLite schema cookie increments modulo 2^32; numeric decreases are not necessarily corruption.",
          "For safety we require schema cookie equality across participants; any change must produce a different cookie."
        ],
        "changed_headings": [
          "Schema epoch / schema cookie"
        ]
      }
    ]
  },
  {
    "commit": "3d568547fd6b8036481df0d73a2c60b5bf30d5a7",
    "change_groups": [
      {
        "summary": "Scrivening + minor clarification: normalize Vfs trait doc formatting and refine cleanup_txn_id comments (ignored unless txn_id==TXN_ID_CLEANING; should be zeroed on free).",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.96,
        "evidence": [
          "Reindent Vfs trait docs for consistent Rustdoc rendering.",
          "cleanup_txn_id is meaningful only when txn_id==TXN_ID_CLEANING; otherwise ignored; must be zeroed when freeing the slot."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "VFS trait"
        ]
      }
    ]
  },
  {
    "commit": "4c07e10c56ee30db5d03453237ae6c29c31a7cf0",
    "change_groups": [
      {
        "summary": "Clarify deterministic rebase semantics for rowid reuse: re-execution is defined on the semantic key (rowid); reused rowids can be updated and this matches commit-time serial order semantics.",
        "categories": [
          2,
          9,
          4
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "SQLite rowids may be reused unless AUTOINCREMENT is used.",
          "Deterministic rebase is merge-by-reexecution on the semantic key; a delete/insert that reuses a rowid can cause replay to update the new row at that key."
        ],
        "changed_headings": [
          "5.10.2 Deterministic Rebase"
        ]
      },
      {
        "summary": "Harden page-encryption metadata + AAD rules: define stable DatabaseId, keep AAD independent of encrypted bytes (no circular dependencies), and allow optional pre-decrypt page_context_tag only when known.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "DatabaseId is generated once and remains stable across the database lifetime including PRAGMA rekey.",
          "AAD inputs must be known before decryption; do not derive AAD from encrypted page bytes such as B-tree flags.",
          "Optional page_context_tag is permitted only when known pre-decrypt; otherwise use a fixed constant."
        ],
        "changed_headings": [
          "Page Encryption",
          "AAD (swap resistance)"
        ]
      },
      {
        "summary": "Ministerial cleanup: normalize indentation in VersionArena / ARC prose blocks and sharpen reserved-space checksum interoperability wording.",
        "categories": [
          5,
          9,
          2
        ],
        "primary_category": 5,
        "confidence": 0.76,
        "evidence": [
          "Normalize indentation in long code-comment blocks for readability.",
          "Clarify that C SQLite can read reserved-space checksums (reserved bytes are opaque) but default remains OFF for interoperability."
        ],
        "changed_headings": [
          "VersionArena",
          "ARC/CAR",
          "Reserved-space checksums"
        ]
      }
    ]
  },
  {
    "commit": "df0313b00f2854929c376434c56129ef6e2740e0",
    "change_groups": [
      {
        "summary": "Scrivening: fix ARC/CAR commentary indentation so rendered docs align with surrounding prose.",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.99,
        "evidence": [
          "Indentation-only change in ARC/CAR explanatory comments."
        ],
        "changed_headings": [
          "ARC/CAR"
        ]
      }
    ]
  },
  {
    "commit": "97df1f07893def20701570db65418ff75ed45656",
    "change_groups": [
      {
        "summary": "Clarify what 'zero-copy' means in this spec: no extra heap allocations or staging copies in hot paths, but not kernel-bypass I/O; small stack buffers are allowed.",
        "categories": [
          9,
          6
        ],
        "primary_category": 9,
        "confidence": 0.9,
        "evidence": [
          "Zero-copy excludes userspace staging buffers/allocations, not buffered syscalls.",
          "Fixed-size header stack buffers are permitted."
        ],
        "changed_headings": [
          "1.5 Hot-path constraints"
        ]
      }
    ]
  },
  {
    "commit": "bbc4a3114572200d7a8a674eb3a4e430ae1d0b47",
    "change_groups": [
      {
        "summary": "Define canonical page-encryption AAD bytes: be_u32(page_number) || database_id_bytes; forbid native-endian encodings for cross-endian opens.",
        "categories": [
          4,
          7,
          5
        ],
        "primary_category": 4,
        "confidence": 0.92,
        "evidence": [
          "aad = be_u32(page_number) || database_id_bytes (normative).",
          "Native-endian integer encoding is forbidden for AAD (cross-endian open must work)."
        ],
        "changed_headings": [
          "Page Encryption",
          "AAD (swap resistance)"
        ]
      }
    ]
  },
  {
    "commit": "4363f50065239e47d56f12250d933f5a1ab75a00",
    "change_groups": [
      {
        "summary": "Add a cross-cutting 'Critical Implementation Controls' checklist to make corruption/deadlock-sensitive invariants impossible to miss.",
        "categories": [
          6,
          7,
          4
        ],
        "primary_category": 6,
        "confidence": 0.88,
        "evidence": [
          "Hybrid SHM interop requires legacy WAL_READ_LOCK/WAL_WRITE_LOCK protocol (not just layout).",
          "Witness instrumentation must be semantic/sub-page for point ops (avoid whole-page reads that collapse merge/rebase).",
          "RaptorQ repair generation must be off the commit critical path; rebuild quiescence is 'no lock holders', not 'no txns'."
        ],
        "changed_headings": [
          "1.6 Critical Implementation Controls (Non-Negotiable)"
        ]
      },
      {
        "summary": "Tighten TxnSlot cleanup: stamp a fresh sentinel-time when transitioning into TXN_ID_CLEANING so stuck-cleaner detection measures time in CLEANING (not inherited CLAIMING time).",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.84,
        "evidence": [
          "On CAS into TXN_ID_CLEANING, set claiming_timestamp = now to start the CLEANING timeout window.",
          "Overwrite stale CLAIMING timestamps when entering CLEANING."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot cleanup"
        ]
      }
    ]
  },
  {
    "commit": "d9021cffb65692624f3990ae2544a96ae0c07021",
    "change_groups": [
      {
        "summary": "Clarification pass: make rowid reuse semantics explicit as a serial-order effect for deterministic rebase, and define DatabaseId precisely as 16 opaque bytes stable across rekey.",
        "categories": [
          9,
          2,
          4
        ],
        "primary_category": 9,
        "confidence": 0.9,
        "evidence": [
          "Rowid reuse is expected: replay matches serial order (delete/insert then update) rather than implying corruption.",
          "DatabaseId is 16 opaque bytes (not host-endian integer) and must remain stable across PRAGMA rekey."
        ],
        "changed_headings": [
          "5.10.2 Deterministic Rebase",
          "Page Encryption"
        ]
      }
    ]
  },
  {
    "commit": "29107df6b155bb20934ef369b934699191076b32",
    "change_groups": [
      {
        "summary": "Draw a hard durability boundary: ARC eviction is memory-only and MUST NOT append to .wal; only the write coordinator may append WAL frames, with large write sets spilled to per-txn temp files.",
        "categories": [
          4,
          7,
          1
        ],
        "primary_category": 4,
        "confidence": 0.9,
        "evidence": [
          "ARC eviction MUST NOT append to .wal; legacy WAL commit markers assume coordinator-only contiguous appends.",
          "Uncommitted/private page images live in txn write_set and are spillable to a per-txn spill file in Compatibility mode."
        ],
        "changed_headings": [
          "6.6 Eviction: Pinned Pages and Durability Boundaries",
          "5.9.2 Write-set spill"
        ]
      },
      {
        "summary": "Simplify ARC REQUEST/REPLACE behavior around pinned pages: remove flush-dirty loops, allow temporary over-capacity as a safety valve when all candidates are pinned, and update resize protocol accordingly.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.82,
        "evidence": [
          "Eviction scans skip only pinned pages (ref_count > 0); durability I/O is not part of eviction.",
          "When all pages are pinned, permit bounded capacity overflow rather than spinning forever."
        ],
        "changed_headings": [
          "6.4 Full ARC Algorithm: REQUEST Subroutine",
          "6.6 Eviction: Pinned Pages and Durability Boundaries"
        ]
      },
      {
        "summary": "Clarify interoperability boundary for encryption: encrypted databases are not readable by stock C SQLite; fail closed rather than attempting legacy interop on ciphertext pages.",
        "categories": [
          9,
          2,
          4
        ],
        "primary_category": 9,
        "confidence": 0.78,
        "evidence": [
          "Encrypted databases are not readable by stock C SQLite; compatibility interop applies only to plaintext.",
          "If encryption is enabled, FrankenSQLite fails closed rather than letting legacy clients treat ciphertext as page bytes."
        ],
        "changed_headings": [
          "Page Encryption",
          "Compatibility mode interoperability"
        ]
      }
    ]
  },
  {
    "commit": "f708f338cb6e435db3822e2aa81b2785b51bf39b",
    "change_groups": [
      {
        "summary": "Clarify pipelined WAL-FEC semantics: commits can be durable before they are repairable; if wal-fec metadata is missing at recovery, fall back to SQLite truncation semantics; optional synchronous mode can require immediate repairability.",
        "categories": [
          7,
          4,
          9
        ],
        "primary_category": 7,
        "confidence": 0.86,
        "evidence": [
          "Eventual repairability: a group is repairable only once WalFecGroupMeta + repair symbols are durable.",
          "If wal-fec metadata is missing, recovery truncates before the affected group (SQLite semantics).",
          "An opt-in synchronous mode may wait for wal-fec fsync before acknowledging COMMIT."
        ],
        "changed_headings": [
          "3.4.1 Self-Healing WAL (Erasure-Coded Durability)"
        ]
      },
      {
        "summary": "Specify Compatibility-mode write-set spilling and coordinator-only WAL append: introduce CommitWriteSet (Inline vs Spilled) and PRAGMA fsqlite.txn_write_set_mem_bytes with a bounded auto default.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.88,
        "evidence": [
          "CommitRequest.write_set becomes CommitWriteSet::Inline(...) or CommitWriteSet::Spilled(...).",
          "Spill files are temporary and explicitly not durability / crash recovery.",
          "Auto spill threshold: clamp(4 * cache.max_bytes, 32 MiB, 512 MiB).",
          "Only the write coordinator may append to .wal to avoid interleaving corruption."
        ],
        "changed_headings": [
          "5.9.2 Write Coordinator",
          "6.6 Eviction: Pinned Pages and Durability Boundaries"
        ]
      },
      {
        "summary": "Add a V1 rule for OP_NewRowid under concurrent writers: allocate rowids from a snapshot-independent per-table allocator and record the concrete RowId in the Insert intent at execution time.",
        "categories": [
          4,
          2,
          7
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "Concurrent mode cannot use max(rowid)+1 per snapshot; writers would collide.",
          "RowId must come from a global allocator and be stable for statement/transaction (preserves last_insert_rowid/RETURNING)."
        ],
        "changed_headings": [
          "5.10.1.1 RowId Allocation in Concurrent Mode (Avoid the Pre-Binding Trap)"
        ]
      }
    ]
  },
  {
    "commit": "a71e1d95715c1190335e8738413382b31b6d167c",
    "change_groups": [
      {
        "summary": "Correct the RFC 6330 LDPC constraint description: each source column updates exactly three LDPC rows using stride a=1+floor(j/S), implying total nonzeros=3*K'.",
        "categories": [
          1,
          6
        ],
        "primary_category": 1,
        "confidence": 0.82,
        "evidence": [
          "For j in 0..K'-1: a=1+floor(j/S); b=j%S; set A[b][j]=1 then advance b=(b+a)%S twice more.",
          "Each source column contributes exactly 3 nonzeros; average LDPC row has ~3*K'/S nonzeros."
        ],
        "changed_headings": [
          "RaptorQ LDPC rows",
          "RFC 6330 §5.3.3.3"
        ]
      },
      {
        "summary": "Harden WAL-FEC metadata + recovery: require per-source xxh3_128 validation hashes, add SQLite fallback when wal-fec is missing, and widen OTI.T to u32 to represent page_size=65536 with explicit corruption invariants.",
        "categories": [
          4,
          7,
          1
        ],
        "primary_category": 4,
        "confidence": 0.9,
        "evidence": [
          "If wal-fec metadata is missing for a torn group, recovery falls back to SQLite truncation semantics.",
          "WalFecGroupMeta stores source_page_xxh3_128: Vec<[u8;16]> for random-access validation.",
          "OTI.T is widened to u32 so symbol_size can equal page_size=65536; mismatches are treated as corruption."
        ],
        "changed_headings": [
          "3.4.1 Self-Healing WAL",
          "WalFecGroupMeta",
          "SymbolRecord / OTI"
        ]
      },
      {
        "summary": "Make ECS root pointer updates truly crash-safe: fsync temp file before rename and fsync the directory after rename to persist the rename itself.",
        "categories": [
          7,
          1
        ],
        "primary_category": 7,
        "confidence": 0.88,
        "evidence": [
          "Crash-safe sequence: write temp, fsync(temp), rename(temp, ecs/root), fsync(directory).",
          "Omitting fsync(temp) risks garbage content; omitting fsync(dir) risks losing the rename after crash."
        ],
        "changed_headings": [
          "ECS directory layout",
          "ecs/root"
        ]
      },
      {
        "summary": "Fix TxnSlot cleanup race: snapshot txn_id once per slot iteration (Acquire load) to avoid branching on multiple unsynchronized reads while sentinels are changing.",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.86,
        "evidence": [
          "Snapshot txn_id once: tid = slot.txn_id.load(Acquire); skip tid==0 early.",
          "Avoid freeing a slot while another cleaner is still releasing locks due to inconsistent reads of sentinel states."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot cleanup"
        ]
      },
      {
        "summary": "Clarify ESCAPE handling in the Pratt parser: ESCAPE is not an infix operator; it is parsed as an optional suffix of LIKE/GLOB/MATCH productions (parse.y %right ESCAPE is for Lemon conflict resolution).",
        "categories": [
          2,
          9,
          5
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "ESCAPE is parsed inside the LIKE/GLOB handler after the pattern expression, not in the infix dispatch table.",
          "C SQLite declares %right ESCAPE for conflict resolution, but it is not a standalone expression operator."
        ],
        "changed_headings": [
          "SQL operator precedence",
          "LIKE/GLOB ESCAPE handling"
        ]
      }
    ]
  },
  {
    "commit": "120eee252b4caa7fe6389602bd2c8a316c6cee2a",
    "change_groups": [
      {
        "summary": "Correct GF(256) elimination language: use nonzero pivot selection (no rounding error over fields), avoiding misleading 'partial pivoting' phrasing.",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.9,
        "evidence": [
          "Over exact fields, pivot choice is simply selecting any nonzero pivot; numerical stability concerns do not apply."
        ],
        "changed_headings": [
          "GF(256) Gaussian solve"
        ]
      },
      {
        "summary": "Strengthen random-access WAL-FEC source-frame validation: compute xxh3_128(page_data) and compare against source_page_xxh3_128 before feeding symbols into the decoder.",
        "categories": [
          7,
          4,
          1
        ],
        "primary_category": 7,
        "confidence": 0.88,
        "evidence": [
          "Validate candidate frames with xxh3_128 and compare to WalFecGroupMeta.source_page_xxh3_128.",
          "Random-access validation remains valid even when the cumulative WAL checksum chain is broken."
        ],
        "changed_headings": [
          "3.4.1 Self-Healing WAL",
          "WAL recovery"
        ]
      }
    ]
  },
  {
    "commit": "975f65c78a5745424665a95f0c222287306c9dd5",
    "change_groups": [
      {
        "summary": "Clarify GF(256) elimination commentary: in exact fields there is no rounding error, so the pivot rule is nonzero selection, not numerical 'partial pivoting'.",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.9,
        "evidence": [
          "Explicitly note that pivoting is for finding a nonzero pivot; there is no floating-point stability issue over GF(256)."
        ],
        "changed_headings": [
          "GF(256) Gaussian elimination"
        ]
      },
      {
        "summary": "Add replication endianness boundary note: UDP packet headers use big-endian network order, while the decoded changeset payload uses little-endian per canonical encoding rules.",
        "categories": [
          6,
          7
        ],
        "primary_category": 6,
        "confidence": 0.84,
        "evidence": [
          "Replication packet header fields are big-endian; the boundary is symbol_data, whose decoded changeset payload is little-endian."
        ],
        "changed_headings": [
          "UDP Packet Format",
          "Canonical encodings"
        ]
      },
      {
        "summary": "Bound version-chain delta reconstruction cost and clarify ECS root file format: chain depth is kept small by GC scheduling targets, and ecs/root includes a magic+version prefix with manifest id + checksum.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.86,
        "evidence": [
          "Reconstructing the oldest version in a chain of depth L requires L-1 sequential delta applications; GC scheduling targets depth ~8.",
          "ecs/root contains: magic (\"FSRT\"), version, manifest_object_id, checksum."
        ],
        "changed_headings": [
          "Version chain deltas",
          "ECS root file format"
        ]
      }
    ]
  },
  {
    "commit": "24b6f60e9e751b699cb232759d85a06c42792019",
    "change_groups": [
      {
        "summary": "Fix GC scheduling cross-references: point Theorem-5 discussion at the GC scheduling policy section (5.6.5), not the lock-table section.",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.95,
        "evidence": [
          "Replace incorrect §5.6.3 references with §5.6.5 for GC scheduling policy citations."
        ],
        "changed_headings": [
          "GC scheduling policy",
          "Theorem 5 discussion"
        ]
      }
    ]
  },
	  {
	    "commit": "80decf6b8ba71dd4331f559a08ee0fba3fbdf4bb",
	    "change_groups": [
	      {
        "summary": "Clarify .db-fec generation binding and repair terminology: specify db_gen_digest derivation inputs, use RFC 6330 ESI naming for symbols, and make commit_time_unix_ns monotonicity enforcement explicit.",
        "categories": [
          9,
          5,
          1,
          7
        ],
        "primary_category": 9,
        "confidence": 0.86,
        "evidence": [
          "db_gen_digest comment now specifies Trunc128(BLAKE3(\"fsqlite:compat:dbgen:v1\" || change_counter || page_count || freelist_count || schema_cookie)) with big-endian u32 reads from header offsets.",
          "Repair pseudocode switches from ISI to ESI terminology and uses repair_rec.esi rather than deriving ids from loop indices.",
          "Binary-search-by-time note now cites the protocol rule: commit_time_unix_ns := max(now_unix_ns(), last_commit_time_unix_ns + 1)."
        ],
        "changed_headings": [
          "Compatibility DB-FEC",
          "Repair pseudocode",
          "Commit protocol time"
        ]
	      }
	    ]
	  },
	  {
	    "commit": "7cc726325faa5cad71d2132480cbb68fb046563d",
	    "change_groups": [
	      {
	        "summary": "Add `.db-fec` freshness and foreign-sidecar guardrails: define db_gen_digest derivation from DB header, require digest match before using repair symbols, and make the .db-fec header update the commit record (fsync-ordered).",
	        "categories": [
	          7,
	          1,
	          2,
	          4
	        ],
	        "primary_category": 7,
	        "confidence": 0.85,
	        "evidence": [
	          "Verify DbFecHeader.checksum and require db_gen_digest_current == DbFecHeader.db_gen_digest before using any .db-fec metadata.",
	          "If repairing page 1, recompute digest from repaired bytes; mismatch fails closed (SQLITE_CORRUPT).",
	          "Checkpoint must fsync .db, then write db_gen_digest + header checksum, then fsync .db-fec before WAL RESTART/TRUNCATE."
	        ],
	        "changed_headings": [
	          "Compatibility DB-FEC",
	          "DbFecHeader",
	          "DbFecGroupMeta"
	        ]
	      },
	      {
	        "summary": "Harden shared-memory coordination: introduce snapshot_seq seqlock for consistent snapshot capture, add serialized-writer indicator fields (token/pid/lease), and define a stale-indicator clearing algorithm for concurrent writers.",
	        "categories": [
	          4,
	          7,
	          1
	        ],
	        "primary_category": 4,
	        "confidence": 0.8,
	        "evidence": [
	          "SharedMemoryLayout gains snapshot_seq (odd/even seqlock) plus serialized_writer_token/pid/pid_birth/lease_expiry.",
	          "Snapshot publish protocol specified: even -> odd -> even around backbone field stores; openers repair crash-stale odd values.",
	          "Concurrent writers check indicator and may clear stale tokens after lease expiry / owner death."
	        ],
	        "changed_headings": [
	          "5.6.1 Shared-Memory Coordination Region",
	          "Serialized writer acquisition ordering"
	        ]
	      },
	      {
	        "summary": "Replace constant TxnSlot sentinels with a tagged txn_id word to prevent ABA claim/cleanup races; update cleanup_orphaned_slots and gc_horizon logic to treat sentinel-tagged slots as blockers.",
	        "categories": [
	          4,
	          1,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.85,
	        "evidence": [
	          "TxnSlot.txn_id reserves the top 2 bits as a tag: Active/CLAIMING/CLEANING; Phase 1 uses claim_word=encode_claiming(txn_id).",
	          "Phase 3 publish is CAS(claim_word -> real_txn_id); claim timestamps are cleared after publish.",
	          "cleanup_orphaned_slots branches on decode_tag(tid) and transitions to encode_cleaning(payload)."
	        ],
	        "changed_headings": [
	          "5.6.2 TxnSlot",
	          "cleanup_orphaned_slots()",
	          "raise_gc_horizon()"
	        ]
	      },
	      {
	        "summary": "Make recently-committed-readers summaries cross-process stable: specify a fixed-layout SHM ring with a per-entry Bloom filter (fail-closed on overflow) instead of RoaringBitmap-in-SHM.",
	        "categories": [
	          7,
	          4
	        ],
	        "primary_category": 7,
	        "confidence": 0.78,
	        "evidence": [
	          "RecentlyCommittedReadersRing lives at committed_readers_offset and uses commit_seq as a publication word (0=unpublished).",
	          "Each entry includes a 4096-bit Bloom filter with k=3 probes over pgno (xxh3_64 domain-separated).",
	          "If inserting would evict an entry with commit_seq > gc_horizon, the committer aborts with SQLITE_BUSY_SNAPSHOT (no false negatives)."
	        ],
	        "changed_headings": [
	          "RecentlyCommittedReadersRing",
	          "Committed readers index"
	        ]
	      },
	      {
	        "summary": "Redesign shared page-lock rebuild as a rolling rotate+drain protocol using two tables (active+draining) to avoid stop-the-world abort storms; update acquire/release/crash-cleanup to consult both tables.",
	        "categories": [
	          4,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.8,
	        "evidence": [
	          "SharedPageLockTable gains active_table/draining_table and two LockTableInstance tables.",
	          "try_acquire consults draining table first for idempotent re-acquire and conflict detection; release probes both tables.",
	          "Rebuild rotates quickly, drains in background, and clears only after lock-quiescence; capacity defaults to 1,048,576 entries."
	        ],
	        "changed_headings": [
	          "5.6.3.1 Table Rebuild",
	          "SharedPageLockTable"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "9ad50ae2a2c7fce76a75d1200e22374eb729914d",
	    "change_groups": [
	      {
	        "summary": "Specify the coordinator IPC transport for multi-process deployments: Unix domain sockets, framed messages, two-phase reserve/submit discipline, SCM_RIGHTS spill-fd passing, and TxnToken idempotency.",
	        "categories": [
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.82,
	        "evidence": [
	          "Defines socket endpoints, permissions, and peer credential checks (UID) for coordinator IPC.",
	          "Framing: len_be + version/kind/request_id + payload; RESERVE returns permit_id or BUSY; SUBMIT_* binds to permit_id.",
	          "Large write sets are passed via spill fd using SCM_RIGHTS; duplicates keyed by (txn_id, txn_epoch) are idempotent."
	        ],
	        "changed_headings": [
	          "5.9.0 Coordinator IPC Transport"
	        ]
	      },
	      {
	        "summary": "Make snapshot capture explicitly seqlock-based: load_consistent_snapshot reads snapshot_seq, retries on odd or change, and returns a self-consistent (commit_seq, schema_epoch) pair.",
	        "categories": [
	          4,
	          1,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Read s1=snapshot_seq; if odd retry; read commit_seq + schema_epoch; read s2; accept only if s1==s2 and even.",
	          "Cross-process snapshot correctness is now specified as a seqlock read, not two commit_seq loads."
	        ],
	        "changed_headings": [
	          "Snapshot capture",
	          "load_consistent_snapshot()"
	        ]
	      },
	      {
	        "summary": "Clarify in-process vs cross-process commit schemas and harden spill semantics: use OwnedFd for spill transfer, allow optional diagnostic path, and recommend unlink-after-open for crash robustness.",
	        "categories": [
	          7,
	          4,
	          6
	        ],
	        "primary_category": 7,
	        "confidence": 0.75,
	        "evidence": [
	          "Adds normative notes: cross-process routing MUST NOT attempt to transmit Vec/HashMap/oneshot through shared memory.",
	          "SpilledWriteSet carries an OwnedFd; cross-process commits MUST use CommitWriteSet::Spilled with SCM_RIGHTS fd passing.",
	          "Recommends creator unlink spill file after open so cleanup is automatic on crash."
	        ],
	        "changed_headings": [
	          "CommitRequest (compatibility/WAL)",
	          "Write-set spilling"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "19106d19e531ea75918241b2858024c34a73f037",
	    "change_groups": [
	      {
	        "summary": "Expand and harden the TxnSlot acquire/publish protocol: make the 3-phase claim/init/publish sequence explicit and require begin_seq/snapshot_high derive from a self-consistent snapshot (seqlock).",
	        "categories": [
	          4,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.82,
	        "evidence": [
	          "acquire_and_publish_txn_slot() wraps claim (CAS 0->claim_word), initializes slot fields, captures snap via load_consistent_snapshot, then publishes real TxnId via CAS(claim_word->txn_id).",
	          "Clears claiming_timestamp after publish to avoid polluting stuck-cleaner detection."
	        ],
	        "changed_headings": [
	          "TxnSlot acquire protocol",
	          "5.6.2 TxnSlot"
	        ]
	      },
	      {
	        "summary": "Fix write_page idempotency for cross-process hints: only increment write_set_pages on first lock acquisition per page; clarify hints are not correctness sources of truth.",
	        "categories": [
	          1,
	          7
	        ],
	        "primary_category": 1,
	        "confidence": 0.8,
	        "evidence": [
	          "Guard write_set_pages.fetch_add(1) behind `newly_locked` to prevent inflated counts on repeated writes to the same page.",
	          "States explicitly that lock tables, not write_set_pages, are the correctness source of truth."
	        ],
	        "changed_headings": [
	          "write_page()"
	        ]
	      },
	      {
	        "summary": "SHM layout hardening: define layout_checksum over immutable metadata only; forbid unsafe reinterpret casts in this repo; and state DDL publication ordering relies on snapshot_seq seqlock windows.",
	        "categories": [
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Renames header checksum -> layout_checksum and documents immutable-only coverage (magic/version/page_size/offsets), excluding dynamic atomics.",
	          "Adds normative safe-Rust constraint: SHM access uses safe offset-based accessors; no &[u8] -> &SharedMemoryLayout casts.",
	          "Clarifies mixed snapshots are prevented by snapshot_seq + load_consistent_snapshot, not store ordering alone."
	        ],
	        "changed_headings": [
	          "5.6.1 Shared-Memory Coordination Region",
	          "Alignment requirement"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "7313951174e317f889851f696de264b546e4b54e",
	    "change_groups": [
	      {
	        "summary": "Fix coordinator IPC framing math and add canonical V1 wire payload schemas (including strict size caps and exact SCM_RIGHTS rules).",
	        "categories": [
	          1,
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.8,
	        "evidence": [
	          "Frame.payload corrected from len_be-16 to len_be-12 (excluding the 4-byte length field itself).",
	          "Defines Reserve/SubmitNativePublish/SubmitWalCommit/RowIdReserve payload schemas + size caps; SUBMIT_WAL_COMMIT requires exactly one spill fd in SCM_RIGHTS.",
	          "CommitRequest identity updated to TxnToken for cross-process stability."
	        ],
	        "changed_headings": [
	          "Coordinator IPC Transport",
	          "Wire payload schemas"
	        ]
	      },
	      {
	        "summary": "Define coordinator-owned per-table RowId allocator state and ROWID_RESERVE semantics (schema_epoch validation, monotone non-reusable ranges, gaps permitted).",
	        "categories": [
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Allocator state lives in coordinator memory keyed by (schema_epoch, TableId), not in SQLite file format or a SHM hash table.",
	          "Initialize next_rowid from max_committed_rowid+1 (AUTOINCREMENT override); reject schema_epoch mismatch with SQLITE_SCHEMA.",
	          "Coordinator advances by count even if caller later aborts (gaps permitted)."
	        ],
	        "changed_headings": [
	          "ROWID_RESERVE",
	          "RowId allocator"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "d329df055a1a13459d0f507bc222b05525bb7522",
	    "change_groups": [
	      {
	        "summary": "Define serialized writer exclusion acquire/release pseudocode and ordering: acquire global exclusion, publish token/pid/lease, drain concurrent writers, and clear indicator before releasing the global exclusion.",
	        "categories": [
	          4,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Adds acquire_serialized_writer_exclusion/release_serialized_writer_exclusion with publication edge on serialized_writer_token (Release).",
	          "Drain concurrent writers via lock-table scan and orphan cleanup; clear token before releasing the global exclusion."
	        ],
	        "changed_headings": [
	          "Serialized writer acquisition ordering",
	          "Indicator check algorithm"
	        ]
	      },
	      {
	        "summary": "Make write_set_summary cross-process canonical (sorted u32_le array, no roaring dependency) and add response payload schemas for SUBMIT_NATIVE_PUBLISH and SUBMIT_WAL_COMMIT.",
	        "categories": [
	          4,
	          7,
	          1,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.74,
	        "evidence": [
	          "write_set_summary_len must be a multiple of 4; pages are sorted ascending with no duplicates.",
	          "Adds NativePublishRespV1 and WalCommitRespV1 Ok/Conflict/Err variants with explicit fields."
	        ],
	        "changed_headings": [
	          "Wire payload schemas",
	          "write_set_summary encoding"
	        ]
	      },
	      {
	        "summary": "Remove duplicate expression precedence table and centralize parsing rules: NOT precedence, ESCAPE not an operator, and unary-vs-COLLATE binding.",
	        "categories": [
	          2,
	          5,
	          9
	        ],
	        "primary_category": 2,
	        "confidence": 0.7,
	        "evidence": [
	          "12.15 now points to the normative Pratt precedence table in §10.2 instead of restating the full table.",
	          "Key rules reiterated: NOT x=y parses as NOT(x=y); ESCAPE is parsed as part of LIKE; unary binds tighter than COLLATE."
	        ],
	        "changed_headings": [
	          "12.15 Expression Syntax",
	          "Pratt precedence table"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "351c282e9a9a2ee118496651cef7a4b33cf309f2",
	    "change_groups": [
	      {
	        "summary": "Apply the no-unsafe constraint to aligned allocation: require safe page-aligned buffers and make PageBuf explicitly page-sized + page-aligned in both the I/O model and formal type definitions.",
	        "categories": [
	          7,
	          4,
	          6
	        ],
	        "primary_category": 7,
	        "confidence": 0.75,
	        "evidence": [
	          "Page alignment section now requires safe abstractions for aligned allocation (dependencies may use unsafe internally).",
	          "PageBuf/PageData and buffer model updated to state page-aligned explicitly."
	        ],
	        "changed_headings": [
	          "1.5 Mechanical Sympathy",
	          "4.10 PageBufferPool",
	          "Formal type definitions"
	        ]
	      },
	      {
	        "summary": "Fix TxnSlot acquire pseudocode: detect lost claim before seeding claiming_timestamp; clean up indentation and clarify omitted fields for brevity.",
	        "categories": [
	          1,
	          4,
	          5
	        ],
	        "primary_category": 1,
	        "confidence": 0.72,
	        "evidence": [
	          "After CAS(0->claim_word), re-load txn_id and require it still equals claim_word before writing claiming_timestamp.",
	          "Normalizes indentation and clarifies begin() pseudocode omits fields that default to empty/false."
	        ],
	        "changed_headings": [
	          "TxnSlot acquire protocol",
	          "acquire_and_publish_txn_slot()"
	        ]
	      }
	    ]
	  }
	];

      // -----------------------------
      // Buckets
      // -----------------------------

      const BUCKETS = [
        {
          id: 1,
          name: "Logic/Math Fixes",
          desc: "Fixing outright mistakes in logic, math, or reasoning.",
          color: getCss("--c1"),
        },
        {
          id: 2,
          name: "SQLite Legacy Corrections",
          desc: "Fixing inaccurate statements about the C SQLite codebase or semantics.",
          color: getCss("--c2"),
        },
        {
          id: 3,
          name: "asupersync Corrections",
          desc: "Fixing inaccurate statements about asupersync APIs or behavior.",
          color: getCss("--c3"),
        },
        {
          id: 4,
          name: "Architecture Fixes",
          desc: "Fixing conceptual errors or architectural mistakes.",
          color: getCss("--c4"),
        },
        {
          id: 5,
          name: "Scrivening",
          desc: "Ministerial fixes: numbering, references, footers, wording cleanup.",
          color: getCss("--c5"),
        },
        {
          id: 6,
          name: "Added Context",
          desc: "Added background information to make the spec more self-contained.",
          color: getCss("--c6"),
        },
        {
          id: 7,
          name: "Standard Engineering",
          desc: "Improvements based on standard computer engineering: cache, concurrency, I/O, durability mechanics.",
          color: getCss("--c7"),
        },
        {
          id: 8,
          name: "Alien Artifact Math",
          desc: "Esoteric math/rigor additions: e-processes, conformal, BOCPD, VOI, proofs, bounds.",
          color: getCss("--c8"),
        },
        {
          id: 9,
          name: "Clarification",
          desc: "Clarification/elaboration without substantive improvements or fixes.",
          color: getCss("--c9"),
        },
        {
          id: 10,
          name: "Other",
          desc: "Catch-all category.",
          color: getCss("--c10"),
        },
      ];

      // -----------------------------
      // App state
      // -----------------------------

      const STATE = {
        q: "",
        minImpact: 0,
        bucketMode: "primary", // 'primary' | 'multi'
        bucketEnabled: new Set(BUCKETS.map((b) => b.id)),
      };

      // -----------------------------
      // Spec evolution dataset (local)
      // -----------------------------

      const SPEC_EVOLUTION_DATA_URL = "spec_evolution_data_v1.json.gz";

      const DATASET = {
        data: null,
        loaded: false,
        error: null,
      };

      const DOC = {
        idx: 0,
        tab: "spec", // 'spec' | 'diff' | 'metrics'
        rawSpec: false,
        diffMode: "pretty", // 'pretty' | 'raw'
      };

      const METRICS = {
        // commit hash -> metric
        tokensChanged: new Map(),
        bytesChanged: new Map(),
        hunks: new Map(),
        lev: new Map(),
      };

      const DOC_CACHE = new Map(); // idx -> { text: string, lines?: string[] }

      const LEV_WASM_URL = "levenshtein_bytes.wasm";
      let LEV_WASM = null;

      // -----------------------------
      // Helpers
      // -----------------------------

      function getCss(varName) {
        return getComputedStyle(document.documentElement).getPropertyValue(varName).trim();
      }

      function clamp(n, lo, hi) {
        return Math.max(lo, Math.min(hi, n));
      }

      function escapeHtml(s) {
        return String(s)
          .replaceAll("&", "&amp;")
          .replaceAll("<", "&lt;")
          .replaceAll(">", "&gt;")
          .replaceAll('"', "&quot;")
          .replaceAll("'", "&#39;");
      }

      function fmtInt(n) {
        return Intl.NumberFormat(undefined).format(n);
      }

      function parseCommitLog() {
        const d = DATASET.data;
        if (d && Array.isArray(d.commits) && d.commits.length) {
          return d.commits.map((c, idx) => {
            return {
              idx,
              hash: c.hash,
              short: c.short,
              dateIso: c.dateIso,
              author: c.author,
              subject: c.subject,
              url: `https://github.com/Dicklesworthstone/frankensqlite/commit/${c.hash}`,
            };
          });
        }

        const rows = COMMIT_LOG_RAW.trim()
          .split("\n")
          .map((l) => l.trim())
          .filter(Boolean);
        return rows.map((r, idx) => {
          const [hash, short, dateIso, author, subject] = r.split("|").map((x) => x.trim());
          return {
            idx,
            hash,
            short,
            dateIso,
            author,
            subject,
            url: `https://github.com/Dicklesworthstone/frankensqlite/commit/${hash}`,
          };
        });
      }

      function parseCommitStats() {
        const d = DATASET.data;
        if (d && Array.isArray(d.commits) && d.commits.length) {
          const m = new Map();
          for (const c of d.commits) {
            const a = Number(c.add || 0);
            const del = Number(c.del || 0);
            m.set(c.hash, { add: a, del, impact: a + del });
          }
          return m;
        }

        const rows = COMMIT_STATS_RAW.trim()
          .split("\n")
          .map((l) => l.trim())
          .filter(Boolean);
        const m = new Map();
        for (const r of rows) {
          const [hash, add, del] = r.split("|").map((x) => x.trim());
          const a = Number(add || 0);
          const d = Number(del || 0);
          m.set(hash, { add: a, del: d, impact: a + d });
        }
        return m;
      }

      // -----------------------------
      // Dataset + WASM loading
      // -----------------------------

      async function gunzipArrayBufferToString(ab) {
        // Prefer native DecompressionStream; fall back to pako.
        if (typeof DecompressionStream !== "undefined") {
          const ds = new DecompressionStream("gzip");
          const decompressedStream = new Blob([ab]).stream().pipeThrough(ds);
          const buf = await new Response(decompressedStream).arrayBuffer();
          return new TextDecoder().decode(buf);
        }
        if (typeof pako !== "undefined" && pako?.ungzip) {
          return pako.ungzip(new Uint8Array(ab), { to: "string" });
        }
        throw new Error("No gzip decompressor available in this browser.");
      }

      async function loadEvolutionDataset() {
        try {
          const res = await fetch(SPEC_EVOLUTION_DATA_URL, { cache: "no-store" });
          if (!res.ok) throw new Error(`Failed to fetch ${SPEC_EVOLUTION_DATA_URL}: HTTP ${res.status}`);
          const ab = await res.arrayBuffer();
          const jsonText = await gunzipArrayBufferToString(ab);
          const data = JSON.parse(jsonText);
          if (!data || !Array.isArray(data.commits) || !Array.isArray(data.patches) || !data.base_doc) {
            throw new Error("Dataset schema mismatch (expected commits[], patches[], base_doc).");
          }
          DATASET.data = data;
          DATASET.loaded = true;
          DATASET.error = null;
          return true;
        } catch (e) {
          DATASET.error = String(e?.message || e);
          DATASET.loaded = false;
          return false;
        }
      }

      async function initLevWasm() {
        if (LEV_WASM) return LEV_WASM;
        const res = await fetch(LEV_WASM_URL, { cache: "force-cache" });
        if (!res.ok) throw new Error(`Failed to fetch ${LEV_WASM_URL}: HTTP ${res.status}`);
        const buf = await res.arrayBuffer();
        const { instance } = await WebAssembly.instantiate(buf, {});
        LEV_WASM = instance.exports;
        return LEV_WASM;
      }

      async function levenshteinBytes(aBytes, bBytes) {
        const ex = await initLevWasm();
        const { memory, alloc, dealloc, levenshtein } = ex;
        if (!memory || !alloc || !dealloc || !levenshtein) {
          throw new Error("WASM exports missing (expected memory/alloc/dealloc/levenshtein).");
        }

        const a = aBytes || new Uint8Array();
        const b = bBytes || new Uint8Array();

        const ptrA = alloc(a.length);
        let viewA = new Uint8Array(memory.buffer, ptrA, a.length);
        viewA.set(a);

        const ptrB = alloc(b.length);
        let viewB = new Uint8Array(memory.buffer, ptrB, b.length);
        viewB.set(b);

        const d = levenshtein(ptrA, a.length, ptrB, b.length) >>> 0;

        dealloc(ptrA, a.length);
        dealloc(ptrB, b.length);

        return d;
      }

      // -----------------------------
      // Unified diff helpers (single-file)
      // -----------------------------

      function countRoughTokens(s) {
        // Approximate tokens for visualization: words + punctuation runs.
        let n = 0;
        const re = /[A-Za-z0-9_]+|[^\\s]/g;
        while (re.exec(String(s))) n++;
        return n;
      }

      function quickMetricsFromPatch(patch) {
        const lines = String(patch || "").split("\n");
        let hunks = 0;
        let addLines = 0;
        let delLines = 0;
        let tokAdd = 0;
        let tokDel = 0;
        let bytesAdd = 0;
        let bytesDel = 0;
        for (const l of lines) {
          if (l.startsWith("@@")) hunks += 1;
          if (l.startsWith("+")) {
            if (l.startsWith("+++")) continue;
            addLines += 1;
            const s = l.slice(1);
            tokAdd += countRoughTokens(s);
            bytesAdd += s.length + 1;
          } else if (l.startsWith("-")) {
            if (l.startsWith("---")) continue;
            delLines += 1;
            const s = l.slice(1);
            tokDel += countRoughTokens(s);
            bytesDel += s.length + 1;
          }
        }
        return {
          hunks,
          addLines,
          delLines,
          tokensChanged: tokAdd + tokDel,
          bytesChanged: bytesAdd + bytesDel,
          tokensDelta: tokAdd - tokDel,
          bytesDelta: bytesAdd - bytesDel,
        };
      }

      function parseUnifiedHunks(patch) {
        const lines = String(patch || "").split("\n");
        const hunks = [];
        for (let i = 0; i < lines.length; i++) {
          const line = lines[i];
          if (!line.startsWith("@@")) continue;
          const m = /^@@ -(\\d+)(?:,(\\d+))? \\+(\\d+)(?:,(\\d+))? @@/.exec(line);
          if (!m) continue;
          const oldStart = Number(m[1]);
          const oldCount = Number(m[2] || "1");
          const newStart = Number(m[3]);
          const newCount = Number(m[4] || "1");

          const hunkLines = [];
          i++;
          for (; i < lines.length; i++) {
            const l = lines[i];
            if (l.startsWith("@@")) {
              i--;
              break;
            }
            if (l.startsWith("diff --git")) break;
            if (l.startsWith("index ") || l.startsWith("---") || l.startsWith("+++")) continue;
            hunkLines.push(l);
          }

          hunks.push({ oldStart, oldCount, newStart, newCount, lines: hunkLines });
        }
        return hunks;
      }

      function bucketById(id) {
        return BUCKETS.find((b) => b.id === id) || BUCKETS[BUCKETS.length - 1];
      }

      function pickPrimary(labels) {
        const s = new Set(labels);
        if (s.has(2)) return 2;
        if (s.has(3)) return 3;
        if (s.has(1)) return 1;
        if (s.has(4)) return 4;
        if (s.has(8)) return 8;
        if (s.has(7)) return 7;
        if (s.has(6)) return 6;
        if (s.has(5)) return 5;
        if (s.has(9)) return 9;
        return 10;
      }

      function normalizeClassification(commits) {
        const out = new Map();
        const add = (entry, source) => {
          if (!entry || !entry.commit) return;
          out.set(entry.commit, { ...entry, _source: source });
        };
        CLASS_EARLY.forEach((e) => add(e, "early"));
        CLASS_MIDDLE.forEach((e) => add(e, "middle"));
        CLASS_LATE.forEach((e) => add(e, "late"));

        const missing = [];
        for (const c of commits) {
          if (!out.has(c.hash)) missing.push(c.hash);
        }

        return { byHash: out, missing };
      }

      function deriveBucketsForGroup(group, commitSubject) {
        // If the group already uses numeric buckets, preserve.
        if (Array.isArray(group.categories) && group.categories.every((x) => Number.isInteger(x))) {
          const labels = uniqInts(group.categories);
          return { labels, primary: group.primary_category ?? pickPrimary(labels) };
        }

        const labels = new Set();
        const s = `${commitSubject || ""} ${group.summary || ""} ${(group.evidence || []).join(" ")}`.toLowerCase();

        // Tag-driven mapping (from middle/late agents)
        const tags = Array.isArray(group.categories) ? group.categories : [];
        for (const t of tags) {
          const tt = String(t).toLowerCase();
          if (tt.includes("doc meta") || tt.includes("summary_update")) labels.add(5);
          if (tt.includes("clarification")) labels.add(9);
          if (tt.includes("spec expansion") || tt.includes("addition")) labels.add(6);
          if (tt.includes("architecture")) labels.add(4);
          if (tt.includes("api/interface")) labels.add(4);
          if (tt.includes("sql semantics")) labels.add(2);
          if (tt.includes("file format")) labels.add(2);
          if (tt.includes("durability")) labels.add(7);
          if (tt.includes("concurrency")) labels.add(7);
          if (tt.includes("performance")) labels.add(7);
          if (tt.includes("math/modeling")) labels.add(8);
          if (tt.includes("correctness fix") || tt.includes("correction")) labels.add(1);
          if (tt.includes("requirement_change")) labels.add(4);
        }

        // Content heuristics to refine buckets.
        if (s.includes("sqlite") || s.includes("wal") || s.includes("wal-index") || s.includes("btree") || s.includes("vdbe") || s.includes("fts5") || s.includes("lemon") || s.includes("parse.y")) {
          labels.add(2);
        }
        if (s.includes("asupersync") || s.includes("cx") || s.includes("virtualtcp") || s.includes("region") || s.includes("spawn_blocking") || s.includes("deadline")) {
          labels.add(3);
        }
        if (s.includes("bocpd") || s.includes("conformal") || s.includes("e-process") || s.includes("evalue") || s.includes("vo i") || s.includes("gf(256)") || s.includes("raptorq") || s.includes("martingale")) {
          labels.add(8);
        }
        if (s.includes("cache") || s.includes("prefetch") || s.includes("alignment") || s.includes("atomic") || s.includes("acquire") || s.includes("release") || s.includes("bulkhead") || s.includes("rate_limit") || s.includes("shard") || s.includes("cache-line")) {
          labels.add(7);
        }
        if (s.includes("renumber") || s.includes("footer") || s.includes("document version") || s.includes("typo") || s.includes("wording tweak")) {
          labels.add(5);
        }
        if (s.startsWith("add ") || s.includes("added ") || s.includes("introduced ") || s.includes("defined ") || s.includes("expanded ")) {
          labels.add(6);
        }
        if (s.includes("clarif") || s.includes("explain") || s.includes("note")) {
          labels.add(9);
        }
        if (s.includes("fix ") || s.includes("fixed ") || s.includes("correct") || s.includes("arithmetic") || s.includes("inversion") || s.includes("swapped")) {
          labels.add(1);
        }
        if (s.includes("rework") || s.includes("redesign") || s.includes("protocol") || s.includes("invariant") || s.includes("formal model")) {
          labels.add(4);
        }

        if (labels.size === 0) labels.add(10);

        const labelsArr = Array.from(labels).sort((a, b) => a - b);
        const primary = pickPrimary(labelsArr);
        return { labels: labelsArr, primary };
      }

      function uniqInts(xs) {
        const s = new Set();
        for (const x of xs) s.add(Number(x));
        return Array.from(s).filter((n) => Number.isInteger(n)).sort((a, b) => a - b);
      }

      // -----------------------------
      // Rendering
      // -----------------------------

      let chartTimeline = null;
      let chartStack = null;
      let chartDonut = null;
      let chartBocpd = null;

      let ALL_COMMITS = [];
      let FILTERED_COMMITS = [];
      let DOCK_READY = false;

      function render() {
        const commits = parseCommitLog();
        const stats = parseCommitStats();
        const { byHash: clsByHash, missing } = normalizeClassification(commits);

        const enriched = commits.map((c) => {
          const st = stats.get(c.hash) || { add: 0, del: 0, impact: 0 };
          const raw = clsByHash.get(c.hash) || null;
          const changeGroupsRaw = raw?.change_groups || [];
          const changeGroups = changeGroupsRaw.map((g) => {
            const { labels, primary } = deriveBucketsForGroup(g, c.subject);
            return {
              summary: g.summary || "",
              evidence: Array.isArray(g.evidence) ? g.evidence : [],
              changed_headings: Array.isArray(g.changed_headings) ? g.changed_headings : [],
              confidence: typeof g.confidence === "number" ? g.confidence : 0.55,
              labels,
              primary,
            };
          });

          const groupLabels = new Set();
          for (const g of changeGroups) {
            for (const b of g.labels) groupLabels.add(b);
          }
          const labels = Array.from(groupLabels).sort((a, b) => a - b);
          const primary = pickPrimary(labels.length ? labels : [10]);

          return {
            ...c,
            ...st,
            labels,
            primary,
            changeGroups,
            hasClassification: Boolean(raw),
          };
        });

        ALL_COMMITS = enriched;

        // KPI
        document.getElementById("kpiCommits").textContent = fmtInt(enriched.length);
        const totalGroups = enriched.reduce((acc, c) => acc + c.changeGroups.length, 0);
        document.getElementById("kpiGroups").textContent = fmtInt(totalGroups);
        const totalLines = enriched.reduce((acc, c) => acc + c.impact, 0);
        document.getElementById("kpiLines").textContent = fmtInt(totalLines);
        document.getElementById("kpiMode").textContent = STATE.bucketMode === "primary" ? "Primary" : "Multi";
        document.getElementById("kpiIntegrity").textContent = missing.length ? `${missing.length} missing` : "OK";

        // Make the impact slider usable even with very large commits: cap at ~p99.
        {
          const impacts = enriched.map((c) => c.impact).slice().sort((a, b) => a - b);
          const idx = Math.max(0, Math.ceil(0.99 * impacts.length) - 1);
          const p99 = impacts[idx] || 200;
          const maxImpact = Math.max(200, p99);
          const impact = document.getElementById("impact");
          const impactMobile = document.getElementById("impactMobile");
          if (impact && impactMobile) {
            impact.max = String(maxImpact);
            impactMobile.max = String(maxImpact);
            if (STATE.minImpact > maxImpact) {
              STATE.minImpact = maxImpact;
              impact.value = String(maxImpact);
              impactMobile.value = String(maxImpact);
              document.getElementById("impactLabel").textContent = `${fmtInt(maxImpact)} lines`;
              document.getElementById("impactLabelMobile").textContent = `${fmtInt(maxImpact)} lines`;
            }
          }
        }

        const earliest = enriched[0];
        const latest = enriched[enriched.length - 1];
        document.getElementById("rangeLabel").textContent = `${earliest.short} → ${latest.short}`;
        document.getElementById("metaSpan").textContent = `${dayjs(earliest.dateIso).format("YYYY-MM-DD HH:mm")} to ${dayjs(latest.dateIso).format("HH:mm")}`;

        // Filter
        const filtered = enriched.filter((c) => matchesFilters(c));
        FILTERED_COMMITS = filtered;
        document.getElementById("showingCount").textContent = `${fmtInt(filtered.length)} commits`;

        // Charts + list
        renderBucketToggles();
        renderCharts(filtered);
        renderCommitList(filtered);
        syncDockAndDoc();

        // Make sure code highlighting is applied to newly inserted excerpts
        requestAnimationFrame(() => {
          document.querySelectorAll("pre code").forEach((el) => {
            try {
              hljs.highlightElement(el);
            } catch {
              // ignore
            }
          });
        });
      }

      function matchesFilters(commit) {
        if (commit.impact < STATE.minImpact) return false;
        const q = STATE.q.trim().toLowerCase();
        if (q) {
          const hay =
            `${commit.hash} ${commit.short} ${commit.author} ${commit.subject} ${commit.changeGroups
              .map((g) => `${g.summary} ${(g.changed_headings || []).join(" ")} ${(g.evidence || []).join(" ")}`)
              .join(" ")}`.toLowerCase();
          if (!hay.includes(q)) return false;
        }

        const enabled = STATE.bucketEnabled;
        if (STATE.bucketMode === "primary") {
          return enabled.has(commit.primary);
        }
        // multi-label: require overlap
        return commit.labels.some((b) => enabled.has(b));
      }

      // -----------------------------
      // Dock + Doc Evolution UI
      // -----------------------------

      const DOC_CURSOR = {
        idx: 0,
        lines: null,
      };

      function setDocTab(tab) {
        DOC.tab = tab;
        // Buttons
        const btnSpec = document.getElementById("docTabSpec");
        const btnDiff = document.getElementById("docTabDiff");
        const btnMetrics = document.getElementById("docTabMetrics");
        const on = "focus-ring rounded-2xl bg-slate-900 px-3 py-2 text-xs font-semibold text-white hover:bg-slate-800";
        const off =
          "focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white";
        if (btnSpec && btnDiff && btnMetrics) {
          btnSpec.className = tab === "spec" ? on : off;
          btnDiff.className = tab === "diff" ? on : off;
          btnMetrics.className = tab === "metrics" ? on : off;
        }
        updateDocPanelVisibility();
        // Re-render diff/spec if needed.
        void updateDocUI();
      }

      function updateDocPanelVisibility() {
        const spec = document.getElementById("docSpecView");
        const diff = document.getElementById("docDiffView");
        const metrics = document.getElementById("docMetricsView");
        if (!spec || !diff || !metrics) return;
        spec.classList.toggle("hidden", DOC.tab !== "spec");
        diff.classList.toggle("hidden", DOC.tab !== "diff");
        metrics.classList.toggle("hidden", DOC.tab !== "metrics");
      }

      function patchForIdx(idx) {
        const d = DATASET.data;
        if (!d || !Array.isArray(d.patches)) return "";
        return d.patches[idx] || "";
      }

      function applyPatchLines(prevLines, patch) {
        const hunks = parseUnifiedHunks(patch);
        let out = prevLines.slice();
        let offset = 0;
        for (const h of hunks) {
          let at = (h.oldStart - 1) + offset;
          at = clamp(at, 0, out.length);
          let cursor = at;
          const next = [];
          for (const hl of h.lines) {
            if (!hl) continue;
            const p = hl[0];
            const content = hl.slice(1);
            if (p === " ") {
              next.push(content);
              cursor += 1;
            } else if (p === "-") {
              cursor += 1;
            } else if (p === "+") {
              next.push(content);
            } else {
              // "\ No newline at end of file" or other metadata
            }
          }
          out.splice(at, cursor - at, ...next);
          offset += next.length - (cursor - at);
        }
        return out;
      }

      async function docTextAt(idx) {
        const d = DATASET.data;
        if (!d) return "";
        if (idx <= 0) return String(d.base_doc || "");

        const cached = DOC_CACHE.get(idx);
        if (cached?.text) return cached.text;

        // Fast path: sequential scrub.
        if (DOC_CURSOR.lines && idx === DOC_CURSOR.idx + 1) {
          const nextLines = applyPatchLines(DOC_CURSOR.lines, patchForIdx(idx));
          DOC_CURSOR.idx = idx;
          DOC_CURSOR.lines = nextLines;
          const text = nextLines.join("\n");
          DOC_CACHE.set(idx, { text });
          return text;
        }

        // Rebuild from nearest cached anchor.
        let anchor = 0;
        for (let j = idx - 1; j > 0; j--) {
          if (DOC_CACHE.has(j)) {
            anchor = j;
            break;
          }
        }

        let lines = String(d.base_doc || "").split("\n");
        if (anchor > 0) lines = String(DOC_CACHE.get(anchor)?.text || "").split("\n");

        for (let k = Math.max(1, anchor + 1); k <= idx; k++) {
          lines = applyPatchLines(lines, patchForIdx(k));
          // Keep sparse anchors to accelerate non-linear scrubs.
          if (k === idx || k % 10 === 0) DOC_CACHE.set(k, { text: lines.join("\n") });
        }

        DOC_CURSOR.idx = idx;
        DOC_CURSOR.lines = lines;
        return DOC_CACHE.get(idx)?.text || lines.join("\n");
      }

      async function levenshteinForPatch(patch) {
        const hunks = parseUnifiedHunks(patch);
        const enc = new TextEncoder();
        let sum = 0;
        for (const h of hunks) {
          const oldLines = [];
          const newLines = [];
          for (const hl of h.lines) {
            if (!hl) continue;
            const p = hl[0];
            const content = hl.slice(1);
            if (p === "-") oldLines.push(content);
            if (p === "+") newLines.push(content);
          }
          if (!oldLines.length && !newLines.length) continue;
          const a = enc.encode(oldLines.join("\n"));
          const b = enc.encode(newLines.join("\n"));
          if (a.length > 20000 || b.length > 20000) {
            // Worst-case guard: fallback to a cheap upper bound.
            sum += a.length + b.length;
          } else {
            sum += await levenshteinBytes(a, b);
          }
        }
        return sum;
      }

      function selectCommitIdx(idx, opts = {}) {
        const max = Math.max(0, (ALL_COMMITS.length || 1) - 1);
        const next = clamp(Number(idx || 0), 0, max);
        DOC.idx = next;

        const slider = document.getElementById("dockSlider");
        if (slider) slider.value = String(next);

        syncDockAndDoc();

        if (opts.scrollToCommitList) {
          const c = ALL_COMMITS[next];
          const el = c ? document.getElementById(`commit-${c.hash}`) : null;
          if (el) {
            el.scrollIntoView({ behavior: "smooth", block: "start" });
            el.open = true;
          }
        }
      }

      function initDockIfNeeded() {
        if (DOCK_READY) return;
        const slider = document.getElementById("dockSlider");
        if (!slider || !ALL_COMMITS.length) return;
        slider.min = "0";
        slider.max = String(ALL_COMMITS.length - 1);
        slider.step = "1";
        document.getElementById("dockLeftLabel").textContent = ALL_COMMITS[0]?.short || "-";
        document.getElementById("dockRightLabel").textContent = ALL_COMMITS[ALL_COMMITS.length - 1]?.short || "-";
        DOCK_READY = true;
      }

      function drawDock() {
        const canvas = document.getElementById("dockCanvas");
        if (!canvas || !ALL_COMMITS.length) return;
        const dpr = window.devicePixelRatio || 1;
        const w = Math.max(1, Math.floor(canvas.clientWidth * dpr));
        const h = Math.max(1, Math.floor(canvas.clientHeight * dpr));
        if (canvas.width !== w || canvas.height !== h) {
          canvas.width = w;
          canvas.height = h;
        }
        const ctx = canvas.getContext("2d");
        if (!ctx) return;
        ctx.clearRect(0, 0, w, h);

        const maxImpact = Math.max(1, ...ALL_COMMITS.map((c) => Number(c.impact || 0)));
        const barW = w / ALL_COMMITS.length;
        const pad = 2 * dpr;

        for (let i = 0; i < ALL_COMMITS.length; i++) {
          const c = ALL_COMMITS[i];
          const v = Number(c.impact || 0);
          const t = Math.sqrt(v / maxImpact);
          const bh = Math.max(1, (h - pad * 2) * t);
          const x = i * barW;
          const y = h - pad - bh;
          ctx.globalAlpha = 0.9;
          ctx.fillStyle = bucketById(c.primary).color;
          ctx.fillRect(x, y, Math.max(1, barW), bh);
        }

        // Selected marker.
        const sx = DOC.idx * barW;
        ctx.globalAlpha = 1;
        ctx.lineWidth = Math.max(1, dpr);
        ctx.strokeStyle = "rgba(2,6,23,0.85)";
        ctx.strokeRect(sx + 0.5, 0.5, Math.max(1, barW - 1), h - 1);

        // Inset glow
        ctx.globalAlpha = 1;
        ctx.strokeStyle = "rgba(37,99,235,0.35)";
        ctx.strokeRect(sx + 0.5, 1.5, Math.max(1, barW - 1), h - 3);
      }

      async function updateDocUI() {
        const loading = document.getElementById("docLoading");
        const main = document.getElementById("docMain");
        if (!loading || !main) return;

        if (!DATASET.loaded) {
          loading.classList.remove("hidden");
          main.classList.add("hidden");
          loading.textContent = DATASET.error
            ? `Spec evolution dataset unavailable: ${DATASET.error}`
            : "Loading spec evolution dataset... (local gzip JSON; no GitHub API)";
          return;
        }

        loading.classList.add("hidden");
        main.classList.remove("hidden");
        updateDocPanelVisibility();

        const c = ALL_COMMITS[DOC.idx];
        if (!c) return;

        document.getElementById("dockTitle").textContent = `${c.short} · ${c.subject}`;

        const title = document.getElementById("docCommitTitle");
        const meta = document.getElementById("docCommitMeta");
        const link = document.getElementById("docCommitLink");
        if (title) title.textContent = c.subject;
        if (meta) meta.textContent = `${c.short} · ${dayjs(c.dateIso).format("YYYY-MM-DD HH:mm:ss")} · +${fmtInt(c.add)} -${fmtInt(c.del)}`;
        if (link) link.href = c.url;

        // Summary box.
        const sum = document.getElementById("docSummary");
        const tok = METRICS.tokensChanged.get(c.hash);
        const byt = METRICS.bytesChanged.get(c.hash);
        const hn = METRICS.hunks.get(c.hash);
        const lv = METRICS.lev.get(c.hash);
        if (sum) {
          sum.innerHTML = `
            <div class="flex flex-wrap gap-2">
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Impact ${fmtInt(c.impact)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Hunks ${fmtInt(hn ?? 0)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Tokens ${fmtInt(tok ?? 0)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Bytes ${fmtInt(byt ?? 0)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Lev ${lv == null ? "?" : fmtInt(lv)}</span>
            </div>
            <div class="mt-2 text-xs text-slate-600">Bucket: <span class="font-semibold">${escapeHtml(bucketById(c.primary).name)}</span></div>
          `;
        }

        // Metrics cards
        document.getElementById("mTokens").textContent = tok == null ? "-" : fmtInt(tok);
        document.getElementById("mBytes").textContent = byt == null ? "-" : fmtInt(byt);
        document.getElementById("mHunks").textContent = hn == null ? "-" : fmtInt(hn);
        document.getElementById("mLev").textContent = lv == null ? "-" : fmtInt(lv);

        const patch = patchForIdx(DOC.idx);

        if (DOC.tab === "diff") {
          const raw = document.getElementById("diffRaw");
          const pretty = document.getElementById("diffPretty");
          if (raw) raw.textContent = patch || "";

          if (pretty) {
            if (DOC.diffMode === "pretty") {
              try {
                pretty.innerHTML = Diff2Html.html(patch || "", {
                  drawFileList: false,
                  matching: "lines",
                  outputFormat: "side-by-side",
                });
              } catch (e) {
                pretty.innerHTML = `<div class="p-3 text-xs text-slate-700">Diff2Html failed: ${escapeHtml(String(e?.message || e))}</div>`;
              }
            } else {
              pretty.innerHTML = "";
            }
          }

          document.getElementById("diffPretty").classList.toggle("hidden", DOC.diffMode !== "pretty");
          document.getElementById("diffRaw").classList.toggle("hidden", DOC.diffMode !== "raw");
        }

        if (DOC.tab === "spec") {
          const raw = document.getElementById("docRaw");
          const rendered = document.getElementById("docRendered");
          const specView = document.getElementById("docSpecView");
          if (specView) specView.classList.remove("hidden");

          const text = await docTextAt(DOC.idx);
          if (raw) raw.textContent = text;

          if (rendered) {
            const md = markdownit({
              html: false,
              linkify: true,
              typographer: true,
              highlight: (str, lang) => {
                try {
                  if (lang && hljs.getLanguage(lang)) {
                    return `<pre class=\"hljs\"><code>${hljs.highlight(str, { language: lang }).value}</code></pre>`;
                  }
                  return `<pre class=\"hljs\"><code>${hljs.highlightAuto(str).value}</code></pre>`;
                } catch {
                  return `<pre class=\"hljs\"><code>${escapeHtml(str)}</code></pre>`;
                }
              },
            });
            const html = md.render(text || "");
            rendered.innerHTML = DOMPurify.sanitize(html);
          }

          document.getElementById("docRendered").classList.toggle("hidden", DOC.rawSpec);
          document.getElementById("docRaw").classList.toggle("hidden", !DOC.rawSpec);
        }

        // On-demand Levenshtein for selected commit.
        if (DATASET.loaded && DOC.idx > 0 && !METRICS.lev.has(c.hash)) {
          // Compute async, don't block UI.
          void (async () => {
            try {
              const d = await levenshteinForPatch(patch);
              METRICS.lev.set(c.hash, d);
              // Update only if still selected.
              if (ALL_COMMITS[DOC.idx]?.hash === c.hash) {
                document.getElementById("mLev").textContent = fmtInt(d);
                syncDockAndDoc();
              }
            } catch {
              // ignore
            }
          })();
        }
      }

      let COMPUTE_RUNNING = false;

      async function computeAllMetrics() {
        if (COMPUTE_RUNNING) return;
        if (!DATASET.loaded) return;
        if (!ALL_COMMITS.length) return;

        COMPUTE_RUNNING = true;
        const prog = document.getElementById("computeProgress");
        if (prog) {
          prog.classList.remove("hidden");
          prog.textContent = "Computing metrics...";
        }

        try {
          const total = ALL_COMMITS.length;
          for (let i = 0; i < total; i++) {
            const c = ALL_COMMITS[i];
            const patch = patchForIdx(i);

            // Always ensure quick metrics are present.
            if (!METRICS.tokensChanged.has(c.hash) || !METRICS.bytesChanged.has(c.hash) || !METRICS.hunks.has(c.hash)) {
              const qm = quickMetricsFromPatch(patch);
              METRICS.tokensChanged.set(c.hash, qm.tokensChanged);
              METRICS.bytesChanged.set(c.hash, qm.bytesChanged);
              METRICS.hunks.set(c.hash, qm.hunks);
            }

            if (i > 0 && !METRICS.lev.has(c.hash)) {
              const d = await levenshteinForPatch(patch);
              METRICS.lev.set(c.hash, d);
            }

            if (prog) {
              const haveLev = METRICS.lev.size;
              prog.textContent = `Computed ${i + 1}/${total} commits · Levenshtein ready ${haveLev}/${total - 1}`;
            }

            if (i % 4 === 0) {
              // Yield to keep UI responsive; refresh charts occasionally.
              await new Promise((r) => setTimeout(r, 0));
              if (i % 12 === 0) render();
            }
          }
        } finally {
          COMPUTE_RUNNING = false;
          if (prog) prog.textContent = "Done. Charts updated.";
          render();
        }
      }

      function syncDockAndDoc() {
        if (!ALL_COMMITS.length) return;
        DOC.idx = clamp(DOC.idx, 0, ALL_COMMITS.length - 1);
        initDockIfNeeded();
        drawDock();
        void updateDocUI();
      }

      function renderBucketToggles() {
        const wrap = document.getElementById("bucketToggles");
        const wrapM = document.getElementById("bucketTogglesMobile");
        wrap.innerHTML = "";
        wrapM.innerHTML = "";

        for (const b of BUCKETS) {
          const item = bucketToggleItem(b);
          const itemM = bucketToggleItem(b, true);
          wrap.appendChild(item);
          wrapM.appendChild(itemM);
        }
      }

      function bucketToggleItem(bucket, isMobile = false) {
        const id = (isMobile ? "m-" : "") + `b-${bucket.id}`;
        const on = STATE.bucketEnabled.has(bucket.id);

        const btn = document.createElement("button");
        btn.type = "button";
        btn.id = id;
        btn.className =
          "focus-ring flex items-start gap-3 rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left hover:bg-white";
        btn.innerHTML = `
          <span class="mt-1 inline-block h-2.5 w-2.5 rounded-full" style="background:${bucket.color}"></span>
          <span class="min-w-0">
            <span class="block text-xs font-semibold text-slate-900">${escapeHtml(bucket.name)}</span>
            <span class="mt-0.5 block text-[11px] leading-snug text-slate-500">${escapeHtml(bucket.desc)}</span>
          </span>
          <span class="ml-auto mt-0.5 inline-flex h-6 w-10 items-center rounded-full border border-slate-900/10 bg-white/60 p-0.5">
            <span class="h-5 w-5 rounded-full transition" style="background:${on ? bucket.color : "#cbd5e1"}; transform: translateX(${on ? "16px" : "0"});"></span>
          </span>
        `;
        btn.addEventListener("click", () => {
          if (STATE.bucketEnabled.has(bucket.id)) {
            STATE.bucketEnabled.delete(bucket.id);
          } else {
            STATE.bucketEnabled.add(bucket.id);
          }
          render();
        });
        return btn;
      }

      function renderCharts(commits) {
        // Timeline scatter
        if (!chartTimeline) chartTimeline = echarts.init(document.getElementById("timelineChart"));
        if (!chartStack) chartStack = echarts.init(document.getElementById("stackChart"));
        if (!chartDonut) chartDonut = echarts.init(document.getElementById("donutChart"));
        if (!chartBocpd) chartBocpd = echarts.init(document.getElementById("bocpdChart"));

        const timelineData = commits.map((c) => {
          return [
            c.dateIso,
            c.impact,
            c.primary,
            c.short,
            c.subject,
            c.hash,
            c.author,
          ];
        });

        chartTimeline.setOption({
          grid: { left: 44, right: 18, top: 18, bottom: 40 },
          tooltip: {
            trigger: "item",
            borderWidth: 1,
            backgroundColor: "rgba(255,255,255,0.95)",
            textStyle: { color: "#0b1220" },
            extraCssText: "box-shadow: 0 16px 40px rgba(2,6,23,0.18); border-radius: 14px;",
            formatter: (p) => {
              const d = p.data;
              const b = bucketById(d[2]);
              return `
                <div style="min-width: 240px">
                  <div style="display:flex;align-items:center;gap:10px;">
                    <span style="width:10px;height:10px;border-radius:99px;background:${b.color};display:inline-block;"></span>
                    <div style="font-weight:700">${escapeHtml(d[3])}</div>
                    <div style="margin-left:auto;font-size:11px;color:rgba(2,6,23,.62)">${dayjs(d[0]).format(
                      "YYYY-MM-DD HH:mm:ss",
                    )}</div>
                  </div>
                  <div style="margin-top:6px;font-size:12px;color:rgba(2,6,23,.8)">${escapeHtml(d[4])}</div>
                  <div style="margin-top:6px;font-size:11px;color:rgba(2,6,23,.62)">Impact ${fmtInt(
                    d[1],
                  )} lines · Bucket ${escapeHtml(b.name)}</div>
                </div>
              `;
            },
          },
          xAxis: {
            type: "time",
            name: "time",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            axisLine: { lineStyle: { color: "rgba(2,6,23,.12)" } },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          yAxis: {
            type: "value",
            name: "lines changed",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            axisLine: { lineStyle: { color: "rgba(2,6,23,.12)" } },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          series: [
            {
              type: "scatter",
              data: timelineData,
              symbolSize: (d) => clamp(6 + Math.sqrt(d[1] || 0) * 0.7, 6, 40),
              itemStyle: {
                color: (p) => bucketById(p.data[2]).color,
                opacity: 0.9,
              },
              emphasis: { scale: true },
            },
          ],
        });

        chartTimeline.off("click");
        chartTimeline.on("click", (p) => {
          const hash = p.data[5];
          const idx = ALL_COMMITS.findIndex((c) => c.hash === hash);
          if (idx >= 0) selectCommitIdx(idx);
          const el = document.getElementById(`commit-${hash}`);
          if (el) {
            el.scrollIntoView({ behavior: "smooth", block: "start" });
            el.open = true;
          }
        });

        // Stacked buckets by time bin (commit/day/hour/15m/5m)
        const resSel = document.getElementById("stackResolution");
        const metricSel = document.getElementById("stackMetric");
        const resolution = resSel?.value || "commit";
        const metric = metricSel?.value || "groups";

        const binLabels = [];
        const binCommits = [];
        const binIdx = new Map();

        const fmt2 = (n) => String(n).padStart(2, "0");
        const binKey = (c) => {
          if (resolution === "commit") return c.short;
          const t = dayjs(c.dateIso);
          if (resolution === "day") return t.format("YYYY-MM-DD");
          if (resolution === "hour") return t.format("YYYY-MM-DD HH:00");
          if (resolution === "15m") {
            const m = Math.floor(t.minute() / 15) * 15;
            return `${t.format("YYYY-MM-DD HH")}:${fmt2(m)}`;
          }
          if (resolution === "5m") {
            const m = Math.floor(t.minute() / 5) * 5;
            return `${t.format("YYYY-MM-DD HH")}:${fmt2(m)}`;
          }
          return t.format();
        };

        for (const c of commits) {
          const k = binKey(c);
          let j = binIdx.get(k);
          if (j == null) {
            j = binLabels.length;
            binIdx.set(k, j);
            binLabels.push(k);
            binCommits.push([]);
          }
          binCommits[j].push(c);
        }

        const valuesByBucket = new Map(BUCKETS.map((b) => [b.id, new Array(binLabels.length).fill(0)]));

        const metricForCommit = (c) => {
          if (metric === "groups") return 1; // handled per-group
          if (metric === "lines") return Number(c.impact || 0);
          if (metric === "tokens") return Number(METRICS.tokensChanged.get(c.hash) || 0);
          if (metric === "lev") return Number(METRICS.lev.get(c.hash) || 0);
          return 0;
        };

        for (let bi = 0; bi < binCommits.length; bi++) {
          for (const c of binCommits[bi]) {
            if (metric === "groups") {
              if (STATE.bucketMode === "primary") {
                for (const g of c.changeGroups) {
                  const a = valuesByBucket.get(g.primary);
                  if (a) a[bi] += 1;
                }
              } else {
                for (const g of c.changeGroups) {
                  for (const b of g.labels) {
                    const a = valuesByBucket.get(b);
                    if (a) a[bi] += 1;
                  }
                }
              }
              continue;
            }

            const v = metricForCommit(c);
            const groups = c.changeGroups.length || 1;
            const perGroup = v / groups;

            if (STATE.bucketMode === "primary") {
              for (const g of c.changeGroups) {
                const a = valuesByBucket.get(g.primary);
                if (a) a[bi] += perGroup;
              }
            } else {
              for (const g of c.changeGroups) {
                const labels = g.labels?.length ? g.labels : [10];
                const perLabel = perGroup / labels.length;
                for (const b of labels) {
                  const a = valuesByBucket.get(b);
                  if (a) a[bi] += perLabel;
                }
              }
            }
          }
        }

        chartStack.setOption({
          grid: { left: 44, right: 18, top: 18, bottom: 60 },
          tooltip: { trigger: "axis" },
          xAxis: {
            type: "category",
            data: binLabels,
            axisLabel: { color: "rgba(2,6,23,.55)", rotate: resolution === "day" ? 0 : 45 },
            axisLine: { lineStyle: { color: "rgba(2,6,23,.12)" } },
          },
          yAxis: {
            type: "value",
            axisLabel: { color: "rgba(2,6,23,.55)" },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          legend: {
            type: "scroll",
            bottom: 0,
            textStyle: { color: "rgba(2,6,23,.62)" },
          },
          series: BUCKETS.map((b) => {
            return {
              name: `${b.id}. ${b.name}`,
              type: "bar",
              stack: "b",
              barWidth: "60%",
              emphasis: { focus: "series" },
              itemStyle: { color: b.color, opacity: 0.9 },
              data: valuesByBucket.get(b.id),
            };
          }),
        });

	        // Donut distribution by (primary or multi)
	        const totals = new Map(BUCKETS.map((b) => [b.id, 0]));
	        if (STATE.bucketMode === "primary") {
	          for (const c of commits) {
	            for (const g of c.changeGroups) {
	              totals.set(g.primary, (totals.get(g.primary) || 0) + 1);
	            }
	          }
	        } else {
	          for (const c of commits) {
	            for (const g of c.changeGroups) {
	              for (const b of g.labels) totals.set(b, (totals.get(b) || 0) + 1);
	            }
	          }
	        }
        const donutData = BUCKETS.map((b) => ({ name: `${b.id}. ${b.name}`, value: totals.get(b.id) || 0, itemStyle: { color: b.color } }));

        chartDonut.setOption({
          tooltip: { trigger: "item" },
          series: [
            {
              type: "pie",
              radius: ["45%", "70%"],
              avoidLabelOverlap: true,
              itemStyle: { borderRadius: 10, borderColor: "rgba(255,255,255,0.8)", borderWidth: 2 },
              label: { show: false },
              emphasis: { label: { show: true, fontWeight: 700, formatter: "{b}\\n{c}" } },
              labelLine: { show: false },
              data: donutData,
            },
          ],
        });

        renderBocpd(commits);
      }

      function renderBocpd(commits) {
        const H = Number(document.getElementById("hazard").value);
        document.getElementById("hazardLabel").textContent = H.toFixed(2);

        const xs = commits.map((c) => c.idx);
        const ys = commits.map((c) => Math.log1p(c.impact));

        const cp = bocpdChangePoints(ys, H);
        const markers = cp.changePoints.map((idx) => ({
          xAxis: xs[idx],
          label: { formatter: "CP", color: "rgba(2,6,23,.75)", fontSize: 10 },
          lineStyle: { color: "rgba(2,6,23,.25)", width: 1, type: "dashed" },
        }));

        chartBocpd.setOption({
          grid: { left: 44, right: 18, top: 18, bottom: 40 },
          tooltip: { trigger: "axis" },
          xAxis: {
            type: "value",
            name: "commit index",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          yAxis: {
            type: "value",
            name: "log(1+impact)",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          series: [
            {
              type: "line",
              data: xs.map((x, i) => [x, ys[i]]),
              showSymbol: false,
              lineStyle: { width: 2, color: "rgba(2,6,23,.78)" },
              markLine: {
                symbol: "none",
                data: markers,
              },
            },
            {
              type: "line",
              data: xs.map((x, i) => [x, cp.p0[i]]),
              yAxisIndex: 0,
              showSymbol: false,
              lineStyle: { width: 2, color: "rgba(37,99,235,.55)" },
            },
          ],
        });
      }

      // Minimal BOCPD over a scalar series with a crude Normal-Gamma model.
      // This is an interpretive visualization only.
      function bocpdChangePoints(y, hazard) {
        // Prior
        let mu0 = 0.0;
        let kappa0 = 0.01;
        let alpha0 = 0.5;
        let beta0 = 0.5;

        // Run-length posterior (log-space)
        let logR = [0.0]; // P(r=0)=1 at t=0
        // Sufficient stats per run length: n, mean, M2
        let stats = [{ n: 0, mean: 0.0, m2: 0.0 }];

        const p0 = [];
        const changePoints = [];

        const logHaz = Math.log(hazard);
        const log1mHaz = Math.log(1.0 - hazard);

        for (let t = 0; t < y.length; t++) {
          const x = y[t];

          // Predictive probabilities for each run length
          const logPred = [];
          for (let r = 0; r < stats.length; r++) {
            const st = stats[r];
            // Conjugate predictive approx: Student-t-ish with parameters from Normal-Gamma.
            const n = st.n;
            const mean = st.mean;
            const kappa = kappa0 + n;
            const alpha = alpha0 + n / 2;
            const beta =
              beta0 +
              0.5 * st.m2 +
              (kappa0 * n * (mean - mu0) * (mean - mu0)) / (2 * (kappa0 + n));

            const dof = 2 * alpha;
            const scale2 = (beta * (kappa + 1)) / (alpha * kappa);
            const logp = studentTLogPdf(x, mean, Math.sqrt(scale2), dof);
            logPred.push(logp);
          }

          // Growth + change point
          const newLogR = new Array(stats.length + 1).fill(-Infinity);

          // r_t = 0
          let logSumCp = -Infinity;
          for (let r = 0; r < logR.length; r++) {
            logSumCp = logAddExp(logSumCp, logR[r] + logPred[r] + logHaz);
          }
          newLogR[0] = logSumCp;

          // r_t = r_{t-1}+1
          for (let r = 0; r < logR.length; r++) {
            newLogR[r + 1] = logR[r] + logPred[r] + log1mHaz;
          }

          // Normalize
          const logZ = newLogR.reduce((a, b) => logAddExp(a, b), -Infinity);
          for (let i = 0; i < newLogR.length; i++) newLogR[i] -= logZ;

          // Record P(r_t=0)
          const p_r0 = Math.exp(newLogR[0]);
          p0.push(p_r0);
          if (p_r0 > 0.5) changePoints.push(t);

          // Update stats for next step
          const newStats = new Array(stats.length + 1);
          // For r=0, reset stats
          newStats[0] = { n: 1, mean: x, m2: 0.0 };
          for (let r = 1; r < newStats.length; r++) {
            newStats[r] = updateWelford(stats[r - 1], x);
          }

          // Prune (keep top K run lengths)
          const K = 120;
          const idxs = newLogR.map((v, i) => [v, i]).sort((a, b) => b[0] - a[0]).slice(0, K).map((x) => x[1]).sort((a,b)=>a-b);
          logR = idxs.map((i) => newLogR[i]);
          stats = idxs.map((i) => newStats[i]);

          // Renormalize after pruning
          const logZ2 = logR.reduce((a, b) => logAddExp(a, b), -Infinity);
          logR = logR.map((v) => v - logZ2);
        }

        return { p0, changePoints };
      }

      function updateWelford(st, x) {
        const n1 = st.n + 1;
        const delta = x - st.mean;
        const mean1 = st.mean + delta / n1;
        const delta2 = x - mean1;
        const m21 = st.m2 + delta * delta2;
        return { n: n1, mean: mean1, m2: m21 };
      }

      function logAddExp(a, b) {
        if (a === -Infinity) return b;
        if (b === -Infinity) return a;
        const m = Math.max(a, b);
        return m + Math.log(Math.exp(a - m) + Math.exp(b - m));
      }

      function studentTLogPdf(x, mu, sigma, nu) {
        // log Γ((ν+1)/2) - log(σ*sqrt(νπ)) - log Γ(ν/2) - (ν+1)/2 log(1 + ((x-μ)/σ)^2 / ν)
        const z = (x - mu) / (sigma || 1e-9);
        return (
          logGamma((nu + 1) / 2) -
          logGamma(nu / 2) -
          Math.log((sigma || 1e-9) * Math.sqrt(nu * Math.PI)) -
          ((nu + 1) / 2) * Math.log(1 + (z * z) / nu)
        );
      }

      // Lanczos approximation for log-gamma
      function logGamma(z) {
        const p = [
          0.99999999999980993, 676.5203681218851, -1259.1392167224028, 771.32342877765313,
          -176.61502916214059, 12.507343278686905, -0.13857109526572012, 9.9843695780195716e-6,
          1.5056327351493116e-7,
        ];
        if (z < 0.5) {
          return Math.log(Math.PI) - Math.log(Math.sin(Math.PI * z)) - logGamma(1 - z);
        }
        z -= 1;
        let x = p[0];
        for (let i = 1; i < p.length; i++) x += p[i] / (z + i);
        const t = z + 7.5;
        return 0.5 * Math.log(2 * Math.PI) + (z + 0.5) * Math.log(t) - t + Math.log(x);
      }

      function renderCommitList(commits) {
        const wrap = document.getElementById("commitList");
        wrap.innerHTML = "";

        for (const c of commits) {
          const b = bucketById(c.primary);
          const details = document.createElement("details");
          details.id = `commit-${c.hash}`;
          details.className = "glass-2 rounded-3xl px-4 py-3 shadow-sm";

          const tags = (STATE.bucketMode === "primary" ? [c.primary] : c.labels).map(bucketById);

          details.innerHTML = `
            <summary class="cursor-pointer list-none">
              <div class="flex flex-col gap-3 sm:flex-row sm:items-start sm:justify-between">
                <div class="min-w-0">
                  <div class="flex flex-wrap items-center gap-2">
                    <span class="mono text-xs font-semibold text-slate-600">${escapeHtml(c.short)}</span>
                    <span class="mono text-xs text-slate-500">${dayjs(c.dateIso).format("HH:mm:ss")}</span>
                    <span class="mono text-xs text-slate-500">+${fmtInt(c.add)} -${fmtInt(c.del)}</span>
                  </div>
                  <div class="mt-1 truncate text-sm font-semibold text-slate-900">${escapeHtml(c.subject)}</div>
                  <div class="mt-1 flex flex-wrap gap-1.5">
                    ${tags
                      .map(
                        (t) => `
                          <span class="chip inline-flex items-center gap-2 rounded-full px-2.5 py-1 text-[11px] font-semibold text-slate-700">
                            <span class="inline-block h-2 w-2 rounded-full" style="background:${t.color}"></span>
                            ${escapeHtml(`${t.id}. ${t.name}`)}
                          </span>`,
                      )
                      .join("")}
                  </div>
                </div>
                <div class="shrink-0">
                  <a class="focus-ring chip inline-flex items-center gap-2 rounded-2xl px-3 py-2 text-xs font-semibold text-slate-700 hover:bg-white"
                     href="${escapeHtml(c.url)}" target="_blank" rel="noreferrer">View commit</a>
                </div>
              </div>
            </summary>
            <div class="mt-3 border-t border-slate-900/10 pt-3">
              ${c.hasClassification ? "" : `<div class="text-xs text-red-700">Missing classification entry for this commit.</div>`}
              ${c.changeGroups
                .map((g, i) => renderGroup(g, i))
                .join("")}
            </div>
          `;

          details.addEventListener("toggle", () => {
            if (details.open) selectCommitIdx(c.idx);
          });

          wrap.appendChild(details);
        }
      }

      function renderGroup(g, i) {
        const chips = g.labels.map((id) => bucketById(id));
        const confPct = Math.round(clamp(g.confidence, 0, 1) * 100);
        const headings = (g.changed_headings || []).slice(0, 8);
        const evidence = (g.evidence || []).slice(0, 3);

        return `
          <div class="mt-3 rounded-3xl border border-slate-900/10 bg-white/60 p-4">
            <div class="flex flex-col gap-2 sm:flex-row sm:items-start sm:justify-between">
              <div class="min-w-0">
                <div class="text-xs font-semibold text-slate-500">Change group ${i + 1}</div>
                <div class="mt-1 text-sm font-semibold text-slate-900">${escapeHtml(g.summary || "")}</div>
                <div class="mt-2 flex flex-wrap gap-1.5">
                  ${chips
                    .map(
                      (c) => `
                        <span class="chip inline-flex items-center gap-2 rounded-full px-2.5 py-1 text-[11px] font-semibold text-slate-700">
                          <span class="inline-block h-2 w-2 rounded-full" style="background:${c.color}"></span>
                          ${escapeHtml(`${c.id}. ${c.name}`)}
                        </span>`,
                    )
                    .join("")}
                  <span class="chip inline-flex items-center rounded-full px-2.5 py-1 text-[11px] font-semibold text-slate-700">
                    Confidence <span class="mono ml-1">${confPct}%</span>
                  </span>
                </div>
              </div>
            </div>

            ${
              headings.length
                ? `
                  <div class="mt-3">
                    <div class="text-[11px] font-semibold text-slate-500">Touched headings</div>
                    <div class="mt-2 flex flex-wrap gap-1.5">
                      ${headings
                        .map(
                          (h) => `<span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">${escapeHtml(h)}</span>`,
                        )
                        .join("")}
                    </div>
                  </div>
                `
                : ""
            }

            ${
              evidence.length
                ? `
                  <div class="mt-3">
                    <div class="text-[11px] font-semibold text-slate-500">Diff excerpts</div>
                    <div class="mt-2 grid grid-cols-1 gap-2">
                      ${evidence
                        .map(
                          (e) => `
                            <pre class="codebox overflow-auto rounded-2xl p-3"><code class="language-diff">${escapeHtml(
                              String(e),
                            )}</code></pre>
                          `,
                        )
                        .join("")}
                    </div>
                  </div>
                `
                : ""
            }
          </div>
        `;
      }

      // -----------------------------
      // Navigation helpers
      // -----------------------------

      function scrollToSection(id) {
        const el = document.getElementById(id);
        if (!el) return;
        el.scrollIntoView({ behavior: "smooth", block: "start" });
      }

      // -----------------------------
      // UI wiring
      // -----------------------------

      function wireUI() {
        const q = document.getElementById("q");
        const impact = document.getElementById("impact");
        const impactLabel = document.getElementById("impactLabel");
        const qMobile = document.getElementById("qMobile");
        const impactMobile = document.getElementById("impactMobile");
        const impactLabelMobile = document.getElementById("impactLabelMobile");

        const setImpact = (v) => {
          STATE.minImpact = Number(v);
          impact.value = String(v);
          impactMobile.value = String(v);
          impactLabel.textContent = `${fmtInt(v)} lines`;
          impactLabelMobile.textContent = `${fmtInt(v)} lines`;
        };
        setImpact(STATE.minImpact);

        q.addEventListener("input", () => {
          STATE.q = q.value;
          qMobile.value = q.value;
          render();
        });
        qMobile.addEventListener("input", () => {
          STATE.q = qMobile.value;
          q.value = qMobile.value;
        });

        impact.addEventListener("input", () => setImpact(impact.value));
        impactMobile.addEventListener("input", () => setImpact(impactMobile.value));

        const setMode = (m) => {
          STATE.bucketMode = m;
          document.getElementById("bucketModeLabel").textContent = m;
          document.getElementById("modePrimary").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "primary" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          document.getElementById("modeMulti").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "multi" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          document.getElementById("modePrimaryMobile").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "primary" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          document.getElementById("modeMultiMobile").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "multi" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          render();
        };

        document.getElementById("modePrimary").addEventListener("click", () => setMode("primary"));
        document.getElementById("modeMulti").addEventListener("click", () => setMode("multi"));
        document.getElementById("modePrimaryMobile").addEventListener("click", () => setMode("primary"));
        document.getElementById("modeMultiMobile").addEventListener("click", () => setMode("multi"));

        document.getElementById("btnReset").addEventListener("click", resetFilters);
        document.getElementById("btnResetMobile").addEventListener("click", resetFilters);

        // Section buttons
        document.getElementById("viewTimeline").addEventListener("click", () => scrollToSection("sectionTimeline"));
        document.getElementById("viewCommits").addEventListener("click", () => scrollToSection("sectionCommits"));
        document.getElementById("viewAlien").addEventListener("click", () => scrollToSection("sectionAlien"));

        // BOCPD hazard slider
        document.getElementById("hazard").addEventListener("input", () => render());

        // Stack chart controls
        document.getElementById("stackResolution")?.addEventListener("change", () => render());
        document.getElementById("stackMetric")?.addEventListener("change", () => render());

        // Doc tabs + toggles
        document.getElementById("docTabSpec")?.addEventListener("click", () => setDocTab("spec"));
        document.getElementById("docTabDiff")?.addEventListener("click", () => setDocTab("diff"));
        document.getElementById("docTabMetrics")?.addEventListener("click", () => setDocTab("metrics"));

        document.getElementById("btnRawToggle")?.addEventListener("click", () => {
          DOC.rawSpec = !DOC.rawSpec;
          void updateDocUI();
        });

        document.getElementById("btnPrettyDiff")?.addEventListener("click", () => {
          DOC.diffMode = "pretty";
          void updateDocUI();
        });
        document.getElementById("btnRawDiff")?.addEventListener("click", () => {
          DOC.diffMode = "raw";
          void updateDocUI();
        });

        document.getElementById("btnComputeAll")?.addEventListener("click", () => {
          void computeAllMetrics();
        });

        // Galaxy brain button: jump to alien section
        document.getElementById("btnGalaxy").addEventListener("click", () => scrollToSection("sectionAlien"));

        // Dock controls
        document.getElementById("dockPrev")?.addEventListener("click", () => selectCommitIdx(DOC.idx - 1));
        document.getElementById("dockNext")?.addEventListener("click", () => selectCommitIdx(DOC.idx + 1));
        document.getElementById("dockSlider")?.addEventListener("input", (e) => {
          const v = Number(e?.target?.value || 0);
          selectCommitIdx(v);
        });

        document.addEventListener("keydown", (e) => {
          const t = e.target;
          const isTyping =
            t && (t.tagName === "INPUT" || t.tagName === "TEXTAREA" || t.tagName === "SELECT" || t.isContentEditable);
          if (isTyping) return;

          if (e.key === "ArrowLeft") {
            e.preventDefault();
            selectCommitIdx(DOC.idx - 1);
          }
          if (e.key === "ArrowRight") {
            e.preventDefault();
            selectCommitIdx(DOC.idx + 1);
          }
        });

        // Mobile sheet
        const overlay = document.getElementById("overlay");
        const sheet = document.getElementById("sheet");
        const openSheet = () => {
          overlay.classList.remove("hidden");
          sheet.classList.remove("hidden");
          requestAnimationFrame(() => sheet.classList.add("open"));
        };
        const closeSheet = () => {
          sheet.classList.remove("open");
          setTimeout(() => {
            overlay.classList.add("hidden");
            sheet.classList.add("hidden");
          }, 200);
        };

        document.getElementById("btnFilters").addEventListener("click", openSheet);
        overlay.addEventListener("click", closeSheet);
        document.getElementById("btnCloseSheet").addEventListener("click", closeSheet);
        document.getElementById("btnApplyMobile").addEventListener("click", () => {
          // Apply mobile search changes
          STATE.q = qMobile.value;
          q.value = qMobile.value;
          render();
          closeSheet();
        });
      }

      function resetFilters() {
        STATE.q = "";
        STATE.minImpact = 0;
        STATE.bucketMode = "primary";
        STATE.bucketEnabled = new Set(BUCKETS.map((b) => b.id));

        document.getElementById("q").value = "";
        document.getElementById("qMobile").value = "";
        document.getElementById("impact").value = "0";
        document.getElementById("impactMobile").value = "0";
        document.getElementById("impactLabel").textContent = "0 lines";
        document.getElementById("impactLabelMobile").textContent = "0 lines";

        render();
      }

      // -----------------------------
      // Boot
      // -----------------------------

      window.addEventListener("resize", () => {
        chartTimeline?.resize();
        chartStack?.resize();
        chartDonut?.resize();
        chartBocpd?.resize();
        drawDock();
      });

      wireUI();
      (async function boot() {
        await loadEvolutionDataset();

        if (DATASET.loaded) {
          // Precompute cheap per-commit metrics from unified patches.
          const d = DATASET.data;
          for (let i = 0; i < d.commits.length; i++) {
            const c = d.commits[i];
            const qm = quickMetricsFromPatch(d.patches[i]);
            METRICS.tokensChanged.set(c.hash, qm.tokensChanged);
            METRICS.bytesChanged.set(c.hash, qm.bytesChanged);
            METRICS.hunks.set(c.hash, qm.hunks);
          }

          // Start at the latest commit (most interesting view).
          DOC.idx = Math.max(0, d.commits.length - 1);
        }

        // Default tabs.
        setDocTab("spec");
        render();
      })();
    </script>
  </body>
</html>
