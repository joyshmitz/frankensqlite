<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="color-scheme" content="light" />
    <title>FrankenSQLite Spec Evolution</title>

    <!-- OpenGraph -->
    <meta property="og:title" content="FrankenSQLite Spec Evolution" />
    <meta property="og:description" content="Interactive visualization of 137 commits across 12 deep sessions building a 10,791-line comprehensive database specification. MVCC page-level versioning, RaptorQ erasure coding, SSI concurrency control." />
    <meta property="og:image" content="https://frankensqlite.com/og-image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />
    <meta property="og:image:type" content="image/png" />
    <meta property="og:url" content="https://frankensqlite.com" />
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="FrankenSQLite" />

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="FrankenSQLite Spec Evolution" />
    <meta name="twitter:description" content="137 commits · 10,791 lines · 12 sessions of deep architectural design for a clean-room Rust reimplementation of SQLite with MVCC." />
    <meta name="twitter:image" content="https://frankensqlite.com/twitter-image.png" />

    <!-- General meta -->
    <meta name="description" content="Interactive visualization tracking the evolution of the FrankenSQLite specification across 137 commits — from initial architecture through MVCC, RaptorQ erasure coding, and SSI concurrency control." />

    <!-- Typography -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Fraunces:opsz,wght@9..144,350..900&family=Manrope:wght@200..800&display=swap"
      rel="stylesheet"
    />

    <!-- Tailwind (precompiled) -->
    <!-- Generated from this HTML via tailwindcss CLI to avoid runtime JIT cost (huge perf win vs https://cdn.tailwindcss.com). -->
    <style id="tw">
      *,:after,:before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }/*! tailwindcss v3.4.17 | MIT License | https://tailwindcss.com*/*,:after,:before{box-sizing:border-box;border:0 solid #e5e7eb}:after,:before{--tw-content:""}:host,html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:Manrope,ui-sans-serif,system-ui,sans-serif;font-feature-settings:normal;font-variation-settings:normal;-webkit-tap-highlight-color:transparent}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,SF Mono,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-feature-settings:normal;font-variation-settings:normal;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button,input,optgroup,select,textarea{font-family:inherit;font-feature-settings:inherit;font-variation-settings:inherit;font-size:100%;font-weight:inherit;line-height:inherit;letter-spacing:inherit;color:inherit;margin:0;padding:0}button,select{text-transform:none}button,input:where([type=button]),input:where([type=reset]),input:where([type=submit]){-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}dialog{padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#9ca3af}input::placeholder,textarea::placeholder{opacity:1;color:#9ca3af}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}[hidden]:where(:not([hidden=until-found])){display:none}.\\!container{width:100%!important}.container{width:100%}@media (min-width:640px){.\\!container{max-width:640px!important}.container{max-width:640px}}@media (min-width:768px){.\\!container{max-width:768px!important}.container{max-width:768px}}@media (min-width:1024px){.\\!container{max-width:1024px!important}.container{max-width:1024px}}@media (min-width:1280px){.\\!container{max-width:1280px!important}.container{max-width:1280px}}@media (min-width:1536px){.\\!container{max-width:1536px!important}.container{max-width:1536px}}.visible{visibility:visible}.collapse{visibility:collapse}.fixed{position:fixed}.absolute{position:absolute}.relative{position:relative}.sticky{position:sticky}.inset-0{inset:0}.inset-x-0{left:0;right:0}.bottom-0{bottom:0}.left-0{left:0}.right-0{right:0}.top-0{top:0}.top-full{top:100%}.z-10{z-index:10}.z-30{z-index:30}.z-40{z-index:40}.z-50{z-index:50}.mx-auto{margin-left:auto;margin-right:auto}.mb-2{margin-bottom:.5rem}.ml-1{margin-left:.25rem}.ml-2{margin-left:.5rem}.ml-auto{margin-left:auto}.mr-1\\.5{margin-right:.375rem}.mt-0\\.5{margin-top:.125rem}.mt-1{margin-top:.25rem}.mt-1\\.5{margin-top:.375rem}.mt-2{margin-top:.5rem}.mt-3{margin-top:.75rem}.mt-4{margin-top:1rem}.mt-5{margin-top:1.25rem}.mt-6{margin-top:1.5rem}.mt-7{margin-top:1.75rem}.mt-8{margin-top:2rem}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.inline-flex{display:inline-flex}.table{display:table}.grid{display:grid}.\\!hidden{display:none!important}.hidden{display:none}.h-1\\.5{height:.375rem}.h-2{height:.5rem}.h-2\\.5{height:.625rem}.h-5{height:1.25rem}.h-6{height:1.5rem}.max-h-\\[70vh\\]{max-height:70vh}.min-h-0{min-height:0}.w-10{width:2.5rem}.w-16{width:4rem}.w-2{width:.5rem}.w-2\\.5{width:.625rem}.w-20{width:5rem}.w-40{width:10rem}.w-5{width:1.25rem}.w-56{width:14rem}.w-6{width:1.5rem}.w-64{width:16rem}.w-72{width:18rem}.w-full{width:100%}.min-w-0{min-width:0}.min-w-\\[3\\.5rem\\]{min-width:3.5rem}.max-w-\\[1200px\\]{max-width:1200px}.max-w-\\[240px\\]{max-width:240px}.max-w-\\[260px\\]{max-width:260px}.max-w-\\[70ch\\]{max-width:70ch}.flex-1{flex:1 1 0%}.flex-shrink,.shrink{flex-shrink:1}.shrink-0{flex-shrink:0}.border-collapse{border-collapse:collapse}.transform{transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.cursor-col-resize{cursor:col-resize}.cursor-pointer{cursor:pointer}.resize{resize:both}.list-none{list-style-type:none}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.items-start{align-items:flex-start}.items-end{align-items:flex-end}.items-center{align-items:center}.justify-end{justify-content:flex-end}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.gap-1{gap:.25rem}.gap-1\\.5{gap:.375rem}.gap-2{gap:.5rem}.gap-3{gap:.75rem}.gap-4{gap:1rem}.gap-6{gap:1.5rem}.gap-px{gap:1px}.space-y-1>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.25rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.25rem*var(--tw-space-y-reverse))}.space-y-2>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.5rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.5rem*var(--tw-space-y-reverse))}.overflow-auto{overflow:auto}.overflow-hidden{overflow:hidden}.overflow-y-auto{overflow-y:auto}.truncate{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.rounded{border-radius:.25rem}.rounded-2xl{border-radius:1rem}.rounded-3xl{border-radius:1.5rem}.rounded-full{border-radius:9999px}.rounded-lg{border-radius:.5rem}.rounded-xl{border-radius:.75rem}.rounded-t-3xl{border-top-left-radius:1.5rem;border-top-right-radius:1.5rem}.border{border-width:1px}.border-b{border-bottom-width:1px}.border-t{border-top-width:1px}.border-blue-200{--tw-border-opacity:1;border-color:rgb(191 219 254/var(--tw-border-opacity,1))}.border-blue-400{--tw-border-opacity:1;border-color:rgb(96 165 250/var(--tw-border-opacity,1))}.border-rose-300{--tw-border-opacity:1;border-color:rgb(253 164 175/var(--tw-border-opacity,1))}.border-slate-100{--tw-border-opacity:1;border-color:rgb(241 245 249/var(--tw-border-opacity,1))}.border-slate-200{--tw-border-opacity:1;border-color:rgb(226 232 240/var(--tw-border-opacity,1))}.border-slate-900\\/10{border-color:rgba(15,23,42,.1)}.bg-amber-50{--tw-bg-opacity:1;background-color:rgb(255 251 235/var(--tw-bg-opacity,1))}.bg-blue-100{--tw-bg-opacity:1;background-color:rgb(219 234 254/var(--tw-bg-opacity,1))}.bg-blue-50\\/60{background-color:rgba(239,246,255,.6)}.bg-blue-50\\/80{background-color:rgba(239,246,255,.8)}.bg-blue-500{--tw-bg-opacity:1;background-color:rgb(59 130 246/var(--tw-bg-opacity,1))}.bg-emerald-50{--tw-bg-opacity:1;background-color:rgb(236 253 245/var(--tw-bg-opacity,1))}.bg-emerald-600{--tw-bg-opacity:1;background-color:rgb(5 150 105/var(--tw-bg-opacity,1))}.bg-red-50{--tw-bg-opacity:1;background-color:rgb(254 242 242/var(--tw-bg-opacity,1))}.bg-rose-50{--tw-bg-opacity:1;background-color:rgb(255 241 242/var(--tw-bg-opacity,1))}.bg-slate-100{--tw-bg-opacity:1;background-color:rgb(241 245 249/var(--tw-bg-opacity,1))}.bg-slate-200{--tw-bg-opacity:1;background-color:rgb(226 232 240/var(--tw-bg-opacity,1))}.bg-slate-200\\/80{background-color:rgba(226,232,240,.8)}.bg-slate-300{--tw-bg-opacity:1;background-color:rgb(203 213 225/var(--tw-bg-opacity,1))}.bg-slate-900{--tw-bg-opacity:1;background-color:rgb(15 23 42/var(--tw-bg-opacity,1))}.bg-slate-900\\/30{background-color:rgba(15,23,42,.3)}.bg-white{--tw-bg-opacity:1;background-color:rgb(255 255 255/var(--tw-bg-opacity,1))}.bg-white\\/60{background-color:hsla(0,0%,100%,.6)}.bg-white\\/70{background-color:hsla(0,0%,100%,.7)}.bg-white\\/80{background-color:hsla(0,0%,100%,.8)}.bg-white\\/90{background-color:hsla(0,0%,100%,.9)}.bg-white\\/95{background-color:hsla(0,0%,100%,.95)}.p-0\\.5{padding:.125rem}.p-2{padding:.5rem}.p-3{padding:.75rem}.p-4{padding:1rem}.p-5{padding:1.25rem}.px-1{padding-left:.25rem;padding-right:.25rem}.px-2{padding-left:.5rem;padding-right:.5rem}.px-2\\.5{padding-left:.625rem;padding-right:.625rem}.px-3{padding-left:.75rem;padding-right:.75rem}.px-3\\.5{padding-left:.875rem;padding-right:.875rem}.px-4{padding-left:1rem;padding-right:1rem}.px-5{padding-left:1.25rem;padding-right:1.25rem}.py-0\\.5{padding-top:.125rem;padding-bottom:.125rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-1\\.5{padding-top:.375rem;padding-bottom:.375rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.py-2\\.5{padding-top:.625rem;padding-bottom:.625rem}.py-3{padding-top:.75rem;padding-bottom:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.py-6{padding-top:1.5rem;padding-bottom:1.5rem}.pb-1{padding-bottom:.25rem}.pb-28{padding-bottom:7rem}.pt-10{padding-top:2.5rem}.pt-3{padding-top:.75rem}.pt-4{padding-top:1rem}.text-left{text-align:left}.text-center{text-align:center}.text-right{text-align:right}.font-display{font-family:Fraunces,ui-serif,Georgia,serif}.font-mono{font-family:ui-monospace,SFMono-Regular,SF Mono,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}.text-2xl{font-size:1.5rem;line-height:2rem}.text-4xl{font-size:2.25rem;line-height:2.5rem}.text-\\[10px\\]{font-size:10px}.text-\\[11px\\]{font-size:11px}.text-base{font-size:1rem;line-height:1.5rem}.text-lg{font-size:1.125rem;line-height:1.75rem}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xs{font-size:.75rem;line-height:1rem}.font-bold{font-weight:700}.font-semibold{font-weight:600}.italic{font-style:italic}.leading-\\[1\\.05\\]{line-height:1.05}.leading-relaxed{line-height:1.625}.leading-snug{line-height:1.375}.leading-tight{line-height:1.25}.text-amber-600{--tw-text-opacity:1;color:rgb(217 119 6/var(--tw-text-opacity,1))}.text-amber-700{--tw-text-opacity:1;color:rgb(180 83 9/var(--tw-text-opacity,1))}.text-blue-600{--tw-text-opacity:1;color:rgb(37 99 235/var(--tw-text-opacity,1))}.text-blue-700{--tw-text-opacity:1;color:rgb(29 78 216/var(--tw-text-opacity,1))}.text-blue-800{--tw-text-opacity:1;color:rgb(30 64 175/var(--tw-text-opacity,1))}.text-blue-900{--tw-text-opacity:1;color:rgb(30 58 138/var(--tw-text-opacity,1))}.text-emerald-600{--tw-text-opacity:1;color:rgb(5 150 105/var(--tw-text-opacity,1))}.text-emerald-700{--tw-text-opacity:1;color:rgb(4 120 87/var(--tw-text-opacity,1))}.text-red-500{--tw-text-opacity:1;color:rgb(239 68 68/var(--tw-text-opacity,1))}.text-red-600{--tw-text-opacity:1;color:rgb(220 38 38/var(--tw-text-opacity,1))}.text-red-700{--tw-text-opacity:1;color:rgb(185 28 28/var(--tw-text-opacity,1))}.text-rose-700{--tw-text-opacity:1;color:rgb(190 18 60/var(--tw-text-opacity,1))}.text-slate-300{--tw-text-opacity:1;color:rgb(203 213 225/var(--tw-text-opacity,1))}.text-slate-400{--tw-text-opacity:1;color:rgb(148 163 184/var(--tw-text-opacity,1))}.text-slate-500{--tw-text-opacity:1;color:rgb(100 116 139/var(--tw-text-opacity,1))}.text-slate-600{--tw-text-opacity:1;color:rgb(71 85 105/var(--tw-text-opacity,1))}.text-slate-700{--tw-text-opacity:1;color:rgb(51 65 85/var(--tw-text-opacity,1))}.text-slate-900{--tw-text-opacity:1;color:rgb(15 23 42/var(--tw-text-opacity,1))}.text-white{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity,1))}.underline{text-decoration-line:underline}.no-underline{text-decoration-line:none}.placeholder-slate-400::-moz-placeholder{--tw-placeholder-opacity:1;color:rgb(148 163 184/var(--tw-placeholder-opacity,1))}.placeholder-slate-400::placeholder{--tw-placeholder-opacity:1;color:rgb(148 163 184/var(--tw-placeholder-opacity,1))}.shadow-2xl{--tw-shadow:0 25px 50px -12px rgba(0,0,0,.25);--tw-shadow-colored:0 25px 50px -12px var(--tw-shadow-color)}.shadow-2xl,.shadow-glow{box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.shadow-glow{--tw-shadow:0 0 0 1px rgba(15,23,42,.06),0 10px 30px rgba(2,6,23,.1);--tw-shadow-colored:0 0 0 1px var(--tw-shadow-color),0 10px 30px var(--tw-shadow-color)}.shadow-glowLg{--tw-shadow:0 0 0 1px rgba(15,23,42,.06),0 24px 60px rgba(2,6,23,.16);--tw-shadow-colored:0 0 0 1px var(--tw-shadow-color),0 24px 60px var(--tw-shadow-color)}.shadow-glowLg,.shadow-sm{box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.shadow-sm{--tw-shadow:0 1px 2px 0 rgba(0,0,0,.05);--tw-shadow-colored:0 1px 2px 0 var(--tw-shadow-color)}.\\!outline{outline-style:solid!important}.outline{outline-style:solid}.ring{--tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);--tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(3px + var(--tw-ring-offset-width)) var(--tw-ring-color);box-shadow:var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 #0000)}.blur{--tw-blur:blur(8px)}.blur,.filter{filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.backdrop-blur{--tw-backdrop-blur:blur(8px)}.backdrop-blur,.backdrop-blur-sm{-webkit-backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia)}.backdrop-blur-sm{--tw-backdrop-blur:blur(4px)}.backdrop-blur-xl{--tw-backdrop-blur:blur(24px)}.backdrop-blur-xl,.backdrop-filter{-webkit-backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia)}.backdrop-filter{-webkit-backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia)}.transition{transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.transition-all{transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.transition-colors{transition-property:color,background-color,border-color,text-decoration-color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.placeholder\\:text-slate-400::-moz-placeholder{--tw-text-opacity:1;color:rgb(148 163 184/var(--tw-text-opacity,1))}.placeholder\\:text-slate-400::placeholder{--tw-text-opacity:1;color:rgb(148 163 184/var(--tw-text-opacity,1))}.hover\\:bg-blue-100:hover{--tw-bg-opacity:1;background-color:rgb(219 234 254/var(--tw-bg-opacity,1))}.hover\\:bg-rose-100:hover{--tw-bg-opacity:1;background-color:rgb(255 228 230/var(--tw-bg-opacity,1))}.hover\\:bg-slate-100\\/60:hover{background-color:rgba(241,245,249,.6)}.hover\\:bg-slate-400:hover{--tw-bg-opacity:1;background-color:rgb(148 163 184/var(--tw-bg-opacity,1))}.hover\\:bg-slate-50:hover{--tw-bg-opacity:1;background-color:rgb(248 250 252/var(--tw-bg-opacity,1))}.hover\\:bg-slate-50\\/60:hover{background-color:rgba(248,250,252,.6)}.hover\\:bg-slate-800:hover{--tw-bg-opacity:1;background-color:rgb(30 41 59/var(--tw-bg-opacity,1))}.hover\\:bg-white:hover{--tw-bg-opacity:1;background-color:rgb(255 255 255/var(--tw-bg-opacity,1))}.hover\\:text-slate-900:hover{--tw-text-opacity:1;color:rgb(15 23 42/var(--tw-text-opacity,1))}.hover\\:brightness-95:hover{--tw-brightness:brightness(.95);filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.focus\\:border-slate-400:focus{--tw-border-opacity:1;border-color:rgb(148 163 184/var(--tw-border-opacity,1))}.focus\\:outline-none:focus{outline:2px solid transparent;outline-offset:2px}@media (min-width:640px){.sm\\:hidden{display:none}.sm\\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.sm\\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.sm\\:grid-cols-4{grid-template-columns:repeat(4,minmax(0,1fr))}.sm\\:flex-row{flex-direction:row}.sm\\:flex-wrap{flex-wrap:wrap}.sm\\:items-start{align-items:flex-start}.sm\\:items-end{align-items:flex-end}.sm\\:items-center{align-items:center}.sm\\:justify-between{justify-content:space-between}.sm\\:px-6{padding-left:1.5rem;padding-right:1.5rem}.sm\\:px-7{padding-left:1.75rem;padding-right:1.75rem}.sm\\:py-7{padding-top:1.75rem;padding-bottom:1.75rem}.sm\\:text-5xl{font-size:3rem;line-height:1}.sm\\:text-lg{font-size:1.125rem;line-height:1.75rem}}@media (min-width:768px){.md\\:grid-cols-5{grid-template-columns:repeat(5,minmax(0,1fr))}}@media (min-width:1024px){.lg\\:block{display:block}.lg\\:grid{display:grid}.lg\\:grid-cols-\\[1fr_360px\\]{grid-template-columns:1fr 360px}.lg\\:grid-cols-\\[360px_1fr\\]{grid-template-columns:360px 1fr}.lg\\:flex-row{flex-direction:row}.lg\\:items-end{align-items:flex-end}.lg\\:justify-end{justify-content:flex-end}.lg\\:justify-between{justify-content:space-between}.lg\\:p-5{padding:1.25rem}.lg\\:px-10{padding-left:2.5rem;padding-right:2.5rem}.lg\\:px-8{padding-left:2rem;padding-right:2rem}.lg\\:py-10{padding-top:2.5rem;padding-bottom:2.5rem}}@media (min-width:1280px){.xl\\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}}
    </style>

    <!-- Code highlighting -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/diff2html/bundles/css/diff2html.min.css"
    />

    <style>
      :root {
        /* Surfaces */
        --bg0: #fbfbfe;
        --bg1: #f6f7ff;
        --card: rgba(255, 255, 255, 0.82);
        --card2: rgba(255, 255, 255, 0.7);
        --stroke: rgba(2, 6, 23, 0.10);
        --stroke2: rgba(2, 6, 23, 0.07);

        /* Ink */
        --ink0: #0b1220;
        --ink1: rgba(2, 6, 23, 0.80);
        --ink2: rgba(2, 6, 23, 0.62);
        --ink3: rgba(2, 6, 23, 0.46);

        /* Brand-ish gradient */
        --a0: rgba(37, 99, 235, 0.14);
        --a1: rgba(219, 39, 119, 0.10);
        --a2: rgba(20, 184, 166, 0.10);
        --a3: rgba(217, 119, 6, 0.10);

        /* Category colors (10 buckets) */
        --c1: #2563eb; /* logic/math */
        --c2: #d97706; /* sqlite legacy */
        --c3: #059669; /* asupersync */
        --c4: #dc2626; /* architecture mistakes */
        --c5: #64748b; /* scrivening */
        --c6: #db2777; /* background/context */
        --c7: #0ea5e9; /* standard eng perf */
        --c8: #7c3aed; /* alien math */
        --c9: #16a34a; /* clarification */
        --c10: #0f172a; /* other */

        --ring: rgba(37, 99, 235, 0.35);
      }

      html,
      body {
        height: 100%;
      }

      body {
        font-family: Manrope, system-ui, -apple-system, Segoe UI, sans-serif;
        color: var(--ink0);
        background: radial-gradient(1200px 700px at 10% -10%, var(--a0), transparent 60%),
          radial-gradient(900px 600px at 95% 5%, var(--a1), transparent 58%),
          radial-gradient(1100px 700px at 40% 110%, var(--a2), transparent 60%),
          radial-gradient(1100px 650px at 100% 85%, var(--a3), transparent 56%),
          linear-gradient(180deg, var(--bg0), var(--bg1));
        background-attachment: fixed;
      }

      /* Subtle noise */
      body::before {
        content: "";
        position: fixed;
        inset: 0;
        pointer-events: none;
        opacity: 0.035;
        mix-blend-mode: multiply;
        background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='320' height='320'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='.9' numOctaves='3' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='320' height='320' filter='url(%23n)' opacity='.35'/%3E%3C/svg%3E");
      }

      .glass {
        background: var(--card);
        border: 1px solid var(--stroke);
        backdrop-filter: blur(14px);
        -webkit-backdrop-filter: blur(14px);
      }

      .glass-2 {
        background: var(--card2);
        border: 1px solid var(--stroke2);
        backdrop-filter: blur(14px);
        -webkit-backdrop-filter: blur(14px);
      }

      .focus-ring:focus {
        outline: none;
        box-shadow: 0 0 0 4px var(--ring);
      }

      @media (prefers-reduced-motion: reduce) {
        * {
          animation: none !important;
          transition: none !important;
          scroll-behavior: auto !important;
        }
      }

      .enter {
        animation: enter 700ms cubic-bezier(0.2, 1, 0.2, 1) both;
      }
      @keyframes enter {
        from {
          opacity: 0;
          transform: translateY(10px);
        }
        to {
          opacity: 1;
          transform: translateY(0);
        }
      }

      .chip {
        border: 1px solid var(--stroke2);
        background: rgba(255, 255, 255, 0.7);
      }

      .codebox {
        background: rgba(15, 23, 42, 0.03);
        border: 1px solid rgba(2, 6, 23, 0.10);
      }

      .mono {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono",
          "Courier New", monospace;
      }

      /* Mobile bottom sheet */
      .sheet {
        transform: translateY(12px);
        opacity: 0;
        transition: transform 200ms ease, opacity 200ms ease;
        will-change: transform, opacity;
      }
      .sheet.open {
        transform: translateY(0);
        opacity: 1;
      }

      /* ECharts container should not shrink weirdly */
      .chart {
        min-height: 280px;
        contain: content;
      }

      @media (max-width: 639px) {
        .glass,
        .glass-2 {
          backdrop-filter: blur(8px);
          -webkit-backdrop-filter: blur(8px);
        }
        .chart {
          min-height: 320px;
        }
        #docMain:not(.hidden) {
          display: flex;
          flex-direction: column;
        }
        #docMain > aside {
          order: -1;
        }
      }

      #commitList {
        contain: content;
      }

      /* Section summary heading highlight */
      @keyframes section-flash {
        0% { background-color: rgba(59, 130, 246, 0.25); }
        100% { background-color: transparent; }
      }
      .section-highlight {
        animation: section-flash 1.2s ease-out;
      }

      /* Section summary table */
      #sectionTable th {
        cursor: pointer;
        user-select: none;
      }
      #sectionTable th:hover {
        color: var(--ink0);
      }
      #sectionTable .sparkline-bar {
        display: inline-block;
        min-width: 2px;
        border-radius: 1px;
        vertical-align: middle;
      }

      /* Markdown rendering (hand-rolled; avoids tailwind/typography plugin dependency) */
      .md {
        color: rgba(2, 6, 23, 0.82);
        font-size: 15px;
        line-height: 1.75;
      }
      .md h1,
      .md h2,
      .md h3,
      .md h4 {
        font-family: Fraunces, ui-serif, Georgia, serif;
        color: rgba(2, 6, 23, 0.92);
        letter-spacing: -0.01em;
      }
      .md h1 {
        font-size: 28px;
        line-height: 1.15;
        margin: 18px 0 10px;
      }
      .md h2 {
        font-size: 22px;
        line-height: 1.2;
        margin: 18px 0 8px;
      }
      .md h3 {
        font-size: 18px;
        line-height: 1.25;
        margin: 14px 0 6px;
      }
      .md p {
        margin: 10px 0;
      }
      .md ul,
      .md ol {
        margin: 10px 0 10px 18px;
      }
      .md li {
        margin: 4px 0;
      }
      .md code {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono",
          "Courier New", monospace;
        font-size: 0.92em;
        padding: 0.12em 0.36em;
        border: 1px solid rgba(2, 6, 23, 0.10);
        border-radius: 10px;
        background: rgba(15, 23, 42, 0.04);
      }
      .md pre code {
        display: block;
        padding: 0;
        border: none;
        background: transparent;
        font-size: 12px;
        line-height: 1.6;
      }
      .md pre {
        margin: 12px 0;
        padding: 12px 14px;
        border-radius: 18px;
        overflow: auto;
        border: 1px solid rgba(2, 6, 23, 0.10);
        background: rgba(15, 23, 42, 0.03);
      }
      .md a {
        color: rgb(37, 99, 235);
        text-decoration: none;
      }
      .md a:hover {
        text-decoration: underline;
      }
      .md table {
        width: 100%;
        border-collapse: collapse;
        margin: 12px 0;
        font-size: 13px;
      }
      .md th,
      .md td {
        border: 1px solid rgba(2, 6, 23, 0.10);
        padding: 8px 10px;
        vertical-align: top;
      }
      .md th {
        background: rgba(15, 23, 42, 0.03);
        font-weight: 800;
      }
      .md blockquote {
        margin: 12px 0;
        padding: 10px 12px;
        border-left: 3px solid rgba(37, 99, 235, 0.35);
        background: rgba(37, 99, 235, 0.06);
        border-radius: 14px;
      }

      /* Bottom timeline dock */
      .dock {
        background: rgba(255, 255, 255, 0.78);
        border-top: 1px solid rgba(2, 6, 23, 0.10);
        backdrop-filter: blur(16px);
        -webkit-backdrop-filter: blur(16px);
      }
      .dock-canvas {
        width: 100%;
        height: 40px;
        display: block;
      }
      .dock-slider {
        width: 100%;
      }
      .dock-heat-stripe {
        width: 100%;
        height: 12px;
        display: block;
        border-radius: 6px;
        cursor: pointer;
      }
      .dock-heat-tooltip {
        position: fixed;
        z-index: 50;
        pointer-events: none;
        padding: 6px 10px;
        border-radius: 10px;
        background: rgba(255,255,255,0.96);
        border: 1px solid rgba(2,6,23,0.12);
        box-shadow: 0 8px 24px rgba(2,6,23,0.14);
        font-size: 11px;
        color: #0b1220;
        line-height: 1.4;
        max-width: 240px;
        white-space: nowrap;
        transition: opacity 0.12s;
      }

      /* A/B Compare Typeahead Pickers (bd-24q.1) */
      .ab-picker {
        position: relative;
        display: inline-flex;
      }
      .ab-picker-btn {
        display: inline-flex;
        align-items: center;
        gap: 4px;
        padding: 4px 10px;
        border: 1px solid rgba(59, 130, 246, 0.3);
        border-radius: 8px;
        background: white;
        font-size: 11px;
        font-weight: 600;
        color: #0f172a;
        cursor: pointer;
        max-width: 240px;
        overflow: hidden;
        text-overflow: ellipsis;
        white-space: nowrap;
        transition: border-color 150ms, box-shadow 150ms;
      }
      .ab-picker-btn:hover { border-color: rgba(59, 130, 246, 0.5); }
      .ab-picker-btn:focus { outline: none; box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.25); }
      .ab-picker-dropdown {
        position: absolute;
        top: 100%;
        left: 0;
        z-index: 60;
        margin-top: 4px;
        width: 340px;
        max-height: 300px;
        border: 1px solid rgba(2, 6, 23, 0.12);
        border-radius: 14px;
        background: white;
        box-shadow: 0 10px 30px rgba(2, 6, 23, 0.16);
        display: flex;
        flex-direction: column;
        overflow: hidden;
      }
      .ab-picker-search {
        width: 100%;
        border: none;
        border-bottom: 1px solid rgba(2, 6, 23, 0.08);
        padding: 8px 12px;
        font-size: 12px;
        outline: none;
        background: transparent;
      }
      .ab-picker-search::placeholder { color: rgba(2, 6, 23, 0.4); }
      .ab-picker-list {
        flex: 1;
        overflow-y: auto;
        padding: 4px;
      }
      .ab-picker-item {
        display: flex;
        align-items: baseline;
        gap: 6px;
        padding: 6px 8px;
        border-radius: 8px;
        font-size: 11px;
        cursor: pointer;
        transition: background 100ms;
      }
      .ab-picker-item:hover,
      .ab-picker-item.keyboard-active { background: rgba(59, 130, 246, 0.08); }
      .ab-picker-item.selected { background: rgba(59, 130, 246, 0.12); font-weight: 700; }
      .ab-picker-item .idx {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
        color: rgba(2, 6, 23, 0.35);
        font-size: 10px;
        min-width: 22px;
        flex-shrink: 0;
      }
      .ab-picker-item .hash {
        font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
        color: rgba(2, 6, 23, 0.5);
        font-size: 10px;
        flex-shrink: 0;
      }
      .ab-picker-item .subject {
        color: #0f172a;
        overflow: hidden;
        text-overflow: ellipsis;
        white-space: nowrap;
        flex: 1;
        min-width: 0;
      }
      @media (max-width: 639px) {
        .ab-picker-dropdown {
          position: fixed;
          inset: 0;
          width: 100%;
          max-height: 100%;
          border-radius: 0;
          margin-top: 0;
          z-index: 100;
        }
        .ab-picker-search {
          padding: 14px 16px;
          font-size: 16px;
        }
        .ab-picker-item {
          padding: 12px 16px;
          font-size: 13px;
        }
        .ab-picker-item .idx { font-size: 11px; }
        .ab-picker-item .hash { font-size: 11px; }
        .ab-picker-dropdown::before {
          content: "";
          display: block;
          height: 4px;
          width: 36px;
          margin: 8px auto 4px;
          border-radius: 2px;
          background: rgba(2, 6, 23, 0.15);
        }
      }

      /* Search Palette (bd-24q.9.2) */
      .search-palette-overlay { position: fixed; inset: 0; z-index: 200; background: rgba(2, 6, 23, 0.35); backdrop-filter: blur(4px); display: flex; justify-content: center; padding-top: min(20vh, 160px); }
      .search-palette { width: 560px; max-height: 480px; background: white; border-radius: 16px; border: 1px solid rgba(2, 6, 23, 0.12); box-shadow: 0 24px 60px rgba(2, 6, 23, 0.24); display: flex; flex-direction: column; overflow: hidden; animation: spFadeIn 120ms ease-out; }
      @keyframes spFadeIn { from { opacity: 0; transform: translateY(-8px); } to { opacity: 1; transform: translateY(0); } }
      .search-palette-input { border: none; border-bottom: 1px solid rgba(2, 6, 23, 0.08); padding: 14px 16px; font-size: 15px; font-family: inherit; outline: none; background: transparent; width: 100%; }
      .search-palette-input::placeholder { color: rgba(2, 6, 23, 0.38); }
      .search-palette-results { flex: 1; overflow-y: auto; padding: 4px; }
      .search-palette-item { display: flex; align-items: baseline; gap: 8px; padding: 8px 12px; border-radius: 10px; cursor: pointer; font-size: 13px; color: #0f172a; }
      .search-palette-item:hover, .search-palette-item.kb-active { background: rgba(59, 130, 246, 0.08); }
      .search-palette-item .sp-idx { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; color: rgba(2, 6, 23, 0.35); font-size: 11px; min-width: 24px; flex-shrink: 0; }
      .search-palette-item .sp-hash { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; color: rgba(59, 130, 246, 0.6); font-size: 11px; flex-shrink: 0; }
      .search-palette-item .sp-subject { overflow: hidden; text-overflow: ellipsis; white-space: nowrap; flex: 1; min-width: 0; }
      .search-palette-item .sp-score { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; color: rgba(2, 6, 23, 0.25); font-size: 10px; flex-shrink: 0; }
      .search-palette-hint { padding: 16px; text-align: center; font-size: 12px; color: rgba(2, 6, 23, 0.4); }
      .search-palette-footer { border-top: 1px solid rgba(2, 6, 23, 0.06); padding: 6px 12px; display: flex; gap: 12px; font-size: 10px; color: rgba(2, 6, 23, 0.38); }
      .search-palette-footer kbd { display: inline-block; padding: 1px 5px; border: 1px solid rgba(2, 6, 23, 0.15); border-radius: 4px; font-family: ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 10px; background: rgba(2, 6, 23, 0.03); }
      @media (max-width: 639px) {
        .search-palette-overlay { padding-top: 0; align-items: stretch; }
        .search-palette { width: 100%; max-height: 100%; border-radius: 0; }
        .search-palette-input { font-size: 16px; padding: 16px; }
        .search-palette-item { padding: 12px 16px; font-size: 14px; }
      }

      /* Side-by-Side Mobile UX (bd-24q.15.3) */
      .sbs-mobile-tabs {
        display: none;
        gap: 2px;
        background: rgba(2, 6, 23, 0.06);
        border-radius: 10px;
        padding: 2px;
      }
      .sbs-mobile-tabs button {
        flex: 1;
        padding: 5px 10px;
        font-size: 11px;
        font-weight: 600;
        border-radius: 8px;
        border: none;
        background: transparent;
        color: rgba(2, 6, 23, 0.5);
        cursor: pointer;
        transition: background 100ms, color 100ms;
      }
      .sbs-mobile-tabs button.active {
        background: white;
        color: #0f172a;
        box-shadow: 0 1px 3px rgba(2, 6, 23, 0.1);
      }
      .sbs-jump-cta {
        display: none;
        position: absolute;
        bottom: 12px;
        left: 50%;
        transform: translateX(-50%);
        z-index: 10;
        padding: 6px 14px;
        font-size: 11px;
        font-weight: 600;
        color: white;
        background: #334155;
        border: none;
        border-radius: 20px;
        cursor: pointer;
        box-shadow: 0 4px 12px rgba(2, 6, 23, 0.2);
        animation: sbsCtaIn 200ms ease-out;
      }
      @keyframes sbsCtaIn { from { opacity: 0; transform: translateX(-50%) translateY(8px); } to { opacity: 1; transform: translateX(-50%) translateY(0); } }
      .sbs-jump-cta:hover { background: #1e293b; }
      @media (max-width: 639px) {
        #sbsContainer .sbs-mobile-tabs { display: flex; }
        #sbsContainer #sbsDivider { display: none; }
        #sbsContainer #sbsPaneA,
        #sbsContainer #sbsPaneB { display: none; }
        #sbsContainer .sbs-pane-visible { display: block !important; flex: 1; }
        #sbsContainer .sbs-jump-cta.visible { display: block; }
      }
      @media (max-width: 639px) and (orientation: landscape) and (min-height: 320px) {
        #sbsContainer .sbs-mobile-tabs { display: none; }
        #sbsContainer #sbsDivider { display: block; }
        #sbsContainer #sbsPaneA,
        #sbsContainer #sbsPaneB { display: block; flex: 1; }
        #sbsContainer .sbs-jump-cta { display: none !important; }
      }
      /* Safe-area insets for notched devices (bd-24q.15.3) */
      @supports (padding-bottom: env(safe-area-inset-bottom)) {
        .dock { padding-bottom: calc(12px + env(safe-area-inset-bottom)); }
        body { padding-bottom: calc(7rem + env(safe-area-inset-bottom)); }
      }
    </style>
  </head>

  <body>
    <div class="mx-auto max-w-[1200px] px-4 pb-28 pt-10 sm:px-6 lg:px-8" style="position:relative;z-index:31">
      <!-- Top -->
      <header class="enter">
        <div
          class="glass shadow-glow rounded-3xl px-5 py-6 sm:px-7 sm:py-7 lg:px-10 lg:py-10"
        >
          <div class="flex flex-col gap-6 lg:flex-row lg:items-end lg:justify-between">
            <div class="max-w-[70ch]">
              <div class="flex flex-wrap items-center gap-2">
                <span
                  class="chip inline-flex items-center gap-2 rounded-full px-3 py-1 text-xs font-semibold text-slate-700"
                >
                  <span
                    class="inline-block h-2 w-2 rounded-full"
                    style="background: linear-gradient(90deg, var(--c1), var(--c6))"
                  ></span>
                  Single-file visualization
                </span>
                <span
                  id="metaSpan"
                  class="chip inline-flex items-center rounded-full px-3 py-1 text-xs font-semibold text-slate-700"
                ></span>
              </div>

              <h1 class="mt-4 font-display text-4xl leading-[1.05] sm:text-5xl">
                Evolution of the FrankenSQLite Spec
              </h1>
              <p class="mt-4 text-base leading-relaxed text-slate-700 sm:text-lg">
                A commit-by-commit atlas of how
                <span class="mono">COMPREHENSIVE_SPEC_FOR_FRANKENSQLITE_V1.md</span>
                changed from inception. Every change is bucketed into 10 categories with
                multi-label support, confidence, and diff excerpts.
              </p>
            </div>

            <div class="flex flex-col gap-3 sm:flex-row sm:flex-wrap sm:items-center lg:justify-end">
              <button
                id="btnFilters"
                class="focus-ring inline-flex items-center justify-center gap-2 rounded-2xl border border-slate-900/10 bg-white/60 px-4 py-2.5 text-sm font-semibold text-slate-900 shadow-sm transition hover:bg-white"
                type="button"
              >
                Filters
              </button>
              <a
                id="btnOpenSpec"
                class="focus-ring inline-flex items-center justify-center gap-2 rounded-2xl border border-slate-900/10 bg-white/60 px-4 py-2.5 text-sm font-semibold text-slate-900 shadow-sm transition hover:bg-white"
                href="COMPREHENSIVE_SPEC_FOR_FRANKENSQLITE_V1.md"
              >
                Open Spec
              </a>
              <button
                id="btnGalaxy"
                class="focus-ring inline-flex items-center justify-center gap-2 rounded-2xl bg-slate-900 px-4 py-2.5 text-sm font-semibold text-white shadow-sm transition hover:bg-slate-800"
                type="button"
              >
                Galaxy Brain
              </button>
            </div>
          </div>

          <div class="mt-7 grid grid-cols-2 gap-3 sm:grid-cols-3 md:grid-cols-5">
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Commits</div>
              <div id="kpiCommits" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Change Groups</div>
              <div id="kpiGroups" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Lines Changed</div>
              <div id="kpiLines" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Primary Mode</div>
              <div id="kpiMode" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
            <div class="glass-2 rounded-2xl p-4 shadow-sm">
              <div class="text-xs font-semibold text-slate-500">Data Integrity</div>
              <div id="kpiIntegrity" class="mt-2 text-2xl font-bold text-slate-900">-</div>
            </div>
          </div>
        </div>
      </header>

      <!-- Main layout -->
      <div class="mt-8 grid grid-cols-1 gap-6 lg:grid-cols-[360px_1fr]">
        <!-- Sidebar (desktop) -->
        <aside class="enter hidden lg:block">
          <div class="glass shadow-glow rounded-3xl p-5">
            <div class="flex items-center justify-between">
              <div class="text-sm font-bold text-slate-900">Filters</div>
              <button
                id="btnReset"
                class="focus-ring rounded-xl border border-slate-900/10 bg-white/60 px-3 py-1.5 text-xs font-semibold text-slate-900 hover:bg-white"
                type="button"
              >
                Reset
              </button>
            </div>

            <div class="mt-4">
              <label class="text-xs font-semibold text-slate-600">Search</label>
              <input
                id="q"
                class="focus-ring mt-2 w-full rounded-2xl border border-slate-900/10 bg-white/70 px-3.5 py-2.5 text-sm text-slate-900 placeholder:text-slate-400"
                placeholder="commit, section, keyword..."
              />
            </div>

            <div class="mt-4">
              <div class="flex items-center justify-between">
                <label class="text-xs font-semibold text-slate-600">Min Impact</label>
                <div id="impactLabel" class="mono text-xs text-slate-500">-</div>
              </div>
              <input id="impact" class="mt-2 w-full" type="range" min="0" max="200" value="0" />
            </div>

            <div class="mt-5">
              <div class="flex items-center justify-between">
                <label class="text-xs font-semibold text-slate-600">Bucket Mode</label>
                <div class="mono text-xs text-slate-500" id="bucketModeLabel">primary</div>
              </div>
              <div class="mt-2 grid grid-cols-2 gap-2">
                <button
                  id="modePrimary"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-slate-900 px-3 py-2 text-xs font-semibold text-white"
                  type="button"
                >
                  Primary (disjoint)
                </button>
                <button
                  id="modeMulti"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900"
                  type="button"
                >
                  Multi-label
                </button>
              </div>
              <p class="mt-2 text-xs leading-relaxed text-slate-500">
                Multi-label counts a change group in every bucket it matches. Primary assigns each group
                exactly one bucket for clean stacks.
              </p>
            </div>

            <div class="mt-5">
              <label class="text-xs font-semibold text-slate-600">Buckets</label>
              <div id="bucketToggles" class="mt-2 grid grid-cols-1 gap-2"></div>
            </div>

            <div class="mt-6">
              <label class="text-xs font-semibold text-slate-600">Quick Views</label>
              <div class="mt-2 grid grid-cols-1 gap-2">
                <button
                  id="viewTimeline"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Timeline + Categories
                </button>
                <button
                  id="viewCommits"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Commit Explorer
                </button>
                <button
                  id="viewAlien"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Alien Telemetry (BOCPD)
                </button>
              </div>
            </div>
          </div>
        </aside>

        <!-- Content -->
        <main class="enter">
          <!-- Timeline -->
          <section id="sectionTimeline" class="glass shadow-glow rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Timeline</div>
                <div class="mt-1 text-xs text-slate-500">
                  Dot = commit. Size = lines changed. Color = primary bucket.
                </div>
              </div>
              <div class="flex flex-wrap items-center gap-2">
                <div class="chip rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                  <span class="mono" id="rangeLabel">-</span>
                </div>
                <a
                  id="btnOpenRepo"
                  class="focus-ring chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700 hover:bg-white"
                  href="https://github.com/Dicklesworthstone/frankensqlite"
                  target="_blank"
                  rel="noreferrer"
                >
                  GitHub
                </a>
              </div>
            </div>

            <div id="timelineChart" class="chart mt-4 w-full"></div>
          </section>

          <section class="mt-6 grid grid-cols-1 gap-6 xl:grid-cols-2">
            <section class="glass shadow-glow rounded-3xl p-5">
              <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
                <div>
                  <div class="text-sm font-bold text-slate-900">Buckets Over Time</div>
                  <div class="mt-1 text-xs text-slate-500">
                    Stacked totals across time bins (or by commit). Use this for day/hour/15m/5m
                    density.
                  </div>
                </div>
                <div class="flex flex-wrap items-center gap-2">
                  <label class="chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                    Resolution
                    <select id="stackResolution" class="ml-1 rounded-xl border border-slate-900/10 bg-white/70 px-2 py-1 text-xs">
                      <option value="commit">Commit</option>
                      <option value="day">Day</option>
                      <option value="hour">Hour</option>
                      <option value="15m">15 min</option>
                      <option value="5m">5 min</option>
                    </select>
                  </label>
                  <label class="chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                    Metric
                    <select id="stackMetric" class="ml-1 rounded-xl border border-slate-900/10 bg-white/70 px-2 py-1 text-xs">
                      <option value="groups">Change groups</option>
                      <option value="lines">Lines changed (approx)</option>
                      <option value="tokens">Tokens changed (approx)</option>
                      <option value="lev">Levenshtein (hunks)</option>
                    </select>
                  </label>
                  <label class="chip inline-flex items-center gap-2 rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                    Timezone
                    <select id="stackTimezone" class="ml-1 rounded-xl border border-slate-900/10 bg-white/70 px-2 py-1 text-xs">
                      <option value="local">Local</option>
                      <option value="utc">UTC</option>
                    </select>
                  </label>
                </div>
              </div>
              <div id="stackChart" class="chart mt-4 w-full"></div>
            </section>

            <section class="glass shadow-glow rounded-3xl p-5">
              <div class="flex items-end justify-between">
                <div>
                  <div class="text-sm font-bold text-slate-900">Bucket Mix</div>
                  <div class="mt-1 text-xs text-slate-500">Distribution in current filter.</div>
                </div>
              </div>
              <div id="donutChart" class="chart mt-4 w-full"></div>
            </section>
          </section>

          <!-- Doc evolution -->
          <section id="sectionDoc" class="glass shadow-glow mt-6 rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Document Evolution</div>
                <div class="mt-1 text-xs text-slate-500">
                  Scrub the timeline dock to step through history. Inspect the rendered spec and the
                  unified diff (with token + Levenshtein metrics).
                </div>
              </div>
              <div class="flex flex-wrap items-center gap-2">
                <button
                  id="docTabSpec"
                  class="focus-ring rounded-2xl bg-slate-900 px-3 py-2 text-xs font-semibold text-white hover:bg-slate-800"
                  type="button"
                >
                  Spec
                </button>
                <button
                  id="docTabDiff"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Diff
                </button>
                <button
                  id="docTabMetrics"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Metrics
                </button>
                <button
                  id="docTabSections"
                  class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
                  type="button"
                >
                  Sections
                </button>
                <span class="relative ml-1">
                  <button
                    id="btnCopyLink"
                    class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
                    type="button"
                    title="Copy a shareable permalink to the current view"
                  >Copy Link</button>
                  <button
                    id="btnShareHelp"
                    class="focus-ring ml-1 rounded-full border border-slate-900/10 bg-white/70 px-2 py-1 text-[10px] font-bold text-slate-500 hover:bg-white hover:text-slate-900"
                    type="button"
                    title="URL parameter reference"
                  >?</button>
                  <div
                    id="shareHelpPopover"
                    class="hidden absolute right-0 top-full z-50 mt-2 w-72 rounded-2xl border border-slate-900/10 bg-white p-4 shadow-glowLg text-left"
                  >
                    <div class="text-xs font-bold text-slate-900 mb-2">Permalink URL Parameters</div>
                    <table class="w-full text-[11px] text-slate-700">
                      <thead><tr class="border-b border-slate-200"><th class="pb-1 text-left font-semibold">Param</th><th class="pb-1 text-left font-semibold">Values</th><th class="pb-1 text-left font-semibold">Default</th></tr></thead>
                      <tbody>
                        <tr><td class="py-0.5 font-mono">v</td><td>Schema version</td><td>1</td></tr>
                        <tr><td class="py-0.5 font-mono">c</td><td>Commit index (0-based)</td><td>latest</td></tr>
                        <tr><td class="py-0.5 font-mono">t</td><td>spec | diff | metrics</td><td>spec</td></tr>
                        <tr><td class="py-0.5 font-mono">raw</td><td>1 = raw markdown</td><td>rendered</td></tr>
                        <tr><td class="py-0.5 font-mono">dm</td><td>pretty | raw</td><td>pretty</td></tr>
                        <tr><td class="py-0.5 font-mono">q</td><td>Search query</td><td>(empty)</td></tr>
                        <tr><td class="py-0.5 font-mono">mi</td><td>Min impact (lines)</td><td>0</td></tr>
                        <tr><td class="py-0.5 font-mono">bm</td><td>primary | multi</td><td>primary</td></tr>
                        <tr><td class="py-0.5 font-mono">b</td><td>Bucket IDs (1-10, comma-sep)</td><td>all</td></tr>
                        <tr><td class="py-0.5 font-mono">cmp</td><td>1 = A/B compare mode</td><td>off</td></tr>
                        <tr><td class="py-0.5 font-mono">ca</td><td>Compare "A" commit index</td><td>0</td></tr>
                        <tr><td class="py-0.5 font-mono">cb</td><td>Compare "B" commit index</td><td>0</td></tr>
                        <tr><td class="py-0.5 font-mono">dl</td><td>side-by-side | line-by-line</td><td>side-by-side</td></tr>
                        <tr><td class="py-0.5 font-mono">avm</td><td>diff | rendered</td><td>diff</td></tr>
                        <tr><td class="py-0.5 font-mono">res</td><td>commit | day | hour | 15m | 5m</td><td>commit</td></tr>
                        <tr><td class="py-0.5 font-mono">tz</td><td>local | utc</td><td>local</td></tr>
                        <tr><td class="py-0.5 font-mono">met</td><td>groups | lines | tokens | lev</td><td>groups</td></tr>
                      </tbody>
                    </table>
                    <div class="mt-2 text-[10px] text-slate-500">Default values are omitted for minimal URLs. Invalid values are clamped. Canonical key order: v, c, t, raw, dm, cmp, ca, cb, dl, avm, q, mi, bm, b, res, tz, met.</div>
                  </div>
                </span>
              </div>
            </div>

            <div id="docLoading" class="mt-4 rounded-3xl border border-slate-900/10 bg-white/60 p-4 text-sm text-slate-700">
              Loading spec evolution dataset... (local gzip JSON; no GitHub API)
            </div>

            <div id="docMain" class="mt-4 hidden grid-cols-1 gap-4 lg:grid lg:grid-cols-[1fr_360px]">
              <section class="glass-2 rounded-3xl p-4 lg:p-5">
                <div class="flex flex-col gap-2 sm:flex-row sm:items-center sm:justify-between">
                  <div class="min-w-0">
                    <div class="text-xs font-semibold text-slate-500">Selected commit</div>
                    <div id="docCommitTitle" class="mt-1 truncate text-sm font-semibold text-slate-900">-</div>
                  </div>
                  <div class="flex shrink-0 flex-wrap items-center gap-2">
                    <span id="docCommitMeta" class="chip mono inline-flex items-center rounded-full px-2.5 py-1 text-[11px] text-slate-700">-</span>
                    <a
                      id="docCommitLink"
                      class="focus-ring chip inline-flex items-center gap-2 rounded-2xl px-3 py-2 text-xs font-semibold text-slate-700 hover:bg-white"
                      href="#"
                      target="_blank"
                      rel="noreferrer"
                    >
                      Open commit
                    </a>
                  </div>
                </div>

                <div class="mt-4">
                  <div id="docSpecView" class="hidden">
                    <div class="flex items-center justify-between">
                      <div class="text-xs font-semibold text-slate-600">Rendered Markdown</div>
                      <div class="flex items-center gap-2">
                        <button
                          id="btnStoryToggle"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                          type="button"
                          title="Toggle story mode milestones"
                        >
                          Story
                        </button>
                        <button
                          id="btnMiniMapToggle"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                          type="button"
                          title="Toggle heading mini-map"
                        >
                          Outline
                        </button>
                        <button
                          id="btnRawToggle"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                          type="button"
                        >
                          Toggle Raw
                        </button>
                      </div>
                    </div>
                    <div class="mt-3 flex gap-3">
                      <nav
                        id="miniMap"
                        class="hidden w-56 shrink-0 flex flex-col rounded-2xl border border-slate-900/10 bg-white/70"
                        style="max-height: 70vh"
                        aria-label="Document outline"
                      >
                        <div class="shrink-0 border-b border-slate-900/10 px-3 py-2">
                          <input
                            id="miniMapSearch"
                            type="text"
                            class="w-full rounded-lg border border-slate-900/10 bg-white/80 px-2 py-1 text-[11px] text-slate-700 placeholder:text-slate-400 focus:border-slate-400 focus:outline-none"
                            placeholder="Filter headings..."
                            autocomplete="off"
                          />
                        </div>
                        <div id="miniMapItems" class="flex-1 overflow-y-auto p-3" role="tree" tabindex="0"></div>
                      </nav>
                      <div id="docRendered" class="md min-w-0 flex-1 max-h-[70vh] overflow-auto rounded-2xl border border-slate-900/10 bg-white/70 p-4"></div>
                      <aside
                        id="storyRail"
                        class="hidden w-64 shrink-0 flex flex-col rounded-2xl border border-slate-900/10 bg-white/70"
                        style="max-height: 70vh"
                        aria-label="Story mode milestones"
                      >
                        <div class="shrink-0 border-b border-slate-900/10 px-3 py-2 flex items-center justify-between">
                          <span class="text-[11px] font-semibold text-slate-600">Milestones</span>
                          <div class="flex items-center gap-1.5">
                            <button id="storyPrev" class="focus-ring rounded-lg border border-slate-900/10 bg-white/80 px-2 py-0.5 text-[10px] font-semibold text-slate-600 hover:bg-white" type="button" aria-label="Previous milestone">&larr;</button>
                            <span id="storyProgress" class="text-[10px] text-slate-400">0/0</span>
                            <button id="storyNext" class="focus-ring rounded-lg border border-slate-900/10 bg-white/80 px-2 py-0.5 text-[10px] font-semibold text-slate-600 hover:bg-white" type="button" aria-label="Next milestone">&rarr;</button>
                          </div>
                        </div>
                        <div id="storyCards" class="flex-1 overflow-y-auto p-3 space-y-2"></div>
                      </aside>
                    </div>
                    <pre id="docRaw" class="codebox mono mt-3 hidden max-h-[70vh] overflow-auto rounded-2xl p-4 text-[11px] leading-relaxed text-slate-900"></pre>
                  </div>

                  <div id="docDiffView" class="hidden">
                    <div class="flex items-center justify-between flex-wrap gap-2">
                      <div class="flex items-center gap-2">
                        <div id="diffLabel" class="text-xs font-semibold text-slate-600">Diff (parent → selected)</div>
                        <button
                          id="btnCompareToggle"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                          type="button"
                          title="Toggle A/B compare mode"
                        >A/B Compare</button>
                      </div>
                      <div class="flex items-center gap-2">
                        <button
                          id="btnDiffLayout"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white hidden"
                          type="button"
                          title="Toggle side-by-side / unified layout"
                        >Side-by-Side</button>
                        <button
                          id="btnSbsRendered"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white hidden"
                          type="button"
                          title="Show rendered markdown side-by-side (A left, B right)"
                        >Rendered A|B</button>
                        <button
                          id="btnPrettyDiff"
                          class="focus-ring rounded-xl bg-slate-900 px-3 py-1.5 text-[11px] font-semibold text-white hover:bg-slate-800"
                          type="button"
                        >
                          Pretty
                        </button>
                        <button
                          id="btnRawDiff"
                          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
                          type="button"
                        >
                          Raw
                        </button>
                      </div>
                    </div>
                    <!-- A/B Compare commit pickers with typeahead (bd-24q.1) -->
                    <div id="abCompareBar" class="hidden mt-2 flex items-center gap-2 flex-wrap rounded-xl border border-blue-200 bg-blue-50/60 px-3 py-2">
                      <label class="text-[11px] font-semibold text-blue-700">A:</label>
                      <div class="ab-picker" id="pickerA">
                        <button type="button" class="ab-picker-btn" id="pickerABtn" title="Select commit A">Select...</button>
                        <div class="ab-picker-dropdown hidden" id="pickerADropdown">
                          <input type="text" class="ab-picker-search" id="pickerASearch" placeholder="Search by subject, hash, or #index..." autocomplete="off" />
                          <div class="ab-picker-list" id="pickerAList"></div>
                        </div>
                      </div>
                      <button id="btnSwapAB" class="focus-ring rounded-lg border border-blue-200 bg-white px-2 py-1 text-[11px] font-semibold text-blue-700 hover:bg-blue-100" type="button" title="Swap A and B">⇄</button>
                      <label class="text-[11px] font-semibold text-blue-700">B:</label>
                      <div class="ab-picker" id="pickerB">
                        <button type="button" class="ab-picker-btn" id="pickerBBtn" title="Select commit B">Select...</button>
                        <div class="ab-picker-dropdown hidden" id="pickerBDropdown">
                          <input type="text" class="ab-picker-search" id="pickerBSearch" placeholder="Search by subject, hash, or #index..." autocomplete="off" />
                          <div class="ab-picker-list" id="pickerBList"></div>
                        </div>
                      </div>
                      <button id="btnResetAB" class="focus-ring rounded-lg border border-blue-200 bg-white px-2 py-1 text-[11px] font-semibold text-blue-700 hover:bg-blue-100" type="button" title="Reset to current commit">Reset</button>
                      <div id="abDiffLoading" class="hidden text-[11px] text-blue-600 ml-2">Computing diff…</div>
                    </div>
                    <!-- A/B Compare metric chips -->
                    <div id="abMetricsBar" class="hidden mt-2 flex items-center gap-2 flex-wrap">
                      <span id="abmLines" class="chip mono rounded-full px-2.5 py-1 text-[11px] text-blue-800 bg-blue-100 border border-blue-200"></span>
                      <span id="abmTokens" class="chip mono rounded-full px-2.5 py-1 text-[11px] text-blue-800 bg-blue-100 border border-blue-200"></span>
                      <span id="abmLev" class="chip mono rounded-full px-2.5 py-1 text-[11px] text-blue-800 bg-blue-100 border border-blue-200"></span>
                      <span id="abmHunks" class="chip mono rounded-full px-2.5 py-1 text-[11px] text-blue-800 bg-blue-100 border border-blue-200"></span>
                      <span id="abmBytes" class="chip mono rounded-full px-2.5 py-1 text-[11px] text-blue-800 bg-blue-100 border border-blue-200"></span>
                    </div>
                    <div id="diffPretty" class="mt-3 max-h-[70vh] overflow-auto rounded-2xl border border-slate-900/10 bg-white/70 p-2"></div>
                    <pre id="diffRaw" class="codebox mono mt-3 hidden max-h-[70vh] overflow-auto rounded-2xl p-4 text-[11px] leading-relaxed text-slate-900"></pre>
                    <!-- Side-by-Side Rendered Markdown Panes (bd-24q.15.1) -->
                    <div id="sbsContainer" class="hidden mt-3 relative flex flex-col rounded-2xl border border-slate-900/10 bg-white/70" style="max-height: 70vh">
                      <!-- Pane header bar: labels + controls -->
                      <div class="flex items-center justify-between border-b border-slate-900/10 px-3 py-1.5 shrink-0">
                        <div class="flex items-center gap-4">
                          <span id="sbsLabelA" class="text-[11px] font-semibold text-blue-700 truncate max-w-[260px]">A</span>
                          <span class="text-[10px] text-slate-300">|</span>
                          <span id="sbsLabelB" class="text-[11px] font-semibold text-emerald-700 truncate max-w-[260px]">B</span>
                        </div>
                        <div class="flex items-center gap-1">
                          <button
                            id="btnSbsCopyLink"
                            class="focus-ring rounded-lg border border-slate-900/10 bg-white/90 px-2 py-0.5 text-[10px] font-semibold text-slate-600 hover:bg-white"
                            type="button"
                            title="Copy permalink for this side-by-side view"
                          >Copy Link</button>
                          <button
                            id="btnSbsSyncScroll"
                            class="focus-ring rounded-lg border border-slate-900/10 bg-white/90 px-2 py-0.5 text-[10px] font-semibold text-slate-600 hover:bg-white"
                            type="button"
                            title="Toggle synced scrolling between panes"
                          >Sync &#x2714;</button>
                        </div>
                      </div>
                      <!-- Mobile segmented control A | B (bd-24q.15.3) -->
                      <div class="sbs-mobile-tabs shrink-0 mx-3 mt-1.5 mb-1">
                        <button id="sbsTabA" class="active" type="button">Pane A</button>
                        <button id="sbsTabB" type="button">Pane B</button>
                      </div>
                      <!-- Pane content area -->
                      <div class="flex flex-1 min-h-0 overflow-hidden relative">
                        <div id="sbsPaneA" class="md flex-1 min-w-0 overflow-auto p-4 sbs-pane-visible" style="scroll-behavior: auto"></div>
                        <div
                          id="sbsDivider"
                          class="shrink-0 cursor-col-resize bg-slate-200 hover:bg-slate-400 transition-colors"
                          style="width: 5px"
                          title="Drag to resize panes"
                        ></div>
                        <div id="sbsPaneB" class="md flex-1 min-w-0 overflow-auto p-4" style="scroll-behavior: auto"></div>
                        <!-- Jump to heading CTA (mobile portrait, bd-24q.15.3) -->
                        <button id="sbsJumpCta" class="sbs-jump-cta" type="button"></button>
                      </div>
                    </div>
                  </div>

                  <div id="docMetricsView" class="hidden">
                    <div class="text-xs font-semibold text-slate-600">Computed metrics</div>
                    <div class="mt-3 grid grid-cols-2 gap-3 sm:grid-cols-4">
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Tokens touched</div>
                        <div id="mTokens" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Levenshtein</div>
                        <div id="mLev" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Hunks</div>
                        <div id="mHunks" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                      <div class="glass-2 rounded-2xl p-4 shadow-sm">
                        <div class="text-[11px] font-semibold text-slate-500">Bytes touched</div>
                        <div id="mBytes" class="mt-2 text-lg font-bold text-slate-900">-</div>
                      </div>
                    </div>
                    <div class="mt-4">
                      <div class="grid grid-cols-1 gap-2 sm:grid-cols-2">
                        <button
                          id="btnComputeAll"
                          class="focus-ring w-full rounded-2xl bg-slate-900 px-4 py-2.5 text-sm font-semibold text-white hover:bg-slate-800"
                          type="button"
                        >
                          Compute token + Levenshtein metrics for all commits
                        </button>
                        <button
                          id="btnCancelCompute"
                          class="focus-ring hidden w-full rounded-2xl border border-rose-300 bg-rose-50 px-4 py-2.5 text-sm font-semibold text-rose-700 hover:bg-rose-100"
                          type="button"
                        >
                          Cancel running compute
                        </button>
                      </div>
                      <div class="mt-2 text-xs text-slate-500">
                        This can take a bit on large diffs. The UI stays responsive; charts update
                        as metrics arrive.
                      </div>
                      <div id="workerStatus" class="mt-2 text-xs text-slate-500"></div>
                      <div id="computeProgress" class="mt-2 hidden text-xs font-semibold text-slate-700"></div>
                    </div>
                  </div>

                  <div id="docSectionsView" class="hidden">
                    <div class="flex items-center justify-between">
                      <div class="text-xs font-semibold text-slate-600">Per-Section Change Summary</div>
                      <div class="flex items-center gap-2">
                        <input
                          id="sectionFilter"
                          type="text"
                          placeholder="Filter headings..."
                          class="focus-ring w-40 rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-[11px] text-slate-700 placeholder-slate-400"
                        />
                      </div>
                    </div>
                    <div id="sectionTableWrap" class="mt-3 max-h-[70vh] overflow-auto rounded-2xl border border-slate-900/10 bg-white/70">
                      <table id="sectionTable" class="w-full text-[11px]">
                        <thead class="sticky top-0 z-10 bg-white/95 backdrop-blur">
                          <tr class="border-b border-slate-200">
                            <th class="px-3 py-2 text-left font-semibold text-slate-500" data-sort="name">Section</th>
                            <th class="px-3 py-2 text-right font-semibold text-slate-500 w-16" data-sort="add">+Lines</th>
                            <th class="px-3 py-2 text-right font-semibold text-slate-500 w-16" data-sort="del">-Lines</th>
                            <th class="px-3 py-2 text-right font-semibold text-slate-500 w-20" data-sort="tokens">Tokens</th>
                            <th class="px-3 py-2 text-right font-semibold text-slate-500 w-20" data-sort="impact">Impact</th>
                          </tr>
                        </thead>
                        <tbody id="sectionTableBody"></tbody>
                      </table>
                    </div>
                    <div id="sectionEmpty" class="hidden mt-3 text-xs text-slate-400 italic p-3">No section changes for this commit.</div>
                    <button id="btnOpenSectionSheet" class="mt-3 w-full sm:hidden focus-ring rounded-2xl bg-slate-900 px-4 py-2.5 text-sm font-semibold text-white hover:bg-slate-800" type="button">View sections (mobile)</button>
                  </div>
                </div>
              </section>

              <aside class="glass-2 rounded-3xl p-4 lg:p-5">
                <div class="text-xs font-semibold text-slate-600">Change summary</div>
                <div id="docSummary" class="mt-3 space-y-2 text-sm text-slate-700"></div>
                <div class="mt-4 border-t border-slate-900/10 pt-4">
                  <div class="text-xs font-semibold text-slate-600">Patch notes</div>
                  <div class="mt-2 text-xs leading-relaxed text-slate-600">
                    Distances are computed per-hunk between removed and added blocks (byte-level
                    Levenshtein in WASM), then summed.
                  </div>
                </div>
              </aside>
            </div>
          </section>

          <!-- Commit explorer -->
          <section id="sectionCommits" class="glass shadow-glow mt-6 rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Commit Explorer</div>
                <div class="mt-1 text-xs text-slate-500">
                  Click a commit to expand its change groups and evidence excerpts.
                </div>
              </div>
              <div class="flex items-center gap-2">
                <div class="chip rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                  Showing <span id="showingCount" class="mono">-</span>
                </div>
              </div>
            </div>

            <div id="commitList" class="mt-4 grid grid-cols-1 gap-3"></div>
          </section>

          <!-- Alien telemetry -->
          <section id="sectionAlien" class="glass shadow-glow mt-6 rounded-3xl p-5">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-end sm:justify-between">
              <div>
                <div class="text-sm font-bold text-slate-900">Alien Telemetry</div>
                <div class="mt-1 text-xs text-slate-500">
                  BOCPD change-point detection over commit impact (lines changed).
                </div>
              </div>
              <div class="chip rounded-2xl px-3 py-1.5 text-xs font-semibold text-slate-700">
                Hazard <span id="hazardLabel" class="mono">-</span>
              </div>
            </div>

            <div class="mt-4 grid grid-cols-1 gap-4 lg:grid-cols-[1fr_360px]">
              <div>
                <div id="bocpdChart" class="chart w-full"></div>
              </div>
              <div class="glass-2 rounded-3xl p-5">
                <div class="text-xs font-semibold text-slate-600">Galaxy Brain Card</div>
                <div class="mt-3 codebox rounded-2xl p-3">
                  <div class="mono text-[11px] leading-relaxed text-slate-900">
                    P(r_t | x_{1:t}) ∝ Σ_{r_{t-1}} P(x_t | r_t, …) · P(r_t | r_{t-1}) · P(r_{t-1} |
                    x_{1:t-1})
                  </div>
                </div>
                <p class="mt-3 text-xs leading-relaxed text-slate-600">
                  This page runs a tiny BOCPD model locally on the commit impact series (add+del).
                  With only 101 points, it is fast and deterministic. Change points are used only as
                  a lens, not a claim of truth.
                </p>
                <div class="mt-4">
                  <label class="text-xs font-semibold text-slate-600">Hazard H</label>
                  <input
                    id="hazard"
                    class="mt-2 w-full"
                    type="range"
                    min="0.01"
                    max="0.30"
                    step="0.01"
                    value="0.10"
                  />
                </div>
              </div>
            </div>
          </section>
        </main>
      </div>
    </div>

    <!-- Mobile filter sheet -->
    <div id="overlay" class="fixed inset-0 z-40 hidden bg-slate-900/30 backdrop-blur-sm"></div>
    <div
      id="sheet"
      class="sheet fixed bottom-0 left-0 right-0 z-50 hidden rounded-t-3xl border border-slate-900/10 bg-white/90 p-5 shadow-2xl backdrop-blur-xl"
    >
      <div class="flex items-center justify-between">
        <div class="text-sm font-bold text-slate-900">Filters</div>
        <button
          id="btnCloseSheet"
          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-xs font-semibold text-slate-900 hover:bg-white"
          type="button"
        >
          Close
        </button>
      </div>
      <div class="mt-4">
        <label class="text-xs font-semibold text-slate-600">Search</label>
        <input
          id="qMobile"
          class="focus-ring mt-2 w-full rounded-2xl border border-slate-900/10 bg-white/70 px-3.5 py-2.5 text-sm text-slate-900 placeholder:text-slate-400"
          placeholder="commit, section, keyword..."
        />
      </div>
      <div class="mt-4">
        <div class="flex items-center justify-between">
          <label class="text-xs font-semibold text-slate-600">Min Impact</label>
          <div id="impactLabelMobile" class="mono text-xs text-slate-500">-</div>
        </div>
        <input id="impactMobile" class="mt-2 w-full" type="range" min="0" max="200" value="0" />
      </div>
      <div class="mt-5">
        <label class="text-xs font-semibold text-slate-600">Bucket Mode</label>
        <div class="mt-2 grid grid-cols-2 gap-2">
          <button
            id="modePrimaryMobile"
            class="focus-ring rounded-2xl border border-slate-900/10 bg-slate-900 px-3 py-2 text-xs font-semibold text-white"
            type="button"
          >
            Primary
          </button>
          <button
            id="modeMultiMobile"
            class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900"
            type="button"
          >
            Multi-label
          </button>
        </div>
      </div>
      <div class="mt-5">
        <label class="text-xs font-semibold text-slate-600">Buckets</label>
        <div id="bucketTogglesMobile" class="mt-2 grid grid-cols-1 gap-2"></div>
      </div>
      <div class="mt-6 grid grid-cols-2 gap-2">
        <button
          id="btnResetMobile"
          class="focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white"
          type="button"
        >
          Reset
        </button>
        <button
          id="btnApplyMobile"
          class="focus-ring rounded-2xl bg-slate-900 px-3 py-2 text-xs font-semibold text-white hover:bg-slate-800"
          type="button"
        >
          Apply
        </button>
      </div>
    </div>

    <!-- Mobile section summary sheet (bd-24q.8.3) -->
    <div id="sectionSheetOverlay" class="fixed inset-0 z-40 hidden bg-slate-900/30 backdrop-blur-sm"></div>
    <div
      id="sectionSheet"
      class="sheet fixed bottom-0 left-0 right-0 z-50 hidden rounded-t-3xl border border-slate-900/10 bg-white/90 p-5 shadow-2xl backdrop-blur-xl"
      style="max-height: 75vh"
    >
      <div class="flex items-center justify-between">
        <div class="text-sm font-bold text-slate-900">Section Changes</div>
        <button
          id="btnCloseSectionSheet"
          class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-1.5 text-xs font-semibold text-slate-900 hover:bg-white"
          type="button"
        >Close</button>
      </div>
      <input
        id="sectionFilterMobile"
        type="text"
        placeholder="Filter headings..."
        class="focus-ring mt-3 w-full rounded-2xl border border-slate-900/10 bg-white/70 px-3.5 py-2.5 text-sm text-slate-900 placeholder:text-slate-400"
      />
      <div id="sectionSheetList" class="mt-3 overflow-auto space-y-1" style="max-height: 55vh"></div>
    </div>

    <!-- History Search Palette (bd-24q.9.2) -->
    <div id="searchPaletteOverlay" class="search-palette-overlay hidden" role="dialog" aria-modal="true" aria-label="Search history">
      <div class="search-palette">
        <input id="searchPaletteInput" class="search-palette-input" type="text" placeholder="Search commits, sections, keywords... (use &quot;quotes&quot; for exact phrase)" autocomplete="off" spellcheck="false" />
        <div id="searchPaletteResults" class="search-palette-results">
          <div class="search-palette-hint">Type to search across all commits</div>
        </div>
        <div class="search-palette-footer">
          <span><kbd>&uarr;</kbd><kbd>&darr;</kbd> navigate</span>
          <span><kbd>Enter</kbd> jump</span>
          <span><kbd>Esc</kbd> close</span>
          <span class="ml-auto"><kbd>Ctrl</kbd>+<kbd>K</kbd></span>
        </div>
      </div>
    </div>

    <!-- Timeline dock -->
    <div id="dock" class="dock fixed inset-x-0 bottom-0 z-30 px-4 py-3">
      <div class="mx-auto max-w-[1200px]">
        <div class="flex items-center justify-between gap-3">
          <div class="min-w-0 flex items-center gap-2">
            <button
              id="dockCollapseToggle"
              class="sm:hidden focus-ring inline-flex h-6 w-6 items-center justify-center rounded-lg border border-slate-900/10 bg-white/70 text-[10px] font-bold text-slate-600 hover:bg-white"
              type="button"
              aria-label="Toggle dock"
            >&#9650;</button>
            <div>
              <div class="text-[11px] font-semibold text-slate-500">Timeline scrubber</div>
              <div id="dockTitle" class="mt-0.5 truncate text-xs font-semibold text-slate-900">-</div>
            </div>
          </div>
          <div class="shrink-0 flex items-center gap-2">
            <button
              id="dockPrev"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-2.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
              type="button"
              aria-label="Previous commit"
            >
              Prev
            </button>
            <button
              id="dockPlayPause"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-2.5 text-[11px] font-semibold text-slate-900 hover:bg-white min-w-[3.5rem]"
              type="button"
              aria-label="Play or pause timeline playback"
            >
              &#9654;
            </button>
            <button
              id="dockNext"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-3 py-2.5 text-[11px] font-semibold text-slate-900 hover:bg-white"
              type="button"
              aria-label="Next commit"
            >
              Next
            </button>
            <select
              id="dockSpeed"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-2 py-2 text-[11px] font-semibold text-slate-900 hover:bg-white cursor-pointer"
              aria-label="Playback speed"
            >
              <option value="0.25">0.25x</option>
              <option value="0.5">0.5x</option>
              <option value="1" selected>1x</option>
              <option value="2">2x</option>
              <option value="4">4x</option>
            </select>
            <button
              id="dockLoop"
              class="focus-ring rounded-xl border border-slate-900/10 bg-white/70 px-2.5 py-2.5 text-[11px] font-semibold text-slate-500 hover:bg-white"
              type="button"
              aria-label="Toggle loop playback"
              title="Loop"
            >
              &#x1F501;
            </button>
          </div>
        </div>

        <div id="dockBody">
          <canvas
            id="dockCanvas"
            class="dock-canvas mt-2 rounded-2xl border border-slate-900/10 bg-white/70"
          ></canvas>
          <input id="dockSlider" class="dock-slider mt-2" type="range" min="0" max="1" value="0" />
          <canvas
            id="dockHeatStripe"
            class="dock-heat-stripe mt-1"
            aria-label="Heat stripe showing bucket density over time"
          ></canvas>
          <div id="dockHeatTooltip" class="dock-heat-tooltip hidden" aria-hidden="true"></div>
          <div class="mt-1 flex items-center justify-between text-[11px] text-slate-500">
            <div id="dockLeftLabel" class="mono">-</div>
            <div id="dockRightLabel" class="mono">-</div>
          </div>
        </div>
      </div>
    </div>

    <!-- Dependencies (deferred to avoid blocking first paint) -->
    <script defer src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/dist/echarts.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/dayjs@1.11.10/dayjs.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/dayjs@1.11.10/plugin/utc.js"></script>
    <script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/highlight.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/pako@2.1.0/dist/pako.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/markdown-it@14.1.0/dist/markdown-it.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/dompurify@3.1.0/dist/purify.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/diff2html/bundles/js/diff2html.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/diff@7.0.0/dist/diff.min.js"></script>

    <script type="module">
      const { dayjs, echarts, hljs, pako, markdownit, DOMPurify, Diff2Html, Diff } = window;

      // Extend dayjs with UTC plugin for timezone-aware binning.
      if (dayjs && window.dayjs_plugin_utc) dayjs.extend(window.dayjs_plugin_utc);

      // requestIdleCallback polyfill (Safari < 16.4)
      if (typeof requestIdleCallback === "undefined") {
        window.requestIdleCallback = function (cb) {
          const start = Date.now();
          return setTimeout(() => {
            cb({
              didTimeout: false,
              timeRemaining: () => Math.max(0, 50 - (Date.now() - start)),
            });
          }, 1);
        };
        window.cancelIdleCallback = function (id) {
          clearTimeout(id);
        };
      }

      // -----------------------------
      // Data: commit metadata + stats
      // -----------------------------

      const COMMIT_LOG_RAW = String.raw`c08f1602d03b1833a4f91c8f77347f8f196bac9d|c08f160|2026-02-07T01:17:42-05:00|Dicklesworthstone|Add comprehensive specification documents (8,628 + 1,206 lines)
f9d88aa96f50893f8531373d0734597ebae3c592|f9d88aa|2026-02-07T01:43:43-05:00|Dicklesworthstone|Promote SSI to V1, add intent logs, shard lock tables, expand specs
76eef31be20a6faedc62e7fecce88e78652ebdcf|76eef31|2026-02-07T02:04:31-05:00|Dicklesworthstone|docs: reconcile v1 specs (RaptorQ/SSI/K semantics)
9800b17df4a56c2dc065cf566c2810d4ed2e576c|9800b17|2026-02-07T02:45:02-05:00|Dicklesworthstone|Spec V1.3: scope doctrine, ECS substrate, multi-process MVCC, encryption
79018f161649e6d7977bc74eb849a0e22eceb286|79018f1|2026-02-07T02:56:16-05:00|Dicklesworthstone|Spec: revise WAL frame layout for true compatibility mode
5ad34871f7242de61378843c6c1e8311e35d9fa3|5ad3487|2026-02-07T03:14:56-05:00|Dicklesworthstone|Spec V1.4: Codex synthesis — RaptorQ everywhere, WAL sidecar overhaul, ECS layout, replication
7b2c677cf61adda977e71524b59d7ec234137962|7b2c677|2026-02-07T03:16:08-05:00|Dicklesworthstone|Spec V1.5: alien-artifact discipline — decision-theoretic SSI, BOCPD, monitoring stack, native mode
bf0426417685504bb2b2f5acfc4de2c2f087ef8b|bf04264|2026-02-07T03:31:40-05:00|Dicklesworthstone|Spec V1.6a: RaptorQ-native SSI witness plane — cross-process, distributed, proof-carrying
05cf07847753f444b9f74dfd0279ef96c3ff86b9|05cf078|2026-02-07T03:32:45-05:00|Dicklesworthstone|Spec V1.6b: alien-artifact discipline — formal derivations for every tunable parameter
e8ddf469d8ab8ff8eefbae92b24453e06fcf4627|e8ddf46|2026-02-07T03:33:30-05:00|Dicklesworthstone|Spec V1.6c: performance optimizations — arena allocators, CAR cache, per-invariant monitoring
480c10086fb73630744364f5fb34966de2572dc1|480c100|2026-02-07T03:35:03-05:00|Dicklesworthstone|Spec V1.6d: SSI transaction struct — TxnToken edges, eager abort, terminology scoping
0313678eff44b70cd4ea40cabc2f2222cac2ba93|0313678|2026-02-07T03:38:40-05:00|Dicklesworthstone|Spec V1.6e: SSI detection algorithm — proof-carrying commit with eager abort
b97b1abe4727a738197180c5639738c1da2f5311|b97b1ab|2026-02-07T03:39:32-05:00|Dicklesworthstone|Spec V1.6f: fixup — remove 3-way merge artifacts, restore canonical state
643c89c1c941d1e47cb6a2574e01fd7556f622ec|643c89c|2026-02-07T03:42:22-05:00|Dicklesworthstone|Spec V1.6g: final reconciliation — canonical SSI detection algorithm
0404e42c9dbdc677da9b8a5731d29290ef9f3b26|0404e42|2026-02-07T03:50:09-05:00|Dicklesworthstone|Spec V1.6h: native mode commit protocol — SSI witness-plane integration
2a6353d2f77a050454d2a6fd4b3fd6c8363064e9|2a6353d|2026-02-07T04:08:59-05:00|Dicklesworthstone|spec: align asupersync integration + preserve harness canon
3253050f2835fb305bd115bd9f5939b72cd46503|3253050|2026-02-07T04:30:26-05:00|Dicklesworthstone|docs/spec: schema epoch + align encryption
06dfe9a709d61fc899e00ee33d54dc15d003bb48|06dfe9a|2026-02-07T04:43:05-05:00|Dicklesworthstone|docs/spec: seal internal traits + clarify extensions
63f6057e8705b7105837952bc8ea977ad6f34da6|63f6057|2026-02-07T04:44:32-05:00|Dicklesworthstone|docs/spec: key ARC pages by commit_seq
2cff3a0287f1de30d2fd1185c376ac81913922c9|2cff3a0|2026-02-07T04:45:11-05:00|Dicklesworthstone|docs/spec: clarify INV-1 monitor name
4ba1ee3bce5eef69acf5e24c61e0fe5482662a79|4ba1ee3|2026-02-07T04:54:23-05:00|Dicklesworthstone|docs/spec: tighten glossary + fix merge pseudocode types
72eb835e83063d8fe19c1288a8c4624438473b2e|72eb835|2026-02-07T11:07:04-05:00|Dicklesworthstone|spec: fix cross-process cleanup + lock table semantics
0b543b5b587d72a5531a37324ad31fab0157b6ed|0b543b5|2026-02-07T11:21:20-05:00|Dicklesworthstone|docs/spec: deepen asupersync integration (regions/cancel/supervision)
d7b38efedc6f77029ce412c1eea2d0197b8b8fc6|d7b38ef|2026-02-07T11:50:08-05:00|Dicklesworthstone|Spec V1.7: deep audit fixes for Section 5 (MVCC Formal Model)
322af1706478c8da09b09af4927e6a011041c5a6|322af17|2026-02-07T11:53:09-05:00|Dicklesworthstone|Spec V1.7a + README: deep audit fixes (MVCC model alignment, SSI/ordering)
1a672dd545885d61c2531bf2be178d0edb4a5065|1a672dd|2026-02-07T12:09:27-05:00|Dicklesworthstone|Spec V1.7b: deep audit fixes for Section 7 (Checksums and Integrity)
a19a3acb957598db6e11ece9ab199ae8f34eb88e|a19a3ac|2026-02-07T12:10:44-05:00|Dicklesworthstone|docs/spec: deepen asupersync integration + witness-plane rigor
d0fda0186411a7f75bd73771f484259c29d7921a|d0fda01|2026-02-07T12:11:01-05:00|Dicklesworthstone|docs/spec: minor wording tweak
b8344dba9b295b31b843807f80c6ec10e601459b|b8344db|2026-02-07T12:11:40-05:00|Dicklesworthstone|docs/spec: tighten crate boundaries + WAL notes
5e2344ce7b5640aaad2fb48bed85838f9c9ecfef|5e2344c|2026-02-07T12:12:14-05:00|Dicklesworthstone|docs/spec: add WAL checksum algorithm + refine repair tail bounds
713e6dc4f8b202870b16e154a597bcd735d5c05b|713e6dc|2026-02-07T12:12:40-05:00|Dicklesworthstone|docs/spec: bump document version
e2dc2232567e901ce8f7192303c9da013e4c8d7c|e2dc223|2026-02-07T12:13:08-05:00|Dicklesworthstone|docs/spec: clarify fragmentation byte + add SQLite varint encoding
3c5d5a177c8fbd78fd6f11f32a02e4c3ada9e172|3c5d5a1|2026-02-07T12:13:41-05:00|Dicklesworthstone|docs/spec: fix index local-payload math + clarify affinity coercion
714570a488c9e93f3349ba527e70e744570555e9|714570a|2026-02-07T12:14:00-05:00|Dicklesworthstone|docs/spec: expand pointer-map entry type semantics
893691fc58cca08e1fba3a25a5ddf520624d6860|893691f|2026-02-07T12:14:48-05:00|Dicklesworthstone|docs/spec: add SSI invariants + correct e-process example + fix index max_local
a9aff80df7c0d04f465db40b74165a2e75ae5e29|a9aff80|2026-02-07T12:15:31-05:00|Dicklesworthstone|docs/spec: tighten budget algebra wording + fix BOCPD recursion
80bc4494162ff420cdb48c5122324d9bdc8d328b|80bc449|2026-02-07T12:16:49-05:00|Dicklesworthstone|docs/spec: refine public API facade + type-erased function state factories
a5a85e64c6356176ad86795d69e1293bd76f2601|a5a85e6|2026-02-07T12:17:16-05:00|Dicklesworthstone|docs/spec: thread Cx into rollback + clarify recursive CTE UNION semantics
7c93dbb54e2d939f820d97a469bf204829ce97c8|7c93dbb|2026-02-07T12:20:46-05:00|Dicklesworthstone|Spec audit round 2: WAL checksum inversion, WAL-index hash, ARC claim
07236c61ff86a87f22bb1aa6fd26885eb527d268|07236c6|2026-02-07T12:23:21-05:00|Dicklesworthstone|docs/spec: fix WAL checksum endianness + clarify WindowsVfs + layering notes
d9146f771541d7e134f540e11016df82cc6e17b9|d9146f7|2026-02-07T12:28:33-05:00|Dicklesworthstone|spec: harden marker stream + compaction + RaptorQ overhead
30619b34ea187d682283f8cd137d8d30e306e6bd|30619b3|2026-02-07T12:28:52-05:00|Dicklesworthstone|docs/spec: clarify R*-tree geopoly wording
7e9cace601485722e7b31411ad74796c0685bd05|7e9cace|2026-02-07T12:29:17-05:00|Dicklesworthstone|docs/spec: refine Zipf conflict probability
ff937f3d678f88eb855051dbbd32e8e5046bea0f|ff937f3|2026-02-07T12:29:51-05:00|Dicklesworthstone|docs/spec: tighten MVCC + merge modeling notes
61ee3e03f4cd5e44b189da55bb70e91cdba63a29|61ee3e0|2026-02-07T12:30:34-05:00|Dicklesworthstone|docs/spec: harden ARC eviction failure path
a90a3794616e12b083f88276e3cb47a045f3ac10|a90a379|2026-02-07T12:32:18-05:00|Dicklesworthstone|Spec V1.7c: deep audit fixes for Section 6 (Buffer Pool: ARC Cache)
246102e6b4266fa15000580a3d016d76bcb1c801|246102e|2026-02-07T12:35:11-05:00|Dicklesworthstone|Spec audit round 3: fix operator precedence tables (§10.2 and §12.15)
5ea1b6fb02945e4bc147c37ae7d054d92fdd9045|5ea1b6f|2026-02-07T12:44:12-05:00|Dicklesworthstone|Spec audit round 4: SSI pseudocode, precedence, RETURNING, merge terminology
f1f25abe3b40ad0fb8704eaee310aee17de78d25|f1f25ab|2026-02-07T12:46:31-05:00|Dicklesworthstone|Spec: harden write-merge (no raw XOR on SQLite pages)
9725f136b2450c6411f5735a1575a068f2aacc0b|9725f13|2026-02-07T12:47:33-05:00|Dicklesworthstone|Spec: clarify cross-process ordering + file format edge cases
56742886aae65bdca3a34acda8d677b52a0c241d|5674288|2026-02-07T12:47:51-05:00|Dicklesworthstone|Spec: witness hot-plane epoch advancement safety
71a41750d478e8ecad031a2f490e84a4424a839e|71a4175|2026-02-07T12:48:33-05:00|Dicklesworthstone|Spec: publish commit_seq only after durable marker
9fa8f7b6082f164d4cb1026296a360cfbafe1f73|9fa8f7b|2026-02-07T12:48:54-05:00|Dicklesworthstone|Spec: make commit_seq allocation marker-tip-derived
86d63af874d7a3dc7d522d47bf5f004f12913adb|86d63af|2026-02-07T12:49:41-05:00|Dicklesworthstone|Spec: compatibility mode legacy writer exclusion + WAL-index bridge
23f575f7d4ee20399865e33abca1f93e60eda2d7|23f575f|2026-02-07T12:49:56-05:00|Dicklesworthstone|Spec: Acquire snapshot commit_seq; tighten V1 rebase scope
6228e273d3dce6ca67c97fd43afb9018d19c6f5f|6228e27|2026-02-07T12:53:57-05:00|Dicklesworthstone|spec: fix native commit_seq gaps + witness epoch race
2e3ea218a908f4a22791b4c8b30a0dbf746f867b|2e3ea21|2026-02-07T12:58:54-05:00|Dicklesworthstone|Spec audit round 5: SharedPageLockTable key-stability, marker encoding, legacy writer exclusion
d05de23ea89da924e86232c8da519b6b58b4a0d5|d05de23|2026-02-07T12:59:44-05:00|Dicklesworthstone|Spec audit round 5b: align §5.6.3.1 rebuild prose with tombstone removal + header notes
fa1830e4593854a492d78bec24da1db90351c2f0|fa1830e|2026-02-07T13:00:08-05:00|Dicklesworthstone|Spec audit round 5c: permeation map, fragment limit, cell payload refs
70436b5c2c04e42c0aaf4b776a8f779416abdeff|70436b5|2026-02-07T13:00:29-05:00|Dicklesworthstone|Spec audit: WAL index byte order note + header layout corrections
a4e773481bd417530fe83f33868ef6ce5656e933|a4e7734|2026-02-07T13:02:16-05:00|Dicklesworthstone|Spec: add VFS shm API + clarify commit marker record
09c095901ddb1e5db47f55ddf5c616b5d51bf74e|09c0959|2026-02-07T13:02:34-05:00|Dicklesworthstone|Spec: checkpoint writer trait + replication gate
40a2ac7739778b30cb11129a782d8746bd13e6ed|40a2ac7|2026-02-07T13:03:14-05:00|Dicklesworthstone|Spec: bump audit footer to v1.18
40c6c3d152cf7d86104ad9ca19fbb850d6fdf343|40c6c3d|2026-02-07T13:04:47-05:00|Dicklesworthstone|Spec: lock-table acquire returns BUSY on insert race
8512e62aed8835864a8800ed895c91a8773dc996|8512e62|2026-02-07T13:08:08-05:00|Dicklesworthstone|spec: move compat page-FEC to sidecar + tighten UDP bounds
e31897fd92088e5305735d080e224a23b7315a11|e31897f|2026-02-07T13:08:45-05:00|Dicklesworthstone|spec: clarify checkpoint chunk MTU rationale
b03db7bc0b8a2705fe6fda19f5f149452755284c|b03db7b|2026-02-07T13:10:18-05:00|Dicklesworthstone|Spec V1.7d: deep audit fixes for Section 12 (SQL Coverage)
dd190e4f7f24aa2a8b7bb1bbc7020aead6d014c0|dd190e4|2026-02-07T13:23:44-05:00|Dicklesworthstone|Spec audit round 5+: fix GF(256) worked example, WAL checksum naming, MMR, IBLT
a664265e3f5876177b7c1410dad7119e01e7f9e9|a664265|2026-02-07T13:30:10-05:00|Dicklesworthstone|Spec+VFS: SAFE write-merge proofs + policy controller
599cafb3f29c52dd2a44f27d5632032c54a34a25|599cafb|2026-02-07T13:30:47-05:00|Dicklesworthstone|Spec: clarify forward target + symbol auth + epoch helpers
e42a43de57ff5d4ee616cd2ec3b54a0db249a3e6|e42a43d|2026-02-07T13:31:08-05:00|Dicklesworthstone|Spec: symbol auth master key derivation + VdbeOp p5 note
f158b44a5bd96ef34b378b58f61399568424f6d4|f158b44|2026-02-07T13:31:30-05:00|Dicklesworthstone|Spec: symbol auth wording + planner cost note
3cf0f13571c101725f9ef34ce2476c90478ff07d|3cf0f13|2026-02-07T13:35:09-05:00|Dicklesworthstone|Spec V1.7e: deep audit fix for Section 3 (RaptorQ MTU/sub-blocking)
0cb22962ec87cb29a29a44acfc5ec14588aadb23|0cb2296|2026-02-07T13:40:27-05:00|Dicklesworthstone|Spec: WAL lock refs + row-value expr
1680d6931f5773673fae021b7cc646e3f3faab44|1680d69|2026-02-07T13:45:48-05:00|Dicklesworthstone|Spec V1.7f: deep audit fixes for Section 4 (Asupersync e-process math)
1e2aae9940969190c6b9bebe94c94749eee91626|1e2aae9|2026-02-07T13:50:03-05:00|Dicklesworthstone|Spec: add UpdateExpression to write-merge system (§5.10)
da22f479dc2f8d1e98294750b741b3cce168fd19|da22f47|2026-02-07T13:55:11-05:00|Dicklesworthstone|Spec: formal durability+policy hardening
c25f0d00238fc36f355f818f571abc3d4a1198df|c25f0d0|2026-02-07T13:56:03-05:00|Dicklesworthstone|Spec: UpdateExpression rebase index regen
02e48a41810bdb2ad471926d9728a9a9af12b155|02e48a4|2026-02-07T14:00:52-05:00|Dicklesworthstone|Spec: fix maxLocal example + add encryption plan gates
bcd893da081fd15b1614a05c4d8b593f55cf7011|bcd893d|2026-02-07T14:16:38-05:00|Dicklesworthstone|Spec V1.7g: Section 9 deep audit — BtreeCursorOps, shm_map safety, opt-level fix
6da51572d2b5b76eb9a37ffa99da76bfb850cd83|6da5157|2026-02-07T14:16:48-05:00|Dicklesworthstone|Spec: deep audit fixes for §5.6.2 + §7.11
22e75e65b831adda852df3a11628e793aaa9e7a9|22e75e6|2026-02-07T14:27:26-05:00|Dicklesworthstone|planning: close obsolete beads; align spec/docs
2f0970b9a5d8fc755269ba848169f5a1369ec6a6|2f0970b|2026-02-07T14:27:39-05:00|Dicklesworthstone|Spec V1.7h: Section 10 deep audit — lexer DQS, cost model, UPDATE trace
5cc32a6bc813ff59db231f29db5b95a13ea94704|5cc32a6|2026-02-07T14:28:53-05:00|Dicklesworthstone|spec: tighten asupersync net + scheduler lane requirements
dc92e549d05ac8dc0c23937d6e6dfa874729fdd4|dc92e54|2026-02-07T14:31:37-05:00|Dicklesworthstone|spec: fix MVCC version-chain delta encoding
2433562451b188c9233f6fd83a9ef7573ce48f97|2433562|2026-02-07T14:33:19-05:00|Dicklesworthstone|spec: add per-source validation for WAL-FEC recovery
82dfd4bf99283e5ab283073651787b3c7975561f|82dfd4b|2026-02-07T14:33:56-05:00|Dicklesworthstone|spec: clarify WAL-FEC repair semantics + WAL checksums
ab20d7fac6f83ac527475927aa53b204c11ed7c8|ab20d7f|2026-02-07T14:34:24-05:00|Dicklesworthstone|spec: add ARC p-update online-learning note
96f32f3174453e68960d849672cb4b7a8d33d1c7|96f32f3|2026-02-07T14:34:56-05:00|Dicklesworthstone|spec: lock-table rebuild busy-wait rule + ARC p-update research note
f37158f2468145272817fd65794d78be539be19b|f37158f|2026-02-07T14:35:20-05:00|Dicklesworthstone|spec: fix UpdateExpression rebase step numbering
19fa01f6d66c19892c634a02da44f7f536b29e43|19fa01f|2026-02-07T14:42:37-05:00|Dicklesworthstone|Spec V1.7i: Section 13 deep audit — strftime specifiers, aggregate ORDER BY
a3e7ae521e6a0dcb3cf9489ac5a67b0f62aad526|a3e7ae5|2026-02-07T14:45:48-05:00|Dicklesworthstone|Spec V1.7j: Section 14 deep audit — FTS5 NOT is binary-only
56a4e91425fa5cba9aecf08f786691ef03563750|56a4e91|2026-02-07T14:46:20-05:00|Dicklesworthstone|spec: define replication changeset_bytes encoding
d2a49862864dff9799e236d2cf81b51ed268f93f|d2a4986|2026-02-07T14:48:36-05:00|Dicklesworthstone|spec: tighten crash/interop guidance (TxnSlot cleaning, WAL marks, ARC, triggers)
859e81752809cd343b00ad6499c159d2f341cc46|859e817|2026-02-07T14:50:40-05:00|Dicklesworthstone|spec: fully reset TxnSlot state/mode during cleanup
be3d256b12679a32f2fb4e44eeb82e513607b284|be3d256|2026-02-07T15:03:41-05:00|Dicklesworthstone|spec: make .db-fec checkpoint-owned + add per-source validation
65ab2f709f724750878f2cb5d045649bf0c53e89|65ab2f7|2026-02-07T15:14:48-05:00|Dicklesworthstone|spec: add auto-tuning defaults and scaling knobs
63ee097eb68a72ac23effab3979978adafb5b411|63ee097|2026-02-07T15:15:18-05:00|Dicklesworthstone|spec: fix §18 probabilistic conflict model — 10x arithmetic error + missing W²
29f7ebe942a43891f2a55fd998d02c37411efc9f|29f7ebe|2026-02-07T15:27:04-05:00|Dicklesworthstone|spec: harden rebase + safe SHM + skew-aware conflicts
6b0c12fc40c5759f5d53028ba692e8aaff80fc92|6b0c12f|2026-02-07T15:30:14-05:00|Dicklesworthstone|spec: fix §16 Phase 7 join ordering — beam search, not exhaustive
b181b6d148e02862b195824020954abadae8de88|b181b6d|2026-02-07T15:31:48-05:00|Dicklesworthstone|spec: fix §8.3 planner join ordering — beam search, not exhaustive
d302b391af5c2932c9097dd85923a8535593e45e|d302b39|2026-02-07T15:44:17-05:00|Dicklesworthstone|mvcc/spec: witness hot-index sizing manifest
017745631c79f0c9061e4fdba8d0ce09ecc6c86d|0177456|2026-02-07T15:44:51-05:00|Dicklesworthstone|spec: clarify Zipf write-set skew section
5dae90d79aef7d70300fe53a17f9e40dba24b309|5dae90d|2026-02-07T15:45:46-05:00|Dicklesworthstone|spec: tighten Zipf s_hat guidance
ca60e008352585f2501ca3f81337849396b4d140|ca60e00|2026-02-07T15:47:59-05:00|Dicklesworthstone|spec: define .db-fec physical layout + crash-consistent update
30203fb1f91acfb45c6085432a66029896e26e66|30203fb|2026-02-07T15:50:22-05:00|Dicklesworthstone|spec: reserve TxnId sentinels + guard allocation
75ac25db5853747e3f56877c943d51ce8d649a5e|75ac25d|2026-02-07T16:07:05-05:00|Dicklesworthstone|spec: harden TxnId alloc + replication changeset id + ARC singleflight
ec9adc1a8f61663d224399711d165a7dd623b919|ec9adc1|2026-02-07T16:13:12-05:00|Dicklesworthstone|spec: fix TxnId monotonicity note + clarify P_eff
e80fdde018b3ce359f49271f082366bbad19f928|e80fdde|2026-02-07T16:14:32-05:00|Dicklesworthstone|spec: deterministic RaptorQ seed for ChangesetId
fa25db0b24e84470e8271309370e0f8093463ddd|fa25db0|2026-02-07T16:21:05-05:00|Dicklesworthstone|spec: adopt NGQP beam search for V1 join ordering
1d8bbfb40fa7a1fe90e710b593dfa2b3e9113c2d|1d8bbfb|2026-02-07T16:22:50-05:00|Dicklesworthstone|spec: add TxnId CAS abort path and correct beam search complexity
4432a3daa2f875bc2d3fe47caf783b3eb286ebfe|4432a3d|2026-02-07T16:25:52-05:00|Dicklesworthstone|spec: conformance mode matrix; bump asupersync
aa8e81601a80b6910a3791490d07c5691b517850|aa8e816|2026-02-07T16:28:25-05:00|Dicklesworthstone|spec: tighten serialized FCW + schema_epoch open + rebase read footprint
0a8d8676ac74f994535eceaa1c6c47cb17868038|0a8d867|2026-02-07T16:38:09-05:00|Dicklesworthstone|spec: fix TxnSlot cleanup crash-safety and reconcile lock/VFS semantics
3d568547fd6b8036481df0d73a2c60b5bf30d5a7|3d56854|2026-02-07T16:39:53-05:00|Dicklesworthstone|spec: fix Vfs trait formatting and cleanup_txn_id comment
4c07e10c56ee30db5d03453237ae6c29c31a7cf0|4c07e10|2026-02-07T16:41:55-05:00|Dicklesworthstone|spec: clarify TxnSlot cleanup_txn_id + fix Vfs trait formatting
df0313b00f2854929c376434c56129ef6e2740e0|df0313b|2026-02-07T16:42:11-05:00|Dicklesworthstone|spec: fix ARC/CAR comment indentation
97df1f07893def20701570db65418ff75ed45656|97df1f0|2026-02-07T16:42:40-05:00|Dicklesworthstone|spec: clarify zero-copy terminology
bbc4a3114572200d7a8a674eb3a4e430ae1d0b47|bbc4a31|2026-02-07T16:45:48-05:00|Dicklesworthstone|spec: define canonical AAD encoding for page encryption
4363f50065239e47d56f12250d933f5a1ab75a00|4363f50|2026-02-07T16:51:53-05:00|Dicklesworthstone|spec: add critical implementation controls checklist
d9021cffb65692624f3990ae2544a96ae0c07021|d9021cf|2026-02-07T16:52:38-05:00|Dicklesworthstone|spec: clarify rebase rowid reuse + DatabaseId encoding
29107df6b155bb20934ef369b934699191076b32|29107df|2026-02-07T17:00:26-05:00|Dicklesworthstone|spec: harden TxnSlot cleanup and epoch reset semantics
f708f338cb6e435db3822e2aa81b2785b51bf39b|f708f33|2026-02-07T17:01:38-05:00|Dicklesworthstone|spec: clarify pipelined durability and compatibility spill semantics
a71e1d95715c1190335e8738413382b31b6d167c|a71e1d9|2026-02-07T17:07:05-05:00|Dicklesworthstone|spec: harden ECS root update; snapshot slot tid; clarify ESCAPE parsing
120eee252b4caa7fe6389602bd2c8a316c6cee2a|120eee2|2026-02-07T17:08:11-05:00|Dicklesworthstone|spec: strengthen WAL-FEC per-source validation hash to xxh3_128
	975f65c78a5745424665a95f0c222287306c9dd5|975f65c|2026-02-07T17:08:59-05:00|Dicklesworthstone|spec: clarify GF(256) elimination note; bound delta reconstruction cost
	24b6f60e9e751b699cb232759d85a06c42792019|24b6f60|2026-02-07T17:15:05-05:00|Dicklesworthstone|spec: fix GC scheduling cross-reference
	80decf6b8ba71dd4331f559a08ee0fba3fbdf4bb|80decf6|2026-02-07T17:28:31-05:00|Dicklesworthstone|spec: clarify db-fec generation digest + ESI terminology
	7cc726325faa5cad71d2132480cbb68fb046563d|7cc7263|2026-02-07T18:11:25-05:00|Dicklesworthstone|spec: harden SHM snapshot seqlock + compat db-fec freshness
	9ad50ae2a2c7fce76a75d1200e22374eb729914d|9ad50ae|2026-02-07T18:15:58-05:00|Dicklesworthstone|spec: define SHM snapshot seqlock + coordinator IPC
	19106d19e531ea75918241b2858024c34a73f037|19106d1|2026-02-07T18:20:51-05:00|Dicklesworthstone|spec: harden MVCC TxnSlot protocol, write_page idempotency, and SHM layout
	7313951174e317f889851f696de264b546e4b54e|7313951|2026-02-07T18:21:25-05:00|Dicklesworthstone|spec: define wire payload schemas, RowId allocator state, and CommitRequest type
	d329df055a1a13459d0f507bc222b05525bb7522|d329df0|2026-02-07T18:28:22-05:00|Dicklesworthstone|spec: fix snapshot seqlock + shm invariants
	351c282e9a9a2ee118496651cef7a4b33cf309f2|351c282|2026-02-07T18:41:22-05:00|Dicklesworthstone|spec: fix TxnSlot acquire pseudocode + add spec viz wasm
	b1c1e72d9331952247c804af6589fe3b349d0b8a|b1c1e72|2026-02-07T18:58:48-05:00|Dicklesworthstone|spec: tighten coordinator IPC framing
	e60049751d7e238e46e45ce8009d9e9f053a41c2|e600497|2026-02-07T19:15:51-05:00|Dicklesworthstone|spec: harden claiming liveness and IPC ordering
	6d5d36a1380d3b4b4b6ddba71828825ef942975b|6d5d36a|2026-02-07T19:16:12-05:00|Dicklesworthstone|spec: update Round 16 audit notes`;
      const COMMIT_STATS_RAW = String.raw`c08f1602d03b1833a4f91c8f77347f8f196bac9d|8628|0
f9d88aa96f50893f8531373d0734597ebae3c592|431|76
76eef31be20a6faedc62e7fecce88e78652ebdcf|242|116
9800b17df4a56c2dc065cf566c2810d4ed2e576c|537|74
79018f161649e6d7977bc74eb849a0e22eceb286|246|151
5ad34871f7242de61378843c6c1e8311e35d9fa3|262|45
7b2c677cf61adda977e71524b59d7ec234137962|425|36
bf0426417685504bb2b2f5acfc4de2c2f087ef8b|290|71
05cf07847753f444b9f74dfd0279ef96c3ff86b9|217|31
e8ddf469d8ab8ff8eefbae92b24453e06fcf4627|141|20
480c10086fb73630744364f5fb34966de2572dc1|60|48
0313678eff44b70cd4ea40cabc2f2222cac2ba93|169|73
b97b1abe4727a738197180c5639738c1da2f5311|79|170
643c89c1c941d1e47cb6a2574e01fd7556f622ec|37|59
0404e42c9dbdc677da9b8a5731d29290ef9f3b26|33|16
2a6353d2f77a050454d2a6fd4b3fd6c8363064e9|643|381
3253050f2835fb305bd115bd9f5939b72cd46503|404|86
06dfe9a709d61fc899e00ee33d54dc15d003bb48|318|424
63f6057e8705b7105837952bc8ea977ad6f34da6|14|14
2cff3a0287f1de30d2fd1185c376ac81913922c9|1|1
4ba1ee3bce5eef69acf5e24c61e0fe5482662a79|18|16
72eb835e83063d8fe19c1288a8c4624438473b2e|56|16
0b543b5b587d72a5531a37324ad31fab0157b6ed|472|64
d7b38efedc6f77029ce412c1eea2d0197b8b8fc6|78|39
322af1706478c8da09b09af4927e6a011041c5a6|21|1
1a672dd545885d61c2531bf2be178d0edb4a5065|449|51
a19a3acb957598db6e11ece9ab199ae8f34eb88e|47|21
d0fda0186411a7f75bd73771f484259c29d7921a|6|3
b8344dba9b295b31b843807f80c6ec10e601459b|6|2
5e2344ce7b5640aaad2fb48bed85838f9c9ecfef|81|11
713e6dc4f8b202870b16e154a597bcd735d5c05b|18|1
e2dc2232567e901ce8f7192303c9da013e4c8d7c|40|3
3c5d5a177c8fbd78fd6f11f32a02e4c3ada9e172|18|7
714570a488c9e93f3349ba527e70e744570555e9|16|8
893691fc58cca08e1fba3a25a5ddf520624d6860|26|14
a9aff80df7c0d04f465db40b74165a2e75ae5e29|14|10
80bc4494162ff420cdb48c5122324d9bdc8d328b|33|5
a5a85e64c6356176ad86795d69e1293bd76f2601|7|5
7c93dbb54e2d939f820d97a469bf204829ce97c8|89|34
07236c61ff86a87f22bb1aa6fd26885eb527d268|43|41
d9146f771541d7e134f540e11016df82cc6e17b9|264|207
30619b34ea187d682283f8cd137d8d30e306e6bd|16|8
7e9cace601485722e7b31411ad74796c0685bd05|17|3
ff937f3d678f88eb855051dbbd32e8e5046bea0f|29|6
61ee3e03f4cd5e44b189da55bb70e91cdba63a29|15|2
a90a3794616e12b083f88276e3cb47a045f3ac10|32|8
246102e6b4266fa15000580a3d016d76bcb1c801|336|117
5ea1b6fb02945e4bc147c37ae7d054d92fdd9045|90|26
f1f25abe3b40ad0fb8704eaee310aee17de78d25|96|14
9725f136b2450c6411f5735a1575a068f2aacc0b|66|48
56742886aae65bdca3a34acda8d677b52a0c241d|14|3
71a41750d478e8ecad031a2f490e84a4424a839e|5|1
9fa8f7b6082f164d4cb1026296a360cfbafe1f73|8|3
86d63af874d7a3dc7d522d47bf5f004f12913adb|99|2
23f575f7d4ee20399865e33abca1f93e60eda2d7|17|1
6228e273d3dce6ca67c97fd43afb9018d19c6f5f|81|5
2e3ea218a908f4a22791b4c8b30a0dbf746f867b|130|93
d05de23ea89da924e86232c8da519b6b58b4a0d5|15|8
fa1830e4593854a492d78bec24da1db90351c2f0|8|7
70436b5c2c04e42c0aaf4b776a8f779416abdeff|9|3
a4e773481bd417530fe83f33868ef6ce5656e933|98|11
09c095901ddb1e5db47f55ddf5c616b5d51bf74e|18|0
40a2ac7739778b30cb11129a782d8746bd13e6ed|1|1
40c6c3d152cf7d86104ad9ca19fbb850d6fdf343|3|2
8512e62aed8835864a8800ed895c91a8773dc996|57|27
e31897fd92088e5305735d080e224a23b7315a11|1|1
b03db7bc0b8a2705fe6fda19f5f149452755284c|18|8
dd190e4f7f24aa2a8b7bb1bbc7020aead6d014c0|478|55
a664265e3f5876177b7c1410dad7119e01e7f9e9|410|93
599cafb3f29c52dd2a44f27d5632032c54a34a25|70|12
e42a43de57ff5d4ee616cd2ec3b54a0db249a3e6|15|5
f158b44a5bd96ef34b378b58f61399568424f6d4|14|6
3cf0f13571c101725f9ef34ce2476c90478ff07d|22|17
0cb22962ec87cb29a29a44acfc5ec14588aadb23|80|16
1680d6931f5773673fae021b7cc646e3f3faab44|47|28
1e2aae9940969190c6b9bebe94c94749eee91626|228|38
da22f479dc2f8d1e98294750b741b3cce168fd19|373|88
c25f0d00238fc36f355f818f571abc3d4a1198df|27|7
02e48a41810bdb2ad471926d9728a9a9af12b155|11|4
bcd893da081fd15b1614a05c4d8b593f55cf7011|379|134
6da51572d2b5b76eb9a37ffa99da76bfb850cd83|4|4
22e75e65b831adda852df3a11628e793aaa9e7a9|214|60
2f0970b9a5d8fc755269ba848169f5a1369ec6a6|8|6
5cc32a6bc813ff59db231f29db5b95a13ea94704|56|1
dc92e549d05ac8dc0c23937d6e6dfa874729fdd4|17|15
2433562451b188c9233f6fd83a9ef7573ce48f97|24|5
82dfd4bf99283e5ab283073651787b3c7975561f|30|5
ab20d7fac6f83ac527475927aa53b204c11ed7c8|26|1
96f32f3174453e68960d849672cb4b7a8d33d1c7|18|6
f37158f2468145272817fd65794d78be539be19b|9|1
19fa01f6d66c19892c634a02da44f7f536b29e43|24|8
a3e7ae521e6a0dcb3cf9489ac5a67b0f62aad526|133|68
56a4e91425fa5cba9aecf08f786691ef03563750|26|0
d2a49862864dff9799e236d2cf81b51ed268f93f|79|28
859e81752809cd343b00ad6499c159d2f341cc46|6|1
be3d256b12679a32f2fb4e44eeb82e513607b284|176|9
65ab2f709f724750878f2cb5d045649bf0c53e89|267|56
63ee097eb68a72ac23effab3979978adafb5b411|10|0
29f7ebe942a43891f2a55fd998d02c37411efc9f|262|65
6b0c12fc40c5759f5d53028ba692e8aaff80fc92|3|1
b181b6d148e02862b195824020954abadae8de88|2|2
d302b391af5c2932c9097dd85923a8535593e45e|229|45
017745631c79f0c9061e4fdba8d0ce09ecc6c86d|12|2
5dae90d79aef7d70300fe53a17f9e40dba24b309|5|1
ca60e008352585f2501ca3f81337849396b4d140|51|0
30203fb1f91acfb45c6085432a66029896e26e66|6|2
75ac25db5853747e3f56877c943d51ce8d649a5e|116|51
ec9adc1a8f61663d224399711d165a7dd623b919|16|8
e80fdde018b3ce359f49271f082366bbad19f928|12|3
fa25db0b24e84470e8271309370e0f8093463ddd|78|34
1d8bbfb40fa7a1fe90e710b593dfa2b3e9113c2d|6|2
4432a3daa2f875bc2d3fe47caf783b3eb286ebfe|119|26
aa8e81601a80b6910a3791490d07c5691b517850|45|20
0a8d8676ac74f994535eceaa1c6c47cb17868038|261|135
3d568547fd6b8036481df0d73a2c60b5bf30d5a7|16|16
4c07e10c56ee30db5d03453237ae6c29c31a7cf0|78|57
df0313b00f2854929c376434c56129ef6e2740e0|5|5
97df1f07893def20701570db65418ff75ed45656|4|0
bbc4a3114572200d7a8a674eb3a4e430ae1d0b47|3|0
4363f50065239e47d56f12250d933f5a1ab75a00|44|2
d9021cffb65692624f3990ae2544a96ae0c07021|5|4
29107df6b155bb20934ef369b934699191076b32|109|166
f708f338cb6e435db3822e2aa81b2785b51bf39b|242|100
a71e1d95715c1190335e8738413382b31b6d167c|178|105
	120eee252b4caa7fe6389602bd2c8a316c6cee2a|6|6
	975f65c78a5745424665a95f0c222287306c9dd5|17|2
	24b6f60e9e751b699cb232759d85a06c42792019|3|3
	80decf6b8ba71dd4331f559a08ee0fba3fbdf4bb|15|10
	7cc726325faa5cad71d2132480cbb68fb046563d|781|148
	9ad50ae2a2c7fce76a75d1200e22374eb729914d|160|23
	19106d19e531ea75918241b2858024c34a73f037|87|21
	7313951174e317f889851f696de264b546e4b54e|183|20
	d329df055a1a13459d0f507bc222b05525bb7522|126|43
	351c282e9a9a2ee118496651cef7a4b33cf309f2|50|45
	b1c1e72d9331952247c804af6589fe3b349d0b8a|56|11
	e60049751d7e238e46e45ce8009d9e9f053a41c2|81|25
	6d5d36a1380d3b4b4b6ddba71828825ef942975b|1|1`;

      // -----------------------------
      // Data: manual classification
      // -----------------------------

      const CLASS_EARLY = [
  {
    "commit": "c08f1602d03b1833a4f91c8f77347f8f196bac9d",
    "change_groups": [
      {
        "summary": "Introduced the comprehensive V1 specification as a new, authoritative single-source document covering architecture, MVCC, RaptorQ, file format, SQL coverage, and testing.",
        "categories": [
          6,
          4,
          7,
          8,
          9
        ],
        "primary_category": 6,
        "confidence": 0.62,
        "evidence": [
          "new file mode 100644",
          "+# COMPREHENSIVE SPECIFICATION FOR FRANKENSQLITE V1"
        ],
        "changed_headings": [
          "0. How to Read This Document",
          "1. Project Identity"
        ]
      }
    ]
  },
  {
    "commit": "f9d88aa96f50893f8531373d0734597ebae3c592",
    "change_groups": [
      {
        "summary": "Promoted SSI to V1 concurrent mode and expanded MVCC structures with SIREAD tracking, sharded lock tables, and intent logs for deterministic rebase and merge policy.",
        "categories": [
          1,
          4,
          7,
          8
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "+**Layer 2 (Ship in V1): MVCC concurrent mode with SSI (Serializable by Default).**",
          "+in_flight       : RoaringBitmap"
        ],
        "changed_headings": [
          "2.4 The Solution: Layered Isolation",
          "5. MVCC Formal Model",
          "5.10 Algebraic Write Merging and Intent Logs"
        ]
      },
      {
        "summary": "Added explicit crash model and formalized Compatibility vs Native operating modes with durable marker rules.",
        "categories": [
          4,
          6,
          7
        ],
        "primary_category": 4,
        "confidence": 0.64,
        "evidence": [
          "+### 7.9 Crash Model (Explicit Contract):",
          "+### 7.10 Two Operating Modes"
        ],
        "changed_headings": [
          "7.9 Crash Model (Explicit Contract)",
          "7.10 Two Operating Modes"
        ]
      },
      {
        "summary": "Threaded `Cx` through storage and pager traits to make I/O and blocking operations cancelable and deadline-aware.",
        "categories": [
          7,
          3
        ],
        "primary_category": 7,
        "confidence": 0.58,
        "evidence": [
          "+fn open(&self, cx: &Cx, path: Option<&Path>, flags: VfsOpenFlags)",
          "+fn commit(&self, cx: &Cx, txn: Transaction) -> Result<()>"
        ],
        "changed_headings": [
          "9. Trait Hierarchy",
          "9.1 Storage Traits"
        ]
      }
    ]
  },
  {
    "commit": "76eef31be20a6faedc62e7fecce88e78652ebdcf",
    "change_groups": [
      {
        "summary": "Reframed RaptorQ decoding guarantees to avoid hard-coded probabilities and require recoverable failure handling with monitoring.",
        "categories": [
          8,
          1,
          9
        ],
        "primary_category": 8,
        "confidence": 0.67,
        "evidence": [
          "+**Decoding Failure Behavior (Normative):**",
          "+Correctness MUST NOT depend on decoding succeeding with exactly `K` symbols."
        ],
        "changed_headings": [
          "3.2 How RaptorQ Works (Essential Understanding)"
        ]
      },
      {
        "summary": "Corrected SQLite legacy behaviors and details (WAL reader limit and integer overflow semantics).",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "+caps the number of simultaneously active reader locks via `WAL_NREADER`",
          "+promote to REAL (floating point) rather than wrapping."
        ],
        "changed_headings": [
          "2.1 The Problem"
        ]
      },
      {
        "summary": "Aligned asupersync module paths and API examples; clarified feature-flag placement and harness notes.",
        "categories": [
          3,
          5,
          9
        ],
        "primary_category": 3,
        "confidence": 0.58,
        "evidence": [
          "+src/raptorq/gf256.rs        -- GF(256) arithmetic",
          "+Feature flags MUST live on a real package manifest"
        ],
        "changed_headings": [
          "3.3 Asupersync's RaptorQ Implementation",
          "8.5 Feature Flags"
        ]
      }
    ]
  },
  {
    "commit": "9800b17df4a56c2dc065cf566c2810d4ed2e576c",
    "change_groups": [
      {
        "summary": "Added non-negotiable scope doctrine, normative language rules, and a formal glossary to eliminate V1-scope escape hatches.",
        "categories": [
          6,
          5,
          9
        ],
        "primary_category": 6,
        "confidence": 0.63,
        "evidence": [
          "+### 0.1 Non-Negotiable Scope Doctrine",
          "+### 0.2 Normative Language",
          "+### 0.3 Glossary"
        ],
        "changed_headings": [
          "0.1 Non-Negotiable Scope Doctrine",
          "0.2 Normative Language",
          "0.3 Glossary"
        ]
      },
      {
        "summary": "Specified ECS substrate details and made erasure-coded page storage fully in-scope.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+### 3.5 ECS: The Erasure-Coded Stream Substrate",
          "+#### 3.5.1 ObjectId: Content-Addressed Identity"
        ],
        "changed_headings": [
          "3.5 ECS: The Erasure-Coded Stream Substrate"
        ]
      },
      {
        "summary": "Introduced multi-process MVCC shared-memory coordination and cross-process lock table protocol.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+#### 5.6.1 Shared-Memory Coordination Region",
          "+#### 5.6.3 Cross-Process Page Lock Table"
        ],
        "changed_headings": [
          "5.6.1 Shared-Memory Coordination Region",
          "5.6.3 Cross-Process Page Lock Table"
        ]
      }
    ]
  },
  {
    "commit": "79018f161649e6d7977bc74eb849a0e22eceb286",
    "change_groups": [
      {
        "summary": "Corrected WAL compatibility by moving RaptorQ repair data to a `.wal-fec` sidecar; standard WAL frames remain byte-for-byte SQLite-compatible.",
        "categories": [
          2,
          7
        ],
        "primary_category": 2,
        "confidence": 0.7,
        "evidence": [
          "+Standard SQLite WAL frames are exactly 24 bytes (header) + page_size (data).",
          "+Instead, we use a **sidecar file** (`.wal-fec`) to store repair symbols."
        ],
        "changed_headings": [
          "Concrete WAL Commit Frame Layout (Compatibility Mode)"
        ]
      }
    ]
  },
  {
    "commit": "5ad34871f7242de61378843c6c1e8311e35d9fa3",
    "change_groups": [
      {
        "summary": "Added RaptorQ Everywhere doctrine, expanded glossary/TOC, and tightened mechanical sympathy constraints.",
        "categories": [
          6,
          4,
          9
        ],
        "primary_category": 6,
        "confidence": 0.62,
        "evidence": [
          "+### 0.4 What \"RaptorQ Everywhere\" Means (No Weasel Words)",
          "+| **CommitSeq** | Monotonically increasing `u64` commit sequence number"
        ],
        "changed_headings": [
          "0.4 What \"RaptorQ Everywhere\" Means"
        ]
      },
      {
        "summary": "Overhauled WAL-FEC sidecar model and ECS/replication architecture to unify repair symbols and replication into ECS objects.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.64,
        "evidence": [
          "+.wal contains ONLY standard SQLite WAL frames (source symbols);",
          "+### 3.4.7 Replication Architecture"
        ],
        "changed_headings": [
          "3.4.7 Replication Architecture"
        ]
      }
    ]
  },
  {
    "commit": "7b2c677cf61adda977e71524b59d7ec234137962",
    "change_groups": [
      {
        "summary": "Applied alien-artifact discipline: decision-theoretic SSI policy, VOI-driven granularity investment, BOCPD monitoring, and formal durability theorems.",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.66,
        "evidence": [
          "+**Decision-Theoretic SSI Abort Policy (Alien-Artifact Discipline).**",
          "+### 4.8 Bayesian Online Change-Point Detection (BOCPD)"
        ],
        "changed_headings": [
          "4.8 Bayesian Online Change-Point Detection (BOCPD)",
          "5.7 SSI"
        ]
      },
      {
        "summary": "Added engineering guardrails: memory accounting, hash-tier strategy, and native-mode commit/recovery protocol details.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.56,
        "evidence": [
          "+### 6.9 Memory Accounting",
          "+### 7.11 Native Mode Commit Protocol"
        ],
        "changed_headings": [
          "6.9 Memory Accounting",
          "7.11 Native Mode Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "bf0426417685504bb2b2f5acfc4de2c2f087ef8b",
    "change_groups": [
      {
        "summary": "Replaced ephemeral SIREAD tables with a RaptorQ-native SSI witness plane (hot+cold planes, durable ECS evidence, cross-process support).",
        "categories": [
          4,
          7,
          8
        ],
        "primary_category": 4,
        "confidence": 0.68,
        "evidence": [
          "+| **WitnessKey** | The canonical key-space for SSI read/write evidence",
          "+SSIWitnessPlane := (see Section 5.6.4)"
        ],
        "changed_headings": [
          "5.6.4 SSI Witness Plane"
        ]
      }
    ]
  },
  {
    "commit": "05cf07847753f444b9f74dfd0279ef96c3ff86b9",
    "change_groups": [
      {
        "summary": "Replaced magic-number defaults with formal derivations and cost models for tunable parameters (delta threshold, BOCPD priors, GC scheduling, etc.).",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.7,
        "evidence": [
          "+// COST MODEL (Extreme Optimization Discipline):",
          "+P(r_t | x_{1:t}) proportional to sum_{r_{t-1}} ..."
        ],
        "changed_headings": [
          "3.4.4 Delta Threshold",
          "4.8 BOCPD",
          "5.6.5 GC Coordination"
        ]
      }
    ]
  },
  {
    "commit": "e8ddf469d8ab8ff8eefbae92b24453e06fcf4627",
    "change_groups": [
      {
        "summary": "Introduced performance-oriented data structures (VersionArena, AppendOnlyVec, CAR cache) and per-invariant monitoring calibration.",
        "categories": [
          7,
          8
        ],
        "primary_category": 7,
        "confidence": 0.63,
        "evidence": [
          "+VersionArena",
          "+CommitLog := AppendOnlyVec<CommitRecord>",
          "+CAR (Clock with Adaptive Replacement)"
        ],
        "changed_headings": [
          "5.5 MVCC Data Structures",
          "6. ARC Cache",
          "4.3 E-process Calibration"
        ]
      }
    ]
  },
  {
    "commit": "480c10086fb73630744364f5fb34966de2572dc1",
    "change_groups": [
      {
        "summary": "Updated SSI transaction struct to use TxnToken edges and added eager abort semantics plus witness-plane-aware commit-time detection pseudocode.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.62,
        "evidence": [
          "+marked_for_abort : bool",
          "+**Commit-time detection + proof emission pseudocode (witness plane):**"
        ],
        "changed_headings": [
          "5.7 SSI Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "0313678eff44b70cd4ea40cabc2f2222cac2ba93",
    "change_groups": [
      {
        "summary": "Clarified SSI detection algorithm as a two-pass pivot/completion check with eager abort marking.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.6,
        "evidence": [
          "+The on_commit(T) pseudocode specifies the two-pass check:",
          "+on_commit(T):"
        ],
        "changed_headings": [
          "5.7 SSI Algorithm"
        ]
      },
      {
        "summary": "Adjusted object identity and Cx capability descriptions (ObjectId truncation and richer capability mechanics).",
        "categories": [
          4,
          3,
          9
        ],
        "primary_category": 4,
        "confidence": 0.52,
        "evidence": [
          "+| **ObjectId** | Content-addressed identifier: 128-bit `Trunc128(BLAKE3(...))`",
          "+**Cooperative cancellation + progress checkpoints**"
        ],
        "changed_headings": [
          "0.3 Glossary",
          "4.2 Asupersync Integration"
        ]
      }
    ]
  },
  {
    "commit": "b97b1abe4727a738197180c5639738c1da2f5311",
    "change_groups": [
      {
        "summary": "Removed merge artifacts by restoring canonical ObjectId size and concise Cx glossary/API examples.",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.66,
        "evidence": [
          "-| **ObjectId** | Content-addressed identifier: 128-bit `Trunc128(...)",
          "+| **ObjectId** | Content-addressed identifier: `BLAKE3(canonical_encoding(object))`, 32 bytes."
        ],
        "changed_headings": [
          "0.3 Glossary"
        ]
      }
    ]
  },
  {
    "commit": "643c89c1c941d1e47cb6a2574e01fd7556f622ec",
    "change_groups": [
      {
        "summary": "Restored canonical SSI detection algorithm and in-process edge representation after merge artifacts.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.64,
        "evidence": [
          "+has_incoming_rw : bool",
          "+**Detection algorithm pseudocode:**"
        ],
        "changed_headings": [
          "5.7 SSI Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "0404e42c9dbdc677da9b8a5731d29290ef9f3b26",
    "change_groups": [
      {
        "summary": "Integrated SSI witness-plane evidence into native-mode commit protocol, adding CommitProof and new ordering constraints.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.63,
        "evidence": [
          "+`proof_object_id`",
          "+**Critical ordering:** Marker publication MUST happen AFTER capsule durability and AFTER `CommitProof` durability is satisfied."
        ],
        "changed_headings": [
          "7.11 Native Mode Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "2a6353d2f77a050454d2a6fd4b3fd6c8363064e9",
    "change_groups": [
      {
        "summary": "Aligned asupersync integration terminology, witness-plane naming, and ObjectId truncation details.",
        "categories": [
          3,
          9,
          4
        ],
        "primary_category": 3,
        "confidence": 0.6,
        "evidence": [
          "+| **ObjectId** | Content-addressed identifier: `Trunc128(BLAKE3(\"fsqlite:ecs:v1\" || canonical_object_header || payload_hash))`",
          "+| **SIREAD witness (legacy term)** | ... represented by `ReadWitness` objects"
        ],
        "changed_headings": [
          "0.3 Glossary"
        ]
      }
    ]
  },
  {
    "commit": "3253050f2835fb305bd115bd9f5939b72cd46503",
    "change_groups": [
      {
        "summary": "Added systematic symbol fast-path flags and tiered storage semantics for ECS objects.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+flags       : u8,           -- bitflags (see below)",
          "+**Systematic read fast path (hybrid decode):**"
        ],
        "changed_headings": [
          "3.5.2 Symbol Record Envelope",
          "3.5.11 Tiered Storage (\"Bottomless\", Native Mode)"
        ]
      },
      {
        "summary": "Introduced SchemaEpoch into MVCC snapshot to forbid intent replay across schema changes.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.56,
        "evidence": [
          "+SchemaEpoch := u64",
          "+schema_epoch    : SchemaEpoch"
        ],
        "changed_headings": [
          "5.1 Core Types"
        ]
      }
    ]
  },
  {
    "commit": "06dfe9a709d61fc899e00ee33d54dc15d003bb48",
    "change_groups": [
      {
        "summary": "Updated core MVCC types to CommitSeq-based snapshots and formalized SSI witness plane in place of SIREAD tables.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.62,
        "evidence": [
          "+CommitSeq   := u64",
          "+SSIWitnessPlane := (see Section 5.6.4)"
        ],
        "changed_headings": [
          "5.1 Core Types"
        ]
      }
    ]
  },
  {
    "commit": "63f6057e8705b7105837952bc8ea977ad6f34da6",
    "change_groups": [
      {
        "summary": "Changed MVCC ARC cache keys from TxnId to CommitSeq and updated invariants accordingly.",
        "categories": [
          7,
          1
        ],
        "primary_category": 7,
        "confidence": 0.62,
        "evidence": [
          "-Standard ARC keys on page number. Our variant keys on `(PageNumber, TxnId)`",
          "+Standard ARC keys on page number. Our variant keys on `(PageNumber, CommitSeq)`"
        ],
        "changed_headings": [
          "6.2 MVCC-Aware ARC Data Structures"
        ]
      }
    ]
  },
  {
    "commit": "2cff3a0287f1de30d2fd1185c376ac81913922c9",
    "change_groups": [
      {
        "summary": "Clarified the INV-1 monitor label to include CommitSeq monotonicity.",
        "categories": [
          9,
          5
        ],
        "primary_category": 9,
        "confidence": 0.8,
        "evidence": [
          "+EProcess::new(\"INV-1: TxnId/CommitSeq Monotonicity\", EProcessConfig {"
        ],
        "changed_headings": [
          "4.3 E-process Monitoring"
        ]
      }
    ]
  },
  {
    "commit": "4ba1ee3bce5eef69acf5e24c61e0fe5482662a79",
    "change_groups": [
      {
        "summary": "Tightened glossary entries and fixed algebraic merge pseudocode types plus MVCC module descriptions.",
        "categories": [
          9,
          5,
          1
        ],
        "primary_category": 9,
        "confidence": 0.62,
        "evidence": [
          "+| **CommitMarker** | The durable \"this commit exists\" record in Native mode: `(commit_seq, commit_time_unix_ns, capsule_object_id, proof_object_id, prev_marker, integrity_hash)`.",
          "+page_T2_committed: &PageData"
        ],
        "changed_headings": [
          "0.3 Glossary",
          "5.10 Algebraic Write Merge"
        ]
      }
    ]
  },
  {
    "commit": "72eb835e83063d8fe19c1288a8c4624438473b2e",
    "change_groups": [
      {
        "summary": "Corrected cross-process TxnSlot cleanup to defend against PID reuse and formalized lock-table tombstone semantics.",
        "categories": [
          7,
          1
        ],
        "primary_category": 7,
        "confidence": 0.65,
        "evidence": [
          "+pid_birth       : AtomicU64",
          "+TOMBSTONE := 0xFFFF_FFFF is reserved."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "5.6.3 Cross-Process Page Lock Table"
        ]
      }
    ]
  },
  {
    "commit": "0b543b5b587d72a5531a37324ad31fab0157b6ed",
    "change_groups": [
      {
        "summary": "Expanded asupersync integration glossary with Budget/Outcome/Region semantics and structured concurrency behavior.",
        "categories": [
          3,
          6
        ],
        "primary_category": 3,
        "confidence": 0.6,
        "evidence": [
          "+| **Budget** | Asupersync resource budget (product semiring) carried by `Cx`",
          "+| **Region** | Asupersync structured concurrency scope"
        ],
        "changed_headings": [
          "0.3 Glossary"
        ]
      },
      {
        "summary": "Corrected RaptorQ failure probability claims and clarified rules of thumb using RFC 6330 Annex B data.",
        "categories": [
          1,
          8
        ],
        "primary_category": 1,
        "confidence": 0.6,
        "evidence": [
          "+**Caution on failure probability claims:**",
          "+Decoding with **exactly K** received symbols: ~99% success (P_fail < 0.01)."
        ],
        "changed_headings": [
          "3.1 RaptorQ Foundation"
        ]
      }
    ]
  },
  {
    "commit": "d7b38efedc6f77029ce412c1eea2d0197b8b8fc6",
    "change_groups": [
      {
        "summary": "Deep audit fixes to MVCC formal model: CommitLog definition, SSI inequality correction, padding alignment, and cost model adjustments.",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.66,
        "evidence": [
          "+CommitLog := AppendOnlyVec<CommitRecord>",
          "+_padding        : [u8; 64]"
        ],
        "changed_headings": [
          "5.1 Core Types",
          "5.6 Shared Memory"
        ]
      }
    ]
  },
  {
    "commit": "322af1706478c8da09b09af4927e6a011041c5a6",
    "change_groups": [
      {
        "summary": "Added normative memory-ordering rules for CommitSeq visibility and clarified SSI pivot abort overapproximation.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.64,
        "evidence": [
          "+MUST be incremented with `Release` ordering AFTER all version chain updates",
          "+**Note (deliberate overapproximation):**"
        ],
        "changed_headings": [
          "5.4 Visibility",
          "5.7 SSI Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "1a672dd545885d61c2531bf2be178d0edb4a5065",
    "change_groups": [
      {
        "summary": "Corrected checksum/format details: WAL magic endianness, integrity check scoping, and symbol overhead interpretation.",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.62,
        "evidence": [
          "+0x377F0682 (bit 0 = 0) = little-endian word order",
          "+loss_fraction_max approx max(0, (R - slack) / (K_source + R))"
        ],
        "changed_headings": [
          "11. Checksums and Integrity"
        ]
      },
      {
        "summary": "Added family-wise error control for multiple e-process monitors using e-value aggregation.",
        "categories": [
          8
        ],
        "primary_category": 8,
        "confidence": 0.56,
        "evidence": [
          "+E_global(t) := prod_i E_i(t)^{w_i}",
          "+sum_i alpha_i <= alpha_total"
        ],
        "changed_headings": [
          "4.3 E-process Monitoring"
        ]
      }
    ]
  },
  {
    "commit": "a19a3acb957598db6e11ece9ab199ae8f34eb88e",
    "change_groups": [
      {
        "summary": "Fixed crate layering to avoid dependency cycles and clarified mvcc/wal relationships.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+fsqlite-mvcc moved from Layer 6 to Layer 3.",
          "+Checkpoint now receives `&dyn CheckpointPageWriter` at runtime"
        ],
        "changed_headings": [
          "8. Architecture: Crate Map and Dependencies"
        ]
      },
      {
        "summary": "Corrected SQLite expression precedence and VDBE p5 flag semantics.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.58,
        "evidence": [
          "+**IMPORTANT:** `NOT` is NOT at the same precedence as unary `~`/`+`/`-`.",
          "+upper 8 bits MUST be zero."
        ],
        "changed_headings": [
          "12. SQL Coverage",
          "VDBE Opcode Layout"
        ]
      }
    ]
  },
  {
    "commit": "d0fda0186411a7f75bd73771f484259c29d7921a",
    "change_groups": [
      {
        "summary": "Minor wording adjustments clarifying wal/pager dependency and header naming.",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.72,
        "evidence": [
          "+Does NOT depend on `fsqlite-pager`",
          "+| `sqliteInt.h` | Main internal header"
        ],
        "changed_headings": [
          "Crate Descriptions",
          "C SQLite Reference Extraction"
        ]
      }
    ]
  },
  {
    "commit": "b8344dba9b295b31b843807f80c6ec10e601459b",
    "change_groups": [
      {
        "summary": "Clarified crate boundaries and added WAL header notes for SQLite format.",
        "categories": [
          4,
          2
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+does not depend on `fsqlite-wal`.",
          "+Format version: 3007000 (constant for all WAL1 databases;"
        ],
        "changed_headings": [
          "Crate Descriptions",
          "WAL Header"
        ]
      }
    ]
  },
  {
    "commit": "5e2344ce7b5640aaad2fb48bed85838f9c9ecfef",
    "change_groups": [
      {
        "summary": "Specified the exact SQLite WAL checksum algorithm and clarified wal-index layout details.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.64,
        "evidence": [
          "+fn wal_checksum(data: &[u8], mut s0: u32, mut s1: u32, native: bool) -> (u32, u32)",
          "+WalIndexHdr (first copy):"
        ],
        "changed_headings": [
          "11.9.1 WAL Checksum Algorithm",
          "11.10 WAL Index (wal-index / SHM)"
        ]
      },
      {
        "summary": "Refined repair tail bounds with concrete orders of magnitude for small K.",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.54,
        "evidence": [
          "+K=4, R=1 (n=5): P(loss) approx C(5,2) p^2 approx 1e-7"
        ],
        "changed_headings": [
          "Durability Bound"
        ]
      }
    ]
  },
  {
    "commit": "713e6dc4f8b202870b16e154a597bcd735d5c05b",
    "change_groups": [
      {
        "summary": "Added explicit SQLite page header field layout description.",
        "categories": [
          2,
          6
        ],
        "primary_category": 2,
        "confidence": 0.62,
        "evidence": [
          "+**Page header field layout:**",
          "+Offset  Size  Field"
        ],
        "changed_headings": [
          "B-tree Page Header"
        ]
      },
      {
        "summary": "Updated document version metadata.",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.6,
        "evidence": [
          "-*Document version: 1.8",
          "+*Document version: 1.9"
        ],
        "changed_headings": []
      }
    ]
  },
  {
    "commit": "e2dc2232567e901ce8f7192303c9da013e4c8d7c",
    "change_groups": [
      {
        "summary": "Clarified fragmentation byte meaning and added explicit SQLite varint encoding spec.",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.65,
        "evidence": [
          "+### 11.2.1 Varint Encoding",
          "+minimum freeblock size is 4 bytes, so gaps of 1-3 bytes cannot be tracked"
        ],
        "changed_headings": [
          "11.2.1 Varint Encoding"
        ]
      }
    ]
  },
  {
    "commit": "3c5d5a177c8fbd78fd6f11f32a02e4c3ada9e172",
    "change_groups": [
      {
        "summary": "Fixed index local-payload math and clarified SQLite comparison affinity coercion rules.",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.64,
        "evidence": [
          "+index max_local = 1001.",
          "+**Comparison affinity rules** (applied before comparison; determines which operand gets type coercion)"
        ],
        "changed_headings": [
          "11.3 Cell Formats",
          "12. SQL Coverage"
        ]
      }
    ]
  },
  {
    "commit": "714570a488c9e93f3349ba527e70e744570555e9",
    "change_groups": [
      {
        "summary": "Documented SQLite pointer-map entry type semantics with explicit codes.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "+1 = PTRMAP_ROOTPAGE",
          "+5 = PTRMAP_BTREE"
        ],
        "changed_headings": [
          "Pointer Map"
        ]
      },
      {
        "summary": "Swapped raw pread usage for safe `FileExt::read_exact_at` in page read example.",
        "categories": [
          7,
          5
        ],
        "primary_category": 7,
        "confidence": 0.56,
        "evidence": [
          "+FileExt::read_exact_at is safe Rust; no `unsafe` needed.",
          "+async fn read_page(cx: &Cx, pool: &PageBufPool, file: &Arc<File>, offset: u64)"
        ],
        "changed_headings": [
          "VFS / Pager Example"
        ]
      }
    ]
  },
  {
    "commit": "893691fc58cca08e1fba3a25a5ddf520624d6860",
    "change_groups": [
      {
        "summary": "Added SSI-related invariants and clarified e-process usage versus hard invariants.",
        "categories": [
          8,
          1
        ],
        "primary_category": 8,
        "confidence": 0.6,
        "evidence": [
          "+**INV-5 (Snapshot Stability)**",
          "+**Recommendation:** Use `debug_assert!` for INV-1 through INV-7"
        ],
        "changed_headings": [
          "4.3 E-process Monitoring"
        ]
      },
      {
        "summary": "Corrected index max_local formula for 4096-byte pages.",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.58,
        "evidence": [
          "+index max_local = 1002.",
          "+`4084 * 64 / 255 - 23` = `1025 - 23` = 1002"
        ],
        "changed_headings": [
          "11.3 Cell Formats"
        ]
      }
    ]
  },
  {
    "commit": "a9aff80df7c0d04f465db40b74165a2e75ae5e29",
    "change_groups": [
      {
        "summary": "Corrected budget algebra terminology and fixed BOCPD recursion by marginalizing over prior run length.",
        "categories": [
          1,
          8
        ],
        "primary_category": 1,
        "confidence": 0.64,
        "evidence": [
          "+product meet-semilattice",
          "+P(r_t | x_{1:t}) proportional to sum_{r_{t-1}} ..."
        ],
        "changed_headings": [
          "0.3 Glossary",
          "4.8 BOCPD"
        ]
      },
      {
        "summary": "Threaded `Cx` through VfsFile methods to make file operations cancelable/deadline-aware.",
        "categories": [
          3,
          7
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+fn read(&mut self, cx: &Cx, buf: &mut [u8], offset: u64) -> Result<usize>;",
          "+fn sync(&mut self, cx: &Cx, flags: SyncFlags) -> Result<()>;"
        ],
        "changed_headings": [
          "9.1 Storage Traits"
        ]
      }
    ]
  },
  {
    "commit": "80bc4494162ff420cdb48c5122324d9bdc8d328b",
    "change_groups": [
      {
        "summary": "Refined public API facade with `Database` wrapper and replaced Default-based function state with `initial_state()` factories for type erasure.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.6,
        "evidence": [
          "+pub struct Database(Connection);",
          "+fn initial_state(&self) -> Self::State;"
        ],
        "changed_headings": [
          "Public API",
          "Scalar/Aggregate/Window Functions"
        ]
      }
    ]
  },
  {
    "commit": "a5a85e64c6356176ad86795d69e1293bd76f2601",
    "change_groups": [
      {
        "summary": "Added `Cx` parameter to rollback for cancelation-aware abort path.",
        "categories": [
          3,
          7
        ],
        "primary_category": 7,
        "confidence": 0.6,
        "evidence": [
          "+fn rollback(&self, cx: &Cx, txn: Transaction);"
        ],
        "changed_headings": [
          "MvccPager Trait"
        ]
      },
      {
        "summary": "Clarified recursive CTE semantics for UNION vs UNION ALL in SQLite.",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.58,
        "evidence": [
          "+Recursive CTEs use `UNION ALL` (keeps duplicates) or `UNION` (discards duplicates, providing implicit cycle detection)"
        ],
        "changed_headings": [
          "Recursive CTEs"
        ]
      }
    ]
  }
];
      const CLASS_MIDDLE = [
  {
    "commit": "7c93dbb54e2d939f820d97a469bf204829ce97c8",
    "change_groups": [
      {
        "summary": "Fix WAL checksum endianness semantics and clarify WAL header magic meaning, correct WAL-index hash and lock region layout, and add rollback journal format details",
        "categories": [
          1,
          2,
          4,
          9
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "WAL checksum parameter semantics corrected; bigEndCksum handling clarified",
          "WAL-index hash function corrected to multiplicative hash; lock region layout fixed",
          "Rollback journal format and checksum described"
        ],
        "changed_headings": [
          "7.1 WAL Checksum Algorithm",
          "11.9.1 WAL Checksum Algorithm",
          "11.10 WAL Index (wal-index / SHM)",
          "11.14 Rollback Journal Format"
        ]
      },
      {
        "summary": "Correct ARC competitive ratio claim",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.58,
        "evidence": [
          "ARC claim changed from competitive ratio 2 to containment/self-tuning wording"
        ],
        "changed_headings": [
          "6. Buffer Pool: ARC Cache"
        ]
      }
    ]
  },
  {
    "commit": "07236c61ff86a87f22bb1aa6fd26885eb527d268",
    "change_groups": [
      {
        "summary": "Revert WAL checksum endianness guidance to match nativeCksum derivation; update examples accordingly",
        "categories": [
          1,
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "big_end_cksum now feeds nativeCksum via target endianness; swap logic changed",
          "endianness table updated to per-reader nativeCksum outcomes"
        ],
        "changed_headings": [
          "7.1 WAL Checksum Algorithm",
          "11.9.1 WAL Checksum Algorithm"
        ]
      },
      {
        "summary": "Clarify Windows VFS inclusion and adjust layering/ARC placement notes",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.63,
        "evidence": [
          "WindowsVfs noted as in-scope; VFS locking/SHM mechanisms clarified",
          "ARC cache and MvccPager trait placement moved to pager layer"
        ],
        "changed_headings": [
          "15. VFS",
          "8. Implementation Plan"
        ]
      },
      {
        "summary": "Adjust B-tree depth capacity note",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.45,
        "evidence": [
          "B-tree depth capacity explanation rewritten"
        ],
        "changed_headings": [
          "8. Implementation Plan"
        ]
      }
    ]
  },
  {
    "commit": "d9146f771541d7e134f540e11016df82cc6e17b9",
    "change_groups": [
      {
        "summary": "Reframe GF(256) byte algebra as encoding-only; forbid raw XOR merges for structured pages and introduce SAFE/LAB_UNSAFE write-merge policy",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.74,
        "evidence": [
          "Byte-disjoint XOR merge prohibited for structured SQLite pages; SAFE merge ladder required",
          "PRAGMA fsqlite.write_merge introduced with SAFE/LAB_UNSAFE"
        ],
        "changed_headings": [
          "3.4.5 Algebraic Write Merging Over GF(256)",
          "5.10 Commit-Time Merge Policy"
        ]
      },
      {
        "summary": "Specify commit marker stream format with fixed-size records, O(1) seek, and divergence checks",
        "categories": [
          4,
          7,
          9
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "New marker segment header and record layout; fixed-size records",
          "O(1) seek and binary search by time described"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream Format (Random-Access, Auditable)"
        ]
      },
      {
        "summary": "Harden ECS compaction publication ordering and ARC eviction edge case; add RaptorQ overhead slack + adaptive tuning note",
        "categories": [
          4,
          1,
          8,
          9
        ],
        "primary_category": 4,
        "confidence": 0.67,
        "evidence": [
          "Compaction publish ordering now two-phase with durability before retiring old segments",
          "ARC T1 eviction path clarified to avoid B1 invariant violation",
          "RaptorQ overhead slack and adaptive tuning (e-process) added"
        ],
        "changed_headings": [
          "3.4.6 Erasure-Coded Page Storage",
          "3.5.4.1 Commit Marker Stream Format (Random-Access, Auditable)",
          "7.11 Publish Protocol",
          "7.9 Compaction Algorithm",
          "6.4 ARC Algorithm: REQUEST Subroutine"
        ]
      },
      {
        "summary": "Correct JSONB node types and size claim; rename R-tree to R*-Tree; tighten conflict model and retry policy",
        "categories": [
          1,
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.62,
        "evidence": [
          "JSONB node type codes updated and size claim adjusted",
          "R*-Tree naming corrected; geometry trait name fixed",
          "Conflict modeling and retry policy clarified"
        ],
        "changed_headings": [
          "JSON1/JSONB section",
          "14.4 R*-Tree",
          "18. Conflict Modeling"
        ]
      }
    ]
  },
  {
    "commit": "30619b34ea187d682283f8cd137d8d30e306e6bd",
    "change_groups": [
      {
        "summary": "Clarify geopoly as built on R*-tree and refine conflict probability interpretation with explicit examples",
        "categories": [
          9,
          1
        ],
        "primary_category": 9,
        "confidence": 0.6,
        "evidence": [
          "Geopoly extension description updated to R*-tree",
          "Birthday-paradox conflict probability explanation corrected with numeric examples"
        ],
        "changed_headings": [
          "14.4 R*-Tree",
          "18.3 Conflict Probability (Uniform)"
        ]
      }
    ]
  },
  {
    "commit": "7e9cace601485722e7b31411ad74796c0685bd05",
    "change_groups": [
      {
        "summary": "Refine Zipf conflict probability derivation with sum of squared probabilities and numerical comparison",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.74,
        "evidence": [
          "P(any conflict) expressed as exp(-C(N,2)*sum p(k)^2)",
          "Numeric comparison vs uniform added"
        ],
        "changed_headings": [
          "18.4 Non-Uniform Page Access: Zipf Distribution"
        ]
      }
    ]
  },
  {
    "commit": "ff937f3d678f88eb855051dbbd32e8e5046bea0f",
    "change_groups": [
      {
        "summary": "Clarify PageVersion hash storage and temper byte-conflict reduction claims; add retry policy",
        "categories": [
          9,
          1,
          7
        ],
        "primary_category": 9,
        "confidence": 0.62,
        "evidence": [
          "XXH3 hash belongs to CachedPage not PageVersion",
          "Byte-level conflict reduction reframed as upper bound; practical limits listed",
          "Retry policy added"
        ],
        "changed_headings": [
          "5. MVCC Formal Model",
          "18.7 Impact of Write Merging",
          "18.8 Throughput Model"
        ]
      }
    ]
  },
  {
    "commit": "61ee3e03f4cd5e44b189da55bb70e91cdba63a29",
    "change_groups": [
      {
        "summary": "Harden ARC eviction failure path to skip dirty pages on WAL flush failure",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.7,
        "evidence": [
          "flush_to_wal errors cause candidate rotation instead of eviction"
        ],
        "changed_headings": [
          "6.4 ARC Algorithm: REPLACE Subroutine"
        ]
      },
      {
        "summary": "Add math-function compile flag note and geopoly_xform function",
        "categories": [
          6,
          9
        ],
        "primary_category": 9,
        "confidence": 0.46,
        "evidence": [
          "SQLite math functions require compile flag; FrankenSQLite always includes",
          "geopoly_xform listed"
        ],
        "changed_headings": [
          "13.2 Math Functions",
          "14.4 R*-Tree"
        ]
      }
    ]
  },
  {
    "commit": "a90a3794616e12b083f88276e3cb47a045f3ac10",
    "change_groups": [
      {
        "summary": "Deep audit fixes for ARC: flush under mutex note, eviction error handling, ghost list overhead corrected, cache_size=0 semantics corrected",
        "categories": [
          1,
          2,
          4,
          9
        ],
        "primary_category": 1,
        "confidence": 0.75,
        "evidence": [
          "cache_size=0 now maps to SQLite default cache size behavior",
          "ghost list overhead recalculated; eviction path handles flush errors"
        ],
        "changed_headings": [
          "6. ARC Cache",
          "PRAGMA cache_size"
        ]
      }
    ]
  },
  {
    "commit": "246102e6b4266fa15000580a3d016d76bcb1c801",
    "change_groups": [
      {
        "summary": "Add adaptive redundancy autopilot and merge-retry loop; add witness refinement policy",
        "categories": [
          4,
          8,
          9
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "New adaptive redundancy section with e-process monitoring and policy actions",
          "Commit path restructured with coordinator conflict retry loop",
          "Witness refinement VOI policy added"
        ],
        "changed_headings": [
          "3.5.12 Adaptive Redundancy",
          "5.7 Witness Refinement Policy",
          "5.9 Commit pseudocode"
        ]
      },
      {
        "summary": "Update merge model to structured patches and operator precedence tables (ESCAPE and relational/equality split)",
        "categories": [
          1,
          2,
          9
        ],
        "primary_category": 1,
        "confidence": 0.68,
        "evidence": [
          "Physical merge retitled to structured page patches; raw XOR forbidden",
          "Precedence table split equality vs relational; ESCAPE right-associative; JSON -> operators added"
        ],
        "changed_headings": [
          "5.10 Physical Merge",
          "10.2 Pratt Parser Table",
          "12.15 Expression Grammar"
        ]
      }
    ]
  },
  {
    "commit": "5ea1b6fb02945e4bc147c37ae7d054d92fdd9045",
    "change_groups": [
      {
        "summary": "Fix SSI pseudocode edge direction and dangerous structure explanation; add claiming timestamp cleanup; cross-process note",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 1,
        "confidence": 0.74,
        "evidence": [
          "ssi_validate_and_publish scans in_edges and sets has_out_rw",
          "dangerous structure definition clarified; claiming cleanup via timeout",
          "cross-process visibility note added"
        ],
        "changed_headings": [
          "5.7 SSI",
          "5.6.2 TxnSlot",
          "SSI correctness"
        ]
      },
      {
        "summary": "Fix precedence tables and RETURNING semantics",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.65,
        "evidence": [
          "ISNULL/NOTNULL added to comparison precedence; COLLATE/unary swap fixed",
          "RETURNING reflects BEFORE but not AFTER triggers"
        ],
        "changed_headings": [
          "10.2 Pratt Parser Table",
          "12.15 Expression Grammar",
          "12.4 RETURNING"
        ]
      },
      {
        "summary": "Rename merge terminology and fix RaptorQ size unit detail",
        "categories": [
          9,
          1
        ],
        "primary_category": 9,
        "confidence": 0.42,
        "evidence": [
          "algebraic write merging renamed to safe write-merge ladder",
          "~220 MiB wording corrected"
        ],
        "changed_headings": [
          "3.1 SSI rationale",
          "3.4 RaptorQ"
        ]
      }
    ]
  },
  {
    "commit": "f1f25abe3b40ad0fb8704eaee310aee17de78d25",
    "change_groups": [
      {
        "summary": "Enforce gap-free commit_seq allocation from marker stream; tighten commit_seq publication semantics and memory ordering",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "CommitSeq derived from marker stream tip; no in-memory counter gaps",
          "commit_seq published only after durable marker; ordering clarified"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream",
          "5.6.1 SharedMemoryLayout",
          "7.11 Commit Protocol"
        ]
      },
      {
        "summary": "Clarify WAL-index layout details and rollback journal checksum loop; page size change rules",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.63,
        "evidence": [
          "WAL-index first segment layout clarified with header overlap",
          "Rollback journal checksum loop bounds clarified",
          "Page size change rules updated"
        ],
        "changed_headings": [
          "11.10 WAL Index",
          "11.14 Rollback Journal Format",
          "11.1 Database Header"
        ]
      },
      {
        "summary": "Add SSI witness rollback note for savepoints",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.4,
        "evidence": [
          "Witness registrations not rolled back on savepoint"
        ],
        "changed_headings": [
          "5.4 Savepoints"
        ]
      }
    ]
  },
  {
    "commit": "9725f136b2450c6411f5735a1575a068f2aacc0b",
    "change_groups": [
      {
        "summary": "Clarify commit_seq publication and cross-process visibility in native vs compatibility modes",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.7,
        "evidence": [
          "commit_seq described as published high-water mark; cross-process visibility split by mode"
        ],
        "changed_headings": [
          "5.6.1 SharedMemoryLayout",
          "7.11 Commit Protocol"
        ]
      },
      {
        "summary": "Define witness hot-plane epoch lock protocol to avoid false negatives",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.66,
        "evidence": [
          "epoch_lock, bucket_epoch swap discipline defined to prevent lost updates"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane"
        ]
      },
      {
        "summary": "Add DB header forward-compat rules and lock-byte page reservation; move WAL checksum impl to \u00a77.1 reference",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "Read/write version compatibility behavior specified",
          "Pending-byte page reserved; WAL checksum impl referenced"
        ],
        "changed_headings": [
          "11.1 Database Header",
          "11.13 Lock-Byte Page",
          "11.9.1 WAL Checksum Algorithm"
        ]
      }
    ]
  },
  {
    "commit": "56742886aae65bdca3a34acda8d677b52a0c241d",
    "change_groups": [
      {
        "summary": "Restrict hot-plane epoch advancement to quiescent concurrent transactions; require epoch_lock refresh semantics",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.72,
        "evidence": [
          "Epoch advance allowed only when no active concurrent txns",
          "Bucket refresh under epoch_lock with Release semantics"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane"
        ]
      }
    ]
  },
  {
    "commit": "71a41750d478e8ecad031a2f490e84a4424a839e",
    "change_groups": [
      {
        "summary": "Publish shm.commit_seq only after marker durable (post-fsync)",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.73,
        "evidence": [
          "commit_seq publish inserted after marker fsync"
        ],
        "changed_headings": [
          "7.11 Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "9fa8f7b6082f164d4cb1026296a360cfbafe1f73",
    "change_groups": [
      {
        "summary": "Require commit_seq allocation from marker tip and align sequencer steps",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.73,
        "evidence": [
          "commit_seq allocated from marker stream tip within commit section"
        ],
        "changed_headings": [
          "7.11 Commit Protocol"
        ]
      }
    ]
  },
  {
    "commit": "86d63af874d7a3dc7d522d47bf5f004f12913adb",
    "change_groups": [
      {
        "summary": "Define legacy writer exclusion for compatibility mode and hybrid SHM bridge to wal-index",
        "categories": [
          2,
          4,
          9
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "WAL_WRITE_LOCK exclusion required; concurrent mode must exclude legacy writers",
          "Hybrid protocol maintains standard wal-index and reader marks"
        ],
        "changed_headings": [
          "5.6.6 Compatibility",
          "5.6.7 Compatibility Mode Hybrid SHM"
        ]
      },
      {
        "summary": "Clarify gc_horizon derivation from published commit_seq high-water mark",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.36,
        "evidence": [
          "begin_seq derived from published commit_seq"
        ],
        "changed_headings": [
          "5.6.5 GC Horizon"
        ]
      }
    ]
  },
  {
    "commit": "23f575f7d4ee20399865e33abca1f93e60eda2d7",
    "change_groups": [
      {
        "summary": "Use Acquire load for snapshot commit_seq; constrain deterministic rebase scope and compatibility note",
        "categories": [
          1,
          4,
          9
        ],
        "primary_category": 1,
        "confidence": 0.7,
        "evidence": [
          "begin snapshot uses Acquire load",
          "Rebase restricted: no splits/overflow/freelist/multi-page ops"
        ],
        "changed_headings": [
          "5.2 begin()",
          "5.10 Deterministic Rebase"
        ]
      }
    ]
  },
  {
    "commit": "6228e273d3dce6ca67c97fd43afb9018d19c6f5f",
    "change_groups": [
      {
        "summary": "Reconcile shm.commit_seq to durable tip on open; add lock-table rebuild lease protocol and epoch_lock acquisition rules",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.73,
        "evidence": [
          "commit_seq initialization/reconciliation rules added",
          "Lock table rebuild lease + quiescence; epoch_lock acquisition details"
        ],
        "changed_headings": [
          "5.6.1 SharedMemoryLayout",
          "5.6.3 SharedPageLockTable",
          "5.6.4 Hot Witness Plane"
        ]
      },
      {
        "summary": "Add ARC patent note and clarify legacy writer exclusion reminder",
        "categories": [
          9,
          2
        ],
        "primary_category": 9,
        "confidence": 0.4,
        "evidence": [
          "ARC patent expired note",
          "Legacy writer exclusion restated"
        ],
        "changed_headings": [
          "6. ARC Cache",
          "7.11 Compatibility mode verifiability"
        ]
      }
    ]
  },
  {
    "commit": "2e3ea218a908f4a22791b4c8b30a0dbf746f867b",
    "change_groups": [
      {
        "summary": "Make SharedPageLockTable key-stable (no tombstones), adjust acquire/release and rebuild rationale",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.76,
        "evidence": [
          "page_number no longer tombstoned; release only clears owner_txn",
          "Acquire CAS failure re-reads same slot; rebuild to clear keys"
        ],
        "changed_headings": [
          "5.6.3 SharedPageLockTable",
          "5.6.3.1 Table Rebuild"
        ]
      },
      {
        "summary": "Define marker stream byte-exact encoding constants and marker_id domain separation",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.69,
        "evidence": [
          "Marker header/record sizes fixed (36/88 bytes)",
          "MarkerId uses domain-separated BLAKE3"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream"
        ]
      },
      {
        "summary": "Tighten compatibility-mode legacy writer exclusion and merge terminology",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "Legacy writer exclusion required whenever fsqlite-shm used",
          "Safe write merging terminology replaces algebraic merging"
        ],
        "changed_headings": [
          "5.6.6 Compatibility",
          "5.10 Safe Write Merging"
        ]
      }
    ]
  },
  {
    "commit": "d05de23ea89da924e86232c8da519b6b58b4a0d5",
    "change_groups": [
      {
        "summary": "Align lock-table rebuild prose with key-stability and load factor accounting",
        "categories": [
          9,
          1
        ],
        "primary_category": 9,
        "confidence": 0.57,
        "evidence": [
          "Rebuild rationale now for non-deleted keys; load factor counts page_number!=0"
        ],
        "changed_headings": [
          "5.6.3.1 Table Rebuild"
        ]
      },
      {
        "summary": "Add database header constraints (usable_size >= 480) and db-size validity condition",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.66,
        "evidence": [
          "usable_size constraint added; db size valid only when version-valid-for matches change counter"
        ],
        "changed_headings": [
          "11.1 Database Header"
        ]
      }
    ]
  },
  {
    "commit": "fa1830e4593854a492d78bec24da1db90351c2f0",
    "change_groups": [
      {
        "summary": "Clarify ECS permeation map distinction between marker stream and coded objects",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.52,
        "evidence": [
          "CommitMarkerRecord separated from coded CommitCapsule/Proof"
        ],
        "changed_headings": [
          "3.5.5 RootManifest / ECS map"
        ]
      },
      {
        "summary": "Correct fragment limit semantics and cell payload local byte wording",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.65,
        "evidence": [
          "Fragment limit is threshold before insertion; cell payload references local_bytes"
        ],
        "changed_headings": [
          "11.2 B-Tree Page Layout",
          "11.3 Cell Format"
        ]
      }
    ]
  },
  {
    "commit": "70436b5c2c04e42c0aaf4b776a8f779416abdeff",
    "change_groups": [
      {
        "summary": "Specify WAL-index SHM native byte order, iVersion constraint, and WalCkptInfo layout fix",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "SHM fields are native endian; iVersion must be 3007000; WalCkptInfo 40-byte block"
        ],
        "changed_headings": [
          "11.10 WAL Index (wal-index / SHM)"
        ]
      }
    ]
  },
  {
    "commit": "a4e773481bd417530fe83f33868ef6ce5656e933",
    "change_groups": [
      {
        "summary": "Add VFS shared-memory API methods and expand trait signatures (cursor ops, virtual tables)",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "VfsFile adds shm_map/shm_lock/shm_barrier/shm_unmap",
          "BtreeCursorOps methods take &Cx and add first/last; VirtualTable lifecycle methods added"
        ],
        "changed_headings": [
          "VFS Trait Definitions",
          "BtreeCursorOps",
          "VirtualTable"
        ]
      },
      {
        "summary": "Clarify CommitMarkerRecord marker_id domain-separated hash reference",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.38,
        "evidence": [
          "marker_id comment updated to refer to domain-separated definition"
        ],
        "changed_headings": [
          "3.5.4.1 Commit Marker Stream"
        ]
      }
    ]
  },
  {
    "commit": "09c095901ddb1e5db47f55ddf5c616b5d51bf74e",
    "change_groups": [
      {
        "summary": "Define CheckpointPageWriter trait for WAL checkpoint and add replication gate acceptance criteria",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.63,
        "evidence": [
          "CheckpointPageWriter trait added in pager; replication gate added in Phase 9"
        ],
        "changed_headings": [
          "9.1 Function Traits",
          "Phase 9 Gates"
        ]
      }
    ]
  },
  {
    "commit": "40a2ac7739778b30cb11129a782d8746bd13e6ed",
    "change_groups": [
      {
        "summary": "Bump document version footer to 1.18 with summary of prior fixes",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.86,
        "evidence": [
          "Footer version line updated"
        ],
        "changed_headings": [
          "Document footer"
        ]
      }
    ]
  },
  {
    "commit": "40c6c3d152cf7d86104ad9ca19fbb850d6fdf343",
    "change_groups": [
      {
        "summary": "Lock-table acquire must return BUSY on CAS race to avoid duplicate keys",
        "categories": [
          1
        ],
        "primary_category": 1,
        "confidence": 0.69,
        "evidence": [
          "CAS failure now returns SQLITE_BUSY and forbids continued probing"
        ],
        "changed_headings": [
          "5.6.3 SharedPageLockTable"
        ]
      }
    ]
  },
  {
    "commit": "8512e62aed8835864a8800ed895c91a8773dc996",
    "change_groups": [
      {
        "summary": "Move compatibility page-FEC repair symbols to sidecar; add UDP payload limits and MTU guidance",
        "categories": [
          2,
          4,
          9
        ],
        "primary_category": 2,
        "confidence": 0.7,
        "evidence": [
          "Compatibility DB file must not append repair region; use .db-fec sidecar",
          "UDP payload <= 65507 and MTU-safe symbol sizing guidance"
        ],
        "changed_headings": [
          "3.4 Replication Packet",
          "3.4.6 Erasure-Coded Page Storage",
          "Compatibility mode verifiability"
        ]
      },
      {
        "summary": "Adjust WAL framing note, checkpoint chunk sizes, and recovery wording",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.46,
        "evidence": [
          "WAL frames are tightly packed; not sector-aligned",
          "Checkpoint chunk size guidance changed; Native mode recovery path tweak"
        ],
        "changed_headings": [
          "7. WAL Durability",
          "3.5 ECS tuning",
          "7.12 Recovery"
        ]
      },
      {
        "summary": "Clarify cross-process MVCC phase gates and compat sidecars",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.38,
        "evidence": [
          "Phase 6 covers cross-process MVCC; .db-fec referenced"
        ],
        "changed_headings": [
          "Phase gates",
          "Implementation notes"
        ]
      }
    ]
  },
  {
    "commit": "e31897fd92088e5305735d080e224a23b7315a11",
    "change_groups": [
      {
        "summary": "Clarify MTU-aware checkpoint chunk sizing rationale",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.58,
        "evidence": [
          "CheckpointChunk sizing note updated to prefer <=1366 on UDP"
        ],
        "changed_headings": [
          "3.5 ECS tuning"
        ]
      }
    ]
  },
  {
    "commit": "b03db7bc0b8a2705fe6fda19f5f149452755284c",
    "change_groups": [
      {
        "summary": "Fix SQL coverage details: join types, LIMIT comma order, MATCH semantics, DROP COLUMN behavior, json(X) error behavior",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.76,
        "evidence": [
          "JOIN types are nested-loop; LIMIT offset,count; MATCH not enforced; DROP COLUMN rewrite/failure conditions",
          "json(X) throws error on invalid JSON"
        ],
        "changed_headings": [
          "12. SQL Coverage",
          "12.1 SELECT",
          "12.2 INSERT",
          "12.8 ALTER TABLE",
          "14.1 JSON1 Functions"
        ]
      },
      {
        "summary": "Replace hash-join mention in vectorized VDBE section",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.44,
        "evidence": [
          "Vectorized VDBE applies to nested-loop joins"
        ],
        "changed_headings": [
          "21.7 Vectorized VDBE"
        ]
      }
    ]
  },
  {
    "commit": "dd190e4f7f24aa2a8b7bb1bbc7020aead6d014c0",
    "change_groups": [
      {
        "summary": "Correct GF(256) worked example and add MMR/IBLT replication enhancements",
        "categories": [
          1,
          8,
          6
        ],
        "primary_category": 1,
        "confidence": 0.72,
        "evidence": [
          "GF(256) log/exp values corrected",
          "MMR inclusion/prefix proofs added; IBLT anti-entropy described"
        ],
        "changed_headings": [
          "3.2 GF(256) Worked Example",
          "3.5.4 Marker Stream (MMR)",
          "3.5.6 Replication"
        ]
      },
      {
        "summary": "Rename WAL checksum variable names to hdr_cksum1/2 in chain description",
        "categories": [
          9,
          1
        ],
        "primary_category": 1,
        "confidence": 0.46,
        "evidence": [
          "hdr_s0/hdr_s1 renamed to hdr_cksum1/2"
        ],
        "changed_headings": [
          "7.1 WAL Checksum Chain",
          "11.9.1 WAL Checksum Chain"
        ]
      },
      {
        "summary": "Add policy controller and mixture e-process guidance; expand IntentFootprint and merge certificates",
        "categories": [
          8,
          4,
          6
        ],
        "primary_category": 8,
        "confidence": 0.66,
        "evidence": [
          "PolicyController section with expected loss and BOCPD guardrails",
          "Mixture e-processes described; IntentFootprint, commutativity rules, MergeCertificate schema added"
        ],
        "changed_headings": [
          "4.3 E-processes",
          "4.17 Policy Controller",
          "5.10 Write Merge System"
        ]
      }
    ]
  },
  {
    "commit": "a664265e3f5876177b7c1410dad7119e01e7f9e9",
    "change_groups": [
      {
        "summary": "Add policy controller, epochs, remote capability/idempotency/saga requirements, and symbol log format",
        "categories": [
          4,
          8,
          6
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "Symbol log segment format with epoch_id; RootManifest ecs_epoch added",
          "RemoteCap, idempotency, saga requirements for remote ops",
          "PolicyController section with expected loss and guardrails"
        ],
        "changed_headings": [
          "3.5.4.2 Symbol Record Logs",
          "3.5.5 RootManifest",
          "4.17 Policy Controller",
          "4.18 Epochs",
          "4.19 Remote Effects"
        ]
      },
      {
        "summary": "Revise hot witness plane to double-buffered epochs; add epoch-advance rules and candidate discovery over two epochs",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.69,
        "evidence": [
          "HotWitnessBucketEntry now has epoch_a/epoch_b buffers",
          "Candidate discovery unions both epochs; epoch advancement rule updated"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane",
          "5.7 SSI"
        ]
      },
      {
        "summary": "ARC eviction safety valve and flush_dirty_page naming; compaction saga requirement",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.58,
        "evidence": [
          "Case IV eviction adds safety valve and flush_dirty_page name",
          "Compaction must be a Saga"
        ],
        "changed_headings": [
          "6. ARC Cache",
          "7.9 Compaction"
        ]
      }
    ]
  },
  {
    "commit": "599cafb3f29c52dd2a44f27d5632032c54a34a25",
    "change_groups": [
      {
        "summary": "Clarify SQLite 3.52.0 forward target and unsafe prefetch requirement; add symbol auth guidance and epoch helper semantics",
        "categories": [
          9,
          4
        ],
        "primary_category": 9,
        "confidence": 0.57,
        "evidence": [
          "3.52.0 noted as forward target; prefetch must use helper crate due to unsafe_code forbid",
          "Symbol auth guidance refined"
        ],
        "changed_headings": [
          "1.1 What It Is",
          "1.4 Constraints",
          "3.5.2 Symbol Auth"
        ]
      },
      {
        "summary": "Add helper views for witness epoch buffers and refine epoch-advance conditions; planner NGQP note updated",
        "categories": [
          9,
          4
        ],
        "primary_category": 4,
        "confidence": 0.55,
        "evidence": [
          "readers_for_epoch/writers_for_epoch helpers defined",
          "Epoch advancement criteria specified in terms of txn states",
          "NGQP described as N3 bounded algorithm"
        ],
        "changed_headings": [
          "5.6.4 Hot Witness Plane",
          "10.5 Query Planning"
        ]
      }
    ]
  },
  {
    "commit": "e42a43de57ff5d4ee616cd2ec3b54a0db249a3e6",
    "change_groups": [
      {
        "summary": "Define symbol auth master key derivation and adjust VdbeOp p5 usage note",
        "categories": [
          4,
          2,
          9
        ],
        "primary_category": 4,
        "confidence": 0.64,
        "evidence": [
          "master_key derived from DEK with domain separation or lab seed",
          "P5 note updated to allow full 16 bits per opcode"
        ],
        "changed_headings": [
          "4.18 Epoch-Scoped Symbol Auth",
          "10.7 VDBE Instruction Format"
        ]
      }
    ]
  },
  {
    "commit": "f158b44a5bd96ef34b378b58f61399568424f6d4",
    "change_groups": [
      {
        "summary": "Clarify symbol auth wording and refine planner cost model with ANALYZE note",
        "categories": [
          9,
          2
        ],
        "primary_category": 2,
        "confidence": 0.6,
        "evidence": [
          "Symbol auth description adjusted to emphasize auth_tag",
          "Cost model formulas updated; ANALYZE note added"
        ],
        "changed_headings": [
          "3.5 ECS",
          "10.5 Query Planning"
        ]
      }
    ]
  },
  {
    "commit": "3cf0f13571c101725f9ef34ce2476c90478ff07d",
    "change_groups": [
      {
        "summary": "Fix RaptorQ MTU and sub-blocking explanation; adjust symbol auth key derivation requirements",
        "categories": [
          1,
          3,
          9
        ],
        "primary_category": 1,
        "confidence": 0.72,
        "evidence": [
          "MTU-safe T corrected to 1464; sub-symbol calculation fixed",
          "Symbol auth key derivation clarified with explicit master key capability"
        ],
        "changed_headings": [
          "3.4 Replication Packet",
          "4.18 Symbol Auth"
        ]
      }
    ]
  },
  {
    "commit": "0cb22962ec87cb29a29a44acfc5ec14588aadb23",
    "change_groups": [
      {
        "summary": "Add lock references, row-value expression, and VDBE opcode examples; clarify blocking pool defaults",
        "categories": [
          7,
          9
        ],
        "primary_category": 7,
        "confidence": 0.62,
        "evidence": [
          "RowValue Expr added; UPDATE/DELETE VDBE examples added",
          "WAL_WRITE_LOCK reference updated; blocking pool defaults clarified"
        ],
        "changed_headings": [
          "10.7 VDBE Instruction Format",
          "10.6 Code Generation",
          "1.2 Innovations",
          "4.2 Blocking Pool"
        ]
      },
      {
        "summary": "Add ObjectId collision bound note; refine invariants monitor; several clarifications about WAL snapshot conflicts and risk sections",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.5,
        "evidence": [
          "ObjectId 128-bit truncation noted as ~2^64 birthday bound",
          "observe_lock_exclusivity now cross-checks lock table vs txn locks"
        ],
        "changed_headings": [
          "Glossary",
          "4.3 Invariant Monitoring",
          "7.4 Page Integrity"
        ]
      }
    ]
  },
  {
    "commit": "1680d6931f5773673fae021b7cc646e3f3faab44",
    "change_groups": [
      {
        "summary": "Fix e-process aggregation to arithmetic mean and correct INV-1 violation detection comment",
        "categories": [
          1,
          8
        ],
        "primary_category": 1,
        "confidence": 0.74,
        "evidence": [
          "E_global aggregation changed to sum of weighted e-values",
          "INV-1 comment corrected to ~20 violations for threshold"
        ],
        "changed_headings": [
          "4.3 E-processes"
        ]
      },
      {
        "summary": "Minor clarifications: WAL snapshot conflict phrasing, opcode traces illustrative, sqliteInt.h size corrected",
        "categories": [
          9
        ],
        "primary_category": 9,
        "confidence": 0.45,
        "evidence": [
          "WAL snapshot conflict clarified; opcode traces labeled illustrative; sqliteInt.h size corrected"
        ],
        "changed_headings": [
          "1.2 Innovations",
          "10.6 Code Generation",
          "21. Reference Files"
        ]
      }
    ]
  },
  {
    "commit": "1e2aae9940969190c6b9bebe94c94749eee91626",
    "change_groups": [
      {
        "summary": "Introduce UpdateExpression and RebaseExpr to enable deterministic rebase of read-modify-write; refine rebase safety and commutativity rules",
        "categories": [
          4,
          1,
          8
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "UpdateExpression intent added with RebaseExpr AST",
          "Rebase safety distinguishes blocking reads vs expression reads; VDBE rules added",
          "Commutativity refined for column-disjoint UpdateExpression ops"
        ],
        "changed_headings": [
          "5.10 Deterministic Rebase",
          "5.10.1 Intent Logs",
          "5.10.7 Intent Footprints"
        ]
      },
      {
        "summary": "Require legacy WAL reader locks when updating read marks; cross-db atomic WAL transactions requirement",
        "categories": [
          2,
          4
        ],
        "primary_category": 2,
        "confidence": 0.64,
        "evidence": [
          "Readers must hold WAL_READ_LOCK when writing aReadMark",
          "Cross-database atomic WAL transactions required via 2PC"
        ],
        "changed_headings": [
          "5.6.7 Compatibility Mode Hybrid SHM",
          "12.11 ATTACH"
        ]
      }
    ]
  }
];
      const CLASS_LATE = [
  {
    "commit": "da22f479dc2f8d1e98294750b741b3cce168fd19",
    "change_groups": [
      {
        "summary": "Move WAL-FEC generation fully off the commit critical path; distinguish design-time p_design from runtime living corruption-rate monitoring.",
        "categories": [
          7,
          8,
          4
        ],
        "primary_category": 7,
        "confidence": 0.82,
        "evidence": [
          "Enqueue a background FEC job ... encoder reads source frames from .wal",
          "p_design = 10^-4; autopilot maintains living estimates + conservative bounds"
        ],
        "changed_headings": [
          "3.4.1 WAL-FEC",
          "3.5.12 Durability Autopilot"
        ]
      },
      {
        "summary": "Add rigorous durability policy math: Bayesian posterior for p (diagnostics) plus anytime-valid p_upper for guarantees; VOI-based monitoring budgeting.",
        "categories": [
          8,
          7
        ],
        "primary_category": 8,
        "confidence": 0.8,
        "evidence": [
          "p | data ~ Beta(\u03b10 + n_bad, \u03b20 + n_ok)",
          "derive p_upper via martingale inversion (anytime-valid under optional stopping)",
          "VOI(m) = E[\u0394Loss(m) | evidence] - Cost(m)"
        ],
        "changed_headings": [
          "3.5.12.2.1 Living Corruption-Rate Estimates",
          "4.16 Observability"
        ]
      },
      {
        "summary": "Reframe background compaction + retry as explicit decision policies: MDP compaction scheduling, online Zipf/s estimation, and optimal-stopping retry control; add interop notes (WAL-index locks, sqliteInt.h line count).",
        "categories": [
          8,
          7,
          2,
          4,
          5
        ],
        "primary_category": 8,
        "confidence": 0.72,
        "evidence": [
          "Model compaction scheduling as a finite-state MDP",
          "retry as expected-loss minimization; mentions Gittins-index threshold rule",
          "WAL-index lock slot mapping: aLock[0]=WAL_WRITE_LOCK ..."
        ],
        "changed_headings": [
          "7.13.1 Workload-Adaptive Compaction Policy",
          "18.4.1 Estimating Zipf s Online",
          "11.10 WAL-index"
        ]
      }
    ]
  },
  {
    "commit": "c25f0d00238fc36f355f818f571abc3d4a1198df",
    "change_groups": [
      {
        "summary": "Make UpdateExpression deterministic rebase correct: regenerate secondary-index ops from schema/row images during replay; forbid rebase for rowid/INTEGER PRIMARY KEY updates; refine commutativity check.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "Index regeneration (critical): stale IndexDelete/IndexInsert MUST be discarded",
          "No SET clause targets rowid/INTEGER PRIMARY KEY column"
        ],
        "changed_headings": [
          "5.10 Safe Write Merging",
          "UpdateExpression"
        ]
      }
    ]
  },
  {
    "commit": "02e48a41810bdb2ad471926d9728a9a9af12b155",
    "change_groups": [
      {
        "summary": "Correct the maxLocal integer-division example by showing truncation and remainder explicitly.",
        "categories": [
          1,
          5
        ],
        "primary_category": 1,
        "confidence": 0.76,
        "evidence": [
          "261376 / 255 = 1025 (truncated; remainder 1)"
        ],
        "changed_headings": [
          "B-tree local payload"
        ]
      },
      {
        "summary": "Add encryption deliverables/acceptance criteria and risk/complexity gates to the implementation phases.",
        "categories": [
          6,
          7
        ],
        "primary_category": 6,
        "confidence": 0.7,
        "evidence": [
          "Page-level encryption: XChaCha20-Poly1305 with envelope DEK/KEK",
          "Encryption acceptance: PRAGMA key/rekey + AAD swap resistance"
        ],
        "changed_headings": [
          "Implementation Plan"
        ]
      }
    ]
  },
  {
    "commit": "bcd893da081fd15b1614a05c4d8b593f55cf7011",
    "change_groups": [
      {
        "summary": "Split BtreeCursorOps into table/index-specific methods to mirror SQLite's dual B-tree APIs (table vs index move/insert semantics).",
        "categories": [
          4,
          2
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "sqlite3BtreeTableMoveTo(i64) vs sqlite3BtreeIndexMoveto(UnpackedRecord*)",
          "Replace key()/data() with payload()"
        ],
        "changed_headings": [
          "Trait Hierarchy",
          "BtreeCursorOps"
        ]
      },
      {
        "summary": "Make SHM mapping spec memory-safe: change shm_map return type to a safe ShmRegion wrapper; update unsafe-code policy boundary for VFS.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "fn shm_map(...) -> Result<ShmRegion>",
          "ShmRegion wraps mmap'd shared memory behind bounds-checked APIs"
        ],
        "changed_headings": [
          "VFS",
          "Shared Memory"
        ]
      },
      {
        "summary": "Fix release profile optimization level inconsistency (size-opt to throughput-opt) and add a release-perf profile description.",
        "categories": [
          7,
          5
        ],
        "primary_category": 7,
        "confidence": 0.74,
        "evidence": [
          "opt-level = 3  # Full optimization (database engine needs throughput)"
        ],
        "changed_headings": [
          "Release Profile"
        ]
      }
    ]
  },
  {
    "commit": "6da51572d2b5b76eb9a37ffa99da76bfb850cd83",
    "change_groups": [
      {
        "summary": "Fix TxnSlot struct sizing math so shared-memory slot stride is exactly 128 bytes.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.83,
        "evidence": [
          "_padding was 52 -> 132B total; corrected to 128B stride"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot"
        ]
      },
      {
        "summary": "Tighten group-commit and request semantics: use TxnSlot.mode via request.txn, clarify durability point for batched capsules, and fix term usage (K_source + R).",
        "categories": [
          4,
          7,
          5
        ],
        "primary_category": 4,
        "confidence": 0.72,
        "evidence": [
          "PublishRequest has no mode field; derive mode via request.txn -> TxnSlot.mode",
          "Coordinator FSYNC_1 is the durability point for batched capsule symbols"
        ],
        "changed_headings": [
          "7.11 Group Commit"
        ]
      }
    ]
  },
  {
    "commit": "22e75e65b831adda852df3a11628e793aaa9e7a9",
    "change_groups": [
      {
        "summary": "Add RecentlyCommittedReadersIndex to preserve committed readers' SSI read evidence so incoming rw-edges aren\"t lost when TxnSlots are freed; enforce T3 rule for committed pivots.",
        "categories": [
          4,
          1,
          6,
          7
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "RecentlyCommittedReadersIndex retains committed transactions' read witness summary",
          "If entry.has_in_rw is true, committer MUST abort (T3 rule for committed pivots)"
        ],
        "changed_headings": [
          "5.6.2.1 Recently Committed Readers"
        ]
      }
    ]
  },
  {
    "commit": "2f0970b9a5d8fc755269ba848169f5a1369ec6a6",
    "change_groups": [
      {
        "summary": "Fix lexer/identifier semantics: double-quoted strings are TK_ID; DQS reinterpretation happens in name resolution, not tokenization.",
        "categories": [
          2,
          5
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "SQLite tokenize.c emits TK_ID for \"...\"; resolve.c reinterprets"
        ],
        "changed_headings": [
          "Lexer",
          "QuotedId"
        ]
      },
      {
        "summary": "Correct planner range-scan cost model by adding index-leaf scanning term; avoids preferring long-range index scans incorrectly.",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.86,
        "evidence": [
          "cost = log2(N_idx_pages) + sel*N_idx_pages + sel*N_tbl_pages"
        ],
        "changed_headings": [
          "Planner Cost Model"
        ]
      },
      {
        "summary": "Fix UPDATE VDBE trace example: MakeRecord must encode all columns (overlay updated column on full-row image).",
        "categories": [
          2,
          6
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "Overlay updated column, then MakeRecord(all columns)"
        ],
        "changed_headings": [
          "VDBE",
          "UPDATE"
        ]
      }
    ]
  },
  {
    "commit": "5cc32a6bc813ff59db231f29db5b95a13ea94704",
    "change_groups": [
      {
        "summary": "Specify required asupersync networking + deterministic VirtualTcp testing and map FrankenSQLite work onto scheduler priority lanes (cancel/timed/ready) for tail-latency control.",
        "categories": [
          3,
          7,
          6
        ],
        "primary_category": 3,
        "confidence": 0.82,
        "evidence": [
          "MUST use asupersync cancel-safe network stack; lab transport swappable to VirtualTcp",
          "Scheduler lanes: Cancel (highest), Timed (EDF), Ready (background)"
        ],
        "changed_headings": [
          "4.19.6 Networking Stack",
          "4.20 Scheduler Priority Lanes"
        ]
      }
    ]
  },
  {
    "commit": "dc92e549d05ac8dc0c23937d6e6dfa874729fdd4",
    "change_groups": [
      {
        "summary": "Correct MVCC version-chain compression: use sparse XOR deltas between adjacent versions (compression), not RaptorQ repair symbols; RaptorQ remains the durability layer for delta objects.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "V2 delta: XOR(V2,V3)",
          "RaptorQ applies at ECS object level for durability"
        ],
        "changed_headings": [
          "Version Chains",
          "Compression"
        ]
      }
    ]
  },
  {
    "commit": "2433562451b188c9233f6fd83a9ef7573ce48f97",
    "change_groups": [
      {
        "summary": "Add independent per-source hashes to WAL-FEC metadata so recovery can validate surviving source frames after the WAL checksum chain breaks.",
        "categories": [
          7,
          2,
          4
        ],
        "primary_category": 7,
        "confidence": 0.86,
        "evidence": [
          "WalFecGroupMeta.source_page_xxh3: Vec<u64> (length=K)",
          "frames at/after checksum mismatch validate via .wal-fec hashes"
        ],
        "changed_headings": [
          "3.4.1 WAL-FEC"
        ]
      }
    ]
  },
  {
    "commit": "82dfd4bf99283e5ab283073651787b3c7975561f",
    "change_groups": [
      {
        "summary": "Clarify cumulative WAL checksums: after first mismatch, frames i+1.. aren\"t WAL-validated; require random-access validation via WAL-FEC and attempt repair-before-truncate.",
        "categories": [
          2,
          7,
          4
        ],
        "primary_category": 2,
        "confidence": 0.86,
        "evidence": [
          "Because checksum is cumulative, WAL format alone cannot validate frames i+1..",
          "Attempt repair first if matching .wal-fec group exists"
        ],
        "changed_headings": [
          "7.5 WAL Checksums",
          "7.8 Error Recovery"
        ]
      },
      {
        "summary": "Correct SQLite header semantics: file change counter is updated when header page is written (not forced on every WAL commit).",
        "categories": [
          2,
          9
        ],
        "primary_category": 2,
        "confidence": 0.78,
        "evidence": [
          "In WAL mode, file change counter is NOT forced on every commit"
        ],
        "changed_headings": [
          "11.1 Database Header"
        ]
      }
    ]
  },
  {
    "commit": "ab20d7fac6f83ac527475927aa53b204c11ed7c8",
    "change_groups": [
      {
        "summary": "Prevent lock-table rebuild deadlocks: transactions holding page locks must not busy-wait on rebuild-busy; abort/retry to reach lock quiescence.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "MUST NOT spin on SQLITE_BUSY while holding page locks; abort/retry"
        ],
        "changed_headings": [
          "PageLockTable Rebuild"
        ]
      },
      {
        "summary": "Add research note: view ARC p-update as online learning (OCO-style) while keeping canonical ARC update rules normative.",
        "categories": [
          8,
          7,
          6
        ],
        "primary_category": 8,
        "confidence": 0.64,
        "evidence": [
          "p_{t+1} = clamp(p_t + \u03b7_t * s_t, 0, capacity)"
        ],
        "changed_headings": [
          "6.4.1 Optional: p-Update as Online Learning"
        ]
      }
    ]
  },
  {
    "commit": "96f32f3174453e68960d849672cb4b7a8d33d1c7",
    "change_groups": [
      {
        "summary": "Harden UpdateExpression replay: enforce NOT NULL/CHECK semantics at replay time; restrict V1 to no foreign keys and rebase-safe CHECK constraints.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "Constraint checks (normative): NOT NULL + CHECK enforced during replay",
          "Foreign keys (V1 restriction): fall back to materialized Update"
        ],
        "changed_headings": [
          "UpdateExpression"
        ]
      }
    ]
  },
  {
    "commit": "f37158f2468145272817fd65794d78be539be19b",
    "change_groups": [
      {
        "summary": "Add explicit WAL-FEC invariants tying group metadata to WAL frame geometry and commit db_size.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.75,
        "evidence": [
          "k_source == end_frame_no - start_frame_no + 1"
        ],
        "changed_headings": [
          "WalFecGroupMeta"
        ]
      },
      {
        "summary": "Fix UpdateExpression rebase step numbering after inserting constraint-check step.",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.9,
        "evidence": [
          "Index regeneration step renumbered (6 -> 7)"
        ],
        "changed_headings": [
          "UpdateExpression"
        ]
      }
    ]
  },
  {
    "commit": "19fa01f6d66c19892c634a02da44f7f536b29e43",
    "change_groups": [
      {
        "summary": "Update built-in function coverage to match SQLite 3.52 target: add missing strftime specifiers and document ORDER BY inside group_concat/string_agg aggregates.",
        "categories": [
          2,
          6
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "strftime adds: %e %k %I %l %p %P %R %T %u %G %g %V",
          "group_concat(name, ', ' ORDER BY name)"
        ],
        "changed_headings": [
          "Built-in Functions"
        ]
      }
    ]
  },
  {
    "commit": "a3e7ae521e6a0dcb3cf9489ac5a67b0f62aad526",
    "change_groups": [
      {
        "summary": "Clarify Compatibility-mode I/O constraints: WAL frames are 24+page_size and break sector alignment, so O_DIRECT must not be required for .wal.",
        "categories": [
          2,
          7,
          9
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "SQLite .wal frames are 24+page_size; MUST NOT require O_DIRECT for .wal"
        ],
        "changed_headings": [
          "Mechanical Sympathy"
        ]
      },
      {
        "summary": "Tighten safety boundary: prefetch and VFS platform ops must use safe abstractions (or move behind external dependency boundary), not unsafe inside workspace crates.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.76,
        "evidence": [
          "Workspace members forbid unsafe; VFS MUST rely on safe SHM/locking APIs"
        ],
        "changed_headings": [
          "Unsafe Policy",
          "VFS"
        ]
      },
      {
        "summary": "Correct FTS5 query semantics: NOT is strictly a binary operator; unary NOT is a syntax error in FTS5 (unlike FTS3/4).",
        "categories": [
          2
        ],
        "primary_category": 2,
        "confidence": 0.86,
        "evidence": [
          "FTS5 NOT: expr NOT expr (binary only); unary NOT not in fts5parse.y"
        ],
        "changed_headings": [
          "FTS5"
        ]
      }
    ]
  },
  {
    "commit": "56a4e91425fa5cba9aecf08f786691ef03563750",
    "change_groups": [
      {
        "summary": "Define replication changeset_bytes encoding as a self-delimiting header + sorted PageEntry records with per-page xxh3; receivers validate hashes before applying.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "ChangesetHeader.total_len (u64) before padding",
          "PageEntry: page_number + page_xxh3 + page_bytes"
        ],
        "changed_headings": [
          "Replication"
        ]
      }
    ]
  },
  {
    "commit": "d2a49862864dff9799e236d2cf81b51ed268f93f",
    "change_groups": [
      {
        "summary": "Harden crash cleanup and SQLite WAL-index interop: reclaim stuck CLEANING slots; enforce WAL_READ_LOCK discipline (exclusive update then shared hold) and state the 5-reader mark limitation explicitly.",
        "categories": [
          4,
          2,
          7
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "Reclaim stuck TXN_ID_CLEANING after timeout",
          "Acquire WAL_READ_LOCK(i) EXCLUSIVE to write aReadMark, then downgrade to SHARED",
          "Legacy WAL-index has only 5 reader marks/locks"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "Hybrid SHM Interop"
        ]
      },
      {
        "summary": "Fix ARC replacement liveness: track rotations per list so a pinned preferred list can\"t spin forever; add explicit fall-through path.",
        "categories": [
          1,
          7,
          4
        ],
        "primary_category": 1,
        "confidence": 0.8,
        "evidence": [
          "if rotations_t1 >= |T1| AND rotations_t2 >= |T2|: safety valve triggers"
        ],
        "changed_headings": [
          "ARC Cache"
        ]
      },
      {
        "summary": "Add deterministic safety directives: triggers must be non-recursive in Rust (explicit frame stack); correct conformal baseline sample size math under Bonferroni across M metrics.",
        "categories": [
          8,
          7,
          4
        ],
        "primary_category": 8,
        "confidence": 0.76,
        "evidence": [
          "Trigger execution MUST NOT use Rust call-stack recursion",
          "N_base >= ceil(M/alpha_total) to satisfy split conformal per-metric alpha"
        ],
        "changed_headings": [
          "Triggers",
          "Conformal No-Regression"
        ]
      }
    ]
  },
  {
    "commit": "859e81752809cd343b00ad6499c159d2f341cc46",
    "change_groups": [
      {
        "summary": "Ensure cleanup fully resets TxnSlot to a Free/Serialized state (not Aborted) when reclaiming or freeing slots.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "slot.state = Free; slot.mode = Serialized during cleanup"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot"
        ]
      }
    ]
  },
  {
    "commit": "be3d256b12679a32f2fb4e44eeb82e513607b284",
    "change_groups": [
      {
        "summary": "Specify Compatibility-mode .db-fec as a checkpoint-owned sidecar: only checkpointer mutates .db/.db-fec; enforce WAL truncation ordering; add independent per-source validation and repair writeback discipline.",
        "categories": [
          7,
          4,
          2,
          6
        ],
        "primary_category": 7,
        "confidence": 0.84,
        "evidence": [
          "V1 rule: .db-fec maintained ONLY by checkpoint subsystem",
          "WAL truncation safety: RESTART/TRUNCATE only after .db-fec updated+fsync'd",
          "DbFecGroupMeta.source_page_xxh3_128 for random-access validation"
        ],
        "changed_headings": [
          "3.4.6 .db-fec",
          "Read Path with On-the-Fly Repair"
        ]
      }
    ]
  },
  {
    "commit": "65ab2f709f724750878f2cb5d045649bf0c53e89",
    "change_groups": [
      {
        "summary": "Add out-of-the-box, bounded auto-tuning knobs and derived defaults to prevent self-DoS on many-core CPUs (bg_cpu_max, remote_max_in_flight, commit_encode_max; profile-based scaling).",
        "categories": [
          7,
          6
        ],
        "primary_category": 7,
        "confidence": 0.83,
        "evidence": [
          "PRAGMA fsqlite.auto_tune=ON (default) + PRAGMA fsqlite.profile",
          "Defaults scale sublinearly: bg_cpu_max_default = clamp(P/8,1,16)"
        ],
        "changed_headings": [
          "4.17.1 Out-of-the-Box Auto-Tuning"
        ]
      }
    ]
  },
  {
    "commit": "63ee097eb68a72ac23effab3979978adafb5b411",
    "change_groups": [
      {
        "summary": "Clarify SERIALIZABLE phantom protection: predicate/range reads must register leaf-page witnesses that intersect any phantom-producing writes.",
        "categories": [
          4,
          2,
          6
        ],
        "primary_category": 4,
        "confidence": 0.74,
        "evidence": [
          "Predicate reads MUST register witnesses (e.g., WitnessKey::Page(leaf_pgno))"
        ],
        "changed_headings": [
          "Witness Plane"
        ]
      },
      {
        "summary": "Warn against common SQLite WAL checksum mis-transcriptions that would break binary interoperability.",
        "categories": [
          2,
          1
        ],
        "primary_category": 2,
        "confidence": 0.74,
        "evidence": [
          "walChecksumBytes: s1 += a + s2; s2 += b + s1 (no avalanche)"
        ],
        "changed_headings": [
          "WAL Checksums"
        ]
      }
    ]
  },
  {
    "commit": "29f7ebe942a43891f2a55fd998d02c37411efc9f",
    "change_groups": [
      {
        "summary": "Place deterministic rebase outside the sequencer: committing txn must rebase before entering serialized commit section; coordinator validates certificates but must not execute B-tree/expression logic.",
        "categories": [
          4,
          7
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "Deterministic rebase MUST run before entering WriteCoordinator serialized section",
          "coordinator MUST NOT perform B-tree traversal or index-key regeneration"
        ],
        "changed_headings": [
          "5.10 Safe Write Merging"
        ]
      },
      {
        "summary": "Harden UpdateExpression index regeneration: handle partial/expression indexes, participation predicates, and enforce UNIQUE constraints during replay.",
        "categories": [
          4,
          2,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "Partial indexes: evaluate WHERE predicate; base/updated participation drives delete/insert"
        ],
        "changed_headings": [
          "UpdateExpression"
        ]
      },
      {
        "summary": "Replace Zipf-only policy input with model-free write-set skew estimation: define collision mass M2 / effective pool P_eff, add second-moment estimators and keep Zipf s_hat interpretability-only.",
        "categories": [
          8,
          7,
          9
        ],
        "primary_category": 8,
        "confidence": 0.8,
        "evidence": [
          "Collision mass M2 := \u03a3 q(pgno)^2; P_eff := 1/M2",
          "Zipf is interpretability-only; policy should prefer M2_hat/P_eff_hat"
        ],
        "changed_headings": [
          "18.4.1 Estimating Write-Set Skew Online"
        ]
      }
    ]
  },
  {
    "commit": "6b0c12fc40c5759f5d53028ba692e8aaff80fc92",
    "change_groups": [
      {
        "summary": "Correct planner join-ordering description: SQLite NGQP uses beam search (mxChoice), not an exhaustive search threshold; update the corresponding phase write-up.",
        "categories": [
          2,
          1,
          4
        ],
        "primary_category": 2,
        "confidence": 0.82,
        "evidence": [
          "wherePathSolver uses beam search; mxChoice=12/18 for 3+ tables"
        ],
        "changed_headings": [
          "Planner"
        ]
      }
    ]
  },
  {
    "commit": "b181b6d148e02862b195824020954abadae8de88",
    "change_groups": [
      {
        "summary": "Fix a second instance of the join-ordering error: beam search for all 3+ table joins, no exhaustive join enumeration path.",
        "categories": [
          2,
          1,
          5
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "No greedy/exhaustive split; beam search modeled on SQLite NGQP"
        ],
        "changed_headings": [
          "Planner"
        ]
      }
    ]
  },
  {
    "commit": "d302b391af5c2932c9097dd85923a8535593e45e",
    "change_groups": [
      {
        "summary": "Add a witness hot-index sizing manifest driven by skew: introduce deterministic second-moment (AMS F2) sketch and heavy-hitter decomposition for explainability; use M2_shard to derive S_eff under skew.",
        "categories": [
          8,
          7,
          4,
          6
        ],
        "primary_category": 8,
        "confidence": 0.82,
        "evidence": [
          "M2_shard := \u03a3 q(shard)^2; S_eff := 1/M2_shard",
          "AMS F2 sketch (normative default)"
        ],
        "changed_headings": [
          "18.4.1.3 Estimator A",
          "HotWitnessIndex"
        ]
      }
    ]
  },
  {
    "commit": "017745631c79f0c9061e4fdba8d0ce09ecc6c86d",
    "change_groups": [
      {
        "summary": "Clarify skew section naming (write-set skew, not page access) and make commit-ledger requirements explicit when contention telemetry influences commit/abort and policy actions.",
        "categories": [
          9,
          8,
          6
        ],
        "primary_category": 9,
        "confidence": 0.72,
        "evidence": [
          "Ledger must include regime_id, writers_active, M2_hat/P_eff_hat, expected losses"
        ],
        "changed_headings": [
          "18.4 Non-Uniform Write-Set Skew",
          "Evidence Ledger"
        ]
      }
    ]
  },
  {
    "commit": "5dae90d79aef7d70300fe53a17f9e40dba24b309",
    "change_groups": [
      {
        "summary": "Tighten Zipf s_hat guidance: require deterministic windowing under LabRuntime and prohibit using s_hat as a direct policy input when M2_hat is available.",
        "categories": [
          9,
          7,
          8
        ],
        "primary_category": 9,
        "confidence": 0.72,
        "evidence": [
          "s_hat MUST NOT be used as direct policy input when M2_hat is available"
        ],
        "changed_headings": [
          "Zipf s_hat"
        ]
      }
    ]
  },
  {
    "commit": "ca60e008352585f2501ca3f81337849396b4d140",
    "change_groups": [
      {
        "summary": "Define Compatibility .db-fec physical layout for O(1) seek and specify crash-consistent group updates (meta-as-commit-record discipline).",
        "categories": [
          7,
          4,
          6
        ],
        "primary_category": 7,
        "confidence": 0.82,
        "evidence": [
          "segment_off = sizeof(DbFecHeader) + SEG1_LEN + g*SEGG_LEN",
          "Write SymbolRecords first, DbFecGroupMeta last"
        ],
        "changed_headings": [
          ".db-fec physical layout"
        ]
      }
    ]
  },
  {
    "commit": "30203fb1f91acfb45c6085432a66029896e26e66",
    "change_groups": [
      {
        "summary": "Reserve TxnId sentinel values for shared-memory protocol and guard TxnId allocation from ever producing them (fail fast on overflow).",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "TxnId allocation MUST never produce u64::MAX/u64::MAX-1 sentinels"
        ],
        "changed_headings": [
          "TxnId",
          "TxnSlot"
        ]
      }
    ]
  },
  {
    "commit": "75ac25db5853747e3f56877c943d51ce8d649a5e",
    "change_groups": [
      {
        "summary": "Clarify replication identifier semantics: rename changeset_object_id to ChangesetId, validate K_source and symbol_size consistency, and truncate decoded bytes using total_len.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "ChangesetId is NOT ECS ObjectId; parse ChangesetHeader.total_len to drop padding"
        ],
        "changed_headings": [
          "Replication"
        ]
      },
      {
        "summary": "Harden TxnId allocation and witness semantics: forbid fetch_add wrap; use CAS loop to avoid publishing illegal TxnIds; tighten predicate-witness registration to include initial seek inspection.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "fetch_add forbidden; CAS loop prevents wrap into TxnId=0",
          "Register leaf-page witnesses during initial Seek*/MoveTo and OP_Next/Prev"
        ],
        "changed_headings": [
          "TxnId",
          "Witness Plane"
        ]
      },
      {
        "summary": "Make ARC cache cancel-safe and singleflight-friendly: add flush_inflight flag + protocol, define Loading watch status enum, and require cancellation to resolve latches.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.8,
        "evidence": [
          "flush_inflight: false -> true via CAS; must clear on all paths",
          "Loading state uses watch::Receiver<LoadStatus>"
        ],
        "changed_headings": [
          "ARC Cache",
          "Cancellation Safety"
        ]
      }
    ]
  },
  {
    "commit": "ec9adc1a8f61663d224399711d165a7dd623b919",
    "change_groups": [
      {
        "summary": "Update the monotonic TxnId proof text to match the CAS-loop allocator and explicitly fail closed on wrap/reserved-sentinel values.",
        "categories": [
          1,
          4
        ],
        "primary_category": 1,
        "confidence": 0.8,
        "evidence": [
          "Abort with FATAL_TXN_ID_OVERFLOW rather than publish illegal TxnId"
        ],
        "changed_headings": [
          "TxnId Invariants"
        ]
      },
      {
        "summary": "Clarify interpretation of P_eff: it\"s an effective collision pool for transaction write sets, not an estimate of physical page count.",
        "categories": [
          9,
          8
        ],
        "primary_category": 9,
        "confidence": 0.76,
        "evidence": [
          "P_eff plays role of \"year length\" in birthday paradox for transactions"
        ],
        "changed_headings": [
          "18.4.1.1 Collision Mass (M2)"
        ]
      }
    ]
  },
  {
    "commit": "e80fdde018b3ce359f49271f082366bbad19f928",
    "change_groups": [
      {
        "summary": "Require deterministic RaptorQ block seeding for replication changesets by deriving the seed from ChangesetId (matches asupersync determinism expectations).",
        "categories": [
          3,
          7,
          4
        ],
        "primary_category": 3,
        "confidence": 0.8,
        "evidence": [
          "seed = xxh3_64(changeset_id_bytes); decoder stores seed"
        ],
        "changed_headings": [
          "Replication"
        ]
      }
    ]
  },
  {
    "commit": "fa25db0b24e84470e8271309370e0f8093463ddd",
    "change_groups": [
      {
        "summary": "Tighten TxnSlot acquisition safety: seed claiming_timestamp via CAS after slot claim; document publish-phase CAS to detect cleanup reclaim.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "Phase 3 publish uses CAS(TXN_ID_CLAIMING -> real_txn_id); store is forbidden"
        ],
        "changed_headings": [
          "5.6.2 TxnSlot"
        ]
      },
      {
        "summary": "Expand ARC implementation guidance and ensure REPLACE terminates: treat prefer_t1 as a hint and fall back to the other list when preferred list is exhausted.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.78,
        "evidence": [
          "prefer_t1 is a hint, not a mandate; fallback to other list to ensure termination"
        ],
        "changed_headings": [
          "ARC Cache"
        ]
      },
      {
        "summary": "Adopt NGQP-style beam search join ordering for V1 (mxChoice bounded best-first search) and remove the exhaustive/greedy split narrative.",
        "categories": [
          2,
          4,
          7
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "Maintain up to mxChoice best partial join paths; no N! exhaustive path"
        ],
        "changed_headings": [
          "Join Ordering"
        ]
      }
    ]
  },
  {
    "commit": "1d8bbfb40fa7a1fe90e710b593dfa2b3e9113c2d",
    "change_groups": [
      {
        "summary": "Make TxnSlot publish phase robust against cleanup races: publish real TxnId via CAS so a reclaimed slot can\"t be silently overwritten.",
        "categories": [
          4,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "if !slot.txn_id.CAS(TXN_ID_CLAIMING, real_txn_id): restart_slot_acquire()"
        ],
        "changed_headings": [
          "TxnSlot acquire protocol"
        ]
      },
      {
        "summary": "Correct beam-search complexity statement to reflect bounded worst-case candidate expansions (~O(mxChoice*N^2)).",
        "categories": [
          1,
          2
        ],
        "primary_category": 1,
        "confidence": 0.8,
        "evidence": [
          "Complexity: worst-case ~O(mxChoice * N^2) candidate expansions"
        ],
        "changed_headings": [
          "Join Ordering"
        ]
      }
    ]
  },
  {
    "commit": "4432a3daa2f875bc2d3fe47caf783b3eb286ebfe",
    "change_groups": [
      {
        "summary": "Make snapshots self-consistent across (commit_seq, schema_epoch) and enforce schema-epoch publication ordering to prevent mixed-schema rebase.",
        "categories": [
          4,
          1,
          7
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "load_consistent_snapshot() reads commit_seq twice around schema_epoch"
        ],
        "changed_headings": [
          "5.4 BEGIN",
          "Memory ordering"
        ]
      },
      {
        "summary": "Replace toy WAL timing constants with measured distributions (fsync dominates); require histograms and policy-driven batching; add I/O-stall semantics that prefer safety over liveness.",
        "categories": [
          7,
          6,
          4
        ],
        "primary_category": 7,
        "confidence": 0.8,
        "evidence": [
          "T_wal = T_wal_write + T_fsync + T_wal_overhead; fsync can be multi-ms",
          "Coordinator MUST record histogram of T_fsync"
        ],
        "changed_headings": [
          "Group Commit",
          "Cancellation Safety"
        ]
      },
      {
        "summary": "Add a normative conformance mode matrix: fixtures must declare required operating modes (compatibility/native) and CI must check both against Oracle and each other.",
        "categories": [
          6,
          4,
          5
        ],
        "primary_category": 6,
        "confidence": 0.8,
        "evidence": [
          "Fixture field: fsqlite_modes: [\"compatibility\",\"native\"] (default both)"
        ],
        "changed_headings": [
          "Harness",
          "Mode matrix"
        ]
      }
    ]
  },
  {
    "commit": "aa8e81601a80b6910a3791490d07c5691b517850",
    "change_groups": [
      {
        "summary": "Tighten serialized-mode correctness: add FCW freshness validation (reader-turned-writer stale snapshot must abort) and simplify commit sequencing in the COMMIT table.",
        "categories": [
          4,
          1,
          2
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "Commit (Serialized): FCW freshness validation still required; abort with SQLITE_BUSY_SNAPSHOT"
        ],
        "changed_headings": [
          "5.4 COMMIT semantics"
        ]
      },
      {
        "summary": "Harden open-sequence invariants: initialize and reconcile shm.schema_epoch from durable schema cookie/manifest and forbid shared-memory schema_epoch ahead of durable reality.",
        "categories": [
          4,
          2
        ],
        "primary_category": 4,
        "confidence": 0.8,
        "evidence": [
          "On open: set shm.schema_epoch to durable schema cookie (offset 40)"
        ],
        "changed_headings": [
          "SharedMemoryLayout",
          "Schema epoch"
        ]
      },
      {
        "summary": "Refine rebase read-footprint semantics: footprint.reads captures non-replayable blocking reads; uniqueness checks for written keys are revalidated during replay and must not be recorded as blocking reads.",
        "categories": [
          4,
          9
        ],
        "primary_category": 4,
        "confidence": 0.78,
        "evidence": [
          "Do NOT include uniqueness checks in footprint.reads; re-validated during replay"
        ],
        "changed_headings": [
          "IntentFootprint"
        ]
      }
    ]
  },
  {
    "commit": "0a8d8676ac74f994535eceaa1c6c47cb17868038",
    "change_groups": [
      {
        "summary": "Make TxnSlot crash cleanup retryable: add cleanup_txn_id, broaden claiming_timestamp to sentinel states, and define release_page_locks_for(txn_id) for crashed writers.",
        "categories": [
          1,
          7,
          4
        ],
        "primary_category": 1,
        "confidence": 0.9,
        "evidence": [
          "cleanup_txn_id preserves the original TxnId under TXN_ID_CLEANING so crash cleanup can be retried safely.",
          "release_page_locks_for(txn_id) scans SharedPageLockTable and CASes owner_txn from txn_id to 0 without clearing the key.",
          "claiming_timestamp now tracks time spent in sentinel states (CLAIMING/CLEANING) for stuck-slot detection."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "5.6.3 SharedPageLockTable",
          "5.8 Conflict Detection and Resolution Detail"
        ]
      },
      {
        "summary": "Reconcile single-process vs multi-process lock semantics: SharedPageLockTable is canonical in Concurrent mode; in-process lock tables are reference-only; resolve() must materialize committed versions from durable storage when caches are stale.",
        "categories": [
          4,
          7,
          9
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "Cross-process writer exclusion is enforced via SharedPageLockTable in shm (not a per-process HashMap).",
          "InProcessPageLockTable is permitted only as a single-process reference implementation / unit-test harness.",
          "resolve(pgno, snapshot) consults WAL/marker stream to materialize committed versions when the in-process version chain cache is missing or stale."
        ],
        "changed_headings": [
          "MVCC resolve()",
          "5.4 COMMIT semantics",
          "5.6.3 SharedPageLockTable"
        ]
      },
      {
        "summary": "Tighten deterministic rebase correctness: treat existence/uniqueness probes as blocking reads for branchy conflict policies (OR IGNORE/REPLACE/UPSERT) unless the chosen branch is encoded in intent.",
        "categories": [
          4,
          2,
          1
        ],
        "primary_category": 4,
        "confidence": 0.82,
        "evidence": [
          "For OR IGNORE/REPLACE/UPSERT, probes can change observable behavior; replay must not silently take a different branch.",
          "Until intent encodes the chosen branch, V1 deterministic rebase requires recording the probe in footprint.reads (blocking) or forbids the op."
        ],
        "changed_headings": [
          "5.10.2 Deterministic Rebase",
          "IntentFootprint"
        ]
      },
      {
        "summary": "Correct schema-cookie assumptions: the SQLite schema cookie is a 32-bit counter modulo 2^32; merge safety requires equality checks, not numeric monotonicity.",
        "categories": [
          2,
          1,
          9
        ],
        "primary_category": 2,
        "confidence": 0.78,
        "evidence": [
          "SQLite schema cookie increments modulo 2^32; numeric decreases are not necessarily corruption.",
          "For safety we require schema cookie equality across participants; any change must produce a different cookie."
        ],
        "changed_headings": [
          "Schema epoch / schema cookie"
        ]
      }
    ]
  },
  {
    "commit": "3d568547fd6b8036481df0d73a2c60b5bf30d5a7",
    "change_groups": [
      {
        "summary": "Scrivening + minor clarification: normalize Vfs trait doc formatting and refine cleanup_txn_id comments (ignored unless txn_id==TXN_ID_CLEANING; should be zeroed on free).",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.96,
        "evidence": [
          "Reindent Vfs trait docs for consistent Rustdoc rendering.",
          "cleanup_txn_id is meaningful only when txn_id==TXN_ID_CLEANING; otherwise ignored; must be zeroed when freeing the slot."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot",
          "VFS trait"
        ]
      }
    ]
  },
  {
    "commit": "4c07e10c56ee30db5d03453237ae6c29c31a7cf0",
    "change_groups": [
      {
        "summary": "Clarify deterministic rebase semantics for rowid reuse: re-execution is defined on the semantic key (rowid); reused rowids can be updated and this matches commit-time serial order semantics.",
        "categories": [
          2,
          9,
          4
        ],
        "primary_category": 2,
        "confidence": 0.84,
        "evidence": [
          "SQLite rowids may be reused unless AUTOINCREMENT is used.",
          "Deterministic rebase is merge-by-reexecution on the semantic key; a delete/insert that reuses a rowid can cause replay to update the new row at that key."
        ],
        "changed_headings": [
          "5.10.2 Deterministic Rebase"
        ]
      },
      {
        "summary": "Harden page-encryption metadata + AAD rules: define stable DatabaseId, keep AAD independent of encrypted bytes (no circular dependencies), and allow optional pre-decrypt page_context_tag only when known.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.86,
        "evidence": [
          "DatabaseId is generated once and remains stable across the database lifetime including PRAGMA rekey.",
          "AAD inputs must be known before decryption; do not derive AAD from encrypted page bytes such as B-tree flags.",
          "Optional page_context_tag is permitted only when known pre-decrypt; otherwise use a fixed constant."
        ],
        "changed_headings": [
          "Page Encryption",
          "AAD (swap resistance)"
        ]
      },
      {
        "summary": "Ministerial cleanup: normalize indentation in VersionArena / ARC prose blocks and sharpen reserved-space checksum interoperability wording.",
        "categories": [
          5,
          9,
          2
        ],
        "primary_category": 5,
        "confidence": 0.76,
        "evidence": [
          "Normalize indentation in long code-comment blocks for readability.",
          "Clarify that C SQLite can read reserved-space checksums (reserved bytes are opaque) but default remains OFF for interoperability."
        ],
        "changed_headings": [
          "VersionArena",
          "ARC/CAR",
          "Reserved-space checksums"
        ]
      }
    ]
  },
  {
    "commit": "df0313b00f2854929c376434c56129ef6e2740e0",
    "change_groups": [
      {
        "summary": "Scrivening: fix ARC/CAR commentary indentation so rendered docs align with surrounding prose.",
        "categories": [
          5
        ],
        "primary_category": 5,
        "confidence": 0.99,
        "evidence": [
          "Indentation-only change in ARC/CAR explanatory comments."
        ],
        "changed_headings": [
          "ARC/CAR"
        ]
      }
    ]
  },
  {
    "commit": "97df1f07893def20701570db65418ff75ed45656",
    "change_groups": [
      {
        "summary": "Clarify what 'zero-copy' means in this spec: no extra heap allocations or staging copies in hot paths, but not kernel-bypass I/O; small stack buffers are allowed.",
        "categories": [
          9,
          6
        ],
        "primary_category": 9,
        "confidence": 0.9,
        "evidence": [
          "Zero-copy excludes userspace staging buffers/allocations, not buffered syscalls.",
          "Fixed-size header stack buffers are permitted."
        ],
        "changed_headings": [
          "1.5 Hot-path constraints"
        ]
      }
    ]
  },
  {
    "commit": "bbc4a3114572200d7a8a674eb3a4e430ae1d0b47",
    "change_groups": [
      {
        "summary": "Define canonical page-encryption AAD bytes: be_u32(page_number) || database_id_bytes; forbid native-endian encodings for cross-endian opens.",
        "categories": [
          4,
          7,
          5
        ],
        "primary_category": 4,
        "confidence": 0.92,
        "evidence": [
          "aad = be_u32(page_number) || database_id_bytes (normative).",
          "Native-endian integer encoding is forbidden for AAD (cross-endian open must work)."
        ],
        "changed_headings": [
          "Page Encryption",
          "AAD (swap resistance)"
        ]
      }
    ]
  },
  {
    "commit": "4363f50065239e47d56f12250d933f5a1ab75a00",
    "change_groups": [
      {
        "summary": "Add a cross-cutting 'Critical Implementation Controls' checklist to make corruption/deadlock-sensitive invariants impossible to miss.",
        "categories": [
          6,
          7,
          4
        ],
        "primary_category": 6,
        "confidence": 0.88,
        "evidence": [
          "Hybrid SHM interop requires legacy WAL_READ_LOCK/WAL_WRITE_LOCK protocol (not just layout).",
          "Witness instrumentation must be semantic/sub-page for point ops (avoid whole-page reads that collapse merge/rebase).",
          "RaptorQ repair generation must be off the commit critical path; rebuild quiescence is 'no lock holders', not 'no txns'."
        ],
        "changed_headings": [
          "1.6 Critical Implementation Controls (Non-Negotiable)"
        ]
      },
      {
        "summary": "Tighten TxnSlot cleanup: stamp a fresh sentinel-time when transitioning into TXN_ID_CLEANING so stuck-cleaner detection measures time in CLEANING (not inherited CLAIMING time).",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.84,
        "evidence": [
          "On CAS into TXN_ID_CLEANING, set claiming_timestamp = now to start the CLEANING timeout window.",
          "Overwrite stale CLAIMING timestamps when entering CLEANING."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot cleanup"
        ]
      }
    ]
  },
  {
    "commit": "d9021cffb65692624f3990ae2544a96ae0c07021",
    "change_groups": [
      {
        "summary": "Clarification pass: make rowid reuse semantics explicit as a serial-order effect for deterministic rebase, and define DatabaseId precisely as 16 opaque bytes stable across rekey.",
        "categories": [
          9,
          2,
          4
        ],
        "primary_category": 9,
        "confidence": 0.9,
        "evidence": [
          "Rowid reuse is expected: replay matches serial order (delete/insert then update) rather than implying corruption.",
          "DatabaseId is 16 opaque bytes (not host-endian integer) and must remain stable across PRAGMA rekey."
        ],
        "changed_headings": [
          "5.10.2 Deterministic Rebase",
          "Page Encryption"
        ]
      }
    ]
  },
  {
    "commit": "29107df6b155bb20934ef369b934699191076b32",
    "change_groups": [
      {
        "summary": "Draw a hard durability boundary: ARC eviction is memory-only and MUST NOT append to .wal; only the write coordinator may append WAL frames, with large write sets spilled to per-txn temp files.",
        "categories": [
          4,
          7,
          1
        ],
        "primary_category": 4,
        "confidence": 0.9,
        "evidence": [
          "ARC eviction MUST NOT append to .wal; legacy WAL commit markers assume coordinator-only contiguous appends.",
          "Uncommitted/private page images live in txn write_set and are spillable to a per-txn spill file in Compatibility mode."
        ],
        "changed_headings": [
          "6.6 Eviction: Pinned Pages and Durability Boundaries",
          "5.9.2 Write-set spill"
        ]
      },
      {
        "summary": "Simplify ARC REQUEST/REPLACE behavior around pinned pages: remove flush-dirty loops, allow temporary over-capacity as a safety valve when all candidates are pinned, and update resize protocol accordingly.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.82,
        "evidence": [
          "Eviction scans skip only pinned pages (ref_count > 0); durability I/O is not part of eviction.",
          "When all pages are pinned, permit bounded capacity overflow rather than spinning forever."
        ],
        "changed_headings": [
          "6.4 Full ARC Algorithm: REQUEST Subroutine",
          "6.6 Eviction: Pinned Pages and Durability Boundaries"
        ]
      },
      {
        "summary": "Clarify interoperability boundary for encryption: encrypted databases are not readable by stock C SQLite; fail closed rather than attempting legacy interop on ciphertext pages.",
        "categories": [
          9,
          2,
          4
        ],
        "primary_category": 9,
        "confidence": 0.78,
        "evidence": [
          "Encrypted databases are not readable by stock C SQLite; compatibility interop applies only to plaintext.",
          "If encryption is enabled, FrankenSQLite fails closed rather than letting legacy clients treat ciphertext as page bytes."
        ],
        "changed_headings": [
          "Page Encryption",
          "Compatibility mode interoperability"
        ]
      }
    ]
  },
  {
    "commit": "f708f338cb6e435db3822e2aa81b2785b51bf39b",
    "change_groups": [
      {
        "summary": "Clarify pipelined WAL-FEC semantics: commits can be durable before they are repairable; if wal-fec metadata is missing at recovery, fall back to SQLite truncation semantics; optional synchronous mode can require immediate repairability.",
        "categories": [
          7,
          4,
          9
        ],
        "primary_category": 7,
        "confidence": 0.86,
        "evidence": [
          "Eventual repairability: a group is repairable only once WalFecGroupMeta + repair symbols are durable.",
          "If wal-fec metadata is missing, recovery truncates before the affected group (SQLite semantics).",
          "An opt-in synchronous mode may wait for wal-fec fsync before acknowledging COMMIT."
        ],
        "changed_headings": [
          "3.4.1 Self-Healing WAL (Erasure-Coded Durability)"
        ]
      },
      {
        "summary": "Specify Compatibility-mode write-set spilling and coordinator-only WAL append: introduce CommitWriteSet (Inline vs Spilled) and PRAGMA fsqlite.txn_write_set_mem_bytes with a bounded auto default.",
        "categories": [
          4,
          7,
          6
        ],
        "primary_category": 4,
        "confidence": 0.88,
        "evidence": [
          "CommitRequest.write_set becomes CommitWriteSet::Inline(...) or CommitWriteSet::Spilled(...).",
          "Spill files are temporary and explicitly not durability / crash recovery.",
          "Auto spill threshold: clamp(4 * cache.max_bytes, 32 MiB, 512 MiB).",
          "Only the write coordinator may append to .wal to avoid interleaving corruption."
        ],
        "changed_headings": [
          "5.9.2 Write Coordinator",
          "6.6 Eviction: Pinned Pages and Durability Boundaries"
        ]
      },
      {
        "summary": "Add a V1 rule for OP_NewRowid under concurrent writers: allocate rowids from a snapshot-independent per-table allocator and record the concrete RowId in the Insert intent at execution time.",
        "categories": [
          4,
          2,
          7
        ],
        "primary_category": 4,
        "confidence": 0.84,
        "evidence": [
          "Concurrent mode cannot use max(rowid)+1 per snapshot; writers would collide.",
          "RowId must come from a global allocator and be stable for statement/transaction (preserves last_insert_rowid/RETURNING)."
        ],
        "changed_headings": [
          "5.10.1.1 RowId Allocation in Concurrent Mode (Avoid the Pre-Binding Trap)"
        ]
      }
    ]
  },
  {
    "commit": "a71e1d95715c1190335e8738413382b31b6d167c",
    "change_groups": [
      {
        "summary": "Correct the RFC 6330 LDPC constraint description: each source column updates exactly three LDPC rows using stride a=1+floor(j/S), implying total nonzeros=3*K'.",
        "categories": [
          1,
          6
        ],
        "primary_category": 1,
        "confidence": 0.82,
        "evidence": [
          "For j in 0..K'-1: a=1+floor(j/S); b=j%S; set A[b][j]=1 then advance b=(b+a)%S twice more.",
          "Each source column contributes exactly 3 nonzeros; average LDPC row has ~3*K'/S nonzeros."
        ],
        "changed_headings": [
          "RaptorQ LDPC rows",
          "RFC 6330 §5.3.3.3"
        ]
      },
      {
        "summary": "Harden WAL-FEC metadata + recovery: require per-source xxh3_128 validation hashes, add SQLite fallback when wal-fec is missing, and widen OTI.T to u32 to represent page_size=65536 with explicit corruption invariants.",
        "categories": [
          4,
          7,
          1
        ],
        "primary_category": 4,
        "confidence": 0.9,
        "evidence": [
          "If wal-fec metadata is missing for a torn group, recovery falls back to SQLite truncation semantics.",
          "WalFecGroupMeta stores source_page_xxh3_128: Vec<[u8;16]> for random-access validation.",
          "OTI.T is widened to u32 so symbol_size can equal page_size=65536; mismatches are treated as corruption."
        ],
        "changed_headings": [
          "3.4.1 Self-Healing WAL",
          "WalFecGroupMeta",
          "SymbolRecord / OTI"
        ]
      },
      {
        "summary": "Make ECS root pointer updates truly crash-safe: fsync temp file before rename and fsync the directory after rename to persist the rename itself.",
        "categories": [
          7,
          1
        ],
        "primary_category": 7,
        "confidence": 0.88,
        "evidence": [
          "Crash-safe sequence: write temp, fsync(temp), rename(temp, ecs/root), fsync(directory).",
          "Omitting fsync(temp) risks garbage content; omitting fsync(dir) risks losing the rename after crash."
        ],
        "changed_headings": [
          "ECS directory layout",
          "ecs/root"
        ]
      },
      {
        "summary": "Fix TxnSlot cleanup race: snapshot txn_id once per slot iteration (Acquire load) to avoid branching on multiple unsynchronized reads while sentinels are changing.",
        "categories": [
          1,
          7
        ],
        "primary_category": 1,
        "confidence": 0.86,
        "evidence": [
          "Snapshot txn_id once: tid = slot.txn_id.load(Acquire); skip tid==0 early.",
          "Avoid freeing a slot while another cleaner is still releasing locks due to inconsistent reads of sentinel states."
        ],
        "changed_headings": [
          "5.6.2 TxnSlot cleanup"
        ]
      },
      {
        "summary": "Clarify ESCAPE handling in the Pratt parser: ESCAPE is not an infix operator; it is parsed as an optional suffix of LIKE/GLOB/MATCH productions (parse.y %right ESCAPE is for Lemon conflict resolution).",
        "categories": [
          2,
          9,
          5
        ],
        "primary_category": 2,
        "confidence": 0.8,
        "evidence": [
          "ESCAPE is parsed inside the LIKE/GLOB handler after the pattern expression, not in the infix dispatch table.",
          "C SQLite declares %right ESCAPE for conflict resolution, but it is not a standalone expression operator."
        ],
        "changed_headings": [
          "SQL operator precedence",
          "LIKE/GLOB ESCAPE handling"
        ]
      }
    ]
  },
  {
    "commit": "120eee252b4caa7fe6389602bd2c8a316c6cee2a",
    "change_groups": [
      {
        "summary": "Correct GF(256) elimination language: use nonzero pivot selection (no rounding error over fields), avoiding misleading 'partial pivoting' phrasing.",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.9,
        "evidence": [
          "Over exact fields, pivot choice is simply selecting any nonzero pivot; numerical stability concerns do not apply."
        ],
        "changed_headings": [
          "GF(256) Gaussian solve"
        ]
      },
      {
        "summary": "Strengthen random-access WAL-FEC source-frame validation: compute xxh3_128(page_data) and compare against source_page_xxh3_128 before feeding symbols into the decoder.",
        "categories": [
          7,
          4,
          1
        ],
        "primary_category": 7,
        "confidence": 0.88,
        "evidence": [
          "Validate candidate frames with xxh3_128 and compare to WalFecGroupMeta.source_page_xxh3_128.",
          "Random-access validation remains valid even when the cumulative WAL checksum chain is broken."
        ],
        "changed_headings": [
          "3.4.1 Self-Healing WAL",
          "WAL recovery"
        ]
      }
    ]
  },
  {
    "commit": "975f65c78a5745424665a95f0c222287306c9dd5",
    "change_groups": [
      {
        "summary": "Clarify GF(256) elimination commentary: in exact fields there is no rounding error, so the pivot rule is nonzero selection, not numerical 'partial pivoting'.",
        "categories": [
          1,
          9
        ],
        "primary_category": 1,
        "confidence": 0.9,
        "evidence": [
          "Explicitly note that pivoting is for finding a nonzero pivot; there is no floating-point stability issue over GF(256)."
        ],
        "changed_headings": [
          "GF(256) Gaussian elimination"
        ]
      },
      {
        "summary": "Add replication endianness boundary note: UDP packet headers use big-endian network order, while the decoded changeset payload uses little-endian per canonical encoding rules.",
        "categories": [
          6,
          7
        ],
        "primary_category": 6,
        "confidence": 0.84,
        "evidence": [
          "Replication packet header fields are big-endian; the boundary is symbol_data, whose decoded changeset payload is little-endian."
        ],
        "changed_headings": [
          "UDP Packet Format",
          "Canonical encodings"
        ]
      },
      {
        "summary": "Bound version-chain delta reconstruction cost and clarify ECS root file format: chain depth is kept small by GC scheduling targets, and ecs/root includes a magic+version prefix with manifest id + checksum.",
        "categories": [
          7,
          4
        ],
        "primary_category": 7,
        "confidence": 0.86,
        "evidence": [
          "Reconstructing the oldest version in a chain of depth L requires L-1 sequential delta applications; GC scheduling targets depth ~8.",
          "ecs/root contains: magic (\"FSRT\"), version, manifest_object_id, checksum."
        ],
        "changed_headings": [
          "Version chain deltas",
          "ECS root file format"
        ]
      }
    ]
  },
  {
    "commit": "24b6f60e9e751b699cb232759d85a06c42792019",
    "change_groups": [
      {
        "summary": "Fix GC scheduling cross-references: point Theorem-5 discussion at the GC scheduling policy section (5.6.5), not the lock-table section.",
        "categories": [
          5,
          9
        ],
        "primary_category": 5,
        "confidence": 0.95,
        "evidence": [
          "Replace incorrect §5.6.3 references with §5.6.5 for GC scheduling policy citations."
        ],
        "changed_headings": [
          "GC scheduling policy",
          "Theorem 5 discussion"
        ]
      }
    ]
  },
	  {
	    "commit": "80decf6b8ba71dd4331f559a08ee0fba3fbdf4bb",
	    "change_groups": [
	      {
        "summary": "Clarify .db-fec generation binding and repair terminology: specify db_gen_digest derivation inputs, use RFC 6330 ESI naming for symbols, and make commit_time_unix_ns monotonicity enforcement explicit.",
        "categories": [
          9,
          5,
          1,
          7
        ],
        "primary_category": 9,
        "confidence": 0.86,
        "evidence": [
          "db_gen_digest comment now specifies Trunc128(BLAKE3(\"fsqlite:compat:dbgen:v1\" || change_counter || page_count || freelist_count || schema_cookie)) with big-endian u32 reads from header offsets.",
          "Repair pseudocode switches from ISI to ESI terminology and uses repair_rec.esi rather than deriving ids from loop indices.",
          "Binary-search-by-time note now cites the protocol rule: commit_time_unix_ns := max(now_unix_ns(), last_commit_time_unix_ns + 1)."
        ],
        "changed_headings": [
          "Compatibility DB-FEC",
          "Repair pseudocode",
          "Commit protocol time"
        ]
	      }
	    ]
	  },
	  {
	    "commit": "7cc726325faa5cad71d2132480cbb68fb046563d",
	    "change_groups": [
	      {
	        "summary": "Add `.db-fec` freshness and foreign-sidecar guardrails: define db_gen_digest derivation from DB header, require digest match before using repair symbols, and make the .db-fec header update the commit record (fsync-ordered).",
	        "categories": [
	          7,
	          1,
	          2,
	          4
	        ],
	        "primary_category": 7,
	        "confidence": 0.85,
	        "evidence": [
	          "Verify DbFecHeader.checksum and require db_gen_digest_current == DbFecHeader.db_gen_digest before using any .db-fec metadata.",
	          "If repairing page 1, recompute digest from repaired bytes; mismatch fails closed (SQLITE_CORRUPT).",
	          "Checkpoint must fsync .db, then write db_gen_digest + header checksum, then fsync .db-fec before WAL RESTART/TRUNCATE."
	        ],
	        "changed_headings": [
	          "Compatibility DB-FEC",
	          "DbFecHeader",
	          "DbFecGroupMeta"
	        ]
	      },
	      {
	        "summary": "Harden shared-memory coordination: introduce snapshot_seq seqlock for consistent snapshot capture, add serialized-writer indicator fields (token/pid/lease), and define a stale-indicator clearing algorithm for concurrent writers.",
	        "categories": [
	          4,
	          7,
	          1
	        ],
	        "primary_category": 4,
	        "confidence": 0.8,
	        "evidence": [
	          "SharedMemoryLayout gains snapshot_seq (odd/even seqlock) plus serialized_writer_token/pid/pid_birth/lease_expiry.",
	          "Snapshot publish protocol specified: even -> odd -> even around backbone field stores; openers repair crash-stale odd values.",
	          "Concurrent writers check indicator and may clear stale tokens after lease expiry / owner death."
	        ],
	        "changed_headings": [
	          "5.6.1 Shared-Memory Coordination Region",
	          "Serialized writer acquisition ordering"
	        ]
	      },
	      {
	        "summary": "Replace constant TxnSlot sentinels with a tagged txn_id word to prevent ABA claim/cleanup races; update cleanup_orphaned_slots and gc_horizon logic to treat sentinel-tagged slots as blockers.",
	        "categories": [
	          4,
	          1,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.85,
	        "evidence": [
	          "TxnSlot.txn_id reserves the top 2 bits as a tag: Active/CLAIMING/CLEANING; Phase 1 uses claim_word=encode_claiming(txn_id).",
	          "Phase 3 publish is CAS(claim_word -> real_txn_id); claim timestamps are cleared after publish.",
	          "cleanup_orphaned_slots branches on decode_tag(tid) and transitions to encode_cleaning(payload)."
	        ],
	        "changed_headings": [
	          "5.6.2 TxnSlot",
	          "cleanup_orphaned_slots()",
	          "raise_gc_horizon()"
	        ]
	      },
	      {
	        "summary": "Make recently-committed-readers summaries cross-process stable: specify a fixed-layout SHM ring with a per-entry Bloom filter (fail-closed on overflow) instead of RoaringBitmap-in-SHM.",
	        "categories": [
	          7,
	          4
	        ],
	        "primary_category": 7,
	        "confidence": 0.78,
	        "evidence": [
	          "RecentlyCommittedReadersRing lives at committed_readers_offset and uses commit_seq as a publication word (0=unpublished).",
	          "Each entry includes a 4096-bit Bloom filter with k=3 probes over pgno (xxh3_64 domain-separated).",
	          "If inserting would evict an entry with commit_seq > gc_horizon, the committer aborts with SQLITE_BUSY_SNAPSHOT (no false negatives)."
	        ],
	        "changed_headings": [
	          "RecentlyCommittedReadersRing",
	          "Committed readers index"
	        ]
	      },
	      {
	        "summary": "Redesign shared page-lock rebuild as a rolling rotate+drain protocol using two tables (active+draining) to avoid stop-the-world abort storms; update acquire/release/crash-cleanup to consult both tables.",
	        "categories": [
	          4,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.8,
	        "evidence": [
	          "SharedPageLockTable gains active_table/draining_table and two LockTableInstance tables.",
	          "try_acquire consults draining table first for idempotent re-acquire and conflict detection; release probes both tables.",
	          "Rebuild rotates quickly, drains in background, and clears only after lock-quiescence; capacity defaults to 1,048,576 entries."
	        ],
	        "changed_headings": [
	          "5.6.3.1 Table Rebuild",
	          "SharedPageLockTable"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "9ad50ae2a2c7fce76a75d1200e22374eb729914d",
	    "change_groups": [
	      {
	        "summary": "Specify the coordinator IPC transport for multi-process deployments: Unix domain sockets, framed messages, two-phase reserve/submit discipline, SCM_RIGHTS spill-fd passing, and TxnToken idempotency.",
	        "categories": [
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.82,
	        "evidence": [
	          "Defines socket endpoints, permissions, and peer credential checks (UID) for coordinator IPC.",
	          "Framing: len_be + version/kind/request_id + payload; RESERVE returns permit_id or BUSY; SUBMIT_* binds to permit_id.",
	          "Large write sets are passed via spill fd using SCM_RIGHTS; duplicates keyed by (txn_id, txn_epoch) are idempotent."
	        ],
	        "changed_headings": [
	          "5.9.0 Coordinator IPC Transport"
	        ]
	      },
	      {
	        "summary": "Make snapshot capture explicitly seqlock-based: load_consistent_snapshot reads snapshot_seq, retries on odd or change, and returns a self-consistent (commit_seq, schema_epoch) pair.",
	        "categories": [
	          4,
	          1,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Read s1=snapshot_seq; if odd retry; read commit_seq + schema_epoch; read s2; accept only if s1==s2 and even.",
	          "Cross-process snapshot correctness is now specified as a seqlock read, not two commit_seq loads."
	        ],
	        "changed_headings": [
	          "Snapshot capture",
	          "load_consistent_snapshot()"
	        ]
	      },
	      {
	        "summary": "Clarify in-process vs cross-process commit schemas and harden spill semantics: use OwnedFd for spill transfer, allow optional diagnostic path, and recommend unlink-after-open for crash robustness.",
	        "categories": [
	          7,
	          4,
	          6
	        ],
	        "primary_category": 7,
	        "confidence": 0.75,
	        "evidence": [
	          "Adds normative notes: cross-process routing MUST NOT attempt to transmit Vec/HashMap/oneshot through shared memory.",
	          "SpilledWriteSet carries an OwnedFd; cross-process commits MUST use CommitWriteSet::Spilled with SCM_RIGHTS fd passing.",
	          "Recommends creator unlink spill file after open so cleanup is automatic on crash."
	        ],
	        "changed_headings": [
	          "CommitRequest (compatibility/WAL)",
	          "Write-set spilling"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "19106d19e531ea75918241b2858024c34a73f037",
	    "change_groups": [
	      {
	        "summary": "Expand and harden the TxnSlot acquire/publish protocol: make the 3-phase claim/init/publish sequence explicit and require begin_seq/snapshot_high derive from a self-consistent snapshot (seqlock).",
	        "categories": [
	          4,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.82,
	        "evidence": [
	          "acquire_and_publish_txn_slot() wraps claim (CAS 0->claim_word), initializes slot fields, captures snap via load_consistent_snapshot, then publishes real TxnId via CAS(claim_word->txn_id).",
	          "Clears claiming_timestamp after publish to avoid polluting stuck-cleaner detection."
	        ],
	        "changed_headings": [
	          "TxnSlot acquire protocol",
	          "5.6.2 TxnSlot"
	        ]
	      },
	      {
	        "summary": "Fix write_page idempotency for cross-process hints: only increment write_set_pages on first lock acquisition per page; clarify hints are not correctness sources of truth.",
	        "categories": [
	          1,
	          7
	        ],
	        "primary_category": 1,
	        "confidence": 0.8,
	        "evidence": [
	          "Guard write_set_pages.fetch_add(1) behind `newly_locked` to prevent inflated counts on repeated writes to the same page.",
	          "States explicitly that lock tables, not write_set_pages, are the correctness source of truth."
	        ],
	        "changed_headings": [
	          "write_page()"
	        ]
	      },
	      {
	        "summary": "SHM layout hardening: define layout_checksum over immutable metadata only; forbid unsafe reinterpret casts in this repo; and state DDL publication ordering relies on snapshot_seq seqlock windows.",
	        "categories": [
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Renames header checksum -> layout_checksum and documents immutable-only coverage (magic/version/page_size/offsets), excluding dynamic atomics.",
	          "Adds normative safe-Rust constraint: SHM access uses safe offset-based accessors; no &[u8] -> &SharedMemoryLayout casts.",
	          "Clarifies mixed snapshots are prevented by snapshot_seq + load_consistent_snapshot, not store ordering alone."
	        ],
	        "changed_headings": [
	          "5.6.1 Shared-Memory Coordination Region",
	          "Alignment requirement"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "7313951174e317f889851f696de264b546e4b54e",
	    "change_groups": [
	      {
	        "summary": "Fix coordinator IPC framing math and add canonical V1 wire payload schemas (including strict size caps and exact SCM_RIGHTS rules).",
	        "categories": [
	          1,
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.8,
	        "evidence": [
	          "Frame.payload corrected from len_be-16 to len_be-12 (excluding the 4-byte length field itself).",
	          "Defines Reserve/SubmitNativePublish/SubmitWalCommit/RowIdReserve payload schemas + size caps; SUBMIT_WAL_COMMIT requires exactly one spill fd in SCM_RIGHTS.",
	          "CommitRequest identity updated to TxnToken for cross-process stability."
	        ],
	        "changed_headings": [
	          "Coordinator IPC Transport",
	          "Wire payload schemas"
	        ]
	      },
	      {
	        "summary": "Define coordinator-owned per-table RowId allocator state and ROWID_RESERVE semantics (schema_epoch validation, monotone non-reusable ranges, gaps permitted).",
	        "categories": [
	          4,
	          7,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Allocator state lives in coordinator memory keyed by (schema_epoch, TableId), not in SQLite file format or a SHM hash table.",
	          "Initialize next_rowid from max_committed_rowid+1 (AUTOINCREMENT override); reject schema_epoch mismatch with SQLITE_SCHEMA.",
	          "Coordinator advances by count even if caller later aborts (gaps permitted)."
	        ],
	        "changed_headings": [
	          "ROWID_RESERVE",
	          "RowId allocator"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "d329df055a1a13459d0f507bc222b05525bb7522",
	    "change_groups": [
	      {
	        "summary": "Define serialized writer exclusion acquire/release pseudocode and ordering: acquire global exclusion, publish token/pid/lease, drain concurrent writers, and clear indicator before releasing the global exclusion.",
	        "categories": [
	          4,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Adds acquire_serialized_writer_exclusion/release_serialized_writer_exclusion with publication edge on serialized_writer_token (Release).",
	          "Drain concurrent writers via lock-table scan and orphan cleanup; clear token before releasing the global exclusion."
	        ],
	        "changed_headings": [
	          "Serialized writer acquisition ordering",
	          "Indicator check algorithm"
	        ]
	      },
	      {
	        "summary": "Make write_set_summary cross-process canonical (sorted u32_le array, no roaring dependency) and add response payload schemas for SUBMIT_NATIVE_PUBLISH and SUBMIT_WAL_COMMIT.",
	        "categories": [
	          4,
	          7,
	          1,
	          6
	        ],
	        "primary_category": 4,
	        "confidence": 0.74,
	        "evidence": [
	          "write_set_summary_len must be a multiple of 4; pages are sorted ascending with no duplicates.",
	          "Adds NativePublishRespV1 and WalCommitRespV1 Ok/Conflict/Err variants with explicit fields."
	        ],
	        "changed_headings": [
	          "Wire payload schemas",
	          "write_set_summary encoding"
	        ]
	      },
	      {
	        "summary": "Remove duplicate expression precedence table and centralize parsing rules: NOT precedence, ESCAPE not an operator, and unary-vs-COLLATE binding.",
	        "categories": [
	          2,
	          5,
	          9
	        ],
	        "primary_category": 2,
	        "confidence": 0.7,
	        "evidence": [
	          "12.15 now points to the normative Pratt precedence table in §10.2 instead of restating the full table.",
	          "Key rules reiterated: NOT x=y parses as NOT(x=y); ESCAPE is parsed as part of LIKE; unary binds tighter than COLLATE."
	        ],
	        "changed_headings": [
	          "12.15 Expression Syntax",
	          "Pratt precedence table"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "351c282e9a9a2ee118496651cef7a4b33cf309f2",
	    "change_groups": [
	      {
	        "summary": "Apply the no-unsafe constraint to aligned allocation: require safe page-aligned buffers and make PageBuf explicitly page-sized + page-aligned in both the I/O model and formal type definitions.",
	        "categories": [
	          7,
	          4,
	          6
	        ],
	        "primary_category": 7,
	        "confidence": 0.75,
	        "evidence": [
	          "Page alignment section now requires safe abstractions for aligned allocation (dependencies may use unsafe internally).",
	          "PageBuf/PageData and buffer model updated to state page-aligned explicitly."
	        ],
	        "changed_headings": [
	          "1.5 Mechanical Sympathy",
	          "4.10 PageBufferPool",
	          "Formal type definitions"
	        ]
	      },
	      {
	        "summary": "Fix TxnSlot acquire pseudocode: detect lost claim before seeding claiming_timestamp; clean up indentation and clarify omitted fields for brevity.",
	        "categories": [
	          1,
	          4,
	          5
	        ],
	        "primary_category": 1,
	        "confidence": 0.72,
	        "evidence": [
	          "After CAS(0->claim_word), re-load txn_id and require it still equals claim_word before writing claiming_timestamp.",
	          "Normalizes indentation and clarifies begin() pseudocode omits fields that default to empty/false."
	        ],
	        "changed_headings": [
	          "TxnSlot acquire protocol",
	          "acquire_and_publish_txn_slot()"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "b1c1e72d9331952247c804af6589fe3b349d0b8a",
	    "change_groups": [
	      {
	        "summary": "Tighten coordinator IPC framing and capability discipline: enforce len/version/kind validity, bind permit_id to a connection as a single-use capability, and make responses canonically tagged.",
	        "categories": [
	          4,
	          7,
	          1
	        ],
	        "primary_category": 4,
	        "confidence": 0.78,
	        "evidence": [
	          "Add len_be bounds (>=12 and <=4MiB), require version_be==1, and enumerate kind_be values (unknown kinds rejected).",
	          "Permit binding: SUBMIT_* must reference a permit_id previously returned by RESERVE on the same connection; consumed permits cannot be reused.",
	          "Response payloads become explicit tag+padding+body wrappers (ReserveRespV1, NativePublishRespV1, WalCommitRespV1, RowIdReserveRespV1)."
	        ],
	        "changed_headings": [
	          "5.9.0 Coordinator IPC Transport",
	          "Wire payload schemas"
	        ]
	      },
	      {
	        "summary": "Fix BEGIN TxnId allocation pseudocode to use SharedMemoryLayout.next_txn_id (cross-process global), not a per-manager field.",
	        "categories": [
	          1,
	          5
	        ],
	        "primary_category": 1,
	        "confidence": 0.9,
	        "evidence": [
	          "begin() pseudocode now reads manager.shm.next_txn_id and CASes it for TxnId allocation."
	        ],
	        "changed_headings": [
	          "BEGIN / TxnId allocation"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "e60049751d7e238e46e45ce8009d9e9f053a41c2",
	    "change_groups": [
	      {
	        "summary": "Harden TAG_CLAIMING liveness safety: require early pid/pid_birth/lease publication before snapshot capture and forbid reclaiming live claimers; add conservative timeouts when pid identity is still unknown.",
	        "categories": [
	          4,
	          1,
	          7
	        ],
	        "primary_category": 4,
	        "confidence": 0.85,
	        "evidence": [
	          "Phase 2 ordering: publish pid/pid_birth/lease_expiry before any potentially blocking work (including seqlock snapshot capture).",
	          "cleanup_orphaned_slots never reclaims a CLAIMING slot if pid/birth are non-zero and process_alive(pid,birth) is true.",
	          "Split timeouts: short fast-path timeout vs longer no-pid fallback timeout."
	        ],
	        "changed_headings": [
	          "5.6.2 TxnSlot",
	          "cleanup_orphaned_slots()"
	        ]
	      },
	      {
	        "summary": "Fix check_serialized_writer_exclusion stale-token cleanup: retry on CAS failure so we never return Ok while a new serialized writer installs a fresh token.",
	        "categories": [
	          1,
	          4,
	          7
	        ],
	        "primary_category": 1,
	        "confidence": 0.8,
	        "evidence": [
	          "Stale indicator clearing loops: if CAS(tok->0) fails, retry because token changed (cleared or replaced).",
	          "CAS uses AcqRel/Acquire to ensure correct publication edges."
	        ],
	        "changed_headings": [
	          "Indicator check algorithm"
	        ]
	      },
	      {
	        "summary": "Make IPC payload set-ordering canonical: ObjectId arrays sorted/deduped, conflict page arrays sorted, and spill_pages sorted by pgno with no duplicates.",
	        "categories": [
	          7,
	          4
	        ],
	        "primary_category": 7,
	        "confidence": 0.75,
	        "evidence": [
	          "Any payload field that semantically represents a set must be encoded in sorted order without duplicates.",
	          "Applies to witness/edge/merge arrays, conflict page lists, and spill_pages ordering."
	        ],
	        "changed_headings": [
	          "Framing",
	          "Canonical ordering"
	        ]
	      }
	    ]
	  },
	  {
	    "commit": "6d5d36a1380d3b4b4b6ddba71828825ef942975b",
	    "change_groups": [
	      {
	        "summary": "Update Round 16 audit note wording to explicitly include TAG_CLAIMING liveness hardening as part of the round's scope.",
	        "categories": [
	          5,
	          9
	        ],
	        "primary_category": 5,
	        "confidence": 0.9,
	        "evidence": [
	          "Footer audit note now mentions early pid/birth publication and forbidding reclaim of live claimers."
	        ],
	        "changed_headings": [
	          "Document version footer"
	        ]
	      }
	    ]
	  }
		];

      const CSS_CACHE = new Map();
      function getCss(varName) {
        if (CSS_CACHE.has(varName)) return CSS_CACHE.get(varName);
        const v = getComputedStyle(document.documentElement).getPropertyValue(varName).trim();
        CSS_CACHE.set(varName, v);
        return v;
      }

      // -----------------------------
      // Buckets
      // -----------------------------

      const BUCKETS = [
        {
          id: 1,
          name: "Logic/Math Fixes",
          desc: "Fixing outright mistakes in logic, math, or reasoning.",
          color: getCss("--c1"),
        },
        {
          id: 2,
          name: "SQLite Legacy Corrections",
          desc: "Fixing inaccurate statements about the C SQLite codebase or semantics.",
          color: getCss("--c2"),
        },
        {
          id: 3,
          name: "asupersync Corrections",
          desc: "Fixing inaccurate statements about asupersync APIs or behavior.",
          color: getCss("--c3"),
        },
        {
          id: 4,
          name: "Architecture Fixes",
          desc: "Fixing conceptual errors or architectural mistakes.",
          color: getCss("--c4"),
        },
        {
          id: 5,
          name: "Scrivening",
          desc: "Ministerial fixes: numbering, references, footers, wording cleanup.",
          color: getCss("--c5"),
        },
        {
          id: 6,
          name: "Added Context",
          desc: "Added background information to make the spec more self-contained.",
          color: getCss("--c6"),
        },
        {
          id: 7,
          name: "Standard Engineering",
          desc: "Improvements based on standard computer engineering: cache, concurrency, I/O, durability mechanics.",
          color: getCss("--c7"),
        },
        {
          id: 8,
          name: "Alien Artifact Math",
          desc: "Esoteric math/rigor additions: e-processes, conformal, BOCPD, VOI, proofs, bounds.",
          color: getCss("--c8"),
        },
        {
          id: 9,
          name: "Clarification",
          desc: "Clarification/elaboration without substantive improvements or fixes.",
          color: getCss("--c9"),
        },
        {
          id: 10,
          name: "Other",
          desc: "Catch-all category.",
          color: getCss("--c10"),
        },
      ];

      // Story Mode: Milestone Schema + Curated Data (bd-24q.4.1)
      const MILESTONES = [
        { id: "genesis", title: "Genesis: 8,628 Lines", commitHash: "c08f160", annotationMd: "The spec is born. A single massive commit lays down the entire architectural blueprint: MVCC page-level versioning, RaptorQ erasure coding, asupersync integration, and the 23-crate workspace structure.", defaultTab: "spec" },
        { id: "ssi-promotion", title: "SSI Promoted to V1", commitHash: "f9d88aa", annotationMd: "Serializable Snapshot Isolation promoted from future goal to V1 requirement. Intent logs, sharded lock tables, and the conservative Page-SSI rule introduced.", focusHeading: "serializable-snapshot-isolation-ssi", defaultTab: "diff" },
        { id: "scope-doctrine", title: "V1.3: Scope Doctrine", commitHash: "9800b17", annotationMd: "\"There is no V1 scope\" \u2014 everything ships. ECS substrate, multi-process MVCC, encryption, WindowsVfs all mandatory.", defaultTab: "diff" },
        { id: "codex-synthesis", title: "V1.4: Codex Synthesis", commitHash: "5ad3487", annotationMd: "Codex (GPT-5.3) spec merged. RaptorQ pervasive: WAL sidecar, ECS layout, replication. Spec crosses 9,000 lines.", defaultTab: "diff" },
        { id: "alien-artifact", title: "V1.5: Alien-Artifact Discipline", commitHash: "7b2c677", annotationMd: "Decision-theoretic rigor: BOCPD, e-process monitoring, conformal calibration. SSI abort gets formal loss matrix. Spec crosses 10,000 lines.", focusHeading: "decision-theoretic-ssi-abort-policy", defaultTab: "diff" },
        { id: "witness-plane", title: "V1.6a: RaptorQ Witness Plane", commitHash: "bf04264", annotationMd: "SSI gains RaptorQ-native witness plane for cross-process proof-carrying commits.", defaultTab: "diff" },
        { id: "perf-optimizations", title: "V1.6c: Performance Hardening", commitHash: "e8ddf46", annotationMd: "Arena allocators, CAR/CLOCK-Pro cache, per-invariant e-process calibration. Cache-line alignment scrutiny.", defaultTab: "diff" },
        { id: "canonical-ssi", title: "V1.6g: Canonical SSI Algorithm", commitHash: "643c89c", annotationMd: "SSI detection algorithm reaches final form. Canonical proof-carrying commit with eager abort.", defaultTab: "diff" },
        { id: "deep-audit-mvcc", title: "V1.7: MVCC Deep Audit", commitHash: "d7b38ef", annotationMd: "Word-by-word audit of Section 5 (~3,000 lines). Finds SSI incoming-edge false negative. RecentlyCommittedReadersIndex added.", focusHeading: "mvcc-formal-model", defaultTab: "diff" },
        { id: "deep-audit-raptorq", title: "V1.7e: RaptorQ Deep Audit", commitHash: "3cf0f13", annotationMd: "Section 3 audit: MTU/sub-blocking fixes, ESI/ISI confusion, OTI.T u16\u2192u32. GF(256) verified against RFC 6330.", defaultTab: "diff" },
        { id: "deep-audit-query", title: "V1.7h: Query Pipeline Audit", commitHash: "2f0970b", annotationMd: "Section 10: lexer DQS, cost model, UPDATE trace. Ne/BangEq fixed. ESCAPE removed from Pratt table.", defaultTab: "diff" },
        { id: "deep-audit-fts5", title: "V1.7j: FTS5 + SQL Coverage", commitHash: "a3e7ae5", annotationMd: "Section 14: FTS5 NOT binary-only. Full section-by-section audit coverage reached.", defaultTab: "diff" },
      ];
      /** Resolve milestones against loaded commit data. Call after ALL_COMMITS is populated. */
      function getMilestones() {
        if (!ALL_COMMITS || !ALL_COMMITS.length) return [];
        const hashToIdx = new Map();
        for (let i = 0; i < ALL_COMMITS.length; i++) {
          const c = ALL_COMMITS[i];
          hashToIdx.set(c.hash, i);
          if (c.short) hashToIdx.set(c.short, i);
        }
        return MILESTONES.map((m) => {
          const idx = hashToIdx.get(m.commitHash) ?? null;
          if (idx === null) console.warn(`Milestone "${m.id}": commit ${m.commitHash} not found`);
          return { ...m, commitIdx: idx, warning: idx === null ? `commit ${m.commitHash} not found` : null };
        });
      }

      // -----------------------------
      // App state
      // -----------------------------

      const STATE = {
        q: "",
        minImpact: 0,
        bucketMode: "primary", // 'primary' | 'multi'
        bucketEnabled: new Set(BUCKETS.map((b) => b.id)),
      };

      // -----------------------------
      // Spec evolution dataset (local)
      // -----------------------------

      const SPEC_EVOLUTION_DATA_URL = "spec_evolution_data_v1.json.gz";

      const DATASET = {
        data: null,
        loaded: false,
        error: null,
      };

      const DOC = {
        idx: 0,
        tab: "spec", // 'spec' | 'diff' | 'metrics'
        rawSpec: false,
        diffMode: "pretty", // 'pretty' | 'raw'
        compareMode: false, // true = A/B compare between two arbitrary commits
        compareFromIdx: 0, // "A" commit index
        compareToIdx: 0, // "B" commit index
        diffLayout: "side-by-side", // 'side-by-side' | 'line-by-line'
        diffCollapse: true, // collapse unchanged context in A/B diffs
        abViewMode: "diff", // 'diff' | 'rendered' — diff shows Diff2Html, rendered shows side-by-side markdown panes
        sbsSyncScroll: true, // sync scroll between side-by-side panes
        sbsMobilePane: "a", // 'a' | 'b' — which pane visible on mobile portrait
      };

      const METRICS = {
        // commit hash -> metric
        tokensChanged: new Map(),
        bytesChanged: new Map(),
        hunks: new Map(),
        lev: new Map(),
      };

      const DOC_CACHE = new Map(); // idx -> { text: string, lines?: string[] }

      const OUTLINE_CACHE = new Map(); // idx -> outline[]

      const LEV_WASM_URL = "levenshtein_bytes.wasm";
      let LEV_WASM = null;

      const WORKER_STATE = {
        worker: null,
        ready: false,
        disabled: false,
        reqSeq: 1,
        pending: new Map(), // reqId -> { resolve, reject, onProgress, timeoutId }
        datasetHash: "",
      };

      const WORKER_DERIVED = {
        searchReady: false,
        clusterReady: false,
        phase: null,
        phaseKey: "",
        outliers: null,
        outlierKey: "",
      };

      let COMPUTE_ABORT_CONTROLLER = null;
      let PHASE_ABORT_CONTROLLER = null;
      let OUTLIER_ABORT_CONTROLLER = null;

      // -----------------------------
      // URL State Schema (Permalinks) — v1
      // -----------------------------
      // Canonical param order: v, c, t, raw, dm, q, mi, bm, b
      // Default values are omitted for minimal URLs.
      // Invalid values are clamped or reset to defaults.

      const URL_SCHEMA_VERSION = 1;

      const URL_DEFAULTS = {
        c: -1,          // commit index; -1 means "latest"
        t: "spec",      // tab: spec | diff | metrics
        raw: false,     // raw spec toggle
        dm: "pretty",   // diff mode: pretty | raw
        q: "",          // search query
        mi: 0,          // minimum impact filter
        bm: "primary",  // bucket mode: primary | multi
        b: null,        // enabled bucket ids; null = all
        res: "commit",  // stack chart resolution: commit | day | hour | 15m | 5m
        tz: "local",    // timezone mode: local | utc
        met: "groups",  // stack chart metric: groups | lines | tokens | lev
      };

      const URL_VALID_TABS = new Set(["spec", "diff", "metrics", "sections"]);
      const URL_VALID_DIFF_MODES = new Set(["pretty", "raw"]);
      const URL_VALID_BUCKET_MODES = new Set(["primary", "multi"]);
      const URL_VALID_RESOLUTIONS = new Set(["commit", "day", "hour", "15m", "5m"]);
      const URL_VALID_TZ_MODES = new Set(["local", "utc"]);
      const URL_VALID_METRICS = new Set(["groups", "lines", "tokens", "lev"]);
      const URL_ALL_BUCKET_IDS = new Set(BUCKETS.map((b) => b.id));

      function encodeUrlState() {
        const p = new URLSearchParams();
        const maxIdx = Math.max(0, (ALL_COMMITS?.length || 1) - 1);

        // Always include version when any non-default param is present.
        // We build params first, then prepend v= if non-empty.

        if (DOC.idx !== maxIdx && DOC.idx >= 0) p.set("c", String(DOC.idx));
        if (DOC.tab !== URL_DEFAULTS.t && URL_VALID_TABS.has(DOC.tab)) p.set("t", DOC.tab);
        if (DOC.rawSpec) p.set("raw", "1");
        if (DOC.diffMode !== URL_DEFAULTS.dm && URL_VALID_DIFF_MODES.has(DOC.diffMode)) p.set("dm", DOC.diffMode);
        if (STATE.q) p.set("q", STATE.q);
        if (STATE.minImpact > 0) p.set("mi", String(STATE.minImpact));
        if (STATE.bucketMode !== URL_DEFAULTS.bm) p.set("bm", STATE.bucketMode);

        // Stack chart resolution, timezone, metric (bd-24q.12.2).
        const resSel = document.getElementById("stackResolution");
        const tzSel = document.getElementById("stackTimezone");
        const metSel = document.getElementById("stackMetric");
        const curRes = resSel?.value || URL_DEFAULTS.res;
        const curTz = tzSel?.value || URL_DEFAULTS.tz;
        const curMet = metSel?.value || URL_DEFAULTS.met;
        if (curRes !== URL_DEFAULTS.res) p.set("res", curRes);
        if (curTz !== URL_DEFAULTS.tz) p.set("tz", curTz);
        if (curMet !== URL_DEFAULTS.met) p.set("met", curMet);

        // Encode enabled buckets only if not all are enabled.
        const allEnabled = URL_ALL_BUCKET_IDS.size === STATE.bucketEnabled.size &&
          [...URL_ALL_BUCKET_IDS].every((id) => STATE.bucketEnabled.has(id));
        if (!allEnabled) {
          const sorted = [...STATE.bucketEnabled].sort((a, b) => a - b);
          p.set("b", sorted.join(","));
        }

        // Canonical ordering: rebuild with v first, then alphabetical key order.
        if ([...p.keys()].length === 0) return "";
        const canon = new URLSearchParams();
        canon.set("v", String(URL_SCHEMA_VERSION));
        // Canonical key order: v, c, t, raw, dm, cmp, ca, cb, dl, avm, q, mi, bm, b, res, tz, met
        if (DOC.compareMode) { p.set("cmp", "1"); p.set("ca", String(DOC.compareFromIdx)); p.set("cb", String(DOC.compareToIdx)); if (DOC.diffLayout !== "side-by-side") p.set("dl", DOC.diffLayout); if (DOC.abViewMode === "rendered") p.set("avm", "rendered"); }
        for (const k of ["c", "t", "raw", "dm", "cmp", "ca", "cb", "dl", "avm", "q", "mi", "bm", "b", "res", "tz", "met"]) {
          if (p.has(k)) canon.set(k, p.get(k));
        }
        return canon.toString();
      }

      function decodeUrlState(search) {
        const p = new URLSearchParams(search || "");
        if (!p.has("v")) return null; // No URL state present.

        const v = Number(p.get("v"));
        if (v !== URL_SCHEMA_VERSION) return null; // Unknown schema version; ignore.

        const result = {};

        // Commit index.
        if (p.has("c")) {
          const raw = Number(p.get("c"));
          result.c = Number.isFinite(raw) && raw >= 0 ? Math.floor(raw) : URL_DEFAULTS.c;
        } else {
          result.c = URL_DEFAULTS.c;
        }

        // Tab.
        const tab = p.get("t") || URL_DEFAULTS.t;
        result.t = URL_VALID_TABS.has(tab) ? tab : URL_DEFAULTS.t;

        // Raw spec.
        result.raw = p.get("raw") === "1";

        // Diff mode.
        const dm = p.get("dm") || URL_DEFAULTS.dm;
        result.dm = URL_VALID_DIFF_MODES.has(dm) ? dm : URL_DEFAULTS.dm;

        // Search query.
        result.q = p.get("q") || URL_DEFAULTS.q;

        // Min impact.
        if (p.has("mi")) {
          const mi = Number(p.get("mi"));
          result.mi = Number.isFinite(mi) && mi >= 0 ? Math.floor(mi) : URL_DEFAULTS.mi;
        } else {
          result.mi = URL_DEFAULTS.mi;
        }

        // Bucket mode.
        const bm = p.get("bm") || URL_DEFAULTS.bm;
        result.bm = URL_VALID_BUCKET_MODES.has(bm) ? bm : URL_DEFAULTS.bm;

        // Enabled buckets.
        if (p.has("b")) {
          const ids = p.get("b").split(",")
            .map((s) => Number(s.trim()))
            .filter((n) => Number.isFinite(n) && URL_ALL_BUCKET_IDS.has(n));
          result.b = ids.length > 0 ? new Set(ids) : new Set(URL_ALL_BUCKET_IDS);
        } else {
          result.b = null; // null = all enabled
        }

        // Stack chart resolution, timezone, metric (bd-24q.12.2).
        const res = p.get("res") || URL_DEFAULTS.res;
        result.res = URL_VALID_RESOLUTIONS.has(res) ? res : URL_DEFAULTS.res;
        const tz = p.get("tz") || URL_DEFAULTS.tz;
        result.tz = URL_VALID_TZ_MODES.has(tz) ? tz : URL_DEFAULTS.tz;
        const met = p.get("met") || URL_DEFAULTS.met;
        result.met = URL_VALID_METRICS.has(met) ? met : URL_DEFAULTS.met;

        // A/B Compare mode.
        result.cmp = p.get("cmp") === "1";
        if (result.cmp) {
          const ca = Number(p.get("ca")); result.ca = Number.isFinite(ca) && ca >= 0 ? Math.floor(ca) : 0;
          const cb = Number(p.get("cb")); result.cb = Number.isFinite(cb) && cb >= 0 ? Math.floor(cb) : 0;
          const dl = p.get("dl") || "side-by-side";
          result.dl = (dl === "line-by-line") ? "line-by-line" : "side-by-side";
          result.avm = p.get("avm") || "diff";
        }

        return result;
      }

      function applyUrlState(s) {
        if (!s) return;
        const maxIdx = Math.max(0, (ALL_COMMITS?.length || 1) - 1);

        // Commit index: -1 means latest, otherwise clamp.
        DOC.idx = s.c < 0 ? maxIdx : clamp(s.c, 0, maxIdx);
        DOC.tab = s.t;
        DOC.rawSpec = s.raw;
        DOC.diffMode = s.dm;
        STATE.q = s.q;
        STATE.minImpact = s.mi;
        STATE.bucketMode = s.bm;
        STATE.bucketEnabled = s.b ? new Set(s.b) : new Set(URL_ALL_BUCKET_IDS);
        if (s.cmp) { DOC.compareMode = true; DOC.compareFromIdx = clamp(s.ca || 0, 0, maxIdx); DOC.compareToIdx = clamp(s.cb || 0, 0, maxIdx); DOC.diffLayout = s.dl || "side-by-side"; DOC.abViewMode = s.avm === "rendered" ? "rendered" : "diff"; }

        // Sync UI inputs to match restored state.
        const qEl = document.getElementById("q");
        const qMob = document.getElementById("qMobile");
        if (qEl) qEl.value = STATE.q;
        if (qMob) qMob.value = STATE.q;

        const impactEl = document.getElementById("impact");
        const impactMob = document.getElementById("impactMobile");
        if (impactEl) impactEl.value = String(STATE.minImpact);
        if (impactMob) impactMob.value = String(STATE.minImpact);

        // Restore stack chart controls from URL state (bd-24q.12.2).
        const resSel = document.getElementById("stackResolution");
        const tzSel = document.getElementById("stackTimezone");
        const metSel = document.getElementById("stackMetric");
        if (resSel && s.res) resSel.value = s.res;
        if (tzSel && s.tz) tzSel.value = s.tz;
        if (metSel && s.met) metSel.value = s.met;
      }

      let _urlSyncScheduled = false;

      function syncUrlToState(opts = {}) {
        // Debounce: avoid thrashing history on rapid slider moves.
        if (_urlSyncScheduled && !opts.immediate) return;
        _urlSyncScheduled = true;
        requestAnimationFrame(() => {
          _urlSyncScheduled = false;
          const qs = encodeUrlState();
          const newUrl = qs ? `${location.pathname}?${qs}` : location.pathname;
          if (location.search !== (qs ? `?${qs}` : "")) {
            history.replaceState(null, "", newUrl);
          }
        });
      }

      function copyPermalink() {
        const qs = encodeUrlState();
        const url = qs
          ? `${location.origin}${location.pathname}?${qs}`
          : `${location.origin}${location.pathname}`;
        if (navigator.clipboard?.writeText) {
          navigator.clipboard.writeText(url).then(() => {
            showCopyToast("Link copied");
          }, () => {
            fallbackCopy(url);
          });
        } else {
          fallbackCopy(url);
        }
      }

      function fallbackCopy(text) {
        const ta = document.createElement("textarea");
        ta.value = text;
        ta.style.position = "fixed";
        ta.style.opacity = "0";
        document.body.appendChild(ta);
        ta.select();
        try {
          document.execCommand("copy");
          showCopyToast("Link copied");
        } catch {
          showCopyToast("Copy failed");
        }
        document.body.removeChild(ta);
      }

      function showCopyToast(msg) {
        const btn = document.getElementById("btnCopyLink");
        if (!btn) return;
        const orig = btn.textContent;
        btn.textContent = msg;
        btn.classList.add("bg-emerald-600", "text-white");
        btn.classList.remove("bg-white/70", "text-slate-900");
        setTimeout(() => {
          btn.textContent = orig;
          btn.classList.remove("bg-emerald-600", "text-white");
          btn.classList.add("bg-white/70", "text-slate-900");
        }, 1500);
      }

      function toggleShareHelp() {
        const el = document.getElementById("shareHelpPopover");
        if (el) el.classList.toggle("hidden");
      }

      // -----------------------------
      // Helpers
      // -----------------------------

      function clamp(n, lo, hi) {
        return Math.max(lo, Math.min(hi, n));
      }

      function escapeHtml(s) {
        return String(s)
          .replaceAll("&", "&amp;")
          .replaceAll("<", "&lt;")
          .replaceAll(">", "&gt;")
          .replaceAll('"', "&quot;")
          .replaceAll("'", "&#39;");
      }

      function fmtInt(n) {
        return Intl.NumberFormat(undefined).format(n);
      }

      function debounce(fn, ms) {
        let t;
        return function (...args) {
          clearTimeout(t);
          t = setTimeout(() => fn.apply(this, args), ms);
        };
      }

      function parseCommitLog() {
        const d = DATASET.data;
        if (d && Array.isArray(d.commits) && d.commits.length) {
          return d.commits.map((c, idx) => {
            return {
              idx,
              hash: c.hash,
              short: c.short,
              dateIso: c.dateIso,
              author: c.author,
              subject: c.subject,
              url: `https://github.com/Dicklesworthstone/frankensqlite/commit/${c.hash}`,
            };
          });
        }

        const rows = COMMIT_LOG_RAW.trim()
          .split("\n")
          .map((l) => l.trim())
          .filter(Boolean);
        return rows.map((r, idx) => {
          const [hash, short, dateIso, author, subject] = r.split("|").map((x) => x.trim());
          return {
            idx,
            hash,
            short,
            dateIso,
            author,
            subject,
            url: `https://github.com/Dicklesworthstone/frankensqlite/commit/${hash}`,
          };
        });
      }

      function parseCommitStats() {
        const d = DATASET.data;
        if (d && Array.isArray(d.commits) && d.commits.length) {
          const m = new Map();
          for (const c of d.commits) {
            const a = Number(c.add || 0);
            const del = Number(c.del || 0);
            m.set(c.hash, { add: a, del, impact: a + del });
          }
          return m;
        }

        const rows = COMMIT_STATS_RAW.trim()
          .split("\n")
          .map((l) => l.trim())
          .filter(Boolean);
        const m = new Map();
        for (const r of rows) {
          const [hash, add, del] = r.split("|").map((x) => x.trim());
          const a = Number(add || 0);
          const d = Number(del || 0);
          m.set(hash, { add: a, del: d, impact: a + d });
        }
        return m;
      }

      function formatErr(e) {
        const name = e?.name || "Error";
        const message = e?.message || String(e || "Unknown error");
        const stack = e?.stack ? String(e.stack) : "";
        return stack ? `${name}: ${message}\n${stack}` : `${name}: ${message}`;
      }

      function setWorkerStatus(text, tone = "neutral", detail = "") {
        const el = document.getElementById("workerStatus");
        if (!el) return;
        el.textContent = text || "";
        el.title = detail ? String(detail) : "";
        if (tone === "error") {
          el.className = "mt-2 text-xs font-semibold text-rose-700";
        } else if (tone === "ok") {
          el.className = "mt-2 text-xs font-semibold text-emerald-700";
        } else {
          el.className = "mt-2 text-xs text-slate-500";
        }
      }

      function supportsAnalysisWorker() {
        return typeof Worker !== "undefined" && typeof URL !== "undefined" && typeof Blob !== "undefined";
      }

      function toHex(buf) {
        return Array.from(new Uint8Array(buf))
          .map((b) => b.toString(16).padStart(2, "0"))
          .join("");
      }

      async function computeDatasetHash(data) {
        const commitHashes = Array.isArray(data?.commits) ? data.commits.map((c) => String(c.hash || "")) : [];
        const patchSizes = Array.isArray(data?.patches) ? data.patches.map((p) => String((p || "").length)) : [];
        const basis = `${String(data?.base_doc || "").length}|${commitHashes.join(",")}|${patchSizes.join(",")}`;
        const enc = new TextEncoder().encode(basis);
        if (crypto?.subtle?.digest) {
          const dig = await crypto.subtle.digest("SHA-256", enc);
          return toHex(dig);
        }
        // Fallback hash (djb2 xor), deterministic but non-cryptographic.
        let h = 5381;
        for (let i = 0; i < basis.length; i++) {
          h = ((h << 5) + h) ^ basis.charCodeAt(i);
        }
        return `djb2-${(h >>> 0).toString(16)}`;
      }

      function makeAnalysisWorkerSource() {
        return `
          const LEV_WASM_URL = ${JSON.stringify(LEV_WASM_URL)};
          const STATE = {
            dataset: null,
            datasetHash: "",
            patchHunks: [],
            snapshotCache: new Map(),
            snapshotCursorIdx: 0,
            snapshotCursorLines: null,
            levWasm: null,
            searchIndex: null,
            clusterData: null,
            minhashSignatures: null,
          };
          const CANCELLED_REQS = new Set();

          class AbortErr extends Error {
            constructor(message) {
              super(message || "Request cancelled");
              this.name = "AbortError";
            }
          }

          function isCancelled(reqId) {
            return CANCELLED_REQS.has(reqId);
          }

          function throwIfCancelled(reqId) {
            if (isCancelled(reqId)) throw new AbortErr("Request cancelled by main thread");
          }

          function serializeError(err) {
            return {
              name: err?.name || "Error",
              message: err?.message || String(err || "Unknown error"),
              stack: err?.stack ? String(err.stack) : "",
            };
          }

          function countRoughTokens(s) {
            let n = 0;
            const re = /[A-Za-z0-9_]+|[^\\s]/g;
            while (re.exec(String(s))) n++;
            return n;
          }

          function parseUnifiedHunks(patch) {
            const lines = String(patch || "").split("\\n");
            const hunks = [];
            for (let i = 0; i < lines.length; i++) {
              const line = lines[i];
              if (!line.startsWith("@@")) continue;
              const m = /^@@ -(\\\\d+)(?:,(\\\\d+))? \\\\+(\\\\d+)(?:,(\\\\d+))? @@/.exec(line);
              if (!m) continue;
              const oldStart = Number(m[1]);
              const oldCount = Number(m[2] || "1");
              const newStart = Number(m[3]);
              const newCount = Number(m[4] || "1");
              const hunkLines = [];
              i++;
              for (; i < lines.length; i++) {
                const l = lines[i];
                if (l.startsWith("@@")) {
                  i--;
                  break;
                }
                if (l.startsWith("diff --git")) break;
                if (l.startsWith("index ") || l.startsWith("---") || l.startsWith("+++")) continue;
                hunkLines.push(l);
              }
              hunks.push({ oldStart, oldCount, newStart, newCount, lines: hunkLines });
            }
            return hunks;
          }

          function quickMetricsFromPatch(patch) {
            const lines = String(patch || "").split("\\n");
            let hunks = 0;
            let addLines = 0;
            let delLines = 0;
            let tokAdd = 0;
            let tokDel = 0;
            let bytesAdd = 0;
            let bytesDel = 0;
            for (const l of lines) {
              if (l.startsWith("@@")) hunks += 1;
              if (l.startsWith("+")) {
                if (l.startsWith("+++")) continue;
                addLines += 1;
                const s = l.slice(1);
                tokAdd += countRoughTokens(s);
                bytesAdd += s.length + 1;
              } else if (l.startsWith("-")) {
                if (l.startsWith("---")) continue;
                delLines += 1;
                const s = l.slice(1);
                tokDel += countRoughTokens(s);
                bytesDel += s.length + 1;
              }
            }
            return {
              hunks,
              addLines,
              delLines,
              tokensChanged: tokAdd + tokDel,
              bytesChanged: bytesAdd + bytesDel,
              tokensDelta: tokAdd - tokDel,
              bytesDelta: bytesAdd - bytesDel,
            };
          }

          function clamp(n, lo, hi) {
            return Math.max(lo, Math.min(hi, n));
          }

          function applyPatchLines(prevLines, patch) {
            const hunks = parseUnifiedHunks(patch);
            let out = prevLines.slice();
            let offset = 0;
            for (const h of hunks) {
              let at = (h.oldStart - 1) + offset;
              at = clamp(at, 0, out.length);
              let cursor = at;
              const next = [];
              for (const hl of h.lines) {
                if (!hl) continue;
                const p = hl[0];
                const content = hl.slice(1);
                if (p === " ") {
                  next.push(content);
                  cursor += 1;
                } else if (p === "-") {
                  cursor += 1;
                } else if (p === "+") {
                  next.push(content);
                }
              }
              out.splice(at, cursor - at, ...next);
              offset += next.length - (cursor - at);
            }
            return out;
          }

          function patchForIdx(idx) {
            const d = STATE.dataset;
            if (!d || !Array.isArray(d.patches)) return "";
            return d.patches[idx] || "";
          }

          function docTextAtLocal(idx, reqId, progressCb) {
            const d = STATE.dataset;
            if (!d) return "";
            if (idx <= 0) return String(d.base_doc || "");
            const cached = STATE.snapshotCache.get(idx);
            if (typeof cached === "string") return cached;

            if (STATE.snapshotCursorLines && idx === STATE.snapshotCursorIdx + 1) {
              throwIfCancelled(reqId);
              const nextLines = applyPatchLines(STATE.snapshotCursorLines, patchForIdx(idx));
              STATE.snapshotCursorIdx = idx;
              STATE.snapshotCursorLines = nextLines;
              const text = nextLines.join("\\n");
              STATE.snapshotCache.set(idx, text);
              return text;
            }

            let anchor = 0;
            for (let j = idx - 1; j > 0; j--) {
              if (STATE.snapshotCache.has(j)) {
                anchor = j;
                break;
              }
            }

            let lines = String(d.base_doc || "").split("\\n");
            if (anchor > 0) lines = String(STATE.snapshotCache.get(anchor) || "").split("\\n");

            for (let k = Math.max(1, anchor + 1); k <= idx; k++) {
              throwIfCancelled(reqId);
              lines = applyPatchLines(lines, patchForIdx(k));
              if (k === idx || k % 10 === 0) {
                STATE.snapshotCache.set(k, lines.join("\\n"));
              }
              if (progressCb && (k % 8 === 0 || k === idx)) {
                progressCb({ stage: "snapshot", done: k, total: idx, message: "Reconstructing snapshot" });
              }
            }

            STATE.snapshotCursorIdx = idx;
            STATE.snapshotCursorLines = lines;
            const out = STATE.snapshotCache.get(idx) || lines.join("\\n");
            STATE.snapshotCache.set(idx, out);
            return out;
          }

          async function initLevWasm() {
            if (STATE.levWasm) return STATE.levWasm;
            const res = await fetch(LEV_WASM_URL, { cache: "force-cache" });
            if (!res.ok) throw new Error("Failed to fetch " + LEV_WASM_URL + ": HTTP " + res.status);
            const buf = await res.arrayBuffer();
            const { instance } = await WebAssembly.instantiate(buf, {});
            STATE.levWasm = instance.exports;
            return STATE.levWasm;
          }

          async function levenshteinBytes(aBytes, bBytes) {
            const ex = await initLevWasm();
            const memory = ex.memory;
            const alloc = ex.alloc;
            const dealloc = ex.dealloc;
            const levenshtein = ex.levenshtein;
            if (!memory || !alloc || !dealloc || !levenshtein) {
              throw new Error("WASM exports missing (memory/alloc/dealloc/levenshtein)");
            }
            const a = aBytes || new Uint8Array();
            const b = bBytes || new Uint8Array();
            const ptrA = alloc(a.length);
            const viewA = new Uint8Array(memory.buffer, ptrA, a.length);
            viewA.set(a);
            const ptrB = alloc(b.length);
            const viewB = new Uint8Array(memory.buffer, ptrB, b.length);
            viewB.set(b);
            const d = levenshtein(ptrA, a.length, ptrB, b.length) >>> 0;
            dealloc(ptrA, a.length);
            dealloc(ptrB, b.length);
            return d;
          }

          async function levenshteinForPatch(patch, reqId) {
            const hunks = parseUnifiedHunks(patch);
            const enc = new TextEncoder();
            let sum = 0;
            for (const h of hunks) {
              throwIfCancelled(reqId);
              const oldLines = [];
              const newLines = [];
              for (const hl of h.lines) {
                if (!hl) continue;
                const p = hl[0];
                const content = hl.slice(1);
                if (p === "-") oldLines.push(content);
                if (p === "+") newLines.push(content);
              }
              if (!oldLines.length && !newLines.length) continue;
              const a = enc.encode(oldLines.join("\\n"));
              const b = enc.encode(newLines.join("\\n"));
              if (a.length > 20000 || b.length > 20000) {
                sum += a.length + b.length;
              } else {
                sum += await levenshteinBytes(a, b);
              }
            }
            return sum;
          }

          function slugifyHeadingW(text) {
            return String(text || "")
              .toLowerCase()
              .replace(/[^a-z0-9\\u00C0-\\u024F]+/g, "-")
              .replace(/^-+|-+$/g, "")
              || "heading";
          }

          function extractOutlineWorker(markdownText) {
            const lines = String(markdownText || "").split("\\n");
            const outline = [];
            const slugCounts = new Map();
            const atxRe = /^(#{1,6})\\s+(.+?)\\s*$/;
            let inFence = false;
            for (let li = 0; li < lines.length; li++) {
              const line = lines[li];
              if (line.startsWith("\`\`\`")) {
                inFence = !inFence;
                continue;
              }
              if (inFence) continue;
              const m = atxRe.exec(line);
              if (!m) continue;
              const level = m[1].length;
              const text = m[2].replace(/\\s+#+\\s*$/, "");
              const baseSlug = slugifyHeadingW(text);
              const count = slugCounts.get(baseSlug) || 0;
              slugCounts.set(baseSlug, count + 1);
              const id = count === 0 ? baseSlug : baseSlug + "-" + count;
              outline.push({ text: text.trim(), level, id, line: li + 1 });
            }
            return outline;
          }

          function buildLineToHeadingMapW(totalLines, outline) {
            const map = new Array(totalLines + 1);
            map[0] = "__preamble__";
            let ptr = 0;
            let currentId = "__preamble__";
            for (let ln = 1; ln <= totalLines; ln++) {
              while (ptr < outline.length && outline[ptr].line != null && outline[ptr].line <= ln) {
                currentId = outline[ptr].id;
                ptr++;
              }
              map[ln] = currentId;
            }
            return map;
          }

          function attributeHunksToHeadingsW(patch, lineToHeading) {
            const hunks = parseUnifiedHunks(patch);
            const metrics = {};
            for (const hunk of hunks) {
              let newLineNum = hunk.newStart;
              for (const hl of hunk.lines) {
                if (!hl) continue;
                const p = hl[0];
                const content = hl.slice(1);
                const hid = lineToHeading[newLineNum] || "__preamble__";
                if (!metrics[hid]) metrics[hid] = { addLines: 0, delLines: 0, tokensAdded: 0, tokensDeleted: 0 };
                if (p === "+") {
                  metrics[hid].addLines++;
                  metrics[hid].tokensAdded += countRoughTokens(content);
                  newLineNum++;
                } else if (p === "-") {
                  metrics[hid].delLines++;
                  metrics[hid].tokensDeleted += countRoughTokens(content);
                } else if (p === " ") {
                  newLineNum++;
                }
              }
            }
            return metrics;
          }

          // --- Search index (bd-24q.9.1) ---

          // Stemming-lite: strip common English suffixes for better recall.
          function stemLite(w) {
            if (w.length < 5) return w;
            if (w.endsWith("ying")) return w;
            if (w.endsWith("ies") && w.length > 5) return w.slice(0, -3) + "y";
            if (w.endsWith("ness") && w.length > 6) return w.slice(0, -4);
            if (w.endsWith("ment") && w.length > 6) return w.slice(0, -4);
            if (w.endsWith("ing") && w.length > 5) return w.slice(0, -3);
            if (w.endsWith("tion") && w.length > 6) return w.slice(0, -4);
            if (w.endsWith("sion") && w.length > 6) return w.slice(0, -4);
            if (w.endsWith("able") && w.length > 6) return w.slice(0, -4);
            if (w.endsWith("ible") && w.length > 6) return w.slice(0, -4);
            if (w.endsWith("ful") && w.length > 5) return w.slice(0, -3);
            if (w.endsWith("ous") && w.length > 5) return w.slice(0, -3);
            if (w.endsWith("ed") && w.length > 4) return w.slice(0, -2);
            if (w.endsWith("ly") && w.length > 4) return w.slice(0, -2);
            if (w.endsWith("er") && w.length > 4) return w.slice(0, -2);
            if (w.endsWith("es") && w.length > 4) return w.slice(0, -2);
            if (w.endsWith("s") && !w.endsWith("ss") && w.length > 3) return w.slice(0, -1);
            return w;
          }

          function tokenize(text) {
            return String(text || "")
              .toLowerCase()
              .split(/[^a-z0-9_]+/g)
              .filter((x) => x.length >= 2);
          }

          function tokenizeStemmed(text) {
            return tokenize(text).map(stemLite);
          }

          // Extract headings from markdown text (lightweight, for indexing).
          function extractHeadingsForIndex(text) {
            const out = [];
            const lines = String(text || "").split("\\n");
            for (const line of lines) {
              const m = line.match(/^(#{1,6})\\s+(.+)/);
              if (m) out.push(m[2]);
            }
            return out.join(" ");
          }

          // Added lines from a unified diff patch (just the content, not the +-prefix).
          function addedLinesFromPatch(patch) {
            const lines = String(patch || "").split("\\n");
            const out = [];
            for (const line of lines) {
              if (line.startsWith("+") && !line.startsWith("+++")) out.push(line.slice(1));
            }
            return out.join(" ");
          }

          function buildSearchIndex(reqId, progressCb) {
            const commits = STATE.dataset?.commits || [];
            const patches = STATE.dataset?.patches || [];
            const postings = new Map(); // stemmed token -> sorted commitIdx[]
            const docs = []; // per-commit doc record
            const N = commits.length;
            for (let i = 0; i < N; i++) {
              if (reqId && i % 20 === 0) throwIfCancelled(reqId);
              if (progressCb && i % 25 === 0) progressCb({ phase: "indexing", current: i, total: N });
              const c = commits[i];
              // Sources: commit metadata + patch added lines + headings from snapshot.
              const metaText = [c.hash || "", c.short || "", c.author || "", c.subject || ""].join(" ");
              const patchText = addedLinesFromPatch(patches[i] || "");
              // Reconstruct headings from snapshot (if cached; skip full reconstruction for speed).
              const cachedSnapshot = STATE.snapshotCache.get(i);
              const headingText = cachedSnapshot ? extractHeadingsForIndex(cachedSnapshot) : "";
              const fullBody = metaText + " " + patchText + " " + headingText;
              const rawTokens = tokenize(fullBody);
              const stemmedTokens = rawTokens.map(stemLite);
              docs.push({
                i,
                hash: c.hash,
                short: c.short,
                subject: c.subject,
                author: c.author,
                body: metaText + " " + patchText.slice(0, 500), // keep body small for phrase search
              });
              const seen = new Set();
              for (const tok of stemmedTokens) {
                if (seen.has(tok)) continue;
                seen.add(tok);
                let arr = postings.get(tok);
                if (!arr) { arr = []; postings.set(tok, arr); }
                arr.push(i);
              }
            }
            STATE.searchIndex = { postings, docs, version: 2 };
            if (progressCb) progressCb({ phase: "done", current: N, total: N });
            return { docs: docs.length, terms: postings.size };
          }

          // Parse query: extract quoted phrases and plain tokens.
          function parseSearchQuery(q) {
            const phrases = [];
            const tokens = [];
            const stripped = String(q || "").replace(/"([^"]+)"/g, (_, phrase) => {
              phrases.push(phrase.toLowerCase());
              return "";
            });
            tokens.push(...tokenizeStemmed(stripped));
            return { phrases, tokens };
          }

          function querySearch(q, limit) {
            const index = STATE.searchIndex;
            if (!index) return { query: q, hits: [] };
            const { phrases, tokens } = parseSearchQuery(q);
            if (!tokens.length && !phrases.length) return { query: q, hits: [] };

            // Token-based intersection (stemmed).
            let candidate = null;
            for (const t of tokens) {
              const posting = index.postings.get(t) || [];
              const postingSet = new Set(posting);
              candidate = candidate === null ? postingSet : new Set([...candidate].filter((x) => postingSet.has(x)));
            }
            // If only phrases (no tokens), start with all docs.
            if (candidate === null) {
              candidate = new Set();
              for (let i = 0; i < index.docs.length; i++) candidate.add(i);
            }

            // Phrase filter: raw substring scan on doc body.
            if (phrases.length) {
              const next = new Set();
              for (const docId of candidate) {
                const d = index.docs[docId];
                if (!d) continue;
                const bodyLower = d.body.toLowerCase();
                if (phrases.every((p) => bodyLower.includes(p))) next.add(docId);
              }
              candidate = next;
            }

            const out = [];
            for (const docId of candidate) {
              const d = index.docs[docId];
              if (!d) continue;
              let score = 0;
              const bodyLower = d.body.toLowerCase();
              for (const t of tokens) { if (bodyLower.includes(t)) score += 1; }
              for (const p of phrases) { if (bodyLower.includes(p)) score += 2; } // phrases worth more
              out.push({ idx: d.i, hash: d.hash, short: d.short, subject: d.subject, author: d.author, score });
            }
            out.sort((a, b) => b.score - a.score || a.idx - b.idx);
            return { query: q, hits: out.slice(0, Math.max(1, Number(limit || 20))) };
          }

          // Export search index as JSON-serializable object for localStorage persistence (bd-24q.9.1).
          function exportSearchIndex() {
            const index = STATE.searchIndex;
            if (!index) return null;
            // Delta-compress postings lists for storage efficiency.
            const entries = [];
            for (const [tok, idxs] of index.postings) {
              const deltas = [idxs[0]];
              for (let i = 1; i < idxs.length; i++) deltas.push(idxs[i] - idxs[i - 1]);
              entries.push([tok, deltas]);
            }
            return { v: index.version || 2, docs: index.docs, postings: entries };
          }

          // Hydrate search index from serialized data (localStorage cache).
          function hydrateSearchIndex(data) {
            if (!data || data.v !== 2) return false;
            const postings = new Map();
            for (const [tok, deltas] of data.postings) {
              const idxs = [deltas[0]];
              for (let i = 1; i < deltas.length; i++) idxs.push(idxs[i - 1] + deltas[i]);
              postings.set(tok, idxs);
            }
            STATE.searchIndex = { postings, docs: data.docs, version: 2 };
            return true;
          }

          function hash32(seed, str) {
            let h = seed >>> 0;
            for (let i = 0; i < str.length; i++) {
              h ^= str.charCodeAt(i);
              h = Math.imul(h, 16777619);
            }
            return h >>> 0;
          }

          // --- MinHash Signature Pipeline (bd-24q.14.1) ---

          /** Generate deterministic hash seeds from dataset hash for stable MinHash results. */
          function generateMinHashSeeds(datasetHash, sigLen) {
            const seeds = new Uint32Array(sigLen);
            let h = 2166136261 >>> 0;
            const basis = String(datasetHash || "minhash");
            for (let i = 0; i < basis.length; i++) {
              h ^= basis.charCodeAt(i);
              h = Math.imul(h, 16777619);
            }
            for (let i = 0; i < sigLen; i++) {
              h ^= i;
              h = Math.imul(h, 16777619);
              h = (h ^ (h >>> 16)) >>> 0;
              seeds[i] = h;
            }
            return seeds;
          }

          /** Generate character-level k-shingles from text. Returns unique shingle strings. */
          function shingle(text, k) {
            const s = String(text || "").toLowerCase();
            if (s.length < k) return s.length > 0 ? [s] : [];
            const seen = new Set();
            for (let i = 0; i <= s.length - k; i++) {
              seen.add(s.substring(i, i + k));
            }
            return Array.from(seen);
          }

          /**
           * Compute MinHash signatures for all commits (bd-24q.14.1).
           * Sources: diff added lines (primary) + commit subject + author.
           * Options: sigLen (default 64), shingleK (default 5), mode ("full"|"added", default "added").
           */
          function computeMinHashSignatures(reqId, progressCb, options) {
            const commits = STATE.dataset?.commits || [];
            const patches = STATE.dataset?.patches || [];
            const N = commits.length;
            const sigLen = Math.max(8, Number(options?.sigLen || 64));
            const shingleK = Math.max(2, Number(options?.shingleK || 5));
            const mode = options?.mode === "full" ? "full" : "added";
            const seeds = generateMinHashSeeds(STATE.datasetHash, sigLen);
            const sigs = new Uint32Array(N * sigLen);
            const meta = [];
            for (let i = 0; i < N; i++) {
              if (reqId && i % 15 === 0) throwIfCancelled(reqId);
              if (progressCb && i % 20 === 0) progressCb({ phase: "minhash", current: i, total: N });
              const c = commits[i];
              const patchRaw = patches[i] || "";
              const diffText = mode === "full" ? patchRaw : addedLinesFromPatch(patchRaw);
              const text = (c.subject || "") + " " + (c.author || "") + " " + diffText;
              const shingles = shingle(text, shingleK);
              const offset = i * sigLen;
              if (shingles.length === 0) {
                sigs.fill(0xffffffff, offset, offset + sigLen);
              } else {
                for (let s = 0; s < sigLen; s++) {
                  let best = 0xffffffff;
                  const seed = seeds[s];
                  for (const sh of shingles) {
                    const h = hash32(seed, sh);
                    if (h < best) best = h;
                  }
                  sigs[offset + s] = best;
                }
              }
              meta.push({ idx: i, hash: c.hash, short: c.short, subject: c.subject });
            }
            STATE.minhashSignatures = { sigs, meta, sigLen, shingleK, version: 1 };
            if (progressCb) progressCb({ phase: "done", current: N, total: N });
            return { docs: N, sigLen, shingleK };
          }

          /** Export MinHash signatures for localStorage persistence (base64-encoded Uint32Array). */
          function exportMinHashSignatures() {
            const mh = STATE.minhashSignatures;
            if (!mh) return null;
            const bytes = new Uint8Array(mh.sigs.buffer, mh.sigs.byteOffset, mh.sigs.byteLength);
            const chunks = [];
            for (let i = 0; i < bytes.length; i += 8192) {
              chunks.push(String.fromCharCode.apply(null, bytes.subarray(i, i + 8192)));
            }
            const b64 = btoa(chunks.join(""));
            return { v: 1, sigLen: mh.sigLen, shingleK: mh.shingleK, docs: mh.meta.length, meta: mh.meta, sigs_b64: b64 };
          }

          /** Hydrate MinHash signatures from exported localStorage data. */
          function hydrateMinHashSignatures(data) {
            if (!data || data.v !== 1 || !data.sigs_b64) return false;
            const binary = atob(data.sigs_b64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
            const sigs = new Uint32Array(bytes.buffer);
            STATE.minhashSignatures = { sigs, meta: data.meta, sigLen: data.sigLen, shingleK: data.shingleK, version: 1 };
            return true;
          }

          // --- Clustering: Deterministic Grouping + Theme Tags (bd-24q.14.2) ---

          /** Estimate Jaccard similarity from MinHash signature agreement. */
          function minhashJaccard(sigA, sigB, len) {
            let agree = 0;
            for (let i = 0; i < len; i++) { if (sigA[i] === sigB[i]) agree++; }
            return agree / len;
          }

          /** Stable cluster ID: FNV-1a hash of sorted member indices. */
          function clusterStableId(members) {
            let h = 2166136261;
            for (const idx of members) {
              h ^= (idx & 0xff); h = Math.imul(h, 16777619);
              h ^= ((idx >> 8) & 0xff); h = Math.imul(h, 16777619);
              h ^= ((idx >> 16) & 0xff); h = Math.imul(h, 16777619);
            }
            return "cl-" + ((h >>> 0).toString(36));
          }

          /** Extract top-K keywords from texts, excluding stopwords. TF-DF scoring. */
          function extractThemeTags(texts, topK) {
            const STOP = new Set(["the","a","an","and","or","but","in","on","at","to","for","of","is","it","this","that","was","be","with","as","by","from","not","are","were","been","have","has","had","do","does","did","will","would","could","should","may","can","if","then","else","when","while","so","no","all","any","each","which","their","its","they","we","he","she","you","i","my","your","our","his","her","up","out","into","over","also","add","added","remove","removed","change","changed","update","updated","fix","fixed","use","used","new","set","get","make"]);
            const freq = new Map();
            for (const text of texts) {
              const words = tokenize(text);
              const seen = new Set();
              for (const w of words) {
                if (w.length < 3 || STOP.has(w) || /^\d+$/.test(w)) continue;
                if (seen.has(w)) continue;
                seen.add(w);
                freq.set(w, (freq.get(w) || 0) + 1);
              }
            }
            return Array.from(freq.entries())
              .sort((a, b) => b[1] - a[1] || a[0].localeCompare(b[0]))
              .slice(0, topK)
              .map((e) => e[0]);
          }

          function computeClusters(limit, options) {
            const commits = STATE.dataset?.commits || [];
            const patches = STATE.dataset?.patches || [];
            const mh = STATE.minhashSignatures;
            const threshold = (options && options.threshold) || 0.3;
            const maxClusters = Math.max(1, Number(limit || 12));
            const N = commits.length;
            if (!N) { STATE.clusterData = []; return { clusters: [] }; }

            // Build signature array (prefer precomputed MinHash).
            let effectiveSigLen;
            let sigs;
            if (mh && mh.sigs.length >= N * mh.sigLen) {
              sigs = mh.sigs;
              effectiveSigLen = mh.sigLen;
            } else {
              const seeds = [2166136261, 19088743, 591798841, 2654435761, 40503, 734539, 1889, 2651];
              effectiveSigLen = seeds.length;
              sigs = new Uint32Array(N * effectiveSigLen);
              for (let i = 0; i < N; i++) {
                const c = commits[i];
                const tokens = Array.from(new Set(tokenize((c.subject || "") + " " + (c.author || ""))));
                for (let s = 0; s < effectiveSigLen; s++) {
                  let best = 0xffffffff;
                  for (const tok of tokens) { const h = hash32(seeds[s], tok); if (h < best) best = h; }
                  sigs[i * effectiveSigLen + s] = best >>> 0;
                }
              }
            }

            // Step 1: LSH banding to find candidate pairs (avoids O(N^2)).
            const rowsPerBand = Math.max(1, Math.min(4, Math.floor(effectiveSigLen / 4)));
            const numBands = Math.floor(effectiveSigLen / rowsPerBand);
            const candidatePairs = new Set();
            for (let b = 0; b < numBands; b++) {
              const buckets = new Map();
              for (let i = 0; i < N; i++) {
                const start = i * effectiveSigLen + b * rowsPerBand;
                let key = "";
                for (let r = 0; r < rowsPerBand; r++) key += sigs[start + r] + ",";
                let arr = buckets.get(key);
                if (!arr) { arr = []; buckets.set(key, arr); }
                arr.push(i);
              }
              for (const bucket of buckets.values()) {
                if (bucket.length < 2) continue;
                for (let x = 0; x < bucket.length; x++) {
                  for (let y = x + 1; y < bucket.length; y++) {
                    const lo = Math.min(bucket[x], bucket[y]);
                    const hi = Math.max(bucket[x], bucket[y]);
                    candidatePairs.add(lo * N + hi);
                  }
                }
              }
            }

            // Step 2: Single-linkage threshold clustering via Union-Find.
            const parent = new Int32Array(N);
            const ufRank = new Uint8Array(N);
            for (let i = 0; i < N; i++) parent[i] = i;
            function ufFind(x) { while (parent[x] !== x) { parent[x] = parent[parent[x]]; x = parent[x]; } return x; }
            function ufUnion(a, b) {
              a = ufFind(a); b = ufFind(b);
              if (a === b) return;
              if (ufRank[a] < ufRank[b]) { const t = a; a = b; b = t; }
              parent[b] = a;
              if (ufRank[a] === ufRank[b]) ufRank[a]++;
            }

            for (const pairKey of candidatePairs) {
              const hi = pairKey % N;
              const lo = (pairKey - hi) / N;
              const sigI = sigs.subarray(lo * effectiveSigLen, lo * effectiveSigLen + effectiveSigLen);
              const sigJ = sigs.subarray(hi * effectiveSigLen, hi * effectiveSigLen + effectiveSigLen);
              if (minhashJaccard(sigI, sigJ, effectiveSigLen) >= threshold) ufUnion(lo, hi);
            }

            // Step 3: Collect clusters (min size 2), sort deterministically.
            const groups = new Map();
            for (let i = 0; i < N; i++) {
              const root = ufFind(i);
              let g = groups.get(root);
              if (!g) { g = []; groups.set(root, g); }
              g.push(i);
            }
            let clusterList = [];
            for (const members of groups.values()) {
              if (members.length < 2) continue;
              members.sort((a, b) => a - b);
              clusterList.push(members);
            }
            clusterList.sort((a, b) => b.length - a.length || a[0] - b[0]);
            clusterList = clusterList.slice(0, maxClusters);

            // Step 4: Medoid selection + theme tags per cluster.
            const clusters = clusterList.map((members) => {
              let bestMedoid = members[0];
              let bestAvg = -1;
              if (members.length <= 50) {
                for (const m of members) {
                  let sum = 0;
                  const sigM = sigs.subarray(m * effectiveSigLen, m * effectiveSigLen + effectiveSigLen);
                  for (const o of members) {
                    if (o === m) continue;
                    sum += minhashJaccard(sigM, sigs.subarray(o * effectiveSigLen, o * effectiveSigLen + effectiveSigLen), effectiveSigLen);
                  }
                  const avg = sum / (members.length - 1);
                  if (avg > bestAvg) { bestAvg = avg; bestMedoid = m; }
                }
              }
              const memberTexts = members.map((idx) => {
                const c = commits[idx] || {};
                const patch = patches[idx] || "";
                return (c.subject || "") + " " + addedLinesFromPatch(patch);
              });
              const tags = extractThemeTags(memberTexts, 4);
              return {
                id: clusterStableId(members),
                size: members.length,
                medoid: bestMedoid,
                tags,
                items: members.map((idx) => {
                  const c = commits[idx] || {};
                  return { idx, hash: c.hash, short: c.short, subject: c.subject };
                }),
              };
            });

            STATE.clusterData = clusters;
            return { clusters };
          }

          function median(values) {
            const arr = values.slice().sort((a, b) => a - b);
            if (!arr.length) return 0;
            const mid = Math.floor(arr.length / 2);
            if (arr.length % 2) return arr[mid];
            return (arr[mid - 1] + arr[mid]) / 2;
          }

          function computeOutliers(values, topK) {
            const xs = values.map((v) => Number(v || 0));
            const med = median(xs);
            const absDev = xs.map((x) => Math.abs(x - med));
            const mad = median(absDev) || 1e-9;
            const scored = xs.map((x, idx) => {
              const z = 0.6745 * (x - med) / mad;
              return { idx, value: x, z };
            });
            scored.sort((a, b) => Math.abs(b.z) - Math.abs(a.z));
            return { median: med, mad, top: scored.slice(0, Math.max(1, Number(topK || 10))) };
          }


          /** Enhanced robust outlier scoring with stable tie-breaking + evidence (bd-24q.10.1). */
          function computeOutliersRobust(entries, topK) {
            if (!entries.length) return { median: 0, mad: 0, top: [], all: [] };
            const values = entries.map(e => Number(e.value || 0));
            const sorted = values.slice().sort((a, b) => a - b);
            const mid = Math.floor(sorted.length / 2);
            const med = sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
            const absDev = values.map(v => Math.abs(v - med));
            const absSorted = absDev.slice().sort((a, b) => a - b);
            const absMid = Math.floor(absSorted.length / 2);
            const mad = absSorted.length % 2 ? absSorted[absMid] : (absSorted[absMid - 1] + absSorted[absMid]) / 2;
            const madSafe = mad || 1e-9;
            const scored = entries.map((e, i) => ({
              idx: e.idx ?? i, value: values[i],
              z: 0.6745 * (values[i] - med) / madSafe,
              ts: e.ts || "", hash: e.hash || "", buckets: e.buckets || [],
            }));
            scored.sort((a, b) => {
              const dz = Math.abs(b.z) - Math.abs(a.z);
              if (Math.abs(dz) > 1e-12) return dz;
              if (a.ts !== b.ts) return a.ts < b.ts ? -1 : 1;
              return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;
            });
            const k = Math.max(1, Math.min(Number(topK) || 10, scored.length));
            const top = scored.slice(0, k).map(e => ({
              idx: e.idx, value: e.value, z: e.z, ts: e.ts, hash: e.hash, buckets: e.buckets,
              evidence: { value: e.value, median: med, mad, z: e.z, contributingBuckets: e.buckets },
            }));
            return { median: med, mad, top, all: scored.map(e => ({ idx: e.idx, value: e.value, z: e.z })) };
          }

          /** Multi-metric outlier computation (bd-24q.10.1). */
          function computeOutliersMultiMetric(metricSeries, topK) {
            const results = {};
            for (const [name, entries] of Object.entries(metricSeries)) {
              results[name] = computeOutliersRobust(Array.isArray(entries) ? entries : [], topK);
            }
            return results;
          }

          function logAddExp(a, b) {
            if (a === -Infinity) return b;
            if (b === -Infinity) return a;
            const m = Math.max(a, b);
            return m + Math.log(Math.exp(a - m) + Math.exp(b - m));
          }

          function updateWelford(st, x) {
            const n1 = st.n + 1;
            const delta = x - st.mean;
            const mean1 = st.mean + delta / n1;
            const delta2 = x - mean1;
            const m21 = st.m2 + delta * delta2;
            return { n: n1, mean: mean1, m2: m21 };
          }

          function logGamma(z) {
            const p = [
              0.99999999999980993, 676.5203681218851, -1259.1392167224028, 771.32342877765313,
              -176.61502916214059, 12.507343278686905, -0.13857109526572012, 9.9843695780195716e-6,
              1.5056327351493116e-7,
            ];
            if (z < 0.5) {
              return Math.log(Math.PI) - Math.log(Math.sin(Math.PI * z)) - logGamma(1 - z);
            }
            z -= 1;
            let x = p[0];
            for (let i = 1; i < p.length; i++) x += p[i] / (z + i);
            const t = z + 7.5;
            return 0.5 * Math.log(2 * Math.PI) + (z + 0.5) * Math.log(t) - t + Math.log(x);
          }

          function studentTLogPdf(x, mu, sigma, nu) {
            const z = (x - mu) / (sigma || 1e-9);
            return (
              logGamma((nu + 1) / 2) -
              logGamma(nu / 2) -
              Math.log((sigma || 1e-9) * Math.sqrt(nu * Math.PI)) -
              ((nu + 1) / 2) * Math.log(1 + (z * z) / nu)
            );
          }

          function computePhaseMap(values, hazard) {
            const y = values.map((v) => Number(v || 0));
            const H = Math.max(1e-4, Math.min(0.9999, Number(hazard || 0.03)));
            let mu0 = 0.0;
            let kappa0 = 0.01;
            let alpha0 = 0.5;
            let beta0 = 0.5;
            let logR = [0.0];
            let stats = [{ n: 0, mean: 0.0, m2: 0.0 }];
            const p0 = [];
            const changePoints = [];
            const logHaz = Math.log(H);
            const log1mHaz = Math.log(1.0 - H);
            for (let t = 0; t < y.length; t++) {
              const x = y[t];
              const logPred = [];
              for (let r = 0; r < stats.length; r++) {
                const st = stats[r];
                const n = st.n;
                const mean = st.mean;
                const kappa = kappa0 + n;
                const alpha = alpha0 + n / 2;
                const beta = beta0 + 0.5 * st.m2 + (kappa0 * n * (mean - mu0) * (mean - mu0)) / (2 * (kappa0 + n));
                const dof = 2 * alpha;
                const scale2 = (beta * (kappa + 1)) / (alpha * kappa);
                logPred.push(studentTLogPdf(x, mean, Math.sqrt(scale2), dof));
              }
              const newLogR = new Array(stats.length + 1).fill(-Infinity);
              let logSumCp = -Infinity;
              for (let r = 0; r < logR.length; r++) {
                logSumCp = logAddExp(logSumCp, logR[r] + logPred[r] + logHaz);
              }
              newLogR[0] = logSumCp;
              for (let r = 0; r < logR.length; r++) {
                newLogR[r + 1] = logR[r] + logPred[r] + log1mHaz;
              }
              const logZ = newLogR.reduce((a, b) => logAddExp(a, b), -Infinity);
              for (let i = 0; i < newLogR.length; i++) newLogR[i] -= logZ;
              const p_r0 = Math.exp(newLogR[0]);
              p0.push(p_r0);
              if (p_r0 > 0.5) changePoints.push(t);
              const newStats = new Array(stats.length + 1);
              newStats[0] = { n: 1, mean: x, m2: 0.0 };
              for (let r = 1; r < newStats.length; r++) {
                newStats[r] = updateWelford(stats[r - 1], x);
              }
              const K = 120;
              const idxs = newLogR
                .map((v, i) => [v, i])
                .sort((a, b) => b[0] - a[0])
                .slice(0, K)
                .map((x) => x[1])
                .sort((a, b) => a - b);
              logR = idxs.map((i) => newLogR[i]);
              stats = idxs.map((i) => newStats[i]);
              const logZ2 = logR.reduce((a, b) => logAddExp(a, b), -Infinity);
              logR = logR.map((v) => v - logZ2);
            }
            return { p0, changePoints };
          }

          
          /** Enhanced BOCPD with evidence ledger + segments (bd-24q.11.1). */
          function computePhaseMapEnhanced(values, hazard, metadata) {
            const y = values.map((v) => Number(v || 0));
            const H = Math.max(1e-4, Math.min(0.9999, Number(hazard || 0.03)));
            const meta = Array.isArray(metadata) ? metadata : [];

            // Normal-Gamma prior (Jeffreys-inspired uninformative).
            let mu0 = 0.0, kappa0 = 0.01, alpha0 = 0.5, beta0 = 0.5;
            let logR = [0.0];
            let stats = [{ n: 0, mean: 0.0, m2: 0.0 }];
            const p0 = [];
            const changePoints = [];
            const logHaz = Math.log(H);
            const log1mHaz = Math.log(1.0 - H);

            // Track running stats for evidence: mean/var per run-length 0 (new segment).
            const segmentStats = []; // per-timestep: { mean, var, n } for MAP run length

            for (let t = 0; t < y.length; t++) {
              const x = y[t];
              const logPred = [];
              for (let r = 0; r < stats.length; r++) {
                const st = stats[r];
                const n = st.n;
                const mean = st.mean;
                const kappa = kappa0 + n;
                const alpha = alpha0 + n / 2;
                const beta = beta0 + 0.5 * st.m2 + (kappa0 * n * (mean - mu0) * (mean - mu0)) / (2 * (kappa0 + n));
                const dof = 2 * alpha;
                const scale2 = (beta * (kappa + 1)) / (alpha * kappa);
                logPred.push(studentTLogPdf(x, mean, Math.sqrt(scale2), dof));
              }
              const newLogR = new Array(stats.length + 1).fill(-Infinity);
              let logSumCp = -Infinity;
              for (let r = 0; r < logR.length; r++) {
                logSumCp = logAddExp(logSumCp, logR[r] + logPred[r] + logHaz);
              }
              newLogR[0] = logSumCp;
              for (let r = 0; r < logR.length; r++) {
                newLogR[r + 1] = logR[r] + logPred[r] + log1mHaz;
              }
              const logZ = newLogR.reduce((a, b) => logAddExp(a, b), -Infinity);
              for (let i = 0; i < newLogR.length; i++) newLogR[i] -= logZ;
              const p_r0 = Math.exp(newLogR[0]);
              p0.push(p_r0);
              if (p_r0 > 0.5) changePoints.push(t);

              // Track MAP run-length stats for evidence.
              let mapR = 0, mapLogR = newLogR[0];
              for (let i = 1; i < newLogR.length; i++) {
                if (newLogR[i] > mapLogR) { mapLogR = newLogR[i]; mapR = i; }
              }

              const newStats = new Array(stats.length + 1);
              newStats[0] = { n: 1, mean: x, m2: 0.0 };
              for (let r = 1; r < newStats.length; r++) {
                newStats[r] = updateWelford(stats[r - 1], x);
              }

              const mapSt = newStats[mapR] || newStats[0];
              segmentStats.push({ mean: mapSt.mean, var: mapSt.n > 1 ? mapSt.m2 / (mapSt.n - 1) : 0, n: mapSt.n });

              const K = 120;
              const idxs = newLogR.map((v, i) => [v, i]).sort((a, b) => b[0] - a[0]).slice(0, K).map((x) => x[1]).sort((a, b) => a - b);
              logR = idxs.map((i) => newLogR[i]);
              stats = idxs.map((i) => newStats[i]);
              const logZ2 = logR.reduce((a, b) => logAddExp(a, b), -Infinity);
              logR = logR.map((v) => v - logZ2);
            }

            // Build segments between change points.
            const cpWithBounds = [0, ...changePoints, y.length];
            const segments = [];
            for (let s = 0; s < cpWithBounds.length - 1; s++) {
              const start = cpWithBounds[s];
              const end = cpWithBounds[s + 1];
              const segValues = y.slice(start, end);
              const n = segValues.length;
              if (n === 0) continue;
              const mean = segValues.reduce((a, b) => a + b, 0) / n;
              const variance = n > 1 ? segValues.reduce((a, v) => a + (v - mean) * (v - mean), 0) / (n - 1) : 0;
              // Posterior mass for this segment: average p0 within segment (low = stable).
              const avgP0 = p0.slice(start, end).reduce((a, b) => a + b, 0) / n;
              segments.push({
                start, end: end - 1, length: n, mean, variance, stddev: Math.sqrt(variance),
                avgP0, confidence: 1 - avgP0,
                startMeta: meta[start] || null, endMeta: meta[end - 1] || null,
              });
            }

            // Build evidence ledger per change point.
            const evidence = changePoints.map((cpIdx) => {
              // Before: stats from previous segment.
              const prevEnd = cpIdx;
              const prevStart = Math.max(0, prevEnd - 10); // Look back up to 10 points.
              const beforeValues = y.slice(prevStart, prevEnd);
              const beforeMean = beforeValues.length ? beforeValues.reduce((a, b) => a + b, 0) / beforeValues.length : 0;
              const beforeVar = beforeValues.length > 1 ? beforeValues.reduce((a, v) => a + (v - beforeMean) * (v - beforeMean), 0) / (beforeValues.length - 1) : 0;

              // After: stats from current segment start.
              const afterEnd = Math.min(y.length, cpIdx + 10);
              const afterValues = y.slice(cpIdx, afterEnd);
              const afterMean = afterValues.length ? afterValues.reduce((a, b) => a + b, 0) / afterValues.length : 0;
              const afterVar = afterValues.length > 1 ? afterValues.reduce((a, v) => a + (v - afterMean) * (v - afterMean), 0) / (afterValues.length - 1) : 0;

              const metaEntry = meta[cpIdx] || {};
              return {
                idx: cpIdx,
                posteriorP0: p0[cpIdx],
                before: { mean: beforeMean, variance: beforeVar, stddev: Math.sqrt(beforeVar), n: beforeValues.length },
                after: { mean: afterMean, variance: afterVar, stddev: Math.sqrt(afterVar), n: afterValues.length },
                meanShift: afterMean - beforeMean,
                varianceRatio: beforeVar > 0 ? afterVar / beforeVar : afterVar > 0 ? Infinity : 1,
                ts: metaEntry.ts || "",
                hash: metaEntry.hash || "",
                buckets: metaEntry.buckets || [],
              };
            });

            return { p0, changePoints, segments, evidence, hazard: H, seriesLength: y.length };
          }


          async function computeAllMetrics(reqId, progressCb, includeLev) {
            const d = STATE.dataset;
            const commits = d?.commits || [];
            const patches = d?.patches || [];
            const tokensChanged = {};
            const bytesChanged = {};
            const hunks = {};
            const lev = {};
            const total = commits.length;
            for (let i = 0; i < total; i++) {
              throwIfCancelled(reqId);
              const c = commits[i] || {};
              const patch = patches[i] || "";
              const qm = quickMetricsFromPatch(patch);
              tokensChanged[c.hash] = qm.tokensChanged;
              bytesChanged[c.hash] = qm.bytesChanged;
              hunks[c.hash] = qm.hunks;
              if (includeLev && i > 0) {
                lev[c.hash] = await levenshteinForPatch(patch, reqId);
              }
              if (progressCb && (i === total - 1 || i % 3 === 0)) {
                progressCb({
                  stage: "metrics",
                  done: i + 1,
                  total,
                  haveLev: Object.keys(lev).length,
                  message: "Computing per-commit metrics",
                });
              }
            }
            return { tokensChanged, bytesChanged, hunks, lev, commitCount: total };
          }
          const AB_METRICS_CACHE = new Map();
          async function computeABMetrics(aIdx, bIdx, reqId, progressCb) {
            const key = aIdx + ":" + bIdx;
            if (AB_METRICS_CACHE.has(key)) return AB_METRICS_CACHE.get(key);
            progressCb({ stage: "ab_snapshot", message: "Reconstructing snapshot A" });
            const textA = docTextAtLocal(aIdx, reqId, progressCb);
            throwIfCancelled(reqId);
            progressCb({ stage: "ab_snapshot", message: "Reconstructing snapshot B" });
            const textB = docTextAtLocal(bIdx, reqId, progressCb);
            throwIfCancelled(reqId);
            progressCb({ stage: "ab_diff", message: "Computing A/B line diff" });
            const lA = textA.split("\\n"), lB = textB.split("\\n");
            let addL = 0, delL = 0, hn = 0, tokA = 0, tokD = 0, byA = 0, byD = 0;
            const n = lA.length, m = lB.length;
            let ia = 0, ib = 0, tags = [];
            while (ia < n || ib < m) {
              if (ia < n && ib < m && lA[ia] === lB[ib]) { tags.push(" "); ia++; ib++; }
              else {
                let fA = -1, fB = -1;
                const ahead = Math.min(200, Math.max(n - ia, m - ib));
                for (let k = 1; k <= ahead; k++) {
                  if (fA < 0 && ib + k < m && ia < n && lA[ia] === lB[ib + k]) fA = k;
                  if (fB < 0 && ia + k < n && ib < m && lB[ib] === lA[ia + k]) fB = k;
                  if (fA >= 0 || fB >= 0) break;
                }
                if (fA >= 0 && (fB < 0 || fA <= fB)) {
                  for (let k = 0; k < fA; k++) { const l = lB[ib++]; tags.push("+"); addL++; tokA += countRoughTokens(l); byA += l.length + 1; }
                } else if (fB >= 0) {
                  for (let k = 0; k < fB; k++) { const l = lA[ia++]; tags.push("-"); delL++; tokD += countRoughTokens(l); byD += l.length + 1; }
                } else {
                  if (ia < n) { const l = lA[ia++]; tags.push("-"); delL++; tokD += countRoughTokens(l); byD += l.length + 1; }
                  if (ib < m) { const l = lB[ib++]; tags.push("+"); addL++; tokA += countRoughTokens(l); byA += l.length + 1; }
                }
              }
              if (tags.length % 500 === 0) throwIfCancelled(reqId);
            }
            let prev = " ";
            for (const t of tags) { if (t !== " " && prev === " ") hn++; prev = t; }
            progressCb({ stage: "ab_lev", message: "Computing Levenshtein" });
            let lev = null;
            try { const enc = new TextEncoder(); lev = await levenshteinBytes(enc.encode(textA), enc.encode(textB)); } catch {}
            const res = { addLines: addL, delLines: delL, deltaLines: addL - delL, tokensChanged: tokA + tokD, tokensDelta: tokA - tokD, bytesChanged: byA + byD, bytesDelta: byA - byD, hunks: hn, lev, aIdx, bIdx };
            AB_METRICS_CACHE.set(key, res);
            return res;
          }

          function validateDatasetHash(inputHash) {
            if (!STATE.datasetHash) return;
            if (!inputHash) throw new Error("datasetHash missing on worker request");
            if (inputHash !== STATE.datasetHash) {
              throw new Error("datasetHash mismatch: stale request against a different dataset");
            }
          }

          self.onmessage = async (event) => {
            const msg = event?.data || {};
            const op = msg.op;
            const reqId = msg.reqId;
            const payload = msg.payload || {};
            const incomingHash = msg.datasetHash || "";
            if (!op) return;

            if (op === "cancel") {
              const targetReqId = payload.targetReqId;
              if (targetReqId) CANCELLED_REQS.add(targetReqId);
              self.postMessage({
                op,
                reqId,
                type: "ok",
                datasetHash: STATE.datasetHash || "",
                payload: { cancelledReqId: targetReqId || null },
              });
              return;
            }

            const progressCb = (info) => {
              self.postMessage({
                op,
                reqId,
                type: "progress",
                datasetHash: STATE.datasetHash || "",
                payload: info || {},
              });
            };

            try {
              if (!reqId) throw new Error("reqId is required");
              if (op !== "init_dataset") {
                if (!STATE.dataset) throw new Error("Worker dataset not initialized");
                validateDatasetHash(incomingHash);
              }
              throwIfCancelled(reqId);

              let result = null;
              switch (op) {
                case "init_dataset": {
                  const ds = payload.dataset;
                  const dsHash = payload.datasetHash || incomingHash;
                  if (!ds || !Array.isArray(ds.commits) || !Array.isArray(ds.patches)) {
                    throw new Error("Invalid dataset payload for init_dataset");
                  }
                  STATE.dataset = ds;
                  STATE.datasetHash = dsHash || "";
                  STATE.patchHunks = ds.patches.map((p) => parseUnifiedHunks(p));
                  STATE.snapshotCache.clear();
                  STATE.snapshotCache.set(0, String(ds.base_doc || ""));
                  STATE.snapshotCursorIdx = 0;
                  STATE.snapshotCursorLines = String(ds.base_doc || "").split("\\n");
                  STATE.searchIndex = null;
                  STATE.clusterData = null;
                  result = {
                    datasetHash: STATE.datasetHash,
                    commits: ds.commits.length,
                    patches: ds.patches.length,
                  };
                  break;
                }
                case "snapshot_at": {
                  const idx = Number(payload.idx || 0);
                  const text = docTextAtLocal(idx, reqId, progressCb);
                  result = { idx, text };
                  break;
                }
                case "quick_patch_metrics": {
                  result = quickMetricsFromPatch(payload.patch || "");
                  break;
                }
                case "levenshtein_patch": {
                  const lev = await levenshteinForPatch(payload.patch || "", reqId);
                  result = { lev };
                  break;
                }
                case "compute_all_metrics": {
                  const includeLev = payload.includeLev !== false;
                  result = await computeAllMetrics(reqId, progressCb, includeLev);
                  break;
                }
                case "ab_metrics": {
                  const aIdx = Number(payload.aIdx || 0);
                  const bIdx = Number(payload.bIdx || 0);
                  result = await computeABMetrics(aIdx, bIdx, reqId, progressCb);
                  break;
                }
                case "build_search_index": {
                  result = buildSearchIndex(reqId, progressCb);
                  break;
                }
                case "export_search_index": {
                  result = exportSearchIndex();
                  break;
                }
                case "hydrate_search_index": {
                  const ok = hydrateSearchIndex(payload.data);
                  result = { hydrated: ok, docs: ok ? STATE.searchIndex.docs.length : 0, terms: ok ? STATE.searchIndex.postings.size : 0 };
                  break;
                }
                case "query_search": {
                  result = querySearch(payload.q || "", payload.limit || 20);
                  break;
                }
                case "compute_minhash_signatures": {
                  result = computeMinHashSignatures(reqId, progressCb, {
                    sigLen: payload.sigLen || 64,
                    shingleK: payload.shingleK || 5,
                    mode: payload.mode || "added",
                  });
                  break;
                }
                case "export_minhash_signatures": {
                  result = exportMinHashSignatures();
                  break;
                }
                case "hydrate_minhash_signatures": {
                  const ok = hydrateMinHashSignatures(payload.data);
                  result = { hydrated: ok, docs: ok ? STATE.minhashSignatures.meta.length : 0, sigLen: ok ? STATE.minhashSignatures.sigLen : 0 };
                  break;
                }
                case "compute_clusters": {
                  result = computeClusters(payload.limit || 12);
                  break;
                }
                case "compute_phase_map": {
                  result = computePhaseMap(payload.values || [], payload.hazard);
                  break;
                }
                case "compute_phase_map_enhanced": {
                  result = computePhaseMapEnhanced(payload.values || [], payload.hazard, payload.metadata || []);
                  break;
                }
                case "compute_outliers": {
                  result = computeOutliers(payload.values || [], payload.topK || 10);
                  break;
                }
                case "compute_outliers_robust": {
                  result = computeOutliersRobust(payload.entries || [], payload.topK || 10);
                  break;
                }
                case "compute_outliers_multi": {
                  result = computeOutliersMultiMetric(payload.metricSeries || {}, payload.topK || 10);
                  break;
                }
                case "extract_outline": {
                  const idx = Number(payload.idx || 0);
                  const text = docTextAtLocal(idx, reqId, progressCb);
                  result = { idx, outline: extractOutlineWorker(text) };
                  break;
                }
                case "heading_metrics": {
                  const idx = Number(payload.idx || 0);
                  const text = docTextAtLocal(idx, reqId, progressCb);
                  const outline = extractOutlineWorker(text);
                  const patch = patchForIdx(idx);
                  const totalLines = text.split("\\n").length;
                  const lineMap = buildLineToHeadingMapW(totalLines, outline);
                  const metrics = attributeHunksToHeadingsW(patch, lineMap);
                  result = { idx, outline, metrics };
                  break;
                }
                default:
                  throw new Error("Unknown worker op: " + op);
              }

              throwIfCancelled(reqId);
              self.postMessage({
                op,
                reqId,
                type: "ok",
                datasetHash: STATE.datasetHash || "",
                payload: result,
              });
            } catch (err) {
              if (err?.name === "AbortError" || isCancelled(reqId)) {
                self.postMessage({
                  op,
                  reqId,
                  type: "cancelled",
                  datasetHash: STATE.datasetHash || "",
                  payload: { message: "Request cancelled" },
                });
              } else {
                self.postMessage({
                  op,
                  reqId,
                  type: "error",
                  datasetHash: STATE.datasetHash || "",
                  error: serializeError(err),
                });
              }
            } finally {
              CANCELLED_REQS.delete(reqId);
            }
          };
        `;
      }

      function tearDownWorker() {
        if (WORKER_STATE.worker) {
          try {
            WORKER_STATE.worker.terminate();
          } catch {
            // ignore
          }
        }
        WORKER_STATE.worker = null;
        WORKER_STATE.ready = false;
        for (const [reqId, req] of WORKER_STATE.pending.entries()) {
          if (req?.timeoutId) clearTimeout(req.timeoutId);
          req?.reject?.(new Error(`Worker terminated while handling reqId=${reqId}`));
        }
        WORKER_STATE.pending.clear();
      }

      function handleWorkerMessage(event) {
        const msg = event?.data || {};
        const reqId = msg.reqId;
        if (!reqId) return;
        const pending = WORKER_STATE.pending.get(reqId);
        if (!pending) return;

        if (msg.type === "progress") {
          pending.onProgress?.(msg.payload || {});
          return;
        }

        if (pending.timeoutId) clearTimeout(pending.timeoutId);
        WORKER_STATE.pending.delete(reqId);

        if (msg.type === "ok") {
          pending.resolve(msg.payload);
          return;
        }
        if (msg.type === "cancelled") {
          const abortErr = new DOMException("Worker request cancelled", "AbortError");
          pending.reject(abortErr);
          return;
        }

        const errObj = msg.error || {};
        const err = new Error(errObj.message || `Worker op failed (${msg.op || "unknown"})`);
        err.name = errObj.name || "WorkerError";
        if (errObj.stack) err.stack = errObj.stack;
        pending.reject(err);
      }

      function workerRequest(op, payload, opts = {}) {
        if (!WORKER_STATE.worker || (op !== "init_dataset" && !WORKER_STATE.ready)) {
          return Promise.reject(new Error(`Worker unavailable for op=${op}`));
        }
        const reqId = `w${WORKER_STATE.reqSeq++}`;
        const timeoutMs = Number(opts.timeoutMs || 0);
        const signal = opts.signal || null;
        let aborted = false;
        let timeoutId = null;

        return new Promise((resolve, reject) => {
          const abortHandler = () => {
            aborted = true;
            try {
              WORKER_STATE.worker.postMessage({
                op: "cancel",
                reqId: `cancel-${reqId}`,
                datasetHash: WORKER_STATE.datasetHash,
                payload: { targetReqId: reqId },
              });
            } catch {
              // ignore transport errors
            }
            WORKER_STATE.pending.delete(reqId);
            reject(new DOMException("Aborted by caller", "AbortError"));
          };

          if (signal) {
            if (signal.aborted) {
              abortHandler();
              return;
            }
            signal.addEventListener("abort", abortHandler, { once: true });
          }

          if (timeoutMs > 0) {
            timeoutId = setTimeout(() => {
              WORKER_STATE.pending.delete(reqId);
              reject(new Error(`Worker request timed out: op=${op} reqId=${reqId} after ${timeoutMs}ms`));
            }, timeoutMs);
          }

          WORKER_STATE.pending.set(reqId, {
            resolve: (value) => {
              if (signal) signal.removeEventListener("abort", abortHandler);
              if (aborted) return;
              resolve(value);
            },
            reject: (err) => {
              if (signal) signal.removeEventListener("abort", abortHandler);
              if (aborted) return;
              reject(err);
            },
            onProgress: opts.onProgress,
            timeoutId,
          });

          WORKER_STATE.worker.postMessage({
            op,
            reqId,
            datasetHash: WORKER_STATE.datasetHash,
            payload: payload || {},
          });
        });
      }

      async function initAnalysisWorker() {
        if (!supportsAnalysisWorker()) {
          WORKER_STATE.disabled = true;
          setWorkerStatus("Web Worker unavailable; using main-thread compute fallback.", "error");
          return false;
        }
        if (WORKER_STATE.ready) return true;
        if (!DATASET.loaded || !DATASET.data) return false;

        try {
          WORKER_STATE.datasetHash = await computeDatasetHash(DATASET.data);
          const src = makeAnalysisWorkerSource();
          const blob = new Blob([src], { type: "text/javascript" });
          const url = URL.createObjectURL(blob);
          const worker = new Worker(url, { name: "spec-evolution-worker" });
          URL.revokeObjectURL(url);
          worker.addEventListener("message", handleWorkerMessage);
          worker.addEventListener("error", (event) => {
            setWorkerStatus(`Worker runtime error: ${event.message || "unknown error"}`, "error");
          });
          WORKER_STATE.worker = worker;

          const initPayload = await workerRequest("init_dataset", {
            datasetHash: WORKER_STATE.datasetHash,
            dataset: DATASET.data,
          });

          if (!initPayload || initPayload.datasetHash !== WORKER_STATE.datasetHash) {
            throw new Error("Worker dataset initialization returned an unexpected dataset hash");
          }
          WORKER_STATE.ready = true;
          setWorkerStatus(
            `Worker online · dataset ${WORKER_STATE.datasetHash.slice(0, 12)}… · ${fmtInt(initPayload.commits)} commits`,
            "ok",
          );
          return true;
        } catch (e) {
          WORKER_STATE.disabled = true;
          tearDownWorker();
          setWorkerStatus("Worker init failed; fallback active.", "error", formatErr(e));
          return false;
        }
      }

      // localStorage key for cached search index (bd-24q.9.1).
      const SEARCH_INDEX_LS_KEY = "fsqlite_viz_search_index";
      const SEARCH_INDEX_SCHEMA_VERSION = 2;

      // localStorage key for cached MinHash signatures (bd-24q.14.1).
      const MINHASH_LS_KEY = "fsqlite_viz_minhash_sigs";
      const MINHASH_SCHEMA_VERSION = 1;

      async function warmDerivedWorkerArtifacts() {
        if (!WORKER_STATE.ready) return;
        try {
          // Try loading cached search index from localStorage (bd-24q.9.1).
          let searchHydrated = false;
          try {
            const raw = localStorage.getItem(SEARCH_INDEX_LS_KEY);
            if (raw) {
              const cached = JSON.parse(raw);
              if (cached && cached.datasetHash === WORKER_STATE.datasetHash && cached.v === SEARCH_INDEX_SCHEMA_VERSION) {
                const res = await workerRequest("hydrate_search_index", { data: cached.index }, { timeoutMs: 10000 });
                if (res?.hydrated) { searchHydrated = true; console.log("[search] Hydrated from localStorage:", res.docs, "docs,", res.terms, "terms"); }
              }
            }
          } catch (e) { console.warn("[search] localStorage hydrate failed, will rebuild:", e); }

          if (!searchHydrated) {
            await workerRequest("build_search_index", {}, { timeoutMs: 30000 });
            // Export and persist to localStorage.
            try {
              const exported = await workerRequest("export_search_index", {}, { timeoutMs: 10000 });
              if (exported) {
                localStorage.setItem(SEARCH_INDEX_LS_KEY, JSON.stringify({ v: SEARCH_INDEX_SCHEMA_VERSION, datasetHash: WORKER_STATE.datasetHash, index: exported }));
              }
            } catch (e) { console.warn("[search] localStorage persist failed:", e); }
          }
          WORKER_DERIVED.searchReady = true;

          // Build or hydrate MinHash signatures (bd-24q.14.1), then cluster.
          let minhashHydrated = false;
          try {
            const raw = localStorage.getItem(MINHASH_LS_KEY);
            if (raw) {
              const cached = JSON.parse(raw);
              if (cached && cached.datasetHash === WORKER_STATE.datasetHash && cached.v === MINHASH_SCHEMA_VERSION) {
                const res = await workerRequest("hydrate_minhash_signatures", { data: cached.index }, { timeoutMs: 10000 });
                if (res?.hydrated) { minhashHydrated = true; console.log("[minhash] Hydrated from localStorage:", res.docs, "docs, sigLen:", res.sigLen); }
              }
            }
          } catch (e) { console.warn("[minhash] localStorage hydrate failed, will rebuild:", e); }

          if (!minhashHydrated) {
            await workerRequest("compute_minhash_signatures", { sigLen: 64, shingleK: 5, mode: "added" }, { timeoutMs: 60000 });
            try {
              const exported = await workerRequest("export_minhash_signatures", {}, { timeoutMs: 10000 });
              if (exported) {
                localStorage.setItem(MINHASH_LS_KEY, JSON.stringify({ v: MINHASH_SCHEMA_VERSION, datasetHash: WORKER_STATE.datasetHash, index: exported }));
              }
            } catch (e) { console.warn("[minhash] localStorage persist failed:", e); }
          }

          await workerRequest("compute_clusters", { limit: 12 }, { timeoutMs: 30000 });
          WORKER_DERIVED.clusterReady = true;
          setWorkerStatus("Worker online · search index + MinHash + clustering ready", "ok");
        } catch (e) {
          console.error("Worker warmup failed:", e);
          setWorkerStatus("Worker warmup partial failure.", "error", formatErr(e));
        }
      }

      // -------------------------------------------------------
      // Outlier Metric Series Builders (bd-24q.10.1)
      // -------------------------------------------------------

      /**
       * Build metric series entries from commits for outlier analysis.
       * Returns per-metric arrays ready for computeOutliersRobust worker call.
       */
      function buildOutlierMetricSeries(commits) {
        const series = { impact: [], linesAdded: [], linesDeleted: [] };
        const hasTokens = METRICS.tokensChanged.size > 0;
        const hasLev = METRICS.lev.size > 0;
        const hasHunks = METRICS.hunks.size > 0;
        if (hasTokens) series.tokens = [];
        if (hasLev) series.lev = [];
        if (hasHunks) series.hunks = [];

        for (const c of commits) {
          const entry = { ts: c.dateIso || "", hash: c.hash || "", idx: c.idx, buckets: c.labels || [] };
          series.impact.push({ ...entry, value: Number(c.impact || 0) });
          series.linesAdded.push({ ...entry, value: Number(c.add || 0) });
          series.linesDeleted.push({ ...entry, value: Number(c.del || 0) });
          if (hasTokens) series.tokens.push({ ...entry, value: Number(METRICS.tokensChanged.get(c.hash) || 0) });
          if (hasLev) series.lev.push({ ...entry, value: Number(METRICS.lev.get(c.hash) || 0) });
          if (hasHunks) series.hunks.push({ ...entry, value: Number(METRICS.hunks.get(c.hash) || 0) });
        }
        return series;
      }

      /**
       * Build time-bin aggregated series for outlier analysis.
       * Groups commits into bins by date and sums the metric per bin.
       */
      function buildTimeBinSeries(commits, binSize, metricField) {
        const bins = new Map();
        for (const c of commits) {
          if (!c.dateIso) continue;
          const d = new Date(c.dateIso);
          let key;
          if (binSize === "day") key = d.toISOString().slice(0, 10);
          else if (binSize === "week") {
            const ws = new Date(d); ws.setDate(d.getDate() - d.getDay());
            key = ws.toISOString().slice(0, 10);
          } else key = d.toISOString().slice(0, 7);

          if (!bins.has(key)) bins.set(key, { sum: 0, count: 0, ts: c.dateIso, hash: c.hash, idx: c.idx, bucketCounts: new Map() });
          const bin = bins.get(key);
          bin.sum += Number(c[metricField] || 0);
          bin.count++;
          for (const b of (c.labels || [])) bin.bucketCounts.set(b, (bin.bucketCounts.get(b) || 0) + 1);
        }
        return Array.from(bins.entries()).sort(([a], [b]) => a < b ? -1 : 1).map(([, bin]) => ({
          value: bin.sum, ts: bin.ts, hash: bin.hash, idx: bin.idx,
          buckets: Array.from(bin.bucketCounts.entries()).sort((a, b) => b[1] - a[1]).map(([id]) => id),
        }));
      }

      /**
       * Compute multi-metric outliers via worker (or inline fallback).
       * Returns { metricName: { median, mad, top: [...evidence...], all: [...] } }
       */
      async function computeMultiMetricOutliers(commits, topK) {
        const series = buildOutlierMetricSeries(commits);
        if (WORKER_STATE.ready) {
          try {
            return await workerRequest("compute_outliers_multi", { metricSeries: series, topK }, { timeoutMs: 30000 });
          } catch (e) { console.warn("Worker outlier fallback:", e); }
        }
        // Inline fallback (same algorithm, just runs on main thread).
        const results = {};
        for (const [name, entries] of Object.entries(series)) {
          results[name] = _inlineOutliersRobust(entries, topK);
        }
        return results;
      }

      /** Inline fallback for computeOutliersRobust (mirrors worker implementation). */
      function _inlineOutliersRobust(entries, topK) {
        if (!entries.length) return { median: 0, mad: 0, top: [], all: [] };
        const values = entries.map(e => Number(e.value || 0));
        const sorted = values.slice().sort((a, b) => a - b);
        const mid = Math.floor(sorted.length / 2);
        const med = sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
        const absDev = values.map(v => Math.abs(v - med));
        const absSorted = absDev.slice().sort((a, b) => a - b);
        const absMid = Math.floor(absSorted.length / 2);
        const mad = absSorted.length % 2 ? absSorted[absMid] : (absSorted[absMid - 1] + absSorted[absMid]) / 2;
        const madSafe = mad || 1e-9;
        const scored = entries.map((e, i) => ({
          idx: e.idx ?? i, value: values[i], z: 0.6745 * (values[i] - med) / madSafe,
          ts: e.ts || "", hash: e.hash || "", buckets: e.buckets || [],
        }));
        scored.sort((a, b) => {
          const dz = Math.abs(b.z) - Math.abs(a.z);
          if (Math.abs(dz) > 1e-12) return dz;
          if (a.ts !== b.ts) return a.ts < b.ts ? -1 : 1;
          return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;
        });
        const k = Math.max(1, Math.min(Number(topK) || 10, scored.length));
        const top = scored.slice(0, k).map(e => ({
          idx: e.idx, value: e.value, z: e.z, ts: e.ts, hash: e.hash, buckets: e.buckets,
          evidence: { value: e.value, median: med, mad, z: e.z, contributingBuckets: e.buckets },
        }));
        return { median: med, mad, top, all: scored.map(e => ({ idx: e.idx, value: e.value, z: e.z })) };
      }

      // -------------------------------------------------------
      // Phase Map Enhanced: Main-Thread Wrapper (bd-24q.11.1)
      // -------------------------------------------------------

      /**
       * Compute enhanced BOCPD phase map with evidence ledger.
       * Uses worker if available, falls back to inline main-thread version.
       * @param {Array} commits - ALL_COMMITS or FILTERED_COMMITS
       * @param {number} hazard - BOCPD hazard rate (0..1)
       * @param {string} metricField - "impact", "add", "del"
       * @returns {{p0, changePoints, segments, evidence, hazard, seriesLength}}
       */
      async function computePhaseMapWithEvidence(commits, hazard, metricField) {
        const values = commits.map(c => Math.log1p(Number(c[metricField || "impact"] || 0)));
        const metadata = commits.map(c => ({
          ts: c.dateIso || "", hash: c.hash || "", idx: c.idx,
          buckets: c.labels || [], subject: c.subject || "",
        }));
        if (WORKER_STATE.ready) {
          try {
            return await workerRequest("compute_phase_map_enhanced", { values, hazard, metadata }, { timeoutMs: 30000 });
          } catch (e) { console.warn("Worker phase map fallback:", e); }
        }
        // Inline fallback.
        return _inlinePhaseMapEnhanced(values, hazard, metadata);
      }

      /** Inline fallback for computePhaseMapEnhanced. */
      function _inlinePhaseMapEnhanced(values, hazard, metadata) {
        const y = values.map(v => Number(v || 0));
        const H = Math.max(1e-4, Math.min(0.9999, Number(hazard || 0.03)));
        const meta = Array.isArray(metadata) ? metadata : [];
        let mu0 = 0.0, kappa0 = 0.01, alpha0 = 0.5, beta0 = 0.5;
        let logR = [0.0], stats = [{ n: 0, mean: 0.0, m2: 0.0 }];
        const p0 = [], changePoints = [];
        const logHaz = Math.log(H), log1mHaz = Math.log(1.0 - H);
        for (let t = 0; t < y.length; t++) {
          const x = y[t];
          const logPred = [];
          for (let r = 0; r < stats.length; r++) {
            const st = stats[r]; const n = st.n; const mean = st.mean;
            const kappa = kappa0 + n; const alpha = alpha0 + n / 2;
            const beta = beta0 + 0.5 * st.m2 + (kappa0 * n * (mean - mu0) * (mean - mu0)) / (2 * (kappa0 + n));
            logPred.push(studentTLogPdf(x, mean, Math.sqrt((beta * (kappa + 1)) / (alpha * kappa)), 2 * alpha));
          }
          const newLogR = new Array(stats.length + 1).fill(-Infinity);
          let logSumCp = -Infinity;
          for (let r = 0; r < logR.length; r++) logSumCp = logAddExp(logSumCp, logR[r] + logPred[r] + logHaz);
          newLogR[0] = logSumCp;
          for (let r = 0; r < logR.length; r++) newLogR[r + 1] = logR[r] + logPred[r] + log1mHaz;
          const logZ = newLogR.reduce((a, b) => logAddExp(a, b), -Infinity);
          for (let i = 0; i < newLogR.length; i++) newLogR[i] -= logZ;
          const p_r0 = Math.exp(newLogR[0]);
          p0.push(p_r0);
          if (p_r0 > 0.5) changePoints.push(t);
          const newStats = new Array(stats.length + 1);
          newStats[0] = { n: 1, mean: x, m2: 0.0 };
          for (let r = 1; r < newStats.length; r++) newStats[r] = updateWelford(stats[r - 1], x);
          const K = 120;
          const idxs = newLogR.map((v, i) => [v, i]).sort((a, b) => b[0] - a[0]).slice(0, K).map(x => x[1]).sort((a, b) => a - b);
          logR = idxs.map(i => newLogR[i]);
          stats = idxs.map(i => newStats[i]);
          const logZ2 = logR.reduce((a, b) => logAddExp(a, b), -Infinity);
          logR = logR.map(v => v - logZ2);
        }
        // Build segments.
        const cpWithBounds = [0, ...changePoints, y.length];
        const segments = [];
        for (let s = 0; s < cpWithBounds.length - 1; s++) {
          const start = cpWithBounds[s], end = cpWithBounds[s + 1];
          const sv = y.slice(start, end); const n = sv.length;
          if (n === 0) continue;
          const mean = sv.reduce((a, b) => a + b, 0) / n;
          const variance = n > 1 ? sv.reduce((a, v) => a + (v - mean) * (v - mean), 0) / (n - 1) : 0;
          const avgP0 = p0.slice(start, end).reduce((a, b) => a + b, 0) / n;
          segments.push({ start, end: end - 1, length: n, mean, variance, stddev: Math.sqrt(variance), avgP0, confidence: 1 - avgP0, startMeta: meta[start] || null, endMeta: meta[end - 1] || null });
        }
        // Build evidence.
        const evidence = changePoints.map(cpIdx => {
          const bv = y.slice(Math.max(0, cpIdx - 10), cpIdx);
          const bm = bv.length ? bv.reduce((a, b) => a + b, 0) / bv.length : 0;
          const bvar = bv.length > 1 ? bv.reduce((a, v) => a + (v - bm) * (v - bm), 0) / (bv.length - 1) : 0;
          const av = y.slice(cpIdx, Math.min(y.length, cpIdx + 10));
          const am = av.length ? av.reduce((a, b) => a + b, 0) / av.length : 0;
          const avar = av.length > 1 ? av.reduce((a, v) => a + (v - am) * (v - am), 0) / (av.length - 1) : 0;
          const me = meta[cpIdx] || {};
          return { idx: cpIdx, posteriorP0: p0[cpIdx], before: { mean: bm, variance: bvar, stddev: Math.sqrt(bvar), n: bv.length }, after: { mean: am, variance: avar, stddev: Math.sqrt(avar), n: av.length }, meanShift: am - bm, varianceRatio: bvar > 0 ? avar / bvar : avar > 0 ? Infinity : 1, ts: me.ts || "", hash: me.hash || "", buckets: me.buckets || [] };
        });
        return { p0, changePoints, segments, evidence, hazard: H, seriesLength: y.length };
      }

      async function maybeRefreshPhaseAndOutliers(commits) {
        if (!WORKER_STATE.ready || !Array.isArray(commits) || !commits.length) return;
        const hazard = Number(document.getElementById("hazard")?.value || 0.03);
        const values = commits.map((c) => Math.log1p(Number(c.impact || 0)));
        const outlierValues = commits.map((c) => Number(c.impact || 0));
        const phaseKey = `${hazard}|${values.join(",")}`;
        const outlierKey = outlierValues.join(",");

        if (WORKER_DERIVED.phaseKey === phaseKey && WORKER_DERIVED.outlierKey === outlierKey) return;

        PHASE_ABORT_CONTROLLER?.abort();
        OUTLIER_ABORT_CONTROLLER?.abort();
        PHASE_ABORT_CONTROLLER = new AbortController();
        OUTLIER_ABORT_CONTROLLER = new AbortController();

        try {
          const [phase, outliers] = await Promise.all([
            workerRequest(
              "compute_phase_map",
              { values, hazard },
              { signal: PHASE_ABORT_CONTROLLER.signal, timeoutMs: 30000 },
            ),
            workerRequest(
              "compute_outliers",
              { values: outlierValues, topK: 10 },
              { signal: OUTLIER_ABORT_CONTROLLER.signal, timeoutMs: 30000 },
            ),
          ]);
          WORKER_DERIVED.phase = phase || null;
          WORKER_DERIVED.outliers = outliers || null;
          WORKER_DERIVED.phaseKey = phaseKey;
          WORKER_DERIVED.outlierKey = outlierKey;
          setWorkerStatus(
            `Worker online · phase CP ${fmtInt(phase?.changePoints?.length || 0)} · outlier set ${fmtInt(
              outliers?.top?.length || 0,
            )}`,
            "ok",
          );
          renderBocpd(commits);
        } catch (e) {
          if (e?.name === "AbortError") return;
          console.error("Phase/outlier worker compute failed:", e);
        }
      }

      // -----------------------------
      // Dataset + WASM loading
      // -----------------------------

      async function gunzipArrayBufferToString(ab) {
        // Prefer native DecompressionStream; fall back to pako.
        if (typeof DecompressionStream !== "undefined") {
          const ds = new DecompressionStream("gzip");
          const decompressedStream = new Blob([ab]).stream().pipeThrough(ds);
          const buf = await new Response(decompressedStream).arrayBuffer();
          return new TextDecoder().decode(buf);
        }
        if (typeof pako !== "undefined" && pako?.ungzip) {
          return pako.ungzip(new Uint8Array(ab), { to: "string" });
        }
        throw new Error("No gzip decompressor available in this browser.");
      }

	      async function loadEvolutionDataset() {
	        try {
	          // Let the browser/edge cache do its job. (The dataset is large enough that bypassing cache is painful.)
	          const res = await fetch(SPEC_EVOLUTION_DATA_URL);
	          if (!res.ok) throw new Error(`Failed to fetch ${SPEC_EVOLUTION_DATA_URL}: HTTP ${res.status}`);
	          const ab = await res.arrayBuffer();
	          const jsonText = await gunzipArrayBufferToString(ab);
	          const data = JSON.parse(jsonText);
          if (!data || !Array.isArray(data.commits) || !Array.isArray(data.patches) || !data.base_doc) {
            throw new Error("Dataset schema mismatch (expected commits[], patches[], base_doc).");
          }
          DATASET.data = data;
          DATASET.loaded = true;
          DATASET.error = null;
          return true;
        } catch (e) {
          DATASET.error = String(e?.message || e);
          DATASET.loaded = false;
          return false;
        }
      }

      async function initLevWasm() {
        if (LEV_WASM) return LEV_WASM;
        const res = await fetch(LEV_WASM_URL, { cache: "force-cache" });
        if (!res.ok) throw new Error(`Failed to fetch ${LEV_WASM_URL}: HTTP ${res.status}`);
        const buf = await res.arrayBuffer();
        const { instance } = await WebAssembly.instantiate(buf, {});
        LEV_WASM = instance.exports;
        return LEV_WASM;
      }

      async function levenshteinBytes(aBytes, bBytes) {
        const ex = await initLevWasm();
        const { memory, alloc, dealloc, levenshtein } = ex;
        if (!memory || !alloc || !dealloc || !levenshtein) {
          throw new Error("WASM exports missing (expected memory/alloc/dealloc/levenshtein).");
        }

        const a = aBytes || new Uint8Array();
        const b = bBytes || new Uint8Array();

        const ptrA = alloc(a.length);
        let viewA = new Uint8Array(memory.buffer, ptrA, a.length);
        viewA.set(a);

        const ptrB = alloc(b.length);
        let viewB = new Uint8Array(memory.buffer, ptrB, b.length);
        viewB.set(b);

        const d = levenshtein(ptrA, a.length, ptrB, b.length) >>> 0;

        dealloc(ptrA, a.length);
        dealloc(ptrB, b.length);

        return d;
      }

      // -----------------------------
      // Unified diff helpers (single-file)
      // -----------------------------

      function countRoughTokens(s) {
        // Approximate tokens for visualization: words + punctuation runs.
        let n = 0;
        const re = /[A-Za-z0-9_]+|[^\s]/g;
        while (re.exec(String(s))) n++;
        return n;
      }

      function quickMetricsFromPatch(patch) {
        const lines = String(patch || "").split("\n");
        let hunks = 0;
        let addLines = 0;
        let delLines = 0;
        let tokAdd = 0;
        let tokDel = 0;
        let bytesAdd = 0;
        let bytesDel = 0;
        for (const l of lines) {
          if (l.startsWith("@@")) hunks += 1;
          if (l.startsWith("+")) {
            if (l.startsWith("+++")) continue;
            addLines += 1;
            const s = l.slice(1);
            tokAdd += countRoughTokens(s);
            bytesAdd += s.length + 1;
          } else if (l.startsWith("-")) {
            if (l.startsWith("---")) continue;
            delLines += 1;
            const s = l.slice(1);
            tokDel += countRoughTokens(s);
            bytesDel += s.length + 1;
          }
        }
        return {
          hunks,
          addLines,
          delLines,
          tokensChanged: tokAdd + tokDel,
          bytesChanged: bytesAdd + bytesDel,
          tokensDelta: tokAdd - tokDel,
          bytesDelta: bytesAdd - bytesDel,
        };
      }

      function parseUnifiedHunks(patch) {
        const lines = String(patch || "").split("\n");
        const hunks = [];
        for (let i = 0; i < lines.length; i++) {
          const line = lines[i];
          if (!line.startsWith("@@")) continue;
          const m = /^@@ -(\\d+)(?:,(\\d+))? \\+(\\d+)(?:,(\\d+))? @@/.exec(line);
          if (!m) continue;
          const oldStart = Number(m[1]);
          const oldCount = Number(m[2] || "1");
          const newStart = Number(m[3]);
          const newCount = Number(m[4] || "1");

          const hunkLines = [];
          i++;
          for (; i < lines.length; i++) {
            const l = lines[i];
            if (l.startsWith("@@")) {
              i--;
              break;
            }
            if (l.startsWith("diff --git")) break;
            if (l.startsWith("index ") || l.startsWith("---") || l.startsWith("+++")) continue;
            hunkLines.push(l);
          }

          hunks.push({ oldStart, oldCount, newStart, newCount, lines: hunkLines });
        }
        return hunks;
      }

      const BUCKET_MAP = new Map();
      function bucketById(id) {
        if (BUCKET_MAP.size === 0) {
          for (const b of BUCKETS) BUCKET_MAP.set(b.id, b);
        }
        return BUCKET_MAP.get(id) || BUCKETS[BUCKETS.length - 1];
      }

      function pickPrimary(labels) {
        const s = new Set(labels);
        if (s.has(2)) return 2;
        if (s.has(3)) return 3;
        if (s.has(1)) return 1;
        if (s.has(4)) return 4;
        if (s.has(8)) return 8;
        if (s.has(7)) return 7;
        if (s.has(6)) return 6;
        if (s.has(5)) return 5;
        if (s.has(9)) return 9;
        return 10;
      }

      function normalizeClassification(commits) {
        const out = new Map();
        const add = (entry, source) => {
          if (!entry || !entry.commit) return;
          out.set(entry.commit, { ...entry, _source: source });
        };
        CLASS_EARLY.forEach((e) => add(e, "early"));
        CLASS_MIDDLE.forEach((e) => add(e, "middle"));
        CLASS_LATE.forEach((e) => add(e, "late"));

        const missing = [];
        for (const c of commits) {
          if (!out.has(c.hash)) missing.push(c.hash);
        }

        return { byHash: out, missing };
      }

      function deriveBucketsForGroup(group, commitSubject) {
        // If the group already uses numeric buckets, preserve.
        if (Array.isArray(group.categories) && group.categories.every((x) => Number.isInteger(x))) {
          const labels = uniqInts(group.categories);
          return { labels, primary: group.primary_category ?? pickPrimary(labels) };
        }

        const labels = new Set();
        const s = `${commitSubject || ""} ${group.summary || ""} ${(group.evidence || []).join(" ")}`.toLowerCase();

        // Tag-driven mapping (from middle/late agents)
        const tags = Array.isArray(group.categories) ? group.categories : [];
        for (const t of tags) {
          const tt = String(t).toLowerCase();
          if (tt.includes("doc meta") || tt.includes("summary_update")) labels.add(5);
          if (tt.includes("clarification")) labels.add(9);
          if (tt.includes("spec expansion") || tt.includes("addition")) labels.add(6);
          if (tt.includes("architecture")) labels.add(4);
          if (tt.includes("api/interface")) labels.add(4);
          if (tt.includes("sql semantics")) labels.add(2);
          if (tt.includes("file format")) labels.add(2);
          if (tt.includes("durability")) labels.add(7);
          if (tt.includes("concurrency")) labels.add(7);
          if (tt.includes("performance")) labels.add(7);
          if (tt.includes("math/modeling")) labels.add(8);
          if (tt.includes("correctness fix") || tt.includes("correction")) labels.add(1);
          if (tt.includes("requirement_change")) labels.add(4);
        }

        // Content heuristics to refine buckets.
        if (s.includes("sqlite") || s.includes("wal") || s.includes("wal-index") || s.includes("btree") || s.includes("vdbe") || s.includes("fts5") || s.includes("lemon") || s.includes("parse.y")) {
          labels.add(2);
        }
        if (s.includes("asupersync") || s.includes("cx") || s.includes("virtualtcp") || s.includes("region") || s.includes("spawn_blocking") || s.includes("deadline")) {
          labels.add(3);
        }
        if (s.includes("bocpd") || s.includes("conformal") || s.includes("e-process") || s.includes("evalue") || s.includes("vo i") || s.includes("gf(256)") || s.includes("raptorq") || s.includes("martingale")) {
          labels.add(8);
        }
        if (s.includes("cache") || s.includes("prefetch") || s.includes("alignment") || s.includes("atomic") || s.includes("acquire") || s.includes("release") || s.includes("bulkhead") || s.includes("rate_limit") || s.includes("shard") || s.includes("cache-line")) {
          labels.add(7);
        }
        if (s.includes("renumber") || s.includes("footer") || s.includes("document version") || s.includes("typo") || s.includes("wording tweak")) {
          labels.add(5);
        }
        if (s.startsWith("add ") || s.includes("added ") || s.includes("introduced ") || s.includes("defined ") || s.includes("expanded ")) {
          labels.add(6);
        }
        if (s.includes("clarif") || s.includes("explain") || s.includes("note")) {
          labels.add(9);
        }
        if (s.includes("fix ") || s.includes("fixed ") || s.includes("correct") || s.includes("arithmetic") || s.includes("inversion") || s.includes("swapped")) {
          labels.add(1);
        }
        if (s.includes("rework") || s.includes("redesign") || s.includes("protocol") || s.includes("invariant") || s.includes("formal model")) {
          labels.add(4);
        }

        if (labels.size === 0) labels.add(10);

        const labelsArr = Array.from(labels).sort((a, b) => a - b);
        const primary = pickPrimary(labelsArr);
        return { labels: labelsArr, primary };
      }

      function uniqInts(xs) {
        const s = new Set();
        for (const x of xs) s.add(Number(x));
        return Array.from(s).filter((n) => Number.isInteger(n)).sort((a, b) => a - b);
      }

      // -----------------------------
      // Rendering
      // -----------------------------

      let chartTimeline = null;
      let chartStack = null;
      let chartDonut = null;
      let chartBocpd = null;

      let ALL_COMMITS = [];
      let FILTERED_COMMITS = [];
      let DOCK_READY = false;

      // --- Phase 1: Lazy enrichment cache (parse + enrich once) ---
      let ENRICHED_READY = false;
      let ENRICHED_MISSING = [];

      function ensureEnriched() {
        if (ENRICHED_READY) return;
        const commits = parseCommitLog();
        const stats = parseCommitStats();
        const { byHash: clsByHash, missing } = normalizeClassification(commits);
        ENRICHED_MISSING = missing;

        ALL_COMMITS = commits.map((c) => {
          const st = stats.get(c.hash) || { add: 0, del: 0, impact: 0 };
          const raw = clsByHash.get(c.hash) || null;
          const changeGroupsRaw = raw?.change_groups || [];
          const changeGroups = changeGroupsRaw.map((g) => {
            const { labels, primary } = deriveBucketsForGroup(g, c.subject);
            return {
              summary: g.summary || "",
              evidence: Array.isArray(g.evidence) ? g.evidence : [],
              changed_headings: Array.isArray(g.changed_headings) ? g.changed_headings : [],
              confidence: typeof g.confidence === "number" ? g.confidence : 0.55,
              labels,
              primary,
            };
          });

          const groupLabels = new Set();
          for (const g of changeGroups) {
            for (const b of g.labels) groupLabels.add(b);
          }
          const labels = Array.from(groupLabels).sort((a, b) => a - b);
          const primary = pickPrimary(labels.length ? labels : [10]);

          return {
            ...c,
            ...st,
            labels,
            primary,
            changeGroups,
            hasClassification: Boolean(raw),
          };
        });

        ENRICHED_READY = true;
      }

      function render() {
        ensureEnriched();
        const enriched = ALL_COMMITS;
        const missing = ENRICHED_MISSING;

        // KPI
        document.getElementById("kpiCommits").textContent = fmtInt(enriched.length);
        const totalGroups = enriched.reduce((acc, c) => acc + c.changeGroups.length, 0);
        document.getElementById("kpiGroups").textContent = fmtInt(totalGroups);
        const totalLines = enriched.reduce((acc, c) => acc + c.impact, 0);
        document.getElementById("kpiLines").textContent = fmtInt(totalLines);
        document.getElementById("kpiMode").textContent = STATE.bucketMode === "primary" ? "Primary" : "Multi";
        document.getElementById("kpiIntegrity").textContent = missing.length ? `${missing.length} missing` : "OK";

        // Make the impact slider usable even with very large commits: cap at ~p99.
        {
          const impacts = enriched.map((c) => c.impact).slice().sort((a, b) => a - b);
          const idx = Math.max(0, Math.ceil(0.99 * impacts.length) - 1);
          const p99 = impacts[idx] || 200;
          const maxImpact = Math.max(200, p99);
          const impact = document.getElementById("impact");
          const impactMobile = document.getElementById("impactMobile");
          if (impact && impactMobile) {
            impact.max = String(maxImpact);
            impactMobile.max = String(maxImpact);
            if (STATE.minImpact > maxImpact) {
              STATE.minImpact = maxImpact;
              impact.value = String(maxImpact);
              impactMobile.value = String(maxImpact);
              document.getElementById("impactLabel").textContent = `${fmtInt(maxImpact)} lines`;
              document.getElementById("impactLabelMobile").textContent = `${fmtInt(maxImpact)} lines`;
            }
          }
        }

        const earliest = enriched[0];
        const latest = enriched[enriched.length - 1];
        document.getElementById("rangeLabel").textContent = `${earliest.short} → ${latest.short}`;
        document.getElementById("metaSpan").textContent = `${dayjs(earliest.dateIso).format("YYYY-MM-DD HH:mm")} to ${dayjs(latest.dateIso).format("HH:mm")}`;

        // Filter
        const filtered = enriched.filter((c) => matchesFilters(c));
        FILTERED_COMMITS = filtered;
        document.getElementById("showingCount").textContent = `${fmtInt(filtered.length)} commits`;

        // Charts + list
        renderBucketToggles();
        renderCharts(filtered);
        renderCommitList(filtered);
        syncDockAndDoc();

        // Make sure code highlighting is applied to newly inserted excerpts
        requestAnimationFrame(() => {
          document.querySelectorAll("pre code:not(.hljs)").forEach((el) => {
            try {
              hljs.highlightElement(el);
            } catch {
              // ignore
            }
          });
        });

        // Keep URL in sync with filter/view state.
        syncUrlToState();
      }

      function matchesFilters(commit) {
        if (commit.impact < STATE.minImpact) return false;
        const q = STATE.q.trim().toLowerCase();
        if (q) {
          const hay =
            `${commit.hash} ${commit.short} ${commit.author} ${commit.subject} ${commit.changeGroups
              .map((g) => `${g.summary} ${(g.changed_headings || []).join(" ")} ${(g.evidence || []).join(" ")}`)
              .join(" ")}`.toLowerCase();
          if (!hay.includes(q)) return false;
        }

        const enabled = STATE.bucketEnabled;
        if (STATE.bucketMode === "primary") {
          return enabled.has(commit.primary);
        }
        // multi-label: require overlap
        return commit.labels.some((b) => enabled.has(b));
      }

      // -----------------------------
      // Dock + Doc Evolution UI
      // -----------------------------

      const DOC_CURSOR = {
        idx: 0,
        lines: null,
      };

      function setDocTab(tab) {
        DOC.tab = tab;
        // Buttons
        const btnSpec = document.getElementById("docTabSpec");
        const btnDiff = document.getElementById("docTabDiff");
        const btnMetrics = document.getElementById("docTabMetrics");
        const btnSections = document.getElementById("docTabSections");
        const on = "focus-ring rounded-2xl bg-slate-900 px-3 py-2 text-xs font-semibold text-white hover:bg-slate-800";
        const off =
          "focus-ring rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-xs font-semibold text-slate-900 hover:bg-white";
        if (btnSpec) btnSpec.className = tab === "spec" ? on : off;
        if (btnDiff) btnDiff.className = tab === "diff" ? on : off;
        if (btnMetrics) btnMetrics.className = tab === "metrics" ? on : off;
        if (btnSections) btnSections.className = tab === "sections" ? on : off;
        updateDocPanelVisibility();
        syncUrlToState();
        // Re-render diff/spec if needed.
        void updateDocUI();
      }

      function updateDocPanelVisibility() {
        const spec = document.getElementById("docSpecView");
        const diff = document.getElementById("docDiffView");
        const metrics = document.getElementById("docMetricsView");
        const sections = document.getElementById("docSectionsView");
        if (!spec || !diff || !metrics) return;
        spec.classList.toggle("hidden", DOC.tab !== "spec");
        diff.classList.toggle("hidden", DOC.tab !== "diff");
        metrics.classList.toggle("hidden", DOC.tab !== "metrics");
        if (sections) sections.classList.toggle("hidden", DOC.tab !== "sections");
      }

      function patchForIdx(idx) {
        const d = DATASET.data;
        if (!d || !Array.isArray(d.patches)) return "";
        return d.patches[idx] || "";
      }

      // --- A/B Compare Typeahead Picker System (bd-24q.1) ---

      /** Format a commit label for the picker button. */
      function fmtPickerLabel(idx) {
        const c = ALL_COMMITS[idx];
        if (!c) return `#${idx}`;
        return `#${idx} ${c.short} – ${c.subject.slice(0, 32)}`;
      }

      /** Render commit items into a picker list element, filtered by query. */
      function renderPickerList(listEl, query, selectedIdx, onSelect) {
        listEl.innerHTML = "";
        const q = (query || "").toLowerCase().trim();
        const items = [];
        for (let i = 0; i < ALL_COMMITS.length; i++) {
          const c = ALL_COMMITS[i];
          const searchable = `#${i} ${c.short} ${c.hash} ${c.subject}`.toLowerCase();
          if (q && !searchable.includes(q)) continue;
          items.push(i);
        }
        if (items.length === 0) {
          const empty = document.createElement("div");
          empty.className = "px-3 py-4 text-center text-[11px] text-slate-400";
          empty.textContent = q ? "No matching commits" : "No commits loaded";
          listEl.appendChild(empty);
          return;
        }
        for (const i of items) {
          const c = ALL_COMMITS[i];
          const div = document.createElement("div");
          div.className = "ab-picker-item" + (i === selectedIdx ? " selected" : "");
          div.dataset.idx = i;
          div.innerHTML = `<span class="idx">#${i}</span><span class="hash">${escapeHtml(c.short)}</span><span class="subject">${escapeHtml(c.subject)}</span>`;
          div.addEventListener("click", () => onSelect(i));
          listEl.appendChild(div);
        }
      }

      /** Open a typeahead picker dropdown. */
      function openPicker(pickerId) {
        const dropdown = document.getElementById(pickerId + "Dropdown");
        const search = document.getElementById(pickerId + "Search");
        if (!dropdown) return;
        // Close any other open picker first.
        document.querySelectorAll(".ab-picker-dropdown").forEach(d => { if (d.id !== pickerId + "Dropdown") d.classList.add("hidden"); });
        dropdown.classList.remove("hidden");
        if (search) { search.value = ""; search.focus(); }
        const isA = pickerId === "pickerA";
        const selectedIdx = isA ? DOC.compareFromIdx : DOC.compareToIdx;
        const listEl = document.getElementById(pickerId + "List");
        if (listEl) {
          renderPickerList(listEl, "", selectedIdx, (idx) => {
            if (isA) DOC.compareFromIdx = idx; else DOC.compareToIdx = idx;
            closePicker(pickerId);
            populateCompareSelects();
            syncUrlToState();
            void updateDocUI();
          });
          // Scroll selected item into view.
          requestAnimationFrame(() => {
            const sel = listEl.querySelector(".selected");
            if (sel) sel.scrollIntoView({ block: "center", behavior: "instant" });
          });
        }
      }

      /** Close a typeahead picker dropdown. */
      function closePicker(pickerId) {
        const dropdown = document.getElementById(pickerId + "Dropdown");
        if (dropdown) dropdown.classList.add("hidden");
      }

      /** Wire up search input filtering for a picker. */
      function wirePickerSearch(pickerId) {
        const search = document.getElementById(pickerId + "Search");
        const listEl = document.getElementById(pickerId + "List");
        if (!search || !listEl) return;
        let debounce = 0;
        const isA = pickerId === "pickerA";
        search.addEventListener("input", () => {
          clearTimeout(debounce);
          debounce = setTimeout(() => {
            const selectedIdx = isA ? DOC.compareFromIdx : DOC.compareToIdx;
            renderPickerList(listEl, search.value, selectedIdx, (idx) => {
              if (isA) DOC.compareFromIdx = idx; else DOC.compareToIdx = idx;
              closePicker(pickerId);
              populateCompareSelects();
              syncUrlToState();
              void updateDocUI();
            });
          }, 80);
        });
        // Keyboard navigation.
        search.addEventListener("keydown", (e) => {
          if (e.key === "Escape") { closePicker(pickerId); return; }
          if (e.key === "ArrowDown" || e.key === "ArrowUp") {
            e.preventDefault();
            const items = listEl.querySelectorAll(".ab-picker-item");
            if (!items.length) return;
            let active = listEl.querySelector(".keyboard-active");
            let nextIdx = 0;
            if (active) {
              active.classList.remove("keyboard-active");
              const arr = Array.from(items);
              const cur = arr.indexOf(active);
              nextIdx = e.key === "ArrowDown" ? Math.min(cur + 1, arr.length - 1) : Math.max(cur - 1, 0);
            }
            items[nextIdx].classList.add("keyboard-active");
            items[nextIdx].scrollIntoView({ block: "nearest" });
          }
          if (e.key === "Enter") {
            const active = listEl.querySelector(".keyboard-active") || listEl.querySelector(".ab-picker-item");
            if (active) active.click();
          }
        });
      }

      /** Populate the A/B compare typeahead pickers from ALL_COMMITS. */
      function populateCompareSelects() {
        if (!ALL_COMMITS.length) return;
        // Update picker button labels.
        const btnA = document.getElementById("pickerABtn");
        const btnB = document.getElementById("pickerBBtn");
        if (btnA) btnA.textContent = fmtPickerLabel(DOC.compareFromIdx);
        if (btnB) btnB.textContent = fmtPickerLabel(DOC.compareToIdx);
      }

      /**
       * Generate a unified diff between two arbitrary commit snapshots.
       * Uses jsdiff (Diff library) to compute and returns a unified-diff string
       * suitable for Diff2Html rendering.
       */
      async function generateABDiff(fromIdx, toIdx) {
        const loading = document.getElementById("abDiffLoading");
        if (loading) loading.classList.remove("hidden");
        try {
          const [textA, textB] = await Promise.all([
            docTextAt(fromIdx),
            docTextAt(toIdx),
          ]);
          const commitA = ALL_COMMITS[fromIdx];
          const commitB = ALL_COMMITS[toIdx];
          const nameA = commitA ? `${commitA.short} (${commitA.subject.slice(0, 30)})` : `commit #${fromIdx}`;
          const nameB = commitB ? `${commitB.short} (${commitB.subject.slice(0, 30)})` : `commit #${toIdx}`;
          // Diff.createTwoFilesPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader)
          const patch = Diff.createTwoFilesPatch(
            nameA, nameB,
            textA, textB,
            `commit #${fromIdx}`, `commit #${toIdx}`
          );
          return patch;
        } finally {
          if (loading) loading.classList.add("hidden");
        }
      }

      // -----------------------------
      // Side-by-Side Rendered Markdown (bd-24q.15.1)
      // -----------------------------

      function renderMarkdownToPane(text, paneEl, idPrefix) {
        if (!paneEl) return;
        if (!window._mdSingleton) {
          window._mdSingleton = markdownit({
            html: false, linkify: true, typographer: true,
            highlight: (str, lang) => {
              try {
                if (lang && hljs.getLanguage(lang)) return `<pre class="hljs"><code>${hljs.highlight(str, { language: lang }).value}</code></pre>`;
                return `<pre class="hljs"><code>${hljs.highlightAuto(str).value}</code></pre>`;
              } catch { return `<pre class="hljs"><code>${escapeHtml(str)}</code></pre>`; }
            },
          });
        }
        const outline = extractOutline(text);
        const prefix = idPrefix || "";
        let oIdx = 0;
        const orig = window._mdSingleton.renderer.rules.heading_open;
        window._mdSingleton.renderer.rules.heading_open = (tokens, idx, options, env, self) => {
          const entry = outline[oIdx++];
          if (entry) tokens[idx].attrSet("id", prefix + entry.id);
          return self.renderToken(tokens, idx, options);
        };
        const html = window._mdSingleton.render(text || "");
        paneEl.innerHTML = DOMPurify.sanitize(html, { ADD_ATTR: ["id"] });
        if (orig) window._mdSingleton.renderer.rules.heading_open = orig;
        else delete window._mdSingleton.renderer.rules.heading_open;
      }

      let _sbsRenderedKey = "";

      async function renderSbsPanes() {
        const key = `${DOC.compareFromIdx}:${DOC.compareToIdx}`;
        if (_sbsRenderedKey === key) return; // already rendered for these indices
        const paneA = document.getElementById("sbsPaneA");
        const paneB = document.getElementById("sbsPaneB");
        const loading = document.getElementById("abDiffLoading");
        if (!paneA || !paneB) return;
        if (loading) loading.classList.remove("hidden");
        try {
          const [textA, textB] = await Promise.all([
            docTextAt(DOC.compareFromIdx),
            docTextAt(DOC.compareToIdx),
          ]);
          renderMarkdownToPane(textA, paneA, "sbs-a-");
          renderMarkdownToPane(textB, paneB, "sbs-b-");
          _sbsRenderedKey = key;
          // Update pane labels with commit info (bd-24q.15.1).
          const cA = ALL_COMMITS[DOC.compareFromIdx];
          const cB = ALL_COMMITS[DOC.compareToIdx];
          const lblA = document.getElementById("sbsLabelA");
          const lblB = document.getElementById("sbsLabelB");
          if (lblA) lblA.textContent = `A: #${DOC.compareFromIdx} ${cA?.short || ""} \u2014 ${cA?.subject || ""}`;
          if (lblB) lblB.textContent = `B: #${DOC.compareToIdx} ${cB?.short || ""} \u2014 ${cB?.subject || ""}`;
          setupSbsDivider();
          setupSbsSyncScroll();
        } finally {
          if (loading) loading.classList.add("hidden");
        }
      }

      function setupSbsDivider() {
        const divider = document.getElementById("sbsDivider");
        const container = divider?.parentElement; // inner flex row containing panes + divider
        const paneA = document.getElementById("sbsPaneA");
        const paneB = document.getElementById("sbsPaneB");
        if (!divider || !container || !paneA || !paneB) return;
        if (divider._sbsSetup) return;
        divider._sbsSetup = true;
        let dragging = false;
        divider.addEventListener("pointerdown", (e) => {
          e.preventDefault();
          dragging = true;
          divider.setPointerCapture(e.pointerId);
          document.body.style.cursor = "col-resize";
          document.body.style.userSelect = "none";
        });
        document.addEventListener("pointermove", (e) => {
          if (!dragging) return;
          const rect = container.getBoundingClientRect();
          const offset = e.clientX - rect.left;
          const pct = Math.max(15, Math.min(85, (offset / rect.width) * 100));
          paneA.style.flex = "none";
          paneA.style.width = `calc(${pct}% - 2.5px)`;
          paneB.style.flex = "none";
          paneB.style.width = `calc(${100 - pct}% - 2.5px)`;
        });
        const stopDrag = () => { if (!dragging) return; dragging = false; document.body.style.cursor = ""; document.body.style.userSelect = ""; };
        document.addEventListener("pointerup", stopDrag);
        document.addEventListener("pointercancel", stopDrag);
      }

      let _sbsScrollCleanup = null;
      let _sbsHeadingMap = null;

      /** Normalize heading text for fuzzy matching. */
      function normalizeHeadingText(text) {
        return String(text || "").toLowerCase().replace(/[^\p{L}\p{N}]+/gu, " ").trim();
      }

      /**
       * Build bidirectional heading match map between outlines A and B (bd-24q.15.2).
       * Pass 1: exact match (normalized text + level). Pass 2: fuzzy (longest common prefix >= 60%).
       */
      function buildHeadingMatchMap(outlineA, outlineB, prefixA, prefixB) {
        const matchAtoB = new Map();
        const matchBtoA = new Map();
        const normA = outlineA.map(h => ({ id: prefixA + h.id, norm: normalizeHeadingText(h.text), level: h.level }));
        const normB = outlineB.map(h => ({ id: prefixB + h.id, norm: normalizeHeadingText(h.text), level: h.level }));
        const usedB = new Set();
        for (const a of normA) {
          for (const b of normB) {
            if (!usedB.has(b.id) && a.norm === b.norm && a.level === b.level) {
              matchAtoB.set(a.id, b.id); matchBtoA.set(b.id, a.id); usedB.add(b.id); break;
            }
          }
        }
        for (const a of normA) {
          if (matchAtoB.has(a.id)) continue;
          let bestId = null, bestScore = 0;
          for (const b of normB) {
            if (usedB.has(b.id) || a.level !== b.level) continue;
            let cp = 0;
            const minLen = Math.min(a.norm.length, b.norm.length);
            while (cp < minLen && a.norm[cp] === b.norm[cp]) cp++;
            const score = minLen > 0 ? cp / Math.max(a.norm.length, b.norm.length) : 0;
            if (score > bestScore && score >= 0.6) { bestScore = score; bestId = b.id; }
          }
          if (bestId) { matchAtoB.set(a.id, bestId); matchBtoA.set(bestId, a.id); usedB.add(bestId); }
        }
        return { matchAtoB, matchBtoA };
      }

      /** Cache heading element offsets within a pane. */
      function cachePaneHeadingOffsets(pane, prefix) {
        const offsets = [];
        if (!pane) return offsets;
        for (const el of pane.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]")) {
          if (el.id.startsWith(prefix)) offsets.push({ id: el.id, top: el.offsetTop });
        }
        return offsets;
      }

      function setupSbsSyncScroll() {
        if (_sbsScrollCleanup) { _sbsScrollCleanup(); _sbsScrollCleanup = null; }
        _sbsHeadingMap = null;
        if (!DOC.sbsSyncScroll) return;
        const paneA = document.getElementById("sbsPaneA");
        const paneB = document.getElementById("sbsPaneB");
        if (!paneA || !paneB) return;

        // Build heading match map from rendered outlines.
        const outlineA = OUTLINE_CACHE.get(DOC.compareFromIdx) || [];
        const outlineB = OUTLINE_CACHE.get(DOC.compareToIdx) || [];
        const { matchAtoB, matchBtoA } = buildHeadingMatchMap(outlineA, outlineB, "sbs-a-", "sbs-b-");
        const offsetsA = cachePaneHeadingOffsets(paneA, "sbs-a-");
        const offsetsB = cachePaneHeadingOffsets(paneB, "sbs-b-");
        _sbsHeadingMap = { matchAtoB, matchBtoA, offsetsA, offsetsB };

        let syncing = false;
        let rafId = 0;

        /** Anchor-based sync with proportional fallback (bd-24q.15.2). */
        const syncFrom = (source, target, srcOffsets, srcToTgt, tgtOffsets) => {
          if (syncing) return;
          syncing = true;
          cancelAnimationFrame(rafId);
          rafId = requestAnimationFrame(() => {
            const viewTop = source.scrollTop + source.clientHeight * 0.15;
            let srcHeading = null, srcIdx = -1;
            for (let i = srcOffsets.length - 1; i >= 0; i--) {
              if (srcOffsets[i].top <= viewTop) { srcHeading = srcOffsets[i]; srcIdx = i; break; }
            }
            if (srcHeading && srcToTgt.has(srcHeading.id)) {
              const tgtId = srcToTgt.get(srcHeading.id);
              const tgtEntry = tgtOffsets.find(o => o.id === tgtId);
              if (tgtEntry) {
                const srcEnd = (srcIdx + 1 < srcOffsets.length) ? srcOffsets[srcIdx + 1].top : source.scrollHeight;
                const srcLen = srcEnd - srcHeading.top;
                const within = srcLen > 0 ? (viewTop - srcHeading.top) / srcLen : 0;
                const tgtIdx = tgtOffsets.indexOf(tgtEntry);
                const tgtEnd = (tgtIdx + 1 < tgtOffsets.length) ? tgtOffsets[tgtIdx + 1].top : target.scrollHeight;
                const tgtLen = tgtEnd - tgtEntry.top;
                target.scrollTop = tgtEntry.top + within * tgtLen - target.clientHeight * 0.15;
                syncing = false;
                return;
              }
            }
            // Proportional fallback.
            const maxS = source.scrollHeight - source.clientHeight;
            const maxT = target.scrollHeight - target.clientHeight;
            if (maxS > 0 && maxT > 0) target.scrollTop = (source.scrollTop / maxS) * maxT;
            syncing = false;
          });
        };

        const onScrollA = () => syncFrom(paneA, paneB, offsetsA, matchAtoB, offsetsB);
        const onScrollB = () => syncFrom(paneB, paneA, offsetsB, matchBtoA, offsetsA);
        paneA.addEventListener("scroll", onScrollA, { passive: true });
        paneB.addEventListener("scroll", onScrollB, { passive: true });
        _sbsScrollCleanup = () => {
          paneA.removeEventListener("scroll", onScrollA);
          paneB.removeEventListener("scroll", onScrollB);
          cancelAnimationFrame(rafId);
        };
      }

      /** Update button styling to reflect current abViewMode. */
      function updateSbsButtonStyles() {
        const sbsBtn = document.getElementById("btnSbsRendered");
        const active = DOC.abViewMode === "rendered";
        if (sbsBtn) {
          sbsBtn.classList.toggle("bg-slate-900", active);
          sbsBtn.classList.toggle("text-white", active);
          sbsBtn.classList.toggle("bg-white/70", !active);
          sbsBtn.classList.toggle("text-slate-900", !active);
        }
      }

      // --- Side-by-Side Mobile UX (bd-24q.15.3) ---
      const _sbsMobileScroll = { a: 0, b: 0 };
      function switchSbsMobilePane(pane) {
        const target = pane === "b" ? "b" : "a";
        const prev = DOC.sbsMobilePane;
        if (prev === target) return;
        const paneA = document.getElementById("sbsPaneA");
        const paneB = document.getElementById("sbsPaneB");
        if (!paneA || !paneB) return;
        if (prev === "a") _sbsMobileScroll.a = paneA.scrollTop;
        else _sbsMobileScroll.b = paneB.scrollTop;
        DOC.sbsMobilePane = target;
        paneA.classList.toggle("sbs-pane-visible", target === "a");
        paneB.classList.toggle("sbs-pane-visible", target === "b");
        document.getElementById("sbsTabA")?.classList.toggle("active", target === "a");
        document.getElementById("sbsTabB")?.classList.toggle("active", target === "b");
        if (target === "a") paneA.scrollTop = _sbsMobileScroll.a;
        else paneB.scrollTop = _sbsMobileScroll.b;
        showSbsJumpCta(prev, target);
      }
      function showSbsJumpCta(fromPane, toPane) {
        const cta = document.getElementById("sbsJumpCta");
        if (!cta || window.innerWidth > 639) return;
        const fromEl = document.getElementById(fromPane === "a" ? "sbsPaneA" : "sbsPaneB");
        if (!fromEl) { cta.classList.remove("visible"); return; }
        const fromPrefix = fromPane === "a" ? "sbs-a-" : "sbs-b-";
        const toPrefix = toPane === "a" ? "sbs-a-" : "sbs-b-";
        const headings = fromEl.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]");
        let topH = null;
        const thresh = fromEl.scrollTop + fromEl.clientHeight * 0.15;
        for (const h of headings) { if (h.offsetTop <= thresh) topH = h; else break; }
        if (!topH || !topH.id.startsWith(fromPrefix)) { cta.classList.remove("visible"); return; }
        const targetId = toPrefix + topH.id.slice(fromPrefix.length);
        const targetEl = document.getElementById(targetId);
        if (!targetEl) { cta.classList.remove("visible"); return; }
        const txt = topH.textContent.trim();
        cta.textContent = "\u2192 Jump to \u201C" + (txt.length > 30 ? txt.slice(0, 30) + "\u2026" : txt) + "\u201D";
        cta.classList.add("visible");
        cta.onclick = () => { targetEl.scrollIntoView({ behavior: "smooth", block: "start" }); cta.classList.remove("visible"); };
        clearTimeout(cta._hideTimer);
        cta._hideTimer = setTimeout(() => cta.classList.remove("visible"), 4000);
      }
      function applySbsMobilePaneState() {
        if (window.innerWidth > 639) return;
        const pA = document.getElementById("sbsPaneA");
        const pB = document.getElementById("sbsPaneB");
        if (!pA || !pB) return;
        const isA = DOC.sbsMobilePane === "a";
        pA.classList.toggle("sbs-pane-visible", isA);
        pB.classList.toggle("sbs-pane-visible", !isA);
      }

      // --- History Search Palette (bd-24q.9.2) ---
      let _spOpen = false;
      let _spActiveIdx = -1;
      let _spResults = [];
      let _spDebounce = 0;
      let _spAbort = null;

      function openSearchPalette() {
        const ov = document.getElementById("searchPaletteOverlay");
        const inp = document.getElementById("searchPaletteInput");
        if (!ov || _spOpen) return;
        _spOpen = true;
        _spActiveIdx = -1;
        _spResults = [];
        ov.classList.remove("hidden");
        inp.value = "";
        document.getElementById("searchPaletteResults").innerHTML =
          '<div class="search-palette-hint">Type to search across all commits</div>';
        requestAnimationFrame(() => inp.focus());
      }

      function closeSearchPalette() {
        const ov = document.getElementById("searchPaletteOverlay");
        if (!ov) return;
        _spOpen = false;
        ov.classList.add("hidden");
        if (_spAbort) { _spAbort.abort(); _spAbort = null; }
        clearTimeout(_spDebounce);
      }

      async function searchPaletteQuery(q) {
        if (_spAbort) { _spAbort.abort(); _spAbort = null; }
        const container = document.getElementById("searchPaletteResults");
        if (!container) return;
        const trimmed = q.trim();
        if (!trimmed) {
          _spResults = [];
          _spActiveIdx = -1;
          container.innerHTML = '<div class="search-palette-hint">Type to search across all commits</div>';
          return;
        }
        container.innerHTML = '<div class="search-palette-hint">Searching\u2026</div>';
        _spAbort = new AbortController();
        try {
          const res = await workerRequest("query_search", { q: trimmed, limit: 30 }, { signal: _spAbort.signal });
          _spResults = res.hits || [];
          _spActiveIdx = _spResults.length ? 0 : -1;
          if (!_spResults.length) {
            container.innerHTML = '<div class="search-palette-hint">No results</div>';
            return;
          }
          container.innerHTML = _spResults.map((h, i) =>
            `<div class="search-palette-item${i === _spActiveIdx ? " active" : ""}" data-sp-idx="${i}">` +
            `<span class="font-medium text-slate-900 truncate">#${h.idx} ${h.short}</span>` +
            `<span class="text-xs text-slate-500 truncate">${h.subject}</span>` +
            `</div>`
          ).join("");
        } catch (err) {
          if (err.name === "AbortError") return;
          container.innerHTML = '<div class="search-palette-hint">Search error</div>';
        }
      }

      function selectSearchResult(i) {
        const hit = _spResults[i];
        if (!hit) return;
        closeSearchPalette();
        selectCommitIdx(hit.idx);
        setDocTab("diff");
      }

      function spNavigate(delta) {
        if (!_spResults.length) return;
        const container = document.getElementById("searchPaletteResults");
        if (!container) return;
        const prev = _spActiveIdx;
        _spActiveIdx = Math.max(0, Math.min(_spResults.length - 1, _spActiveIdx + delta));
        if (prev === _spActiveIdx) return;
        const items = container.querySelectorAll(".search-palette-item");
        if (items[prev]) items[prev].classList.remove("active");
        if (items[_spActiveIdx]) {
          items[_spActiveIdx].classList.add("active");
          items[_spActiveIdx].scrollIntoView({ block: "nearest" });
        }
      }

      const AB_METRICS_MAIN_CACHE = new Map();
      let AB_METRICS_ABORT = null;
      async function computeAndShowABMetrics(aIdx, bIdx) {
        const bar = document.getElementById("abMetricsBar");
        if (!bar) return;
        if (aIdx === bIdx) { bar.classList.add("hidden"); return; }
        bar.classList.remove("hidden");
        const chips = ["abmLines", "abmTokens", "abmLev", "abmHunks", "abmBytes"];
        for (const id of chips) { const el = document.getElementById(id); if (el) el.textContent = "..."; }
        if (AB_METRICS_ABORT) AB_METRICS_ABORT.abort();
        AB_METRICS_ABORT = new AbortController();
        const cacheKey = `${WORKER_STATE.datasetHash}:${aIdx}:${bIdx}`;
        const cached = AB_METRICS_MAIN_CACHE.get(cacheKey);
        if (cached) { renderABMetricChips(cached); return; }
        try {
          let metrics;
          if (WORKER_STATE.ready) {
            metrics = await workerRequest("ab_metrics", { aIdx, bIdx }, { timeoutMs: 120000, signal: AB_METRICS_ABORT.signal });
          } else {
            const patch = await generateABDiff(aIdx, bIdx);
            metrics = quickMetricsFromPatch(patch);
            metrics.lev = null;
          }
          AB_METRICS_MAIN_CACHE.set(cacheKey, metrics);
          renderABMetricChips(metrics);
        } catch (e) {
          if (e?.name !== "AbortError") {
            console.error("A/B metrics failed:", e);
            for (const id of chips) { const el = document.getElementById(id); if (el) el.textContent = "ERR"; }
          }
        }
      }
      function renderABMetricChips(m) {
        const sign = (v) => v > 0 ? "+" + fmtInt(v) : v < 0 ? fmtInt(v) : "0";
        const el = (id) => document.getElementById(id);
        if (el("abmLines")) el("abmLines").textContent = `\u0394lines ${sign(m.deltaLines || 0)} (+${fmtInt(m.addLines || 0)} -${fmtInt(m.delLines || 0)})`;
        if (el("abmTokens")) el("abmTokens").textContent = `\u0394tokens ${sign(m.tokensDelta || 0)} (${fmtInt(m.tokensChanged || 0)} touched)`;
        if (el("abmLev")) el("abmLev").textContent = `Lev ${m.lev != null ? fmtInt(m.lev) : "?"}`;
        if (el("abmHunks")) el("abmHunks").textContent = `Hunks ${fmtInt(m.hunks || 0)}`;
        if (el("abmBytes")) el("abmBytes").textContent = `\u0394bytes ${sign(m.bytesDelta || 0)} (${fmtInt(m.bytesChanged || 0)} touched)`;
      }

      function applyPatchLines(prevLines, patch) {
        const hunks = parseUnifiedHunks(patch);
        let out = prevLines.slice();
        let offset = 0;
        for (const h of hunks) {
          let at = (h.oldStart - 1) + offset;
          at = clamp(at, 0, out.length);
          let cursor = at;
          const next = [];
          for (const hl of h.lines) {
            if (!hl) continue;
            const p = hl[0];
            const content = hl.slice(1);
            if (p === " ") {
              next.push(content);
              cursor += 1;
            } else if (p === "-") {
              cursor += 1;
            } else if (p === "+") {
              next.push(content);
            } else {
              // "\ No newline at end of file" or other metadata
            }
          }
          out.splice(at, cursor - at, ...next);
          offset += next.length - (cursor - at);
        }
        return out;
      }

      async function docTextAtLocal(idx) {
        const d = DATASET.data;
        if (!d) return "";
        if (idx <= 0) return String(d.base_doc || "");

        const cached = DOC_CACHE.get(idx);
        if (cached?.text) return cached.text;

        // Fast path: sequential scrub.
        if (DOC_CURSOR.lines && idx === DOC_CURSOR.idx + 1) {
          const nextLines = applyPatchLines(DOC_CURSOR.lines, patchForIdx(idx));
          DOC_CURSOR.idx = idx;
          DOC_CURSOR.lines = nextLines;
          const text = nextLines.join("\n");
          DOC_CACHE.set(idx, { text });
          return text;
        }

        // Rebuild from nearest cached anchor.
        let anchor = 0;
        for (let j = idx - 1; j > 0; j--) {
          if (DOC_CACHE.has(j)) {
            anchor = j;
            break;
          }
        }

        let lines = String(d.base_doc || "").split("\n");
        if (anchor > 0) lines = String(DOC_CACHE.get(anchor)?.text || "").split("\n");

        for (let k = Math.max(1, anchor + 1); k <= idx; k++) {
          lines = applyPatchLines(lines, patchForIdx(k));
          // Keep sparse anchors to accelerate non-linear scrubs.
          if (k === idx || k % 10 === 0) DOC_CACHE.set(k, { text: lines.join("\n") });
        }

        DOC_CURSOR.idx = idx;
        DOC_CURSOR.lines = lines;
        return DOC_CACHE.get(idx)?.text || lines.join("\n");
      }

      async function docTextAt(idx) {
        if (WORKER_STATE.ready) {
          try {
            const res = await workerRequest("snapshot_at", { idx }, { timeoutMs: 45000 });
            if (typeof res?.text === "string") return res.text;
          } catch (e) {
            console.error("Worker snapshot reconstruction failed; falling back to local path:", e);
          }
        }
        return docTextAtLocal(idx);
      }

      // -----------------------------
      // Heading Outline Extraction (bd-24q.8.1)
      // -----------------------------

      /**
       * Generate a URL-safe slug from heading text.
       * Deterministic: same input always yields same output.
       */
      function slugifyHeading(text) {
        return String(text || "")
          .toLowerCase()
          .replace(/[^\p{L}\p{N}]+/gu, "-")
          .replace(/^-+|-+$/g, "")
          || "heading";
      }

      /**
       * Extract an outline from markdown text using markdown-it's token stream.
       * Returns: [{ text: string, level: number, id: string }]
       *
       * Anchor IDs are deterministic and disambiguated: if two headings
       * produce the same slug, a numeric suffix (-1, -2, ...) is appended.
       */
      function extractOutline(markdownText) {
        if (!window._mdSingleton) {
          window._mdSingleton = markdownit({
            html: false,
            linkify: true,
            typographer: true,
            highlight: (str, lang) => {
              try {
                if (lang && hljs.getLanguage(lang)) {
                  return `<pre class="hljs"><code>${hljs.highlight(str, { language: lang }).value}</code></pre>`;
                }
                return `<pre class="hljs"><code>${hljs.highlightAuto(str).value}</code></pre>`;
              } catch {
                return `<pre class="hljs"><code>${escapeHtml(str)}</code></pre>`;
              }
            },
          });
        }
        const tokens = window._mdSingleton.parse(markdownText || "", {});
        const outline = [];
        const slugCounts = new Map(); // slug -> count for disambiguation

        for (let i = 0; i < tokens.length; i++) {
          const tok = tokens[i];
          if (tok.type !== "heading_open") continue;

          // Level from tag: "h1" -> 1, "h2" -> 2, etc.
          const level = Number(tok.tag?.slice(1)) || 1;

          // Source line (1-based) from markdown-it token map.
          const line = tok.map ? tok.map[0] + 1 : null;

          // Next token should be the inline content.
          const inlineTok = tokens[i + 1];
          let text = "";
          if (inlineTok?.type === "inline") {
            // Collect all text children (handles bold, code, etc. inside headings).
            text = (inlineTok.children || [])
              .filter((c) => c.type === "text" || c.type === "code_inline")
              .map((c) => c.content)
              .join("");
            if (!text) text = inlineTok.content || "";
          }

          // Generate stable, disambiguated slug.
          const baseSlug = slugifyHeading(text);
          const count = slugCounts.get(baseSlug) || 0;
          slugCounts.set(baseSlug, count + 1);
          const id = count === 0 ? baseSlug : `${baseSlug}-${count}`;

          outline.push({ text: text.trim(), level, id, line });
        }
        return outline;
      }

      /**
       * Get the heading outline for a given commit index.
       * Caches results; uses docTextAt to reconstruct the spec.
       *
       * Returns: Promise<[{ text: string, level: number, id: string }]>
       */
      async function getOutline(commitIdx) {
        const idx = Number(commitIdx || 0);
        if (OUTLINE_CACHE.has(idx)) return OUTLINE_CACHE.get(idx);

        const text = await docTextAt(idx);
        const outline = extractOutline(text);
        OUTLINE_CACHE.set(idx, outline);
        return outline;
      }

      /**
       * Resolve offsetTop values for outline entries by querying the DOM.
       * Call this AFTER rendering markdown to get accurate positions.
       * Returns: [{ text, level, id, offsetTop }]
       */
      function resolveOutlineOffsets(outline, containerEl) {
        if (!containerEl || !outline?.length) return outline || [];
        return outline.map((entry) => {
          const el = containerEl.querySelector(`#${CSS.escape(entry.id)}`);
          return {
            ...entry,
            offsetTop: el ? el.offsetTop : null,
          };
        });
      }

      // -----------------------------
      // Per-Heading Change Metrics (bd-24q.8.2)
      // -----------------------------

      const HEADING_METRICS_CACHE = new Map(); // idx -> Map<headingId, metrics>

      /**
       * Build a lookup: 1-based line number -> heading ID.
       * Lines before the first heading map to "__preamble__".
       */
      function buildLineToHeadingMap(totalLines, outline) {
        const map = new Array(totalLines + 1);
        map[0] = "__preamble__";

        // Determine the heading boundary for each line by walking
        // through the outline's sorted line numbers.
        let ptr = 0;
        let currentId = "__preamble__";
        for (let ln = 1; ln <= totalLines; ln++) {
          while (ptr < outline.length && outline[ptr].line != null && outline[ptr].line <= ln) {
            currentId = outline[ptr].id;
            ptr++;
          }
          map[ln] = currentId;
        }
        return map;
      }

      /**
       * Attribute each added/removed line in a unified diff to the
       * nearest preceding heading in the new (current) snapshot.
       *
       * Returns: Map<headingId, { addLines, delLines, tokensAdded, tokensDeleted }>
       */
      function attributeHunksToHeadings(patch, lineToHeading) {
        const hunks = parseUnifiedHunks(patch);
        const metrics = new Map();

        const ensure = (id) => {
          if (!metrics.has(id)) {
            metrics.set(id, { addLines: 0, delLines: 0, tokensAdded: 0, tokensDeleted: 0 });
          }
          return metrics.get(id);
        };

        for (const hunk of hunks) {
          let newLineNum = hunk.newStart;
          for (const hl of hunk.lines) {
            if (!hl) continue;
            const p = hl[0];
            const content = hl.slice(1);
            const headingId = lineToHeading[newLineNum] || "__preamble__";

            if (p === "+") {
              const m = ensure(headingId);
              m.addLines++;
              m.tokensAdded += countRoughTokens(content);
              newLineNum++;
            } else if (p === "-") {
              const m = ensure(headingId);
              m.delLines++;
              m.tokensDeleted += countRoughTokens(content);
              // Deleted lines don't advance the new-file cursor.
            } else if (p === " ") {
              newLineNum++;
            }
          }
        }
        return metrics;
      }

      /**
       * Get per-heading change metrics for a commit.
       *
       * Returns: Promise<Map<headingId, { addLines, delLines, tokensAdded, tokensDeleted }>>
       */
      async function getHeadingMetrics(commitIdx) {
        const idx = Number(commitIdx || 0);
        if (HEADING_METRICS_CACHE.has(idx)) return HEADING_METRICS_CACHE.get(idx);

        const outline = await getOutline(idx);
        const text = await docTextAt(idx);
        const patch = patchForIdx(idx);

        if (!patch || !outline.length) {
          const empty = new Map();
          HEADING_METRICS_CACHE.set(idx, empty);
          return empty;
        }

        const totalLines = text.split("\n").length;
        const lineToHeading = buildLineToHeadingMap(totalLines, outline);
        const metrics = attributeHunksToHeadings(patch, lineToHeading);
        HEADING_METRICS_CACHE.set(idx, metrics);
        return metrics;
      }

      /**
       * Render the mini-map outline panel for the current commit.
       *
       * Features (bd-24q.2.2):
       * - Heading hierarchy with change-heat indicators
       * - Follow-along: tracks visible heading while scrolling docRendered
       * - Search/filter headings by text
       * - Keyboard navigation (arrow keys, Enter to jump)
       */
      let _miniMapOutline = [];
      let _miniMapScrollCleanup = null;

      async function updateMiniMap() {
        const mm = document.getElementById("miniMap");
        if (!mm || mm.classList.contains("hidden")) return;

        const itemsContainer = document.getElementById("miniMapItems") || mm;
        const outline = await getOutline(DOC.idx);
        _miniMapOutline = outline;

        if (!outline.length) {
          itemsContainer.innerHTML = '<div class="text-xs text-slate-400 italic p-2">No headings</div>';
          return;
        }

        // In A/B compare mode, compute metrics between A and B; otherwise parent→current.
        let headingMetrics = null;
        if (DOC.compareMode && DOC.compareToIdx > 0) {
          try { headingMetrics = await getHeadingMetrics(DOC.compareToIdx); } catch { /* best-effort */ }
        } else if (DOC.idx > 0) {
          try { headingMetrics = await getHeadingMetrics(DOC.idx); } catch { /* best-effort */ }
        }

        // Bucket accent: use current commit's primary bucket color.
        const commitForAccent = DOC.compareMode
          ? ALL_COMMITS[DOC.compareToIdx]
          : ALL_COMMITS[DOC.idx];
        const accentColor = commitForAccent ? bucketById(commitForAccent.primary)?.color : null;

        const docEl = document.getElementById("docRendered");
        const searchInput = document.getElementById("miniMapSearch");
        const filterText = (searchInput?.value || "").toLowerCase().trim();

        const filtered = filterText
          ? outline.filter((e) => e.text.toLowerCase().includes(filterText))
          : outline;

        const items = filtered.map((entry, i) => {
          const indent = Math.max(0, entry.level - 1) * 12;
          const hasChange = headingMetrics?.has(entry.id);
          const m = hasChange ? headingMetrics.get(entry.id) : null;
          const changeTotal = m ? m.addLines + m.delLines : 0;
          const tokenTotal = m ? m.tokensAdded + m.tokensDeleted : 0;
          // Intensity: use token count for size, line count for color.
          const dotSize = tokenTotal > 50 ? 10 : tokenTotal > 10 ? 8 : 6;
          const dotColor = changeTotal > 20 ? '#dc2626' : changeTotal > 5 ? '#d97706' : '#059669';
          const borderStyle = accentColor && hasChange && changeTotal > 0
            ? `; border: 1.5px solid ${accentColor}` : "";
          const marker = hasChange && changeTotal > 0
            ? `<span class="inline-block rounded-full mr-1.5 shrink-0" style="width: ${dotSize}px; height: ${dotSize}px; background: ${dotColor}${borderStyle}" title="+${m.addLines} -${m.delLines} lines, ~${tokenTotal} tokens"></span>`
            : "";
          return `<a href="#${escapeHtml(entry.id)}" role="treeitem" tabindex="${i === 0 ? '0' : '-1'}" class="minimap-item flex items-center py-0.5 text-[11px] leading-tight text-slate-700 hover:text-slate-900 hover:bg-slate-100/60 rounded px-1 cursor-pointer no-underline transition-colors" style="padding-left: ${indent}px" data-heading-id="${escapeHtml(entry.id)}" title="${escapeHtml(entry.text)}">${marker}<span class="truncate">${escapeHtml(entry.text)}</span></a>`;
        });
        itemsContainer.innerHTML = items.join("");

        // Click handlers: smooth-scroll to heading in doc.
        itemsContainer.querySelectorAll(".minimap-item").forEach((a) => {
          a.addEventListener("click", (e) => {
            e.preventDefault();
            const hid = a.dataset.headingId;
            if (!hid || !docEl) return;
            const target = docEl.querySelector(`#${CSS.escape(hid)}`);
            if (target) target.scrollIntoView({ behavior: "smooth", block: "start" });
            miniMapSetActive(a);
          });
        });

        // Keyboard navigation on items container.
        itemsContainer.onkeydown = (e) => {
          const links = [...itemsContainer.querySelectorAll(".minimap-item")];
          if (!links.length) return;
          const cur = itemsContainer.querySelector(".minimap-item[tabindex='0']");
          const idx = cur ? links.indexOf(cur) : 0;
          if (e.key === "ArrowDown" || e.key === "ArrowUp") {
            e.preventDefault();
            const next = e.key === "ArrowDown" ? Math.min(idx + 1, links.length - 1) : Math.max(idx - 1, 0);
            if (cur) cur.tabIndex = -1;
            links[next].tabIndex = 0;
            links[next].focus();
          } else if (e.key === "Enter") {
            e.preventDefault();
            if (cur) cur.click();
          } else if (e.key === "Home") {
            e.preventDefault();
            if (cur) cur.tabIndex = -1;
            links[0].tabIndex = 0;
            links[0].focus();
          } else if (e.key === "End") {
            e.preventDefault();
            if (cur) cur.tabIndex = -1;
            links[links.length - 1].tabIndex = 0;
            links[links.length - 1].focus();
          }
        };

        // Follow-along: highlight current heading while scrolling docRendered.
        setupMiniMapFollowAlong(docEl, itemsContainer, outline);
      }

      /** Highlight a mini-map item as active and scroll it into view. */
      function miniMapSetActive(el) {
        const container = el?.closest("#miniMapItems") || el?.closest("#miniMap");
        if (!container) return;
        container.querySelectorAll(".minimap-item.minimap-active").forEach((a) => {
          a.classList.remove("minimap-active", "bg-slate-200/80", "font-semibold", "text-slate-900");
        });
        if (el) {
          el.classList.add("minimap-active", "bg-slate-200/80", "font-semibold", "text-slate-900");
          el.scrollIntoView({ block: "nearest", behavior: "smooth" });
        }
      }

      /** Attach a scroll listener on docRendered to track the current heading. */
      function setupMiniMapFollowAlong(docEl, itemsContainer, outline) {
        if (_miniMapScrollCleanup) { _miniMapScrollCleanup(); _miniMapScrollCleanup = null; }
        if (!docEl || !outline.length) return;

        // Cache heading offsets to avoid O(N) DOM queries per scroll.
        const headingOffsets = [];
        for (const entry of outline) {
          const el = docEl.querySelector(`#${CSS.escape(entry.id)}`);
          headingOffsets.push({ id: entry.id, top: el ? el.offsetTop : 0 });
        }

        let rafId = 0;
        const onScroll = () => {
          cancelAnimationFrame(rafId);
          rafId = requestAnimationFrame(() => {
            const viewportMid = docEl.scrollTop + docEl.clientHeight * 0.25;
            let activeId = headingOffsets[0]?.id;
            for (const h of headingOffsets) {
              if (h.top <= viewportMid) activeId = h.id;
            }
            const activeLink = activeId ? itemsContainer.querySelector(`[data-heading-id="${CSS.escape(activeId)}"]`) : null;
            if (activeLink && !activeLink.classList.contains("minimap-active")) miniMapSetActive(activeLink);
          });
        };
        docEl.addEventListener("scroll", onScroll, { passive: true });
        onScroll();
        _miniMapScrollCleanup = () => { docEl.removeEventListener("scroll", onScroll); cancelAnimationFrame(rafId); };
      }

      // ---- Section Summary Panel (bd-24q.8.3) ----
      const SECTION_SORT = { key: "impact", asc: false };
      function sectionSparkline(headingId, currentIdx) {
        const range = 5, startIdx = Math.max(1, currentIdx - range + 1), vals = [];
        for (let i = startIdx; i <= currentIdx; i++) {
          const cached = HEADING_METRICS_CACHE.get(i);
          if (cached && cached.has(headingId)) { const m = cached.get(headingId); vals.push(m.addLines + m.delLines); }
          else vals.push(0);
        }
        const maxVal = Math.max(1, ...vals);
        return vals.map(v => {
          const h = Math.max(1, Math.round((v / maxVal) * 14));
          const color = v === 0 ? "#cbd5e1" : v > 20 ? "#dc2626" : v > 5 ? "#d97706" : "#059669";
          return `<span class="sparkline-bar" style="width:3px;height:${h}px;background:${color};"><\/span>`;
        }).join("");
      }
      async function updateSectionSummary() {
        const view = document.getElementById("docSectionsView");
        if (!view || view.classList.contains("hidden")) return;
        const tbody = document.getElementById("sectionTableBody");
        const empty = document.getElementById("sectionEmpty");
        const wrap = document.getElementById("sectionTableWrap");
        if (!tbody) return;
        const outline = await getOutline(DOC.idx);
        const metrics = DOC.idx > 0 ? await getHeadingMetrics(DOC.idx) : new Map();
        const filter = (document.getElementById("sectionFilter")?.value || "").trim().toLowerCase();
        const rows = [];
        for (const entry of outline) {
          if (filter && !entry.text.toLowerCase().includes(filter)) continue;
          const m = metrics.get(entry.id) || { addLines: 0, delLines: 0, tokensAdded: 0, tokensDeleted: 0 };
          rows.push({ id: entry.id, text: entry.text, level: entry.level, add: m.addLines, del: m.delLines, tokens: m.tokensAdded + m.tokensDeleted, impact: m.addLines + m.delLines });
        }
        const sortKey = SECTION_SORT.key, dir = SECTION_SORT.asc ? 1 : -1;
        rows.sort((a, b) => sortKey === "name" ? dir * a.text.localeCompare(b.text) : dir * ((a[sortKey] || 0) - (b[sortKey] || 0)));
        if (!rows.length) { tbody.innerHTML = ""; if (wrap) wrap.classList.add("hidden"); if (empty) empty.classList.remove("hidden"); return; }
        if (wrap) wrap.classList.remove("hidden");
        if (empty) empty.classList.add("hidden");
        const maxImpact = Math.max(1, ...rows.map(r => r.impact));
        tbody.innerHTML = rows.map(r => {
          const indent = Math.max(0, r.level - 1) * 10;
          const barW = Math.round((r.impact / maxImpact) * 100);
          const spark = sectionSparkline(r.id, DOC.idx);
          const ic = r.impact === 0 ? "text-slate-400" : r.impact > 20 ? "text-red-600" : r.impact > 5 ? "text-amber-600" : "text-emerald-600";
          return `<tr class="border-b border-slate-100 hover:bg-slate-50/60 cursor-pointer transition-colors" data-heading-id="${escapeHtml(r.id)}"><td class="px-3 py-2 text-left"><div class="flex items-center gap-1.5" style="padding-left:${indent}px"><span class="truncate max-w-[240px]" title="${escapeHtml(r.text)}">${escapeHtml(r.text)}<\/span><span class="flex items-end gap-px ml-1">${spark}<\/span><\/div><\/td><td class="px-3 py-2 text-right mono text-emerald-600">${r.add > 0 ? "+" + r.add : ""}<\/td><td class="px-3 py-2 text-right mono text-red-500">${r.del > 0 ? "-" + r.del : ""}<\/td><td class="px-3 py-2 text-right mono text-slate-600">${r.tokens || ""}<\/td><td class="px-3 py-2 text-right"><div class="flex items-center justify-end gap-1.5"><span class="mono ${ic} font-semibold">${r.impact || ""}<\/span><span class="inline-block h-1.5 rounded-full bg-slate-200" style="width:40px"><span class="inline-block h-1.5 rounded-full" style="width:${barW}%;background:${r.impact > 20 ? '#dc2626' : r.impact > 5 ? '#d97706' : '#059669'}"><\/span><\/span><\/div><\/td><\/tr>`;
        }).join("");
        tbody.querySelectorAll("tr[data-heading-id]").forEach(tr => {
          tr.addEventListener("click", () => {
            const hid = tr.dataset.headingId;
            if (!hid) return;
            if (DOC.tab !== "spec") setDocTab("spec");
            setTimeout(() => {
              const docEl = document.getElementById("docRendered");
              if (!docEl) return;
              const target = docEl.querySelector(`#${CSS.escape(hid)}`);
              if (target) { target.scrollIntoView({ behavior: "smooth", block: "start" }); target.classList.remove("section-highlight"); void target.offsetWidth; target.classList.add("section-highlight"); }
            }, 350);
          });
        });
      }
      document.addEventListener("click", e => {
        const th = e.target.closest("#sectionTable th[data-sort]");
        if (!th) return;
        const key = th.dataset.sort;
        if (SECTION_SORT.key === key) SECTION_SORT.asc = !SECTION_SORT.asc;
        else { SECTION_SORT.key = key; SECTION_SORT.asc = key === "name"; }
        th.closest("thead")?.querySelectorAll("th[data-sort]").forEach(h => {
          const arrow = SECTION_SORT.key === h.dataset.sort ? (SECTION_SORT.asc ? " \u25B2" : " \u25BC") : "";
          h.textContent = h.textContent.replace(/\s*[\u25B2\u25BC]$/, "") + arrow;
        });
        void updateSectionSummary();
      });
      document.addEventListener("input", e => {
        if (e.target?.id === "sectionFilter") { clearTimeout(e.target._debounce); e.target._debounce = setTimeout(() => void updateSectionSummary(), 150); }
      });
      // Mobile section sheet open/close.
      function openSectionSheet() {
        const sheet = document.getElementById("sectionSheet");
        const overlay = document.getElementById("sectionSheetOverlay");
        if (sheet) { sheet.classList.remove("hidden"); requestAnimationFrame(() => sheet.classList.add("open")); }
        if (overlay) overlay.classList.remove("hidden");
        void updateSectionSheetList();
      }
      function closeSectionSheet() {
        const sheet = document.getElementById("sectionSheet");
        const overlay = document.getElementById("sectionSheetOverlay");
        if (sheet) { sheet.classList.remove("open"); setTimeout(() => sheet.classList.add("hidden"), 220); }
        if (overlay) overlay.classList.add("hidden");
      }
      async function updateSectionSheetList() {
        const list = document.getElementById("sectionSheetList");
        if (!list) return;
        const outline = await getOutline(DOC.idx);
        const metrics = DOC.idx > 0 ? await getHeadingMetrics(DOC.idx) : new Map();
        const filter = (document.getElementById("sectionFilterMobile")?.value || "").trim().toLowerCase();
        const items = [];
        for (const entry of outline) {
          if (filter && !entry.text.toLowerCase().includes(filter)) continue;
          const m = metrics.get(entry.id) || { addLines: 0, delLines: 0, tokensAdded: 0, tokensDeleted: 0 };
          const total = m.addLines + m.delLines;
          const color = total === 0 ? "bg-slate-100 text-slate-400" : total > 20 ? "bg-red-50 text-red-700" : total > 5 ? "bg-amber-50 text-amber-700" : "bg-emerald-50 text-emerald-700";
          const indent = Math.max(0, entry.level - 1) * 12;
          items.push(`<button class="w-full text-left rounded-2xl px-4 py-3 ${color} hover:brightness-95 transition-colors" data-heading-id="${escapeHtml(entry.id)}" style="padding-left:${indent + 16}px"><div class="text-sm font-semibold">${escapeHtml(entry.text)}<\/div><div class="mt-0.5 text-[11px]">+${m.addLines} -${m.delLines} lines \u00b7 ${m.tokensAdded + m.tokensDeleted} tokens<\/div><\/button>`);
        }
        list.innerHTML = items.length ? items.join("") : '<div class="text-xs text-slate-400 italic p-3">No section changes<\/div>';
        list.querySelectorAll("button[data-heading-id]").forEach(btn => {
          btn.addEventListener("click", () => {
            closeSectionSheet();
            setDocTab("spec");
            setTimeout(() => {
              const docEl = document.getElementById("docRendered");
              if (!docEl) return;
              const target = docEl.querySelector(`#${CSS.escape(btn.dataset.headingId)}`);
              if (target) { target.scrollIntoView({ behavior: "smooth", block: "start" }); target.classList.remove("section-highlight"); void target.offsetWidth; target.classList.add("section-highlight"); }
            }, 300);
          });
        });
      }
      document.getElementById("btnOpenSectionSheet")?.addEventListener("click", openSectionSheet);
      document.getElementById("btnCloseSectionSheet")?.addEventListener("click", closeSectionSheet);
      document.getElementById("sectionSheetOverlay")?.addEventListener("click", closeSectionSheet);
      document.getElementById("sectionFilterMobile")?.addEventListener("input", e => {
        clearTimeout(e.target._debounce);
        e.target._debounce = setTimeout(() => void updateSectionSheetList(), 150);
      });

      // ---- End Section Summary Panel ----

      // ---- Section Summary Unit Tests (bd-24q.8.4) ----
      // Run via console: window.__runSectionTests()
      window.__runSectionTests = function () {
        const results = [];
        const assert = (cond, msg, ctx) => {
          if (!cond) { results.push({ pass: false, msg, ctx }); console.error("FAIL:", msg, ctx || ""); }
          else results.push({ pass: true, msg });
        };

        // --- extractOutline tests ---
        (function testOutline_basic() {
          const md = "# Title\n\nSome text\n\n## Section A\n\nBody\n\n## Section B\n\nMore body\n\n### Subsection B.1\n";
          const o = extractOutline(md);
          assert(o.length === 4, "outline: 4 headings", { got: o.length });
          assert(o[0].text === "Title" && o[0].level === 1, "outline: h1 Title");
          assert(o[1].text === "Section A" && o[1].level === 2, "outline: h2 Section A");
          assert(o[2].text === "Section B" && o[2].level === 2, "outline: h2 Section B");
          assert(o[3].text === "Subsection B.1" && o[3].level === 3, "outline: h3 Subsection B.1");
        })();

        (function testOutline_duplicateSlugs() {
          const md = "## Intro\n\nText\n\n## Intro\n\nText\n\n## Intro\n";
          const o = extractOutline(md);
          assert(o.length === 3, "duplicate: 3 headings");
          assert(o[0].id === "intro", "duplicate: first is 'intro'", { got: o[0].id });
          assert(o[1].id === "intro-1", "duplicate: second is 'intro-1'", { got: o[1].id });
          assert(o[2].id === "intro-2", "duplicate: third is 'intro-2'", { got: o[2].id });
        })();

        (function testOutline_weirdPunctuation() {
          const md = "# Hello, World! (v2.0)\n\n## 日本語の見出し\n\n## `code_heading`\n";
          const o = extractOutline(md);
          assert(o.length === 3, "punctuation: 3 headings");
          assert(o[0].id.length > 0, "punctuation: non-empty slug for punctuated heading");
          assert(o[1].id.length > 0, "punctuation: non-empty slug for Unicode heading");
        })();

        (function testOutline_emptyHeading() {
          const md = "## \n\n## Real\n";
          const o = extractOutline(md);
          assert(o.length === 2, "empty: 2 headings (one empty)");
          assert(o[0].id === "heading", "empty: empty heading gets fallback slug 'heading'", { got: o[0].id });
        })();

        (function testOutline_deepNesting() {
          const md = "# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6\n";
          const o = extractOutline(md);
          assert(o.length === 6, "deep: 6 levels");
          assert(o[5].level === 6, "deep: h6 detected", { got: o[5].level });
        })();

        // --- slugifyHeading tests ---
        (function testSlug_basic() {
          assert(slugifyHeading("Hello World") === "hello-world", "slug: basic");
          assert(slugifyHeading("") === "heading", "slug: empty string fallback");
          assert(slugifyHeading("  ") === "heading", "slug: whitespace fallback");
          assert(slugifyHeading("CamelCase") === "camelcase", "slug: lowercased");
          assert(slugifyHeading("a--b") === "a-b", "slug: collapsed hyphens");
        })();

        // --- buildLineToHeadingMap tests ---
        (function testLineMap_basic() {
          const outline = [
            { text: "A", level: 1, id: "a", line: 1 },
            { text: "B", level: 2, id: "b", line: 5 },
            { text: "C", level: 2, id: "c", line: 10 },
          ];
          const map = buildLineToHeadingMap(15, outline);
          assert(map[1] === "a", "linemap: line 1 -> a", { got: map[1] });
          assert(map[4] === "a", "linemap: line 4 -> a (before B)", { got: map[4] });
          assert(map[5] === "b", "linemap: line 5 -> b", { got: map[5] });
          assert(map[9] === "b", "linemap: line 9 -> b", { got: map[9] });
          assert(map[10] === "c", "linemap: line 10 -> c", { got: map[10] });
          assert(map[15] === "c", "linemap: line 15 -> c", { got: map[15] });
        })();

        (function testLineMap_preamble() {
          const outline = [{ text: "A", level: 1, id: "a", line: 5 }];
          const map = buildLineToHeadingMap(10, outline);
          assert(map[1] === "__preamble__", "preamble: line 1 before any heading", { got: map[1] });
          assert(map[4] === "__preamble__", "preamble: line 4 before first heading", { got: map[4] });
          assert(map[5] === "a", "preamble: line 5 at first heading", { got: map[5] });
        })();

        // --- attributeHunksToHeadings tests ---
        (function testAttribution_basic() {
          const patch = `--- a/doc.md
+++ b/doc.md
@@ -3,2 +3,3 @@
 unchanged
+new line in section A
+another new line
@@ -8,1 +9,2 @@
 unchanged
+added in section B`;
          const lineToHeading = new Array(12);
          for (let i = 0; i <= 11; i++) lineToHeading[i] = i < 7 ? "a" : "b";
          const m = attributeHunksToHeadings(patch, lineToHeading);
          assert(m.has("a"), "attr: section a has metrics");
          assert(m.get("a").addLines === 2, "attr: section a +2 lines", { got: m.get("a")?.addLines });
          assert(m.has("b"), "attr: section b has metrics");
          assert(m.get("b").addLines === 1, "attr: section b +1 line", { got: m.get("b")?.addLines });
        })();

        (function testAttribution_deletions() {
          const patch = `--- a/doc.md
+++ b/doc.md
@@ -3,3 +3,1 @@
 unchanged
-removed line 1
-removed line 2`;
          const lineToHeading = new Array(8);
          for (let i = 0; i <= 7; i++) lineToHeading[i] = "section";
          const m = attributeHunksToHeadings(patch, lineToHeading);
          assert(m.has("section"), "del: section has metrics");
          assert(m.get("section").delLines === 2, "del: 2 lines deleted", { got: m.get("section")?.delLines });
          assert(m.get("section").addLines === 0, "del: 0 lines added", { got: m.get("section")?.addLines });
        })();

        (function testAttribution_empty_patch() {
          const m = attributeHunksToHeadings("", []);
          assert(m.size === 0, "empty: no metrics for empty patch");
        })();

        // --- countRoughTokens tests ---
        (function testTokens() {
          assert(countRoughTokens("hello world") === 2, "tokens: 2 words");
          assert(countRoughTokens("a + b = c") === 5, "tokens: operators count", { got: countRoughTokens("a + b = c") });
          assert(countRoughTokens("") === 0, "tokens: empty string");
          assert(countRoughTokens("single") === 1, "tokens: single word");
        })();

        // --- sectionSparkline tests ---
        (function testSparkline() {
          const html = sectionSparkline("nonexistent", 3);
          assert(html.includes("sparkline-bar"), "sparkline: contains bar spans");
          assert(!html.includes("undefined"), "sparkline: no undefined in output");
        })();

        // --- Performance sanity ---
        (function testPerformance_attribution() {
          // Generate a large synthetic diff.
          const lines = [];
          lines.push("--- a/big.md", "+++ b/big.md", "@@ -1,500 +1,600 @@");
          for (let i = 0; i < 500; i++) lines.push(" unchanged line " + i);
          for (let i = 0; i < 100; i++) lines.push("+added line " + i);
          const bigPatch = lines.join("\n");
          const bigMap = new Array(700);
          for (let i = 0; i < 700; i++) bigMap[i] = "section-" + Math.floor(i / 100);
          const t0 = performance.now();
          attributeHunksToHeadings(bigPatch, bigMap);
          const elapsed = performance.now() - t0;
          assert(elapsed < 100, "perf: 600-line attribution < 100ms", { elapsed: elapsed.toFixed(1) + "ms" });
        })();

        // Summary
        const passed = results.filter(r => r.pass).length;
        const failed = results.filter(r => !r.pass).length;
        const summary = `Section Summary Tests: ${passed} passed, ${failed} failed, ${results.length} total`;
        if (failed > 0) {
          console.warn(summary);
          results.filter(r => !r.pass).forEach(r => console.error("  FAIL:", r.msg, r.ctx || ""));
        } else {
          console.log("%c" + summary, "color: green; font-weight: bold");
        }
        return { passed, failed, total: results.length, results };
      };
      // ---- End Section Summary Unit Tests ----

      // ---- Section Summary E2E Tests (bd-24q.8.5) ----
      // Run via console: window.__runSectionE2ETests()
      // Requires dataset to be loaded and at least one commit with changes.
      window.__runSectionE2ETests = async function () {
        const results = [];
        const log = (msg, ctx) => console.log("  [E2E]", msg, ctx || "");
        const assert = (cond, msg, ctx) => {
          if (!cond) { results.push({ pass: false, msg, ctx }); console.error("  FAIL:", msg, ctx || ""); }
          else { results.push({ pass: true, msg }); log("PASS: " + msg); }
        };

        if (!DATASET.loaded || !ALL_COMMITS.length) {
          console.error("E2E: Dataset not loaded. Cannot run tests.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded" }] };
        }

        // Find a commit with actual changes for meaningful testing.
        let testIdx = -1;
        for (let i = 1; i < ALL_COMMITS.length; i++) {
          if (ALL_COMMITS[i].impact > 10) { testIdx = i; break; }
        }
        if (testIdx < 0) testIdx = Math.min(1, ALL_COMMITS.length - 1);
        log("Using commit idx=" + testIdx + " (" + ALL_COMMITS[testIdx].short + ")");

        // E2E 1: Switch to sections tab and verify table renders.
        await (async function testE2E_sectionsTabRenders() {
          selectCommitIdx(testIdx);
          setDocTab("sections");
          // Give async updateSectionSummary time to complete.
          await new Promise(r => setTimeout(r, 500));
          const view = document.getElementById("docSectionsView");
          assert(view && !view.classList.contains("hidden"), "e2e: sections view is visible");
          const tbody = document.getElementById("sectionTableBody");
          const rowCount = tbody ? tbody.querySelectorAll("tr").length : 0;
          log("Table has " + rowCount + " rows");
          assert(rowCount > 0, "e2e: section table has rows", { rowCount });
        })();

        // E2E 2: Sort by impact and verify order changes.
        await (async function testE2E_sortByImpact() {
          const th = document.querySelector('#sectionTable th[data-sort="impact"]');
          if (th) {
            th.click();
            await new Promise(r => setTimeout(r, 300));
            const rows = document.querySelectorAll("#sectionTableBody tr");
            if (rows.length >= 2) {
              const first = rows[0].querySelector("td:last-child .mono")?.textContent?.trim() || "0";
              const last = rows[rows.length - 1].querySelector("td:last-child .mono")?.textContent?.trim() || "0";
              log("First row impact: " + first + ", last row: " + last);
              assert(true, "e2e: sort by impact executed without error");
            } else {
              assert(true, "e2e: sort by impact (not enough rows to verify order)");
            }
          } else {
            assert(false, "e2e: impact sort header not found");
          }
        })();

        // E2E 3: Filter headings.
        await (async function testE2E_filterHeadings() {
          const input = document.getElementById("sectionFilter");
          if (input) {
            const tbody = document.getElementById("sectionTableBody");
            const beforeCount = tbody ? tbody.querySelectorAll("tr").length : 0;
            input.value = "xyznonexistent";
            input.dispatchEvent(new Event("input", { bubbles: true }));
            await new Promise(r => setTimeout(r, 300));
            const afterCount = tbody ? tbody.querySelectorAll("tr").length : 0;
            log("Before filter: " + beforeCount + " rows, after: " + afterCount);
            assert(afterCount <= beforeCount, "e2e: filter reduces or maintains row count");
            // Reset filter.
            input.value = "";
            input.dispatchEvent(new Event("input", { bubbles: true }));
            await new Promise(r => setTimeout(r, 300));
          } else {
            assert(false, "e2e: filter input not found");
          }
        })();

        // E2E 4: Click row jumps to spec tab with heading.
        await (async function testE2E_clickRowJumps() {
          setDocTab("sections");
          await new Promise(r => setTimeout(r, 500));
          const firstRow = document.querySelector("#sectionTableBody tr[data-heading-id]");
          if (firstRow) {
            const hid = firstRow.dataset.headingId;
            log("Clicking row for heading: " + hid);
            firstRow.click();
            await new Promise(r => setTimeout(r, 600));
            assert(DOC.tab === "spec", "e2e: after click, tab switched to spec", { got: DOC.tab });
            const docEl = document.getElementById("docRendered");
            const target = docEl ? docEl.querySelector("#" + CSS.escape(hid)) : null;
            assert(target !== null, "e2e: heading element exists in rendered doc", { hid });
            if (target) {
              const hasHighlight = target.classList.contains("section-highlight");
              log("Heading has highlight class: " + hasHighlight);
              assert(true, "e2e: heading element found (highlight animation triggered)");
            }
          } else {
            assert(false, "e2e: no rows in section table to click");
          }
        })();

        // E2E 5: Mobile sheet open/close.
        await (async function testE2E_mobileSheet() {
          const sheet = document.getElementById("sectionSheet");
          const overlay = document.getElementById("sectionSheetOverlay");
          if (sheet && overlay) {
            // Open.
            if (typeof openSectionSheet === "function") {
              openSectionSheet();
              await new Promise(r => setTimeout(r, 300));
              assert(!sheet.classList.contains("hidden"), "e2e: mobile sheet opened");
              const list = document.getElementById("sectionSheetList");
              const itemCount = list ? list.querySelectorAll("button[data-heading-id]").length : 0;
              log("Mobile sheet has " + itemCount + " items");
              assert(itemCount > 0, "e2e: mobile sheet has items", { itemCount });
              // Close.
              closeSectionSheet();
              await new Promise(r => setTimeout(r, 300));
              assert(overlay.classList.contains("hidden"), "e2e: mobile sheet overlay hidden after close");
            } else {
              assert(false, "e2e: openSectionSheet function not found");
            }
          } else {
            assert(false, "e2e: mobile sheet elements not found");
          }
        })();

        // E2E 6: Mobile sheet tap navigates.
        await (async function testE2E_mobileSheetTap() {
          if (typeof openSectionSheet === "function") {
            openSectionSheet();
            await new Promise(r => setTimeout(r, 300));
            const firstBtn = document.querySelector("#sectionSheetList button[data-heading-id]");
            if (firstBtn) {
              const hid = firstBtn.dataset.headingId;
              log("Mobile: tapping heading " + hid);
              firstBtn.click();
              await new Promise(r => setTimeout(r, 600));
              assert(DOC.tab === "spec", "e2e: mobile tap switched to spec", { got: DOC.tab });
              const sheet = document.getElementById("sectionSheet");
              // Sheet may still be animating closed.
              log("Sheet hidden: " + sheet?.classList.contains("hidden"));
              assert(true, "e2e: mobile tap navigation executed");
            } else {
              assert(false, "e2e: no mobile sheet items to tap");
            }
          }
        })();

        // E2E 7: No dock overlap check.
        await (async function testE2E_noDockOverlap() {
          const sheet = document.getElementById("sectionSheet");
          const dock = document.getElementById("dock");
          if (sheet && dock) {
            if (typeof openSectionSheet === "function") {
              openSectionSheet();
              await new Promise(r => setTimeout(r, 300));
              const sheetRect = sheet.getBoundingClientRect();
              const dockRect = dock.getBoundingClientRect();
              // Sheet z-index (50) should be above dock z-index (30).
              const sheetZ = parseInt(getComputedStyle(sheet).zIndex) || 0;
              const dockZ = parseInt(getComputedStyle(dock).zIndex) || 0;
              log("Sheet z-index: " + sheetZ + ", dock z-index: " + dockZ);
              assert(sheetZ > dockZ, "e2e: sheet z-index above dock", { sheetZ, dockZ });
              closeSectionSheet();
              await new Promise(r => setTimeout(r, 300));
            }
          }
        })();

        // Summary.
        const passed = results.filter(r => r.pass).length;
        const failed = results.filter(r => !r.pass).length;
        const summary = `Section E2E Tests: ${passed} passed, ${failed} failed, ${results.length} total`;
        if (failed > 0) {
          console.warn(summary);
          results.filter(r => !r.pass).forEach(r => console.error("  FAIL:", r.msg, r.ctx || ""));
        } else {
          console.log("%c" + summary, "color: green; font-weight: bold");
        }
        return { passed, failed, total: results.length, results };
      };
      // ---- End Section Summary E2E Tests ----

      // ---- A/B Compare Unit Tests (bd-24q.1.5) ----
      window.__runABCompareTests = async function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || ""); };
        A(quickMetricsFromPatch("").hunks === 0, "empty patch: 0 hunks");
        let m = quickMetricsFromPatch("--- a/f\n+++ b/f\n@@ -1,2 +1,3 @@\n l1\n+added\n l2\n");
        A(m.hunks === 1 && m.addLines === 1 && m.delLines === 0, "simple add", m);
        m = quickMetricsFromPatch("--- a/f\n+++ b/f\n@@ -1,3 +1,3 @@\n ctx\n-old\n+new\n ctx2\n");
        A(m.addLines === 1 && m.delLines === 1, "replace 1+1", m);
        m = quickMetricsFromPatch("--- a/f\n+++ b/f\n@@ -1 +1 @@\n-x\n+y\n@@ -5 +5 @@\n-a\n+b\n");
        A(m.hunks === 2, "multi-hunk", m);
        let h = parseUnifiedHunks("@@ -1,3 +1,4 @@\n l1\n+ins\n l2\n l3\n");
        A(h.length === 1 && h[0].oldStart === 1, "hunks basic");
        h = parseUnifiedHunks("@@ -5 +5 @@\n-old\n+new\n");
        A(h.length === 1 && h[0].oldCount === 1, "hunks no-count");
        let r = applyPatchLines(["a","b","c"], "@@ -2,2 +2,3 @@\n b\n+ins\n c\n");
        A(r.length === 4 && r[2] === "ins", "apply add");
        r = applyPatchLines(["a","b","c"], "@@ -1,3 +1,2 @@\n a\n-b\n c\n");
        A(r.length === 2 && r[1] === "c", "apply del");
        r = applyPatchLines(["a","b","c"], "@@ -2,1 +2,1 @@\n-b\n+B\n");
        A(r.length === 3 && r[1] === "B", "apply replace");
        if (DATASET.loaded && DATASET.data) {
          const base = String(DATASET.data.base_doc || "");
          A((await docTextAtLocal(0)) === base, "snapshot 0==base");
          if (ALL_COMMITS.length > 1) { DOC_CACHE.delete(1); DOC_CURSOR.idx=-1; DOC_CURSOR.lines=null; const a=await docTextAtLocal(1); DOC_CACHE.delete(1); DOC_CURSOR.idx=-1; DOC_CURSOR.lines=null; A(a===(await docTextAtLocal(1)), "snapshot 1 deterministic"); }
          if (ALL_COMMITS.length > 5) { DOC_CACHE.clear(); DOC_CURSOR.idx=-1; DOC_CURSOR.lines=null; const d=await docTextAtLocal(5); DOC_CACHE.clear(); DOC_CURSOR.idx=-1; DOC_CURSOR.lines=null; let ln=base.split("\n"); for(let i=1;i<=5;i++) ln=applyPatchLines(ln,patchForIdx(i)); A(d===ln.join("\n"), "snapshot 5 far-jump"); }
          if (typeof Diff!=="undefined" && ALL_COMMITS.length>3) {
            A((await generateABDiff(0,2))===(await generateABDiff(0,2)), "diff deterministic");
            const ms=quickMetricsFromPatch(await generateABDiff(1,1)); A(ms.addLines===0&&ms.delLines===0, "diff same: 0");
            const mAB=quickMetricsFromPatch(await generateABDiff(0,3)); const mBA=quickMetricsFromPatch(await generateABDiff(3,0));
            A(mAB.addLines===mBA.delLines&&mAB.delLines===mBA.addLines, "diff swap symmetry");
            A(quickMetricsFromPatch(await generateABDiff(0,ALL_COMMITS.length-1)).tokensDelta>0, "spec grew");
          }
        }
        (() => { const c=document.createElement("div"); c.innerHTML='<span id="abmLines"></span><span id="abmTokens"></span><span id="abmLev"></span><span id="abmHunks"></span><span id="abmBytes"></span>'; document.body.appendChild(c); renderABMetricChips({addLines:100,delLines:50,deltaLines:50,tokensChanged:300,tokensDelta:100,bytesChanged:5000,bytesDelta:2000,hunks:5,lev:42}); A(document.getElementById("abmLines").textContent.includes("+100"),"chip +100"); A(document.getElementById("abmLev").textContent.includes("42"),"chip lev"); document.body.removeChild(c); })();
        (() => { const c=document.createElement("div"); c.innerHTML='<span id="abmLines"></span><span id="abmTokens"></span><span id="abmLev"></span><span id="abmHunks"></span><span id="abmBytes"></span>'; document.body.appendChild(c); renderABMetricChips({addLines:0,delLines:0,deltaLines:0,tokensChanged:0,tokensDelta:0,bytesChanged:0,bytesDelta:0,hunks:0,lev:null}); A(document.getElementById("abmLev").textContent.includes("?"),"chip null lev"); document.body.removeChild(c); })();
        const p=R.filter(x=>x.pass).length, f=R.filter(x=>!x.pass).length;
        const s=`A/B Compare Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if(f>0){console.warn(s);R.filter(x=>!x.pass).forEach(x=>console.error("  FAIL:",x.msg,x.ctx||""));}else console.log("%c"+s,"color:green;font-weight:bold");
        return{passed:p,failed:f,total:R.length,results:R};
      };
      // ---- End A/B Compare Unit Tests ----

      // ---- A/B Compare E2E Tests (bd-24q.1.6) ----
      // Run via console: window.__runABCompareE2ETests()
      // Requires dataset to be loaded with at least 3 commits.
      window.__runABCompareE2ETests = async function () {
        const results = [];
        const log = (msg, ctx) => console.log("  [AB-E2E]", msg, ctx || "");
        const assert = (cond, msg, ctx) => {
          if (!cond) { results.push({ pass: false, msg, ctx }); console.error("  FAIL:", msg, ctx || ""); }
          else { results.push({ pass: true, msg }); log("PASS: " + msg); }
        };
        const wait = (ms) => new Promise((r) => setTimeout(r, ms));

        if (!DATASET.loaded || ALL_COMMITS.length < 3) {
          console.error("AB-E2E: Need loaded dataset with >= 3 commits.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded or < 3 commits" }] };
        }

        const origIdx = DOC.idx;
        const origTab = DOC.tab;
        const origCompare = DOC.compareMode;
        const origFromIdx = DOC.compareFromIdx;
        const origToIdx = DOC.compareToIdx;
        const origLayout = DOC.diffLayout;

        // --- E2E 1: Enable compare mode via toggle ---
        await (async function testE2E_enableCompare() {
          DOC.compareMode = false;
          setDocTab("diff");
          await wait(200);
          const btn = document.getElementById("btnCompareToggle");
          if (btn) {
            btn.click();
            await wait(400);
            assert(DOC.compareMode === true, "ab-e2e: compare mode enabled after toggle click");
            const bar = document.getElementById("abCompareBar");
            assert(bar && !bar.classList.contains("hidden"), "ab-e2e: abCompareBar is visible");
            log("compareFromIdx=" + DOC.compareFromIdx + " compareToIdx=" + DOC.compareToIdx);
          } else {
            assert(false, "ab-e2e: btnCompareToggle not found");
          }
        })();

        // --- E2E 2: Pick A and B, verify diff renders ---
        await (async function testE2E_pickAB() {
          DOC.compareFromIdx = 0;
          DOC.compareToIdx = Math.min(2, ALL_COMMITS.length - 1);
          DOC.compareMode = true;
          populateCompareSelects();
          setDocTab("diff");
          await wait(1500);
          const diffEl = document.getElementById("diffPretty");
          const hasContent = diffEl && diffEl.innerHTML.length > 50;
          assert(hasContent, "ab-e2e: diffPretty has content after picking A=0 B=2", { htmlLen: diffEl?.innerHTML.length });
          const btnA = document.getElementById("pickerABtn");
          const btnB = document.getElementById("pickerBBtn");
          assert(btnA && btnA.textContent.length > 2, "ab-e2e: picker A has label text");
          assert(btnB && btnB.textContent.length > 2, "ab-e2e: picker B has label text");
        })();

        // --- E2E 3: Metrics bar appears for different A/B ---
        await (async function testE2E_metricsBar() {
          DOC.compareFromIdx = 0;
          DOC.compareToIdx = 2;
          DOC.compareMode = true;
          setDocTab("diff");
          await wait(2000);
          const bar = document.getElementById("abMetricsBar");
          const visible = bar && !bar.classList.contains("hidden");
          assert(visible, "ab-e2e: abMetricsBar visible for A!=B");
          if (visible) {
            const linesChip = document.getElementById("abmLines");
            const hunksChip = document.getElementById("abmHunks");
            log("Lines chip: " + (linesChip?.textContent || "(empty)"));
            log("Hunks chip: " + (hunksChip?.textContent || "(empty)"));
            assert(linesChip && linesChip.textContent.length > 0 && linesChip.textContent !== "...", "ab-e2e: lines chip populated");
            assert(hunksChip && hunksChip.textContent.length > 0 && hunksChip.textContent !== "...", "ab-e2e: hunks chip populated");
          }
        })();

        // --- E2E 4: Swap A and B, verify indices swap ---
        await (async function testE2E_swap() {
          DOC.compareFromIdx = 0;
          DOC.compareToIdx = 2;
          DOC.compareMode = true;
          populateCompareSelects();
          syncUrlToState();
          await wait(200);
          const swapBtn = document.getElementById("btnSwapAB");
          if (swapBtn) {
            swapBtn.click();
            await wait(800);
            assert(DOC.compareFromIdx === 2, "ab-e2e: after swap, fromIdx=2", { got: DOC.compareFromIdx });
            assert(DOC.compareToIdx === 0, "ab-e2e: after swap, toIdx=0", { got: DOC.compareToIdx });
          } else {
            assert(false, "ab-e2e: btnSwapAB not found");
          }
        })();

        // --- E2E 5: Toggle diff layout ---
        await (async function testE2E_diffLayout() {
          DOC.compareMode = true;
          DOC.compareFromIdx = 0;
          DOC.compareToIdx = 2;
          DOC.diffLayout = "side-by-side";
          setDocTab("diff");
          await wait(800);
          const layoutBtn = document.getElementById("btnDiffLayout");
          if (layoutBtn) {
            const beforeLayout = DOC.diffLayout;
            layoutBtn.click();
            await wait(800);
            assert(DOC.diffLayout !== beforeLayout, "ab-e2e: layout toggled");
            assert(DOC.diffLayout === "line-by-line", "ab-e2e: layout is now line-by-line");
            layoutBtn.click();
            await wait(400);
            assert(DOC.diffLayout === "side-by-side", "ab-e2e: layout back to side-by-side");
          } else {
            assert(false, "ab-e2e: btnDiffLayout not found");
          }
        })();

        // --- E2E 6: Switch tabs while in compare mode ---
        await (async function testE2E_tabSwitch() {
          DOC.compareMode = true;
          DOC.compareFromIdx = 0;
          DOC.compareToIdx = 2;
          for (const tab of ["spec", "diff", "metrics", "sections", "diff"]) {
            try {
              setDocTab(tab);
              await wait(300);
              assert(DOC.tab === tab, "ab-e2e: tab switch to " + tab + " ok");
            } catch (e) {
              assert(false, "ab-e2e: tab switch to " + tab + " threw", { error: String(e) });
            }
          }
        })();

        // --- E2E 7: Permalink round-trip ---
        await (async function testE2E_permalink() {
          DOC.compareMode = true;
          DOC.compareFromIdx = 1;
          DOC.compareToIdx = Math.min(3, ALL_COMMITS.length - 1);
          DOC.diffLayout = "line-by-line";
          setDocTab("diff");
          await wait(200);
          const encoded = encodeUrlState();
          log("Encoded URL state: " + encoded);
          assert(encoded.includes("cmp=1"), "ab-e2e: permalink has cmp=1");
          assert(encoded.includes("ca=1"), "ab-e2e: permalink has ca=1");
          assert(encoded.includes("cb="), "ab-e2e: permalink has cb=");
          assert(encoded.includes("dl=line-by-line"), "ab-e2e: permalink has dl=line-by-line");
          const decoded = decodeUrlState(encoded);
          assert(decoded !== null, "ab-e2e: decoded is not null");
          assert(decoded.cmp === true, "ab-e2e: decoded.cmp is true");
          assert(decoded.ca === 1, "ab-e2e: decoded.ca is 1", { got: decoded?.ca });
          assert(decoded.cb === DOC.compareToIdx, "ab-e2e: decoded.cb matches", { got: decoded?.cb });
          assert(decoded.dl === "line-by-line", "ab-e2e: decoded.dl is line-by-line");
          const savedFrom = DOC.compareFromIdx;
          const savedTo = DOC.compareToIdx;
          DOC.compareMode = false; DOC.compareFromIdx = 0; DOC.compareToIdx = 0; DOC.diffLayout = "side-by-side";
          applyUrlState(decoded);
          assert(DOC.compareMode === true, "ab-e2e: applyUrlState restored compareMode");
          assert(DOC.compareFromIdx === savedFrom, "ab-e2e: applyUrlState restored fromIdx");
          assert(DOC.compareToIdx === savedTo, "ab-e2e: applyUrlState restored toIdx");
          assert(DOC.diffLayout === "line-by-line", "ab-e2e: applyUrlState restored diffLayout");
        })();

        // --- E2E 8: Disable compare mode ---
        await (async function testE2E_disableCompare() {
          DOC.compareMode = true;
          setDocTab("diff");
          await wait(200);
          const btn = document.getElementById("btnCompareToggle");
          if (btn) {
            if (!DOC.compareMode) { btn.click(); await wait(200); }
            btn.click();
            await wait(400);
            assert(DOC.compareMode === false, "ab-e2e: compare mode disabled after toggle");
            const bar = document.getElementById("abCompareBar");
            assert(bar && bar.classList.contains("hidden"), "ab-e2e: abCompareBar hidden after disable");
            const metricsBar = document.getElementById("abMetricsBar");
            assert(!metricsBar || metricsBar.classList.contains("hidden"), "ab-e2e: abMetricsBar hidden after disable");
          } else {
            assert(false, "ab-e2e: btnCompareToggle not found");
          }
        })();

        // Restore original state.
        DOC.compareMode = origCompare;
        DOC.compareFromIdx = origFromIdx;
        DOC.compareToIdx = origToIdx;
        DOC.diffLayout = origLayout;
        DOC.idx = origIdx;
        setDocTab(origTab);
        await wait(300);

        const passed = results.filter((r) => r.pass).length;
        const failed = results.filter((r) => !r.pass).length;
        const summary = `A/B Compare E2E Tests: ${passed} passed, ${failed} failed, ${results.length} total`;
        if (failed > 0) {
          console.warn(summary);
          results.filter((r) => !r.pass).forEach((r) => console.error("  FAIL:", r.msg, r.ctx || ""));
        } else {
          console.log("%c" + summary, "color: green; font-weight: bold");
        }
        return { passed, failed, total: results.length, results };
      };
      // ---- End A/B Compare E2E Tests ----

      // ---- Permalink Unit Tests (bd-24q.3.4) ----
      // Run via console: window.__runPermalinkTests()
      window.__runPermalinkTests=function(){const R=[];const A=(c,m,x)=>{R.push(c?{pass:true,msg:m}:{pass:false,msg:m,ctx:x});if(!c)console.error("FAIL:",m,x||"")};const oD={idx:DOC.idx,tab:DOC.tab,rawSpec:DOC.rawSpec,diffMode:DOC.diffMode,compareMode:DOC.compareMode,compareFromIdx:DOC.compareFromIdx,compareToIdx:DOC.compareToIdx,diffLayout:DOC.diffLayout};const oS={q:STATE.q,minImpact:STATE.minImpact,bucketMode:STATE.bucketMode,bucketEnabled:new Set(STATE.bucketEnabled)};const mx=Math.max(0,(ALL_COMMITS?.length||1)-1);A(decodeUrlState("")===null,"decode:empty->null");A(decodeUrlState("c=5")===null,"decode:no-v->null");A(decodeUrlState("v=999")===null,"decode:bad-v->null");let d=decodeUrlState("v=1");A(d!==null,"decode:v=1 ok");A(d.c===-1,"decode:c=-1",{got:d?.c});A(d.t==="spec","decode:t=spec");A(d.raw===false,"decode:raw=false");A(d.dm==="pretty","decode:dm=pretty");A(d.q==="","decode:q=empty");A(d.mi===0,"decode:mi=0");A(d.bm==="primary","decode:bm=primary");A(d.b===null,"decode:b=null");A(d.cmp===false,"decode:cmp=false");d=decodeUrlState("v=1&c=5&t=diff&raw=1&dm=raw&q=hello&mi=10&bm=multi&b=1,2,3&cmp=1&ca=2&cb=7&dl=line-by-line");A(d.c===5,"decode:c=5");A(d.t==="diff","decode:t=diff");A(d.raw===true,"decode:raw=1");A(d.dm==="raw","decode:dm=raw");A(d.q==="hello","decode:q=hello");A(d.mi===10,"decode:mi=10");A(d.bm==="multi","decode:bm=multi");A(d.b instanceof Set&&d.b.size===3,"decode:b=3ids");A(d.cmp===true,"decode:cmp=true");A(d.ca===2,"decode:ca=2");A(d.cb===7,"decode:cb=7");A(d.dl==="line-by-line","decode:dl=l-b-l");A(decodeUrlState("v=1&t=bogus").t==="spec","decode:bad-tab->spec");A(decodeUrlState("v=1&dm=bogus").dm==="pretty","decode:bad-dm->pretty");A(decodeUrlState("v=1&c=-5").c===-1,"decode:neg-c->-1");A(decodeUrlState("v=1&c=3.7").c===3,"decode:float-c->3");A(decodeUrlState("v=1&c=abc").c===-1,"decode:nan-c->-1");d=decodeUrlState("v=1&b=abc,def");A(d.b instanceof Set&&d.b.size===URL_ALL_BUCKET_IDS.size,"decode:bad-b->all");d=decodeUrlState("v=1&cmp=1");A(d.cmp===true&&d.ca===0&&d.cb===0,"decode:partial-cmp");A(d.dl==="side-by-side","decode:no-dl->sbs");A(decodeUrlState("v=1&cmp=1&dl=bogus").dl==="side-by-side","decode:bad-dl->sbs");DOC.idx=mx;DOC.tab="spec";DOC.rawSpec=false;DOC.diffMode="pretty";DOC.compareMode=false;STATE.q="";STATE.minImpact=0;STATE.bucketMode="primary";STATE.bucketEnabled=new Set(URL_ALL_BUCKET_IDS);A(encodeUrlState()==="","encode:defaults->empty");DOC.tab="diff";let enc=encodeUrlState();A(enc.includes("v=1"),"encode:has-v");A(enc.includes("t=diff"),"encode:t=diff");A(!enc.includes("c="),"encode:no-c@max");DOC.tab="spec";DOC.idx=3;enc=encodeUrlState();A(enc.includes("c=3"),"encode:c=3");DOC.idx=mx;DOC.tab="diff";DOC.compareMode=true;DOC.compareFromIdx=1;DOC.compareToIdx=5;DOC.diffLayout="line-by-line";enc=encodeUrlState();A(enc.includes("cmp=1"),"encode:cmp");A(enc.includes("ca=1"),"encode:ca");A(enc.includes("cb=5"),"encode:cb");A(enc.includes("dl=line-by-line"),"encode:dl");DOC.diffLayout="side-by-side";DOC.compareFromIdx=0;DOC.compareToIdx=1;enc=encodeUrlState();A(!enc.includes("dl="),"encode:sbs-omit");DOC.compareMode=false;DOC.tab="spec";STATE.q="MVCC";enc=encodeUrlState();A(enc.includes("q=MVCC"),"encode:q");STATE.q="";const ids=[...URL_ALL_BUCKET_IDS];STATE.bucketEnabled=new Set(ids.slice(0,2));enc=encodeUrlState();A(enc.includes("b="),"encode:subset-b");STATE.bucketEnabled=new Set(URL_ALL_BUCKET_IDS);DOC.idx=2;DOC.tab="diff";DOC.rawSpec=true;DOC.diffMode="raw";DOC.compareMode=false;STATE.q="test query";STATE.minImpact=5;STATE.bucketMode="multi";const e1=encodeUrlState();applyUrlState(decodeUrlState(e1));const e2=encodeUrlState();A(e1===e2,"roundtrip:basic",{e1,e2});DOC.idx=0;DOC.tab="diff";DOC.rawSpec=false;DOC.diffMode="pretty";DOC.compareMode=true;DOC.compareFromIdx=1;DOC.compareToIdx=Math.min(4,mx);DOC.diffLayout="line-by-line";STATE.q="";STATE.minImpact=0;STATE.bucketMode="primary";STATE.bucketEnabled=new Set(URL_ALL_BUCKET_IDS);const e3=encodeUrlState();applyUrlState(decodeUrlState(e3));const e4=encodeUrlState();A(e3===e4,"roundtrip:compare",{e3,e4});A(DOC.compareMode===true&&DOC.compareFromIdx===1&&DOC.diffLayout==="line-by-line","roundtrip:cmp-ok");DOC.idx=2;DOC.tab="diff";DOC.rawSpec=true;DOC.diffMode="raw";DOC.compareMode=true;DOC.compareFromIdx=0;DOC.compareToIdx=1;DOC.diffLayout="line-by-line";STATE.q="foo";STATE.minImpact=3;STATE.bucketMode="multi";STATE.bucketEnabled=new Set(URL_ALL_BUCKET_IDS);enc=encodeUrlState();const keys=[...new URLSearchParams(enc).keys()];const ord=["v","c","t","raw","dm","cmp","ca","cb","dl","q","mi","bm"];let pv=-1,ok=true;for(const k of ord){const p=keys.indexOf(k);if(p>=0){if(p<pv){ok=false;break}pv=p}}A(ok,"canonical:order",{keys});A(keys[0]==="v","canonical:v-first");A(decodeUrlState("v=1&mi=0").mi===0,"edge:mi=0");A(decodeUrlState("v=1&mi=-5").mi===0,"edge:neg-mi");A(decodeUrlState("v=1&raw=1").raw===true,"edge:raw=1");A(decodeUrlState("v=1&raw=0").raw===false,"edge:raw=0");A(decodeUrlState("v=1&raw=yes").raw===false,"edge:raw=yes");d=decodeUrlState("v=1&b=");A(d.b instanceof Set&&d.b.size===URL_ALL_BUCKET_IDS.size,"edge:empty-b->all");Object.assign(DOC,oD);Object.assign(STATE,oS);const p=R.filter(x=>x.pass).length,f=R.filter(x=>!x.pass).length;const s=`Permalink Tests: ${p} passed, ${f} failed, ${R.length} total`;if(f>0){console.warn(s);R.filter(x=>!x.pass).forEach(x=>console.error("  FAIL:",x.msg,x.ctx||""))}else console.log("%c"+s,"color:green;font-weight:bold");return{passed:p,failed:f,total:R.length,results:R}};
      // ---- End Permalink Unit Tests ----

      // ---- Permalink E2E Tests (bd-24q.3.5) ----
      // Run via console: window.__runPermalinkE2ETests()
      // Requires dataset to be loaded.
      window.__runPermalinkE2ETests = async function () {
        const results = [];
        const log = (msg, ctx) => console.log("  [PL-E2E]", msg, ctx || "");
        const assert = (cond, msg, ctx) => {
          if (!cond) { results.push({ pass: false, msg, ctx }); console.error("  FAIL:", msg, ctx || ""); }
          else { results.push({ pass: true, msg }); log("PASS: " + msg); }
        };
        const wait = (ms) => new Promise((r) => setTimeout(r, ms));

        if (!DATASET.loaded || ALL_COMMITS.length < 3) {
          console.error("PL-E2E: Need loaded dataset with >= 3 commits.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded or < 3 commits" }] };
        }

        const maxIdx = ALL_COMMITS.length - 1;
        // Save original state.
        const origDoc = { idx: DOC.idx, tab: DOC.tab, rawSpec: DOC.rawSpec, diffMode: DOC.diffMode, compareMode: DOC.compareMode, compareFromIdx: DOC.compareFromIdx, compareToIdx: DOC.compareToIdx, diffLayout: DOC.diffLayout, abViewMode: DOC.abViewMode };
        const origState = { q: STATE.q, minImpact: STATE.minImpact, bucketMode: STATE.bucketMode, bucketEnabled: new Set(STATE.bucketEnabled) };

        // --- E2E 1: Complex state round-trip via encode/decode/apply ---
        await (async function testE2E_complexRoundTrip() {
          log("Setting complex state...");
          DOC.idx = 2; DOC.tab = "diff"; DOC.rawSpec = true; DOC.diffMode = "raw";
          DOC.compareMode = true; DOC.compareFromIdx = 0; DOC.compareToIdx = Math.min(3, maxIdx);
          DOC.diffLayout = "line-by-line"; DOC.abViewMode = "rendered";
          STATE.q = "MVCC concurrency"; STATE.minImpact = 5; STATE.bucketMode = "multi";
          const ids = [...URL_ALL_BUCKET_IDS];
          STATE.bucketEnabled = new Set(ids.slice(0, Math.min(3, ids.length)));

          const encoded = encodeUrlState();
          log("Encoded URL: " + encoded);
          assert(encoded.length > 20, "pl-e2e: complex state produces non-trivial URL", { len: encoded.length });

          // Summarize state before.
          const stateBefore = { idx: DOC.idx, tab: DOC.tab, raw: DOC.rawSpec, dm: DOC.diffMode, cmp: DOC.compareMode, ca: DOC.compareFromIdx, cb: DOC.compareToIdx, dl: DOC.diffLayout, avm: DOC.abViewMode, q: STATE.q, mi: STATE.minImpact, bm: STATE.bucketMode, bCount: STATE.bucketEnabled.size };
          log("State before: " + JSON.stringify(stateBefore));

          // Reset to defaults.
          DOC.idx = maxIdx; DOC.tab = "spec"; DOC.rawSpec = false; DOC.diffMode = "pretty";
          DOC.compareMode = false; DOC.compareFromIdx = 0; DOC.compareToIdx = 0;
          DOC.diffLayout = "side-by-side"; DOC.abViewMode = "diff";
          STATE.q = ""; STATE.minImpact = 0; STATE.bucketMode = "primary";
          STATE.bucketEnabled = new Set(URL_ALL_BUCKET_IDS);

          // Decode and apply.
          const decoded = decodeUrlState(encoded);
          assert(decoded !== null, "pl-e2e: decoded is not null");
          applyUrlState(decoded);

          // Summarize state after.
          const stateAfter = { idx: DOC.idx, tab: DOC.tab, raw: DOC.rawSpec, dm: DOC.diffMode, cmp: DOC.compareMode, ca: DOC.compareFromIdx, cb: DOC.compareToIdx, dl: DOC.diffLayout, q: STATE.q, mi: STATE.minImpact, bm: STATE.bucketMode, bCount: STATE.bucketEnabled.size };
          log("State after: " + JSON.stringify(stateAfter));

          assert(DOC.idx === 2, "pl-e2e: idx restored to 2", { got: DOC.idx });
          assert(DOC.tab === "diff", "pl-e2e: tab restored to diff");
          assert(DOC.rawSpec === true, "pl-e2e: rawSpec restored");
          assert(DOC.diffMode === "raw", "pl-e2e: diffMode restored");
          assert(DOC.compareMode === true, "pl-e2e: compareMode restored");
          assert(DOC.compareFromIdx === 0, "pl-e2e: fromIdx restored");
          assert(DOC.compareToIdx === Math.min(3, maxIdx), "pl-e2e: toIdx restored");
          assert(DOC.diffLayout === "line-by-line", "pl-e2e: diffLayout restored");
          assert(STATE.q === "MVCC concurrency", "pl-e2e: query restored");
          assert(STATE.minImpact === 5, "pl-e2e: minImpact restored");
          assert(STATE.bucketMode === "multi", "pl-e2e: bucketMode restored");
          assert(STATE.bucketEnabled.size <= 3, "pl-e2e: bucket subset restored", { got: STATE.bucketEnabled.size });
        })();

        // --- E2E 2: URL updates when commit changes via selectCommitIdx ---
        await (async function testE2E_commitChangeUpdatesUrl() {
          DOC.compareMode = false;
          DOC.tab = "spec"; DOC.rawSpec = false; DOC.diffMode = "pretty";
          STATE.q = ""; STATE.minImpact = 0; STATE.bucketMode = "primary";
          STATE.bucketEnabled = new Set(URL_ALL_BUCKET_IDS);
          selectCommitIdx(3);
          await wait(200); // Wait for rAF debounce in syncUrlToState.
          const qs = encodeUrlState();
          log("After selectCommitIdx(3), URL: " + qs);
          assert(qs.includes("c=3"), "pl-e2e: URL has c=3 after selectCommitIdx(3)", { got: qs });

          selectCommitIdx(maxIdx);
          await wait(200);
          const qs2 = encodeUrlState();
          log("After selectCommitIdx(max), URL: " + qs2);
          assert(!qs2.includes("c=") || qs2 === "", "pl-e2e: URL omits c at maxIdx", { got: qs2 });
        })();

        // --- E2E 3: Tab switch persists in URL ---
        await (async function testE2E_tabPersists() {
          DOC.compareMode = false;
          setDocTab("metrics");
          await wait(200);
          const qs = encodeUrlState();
          log("After setDocTab(metrics), URL: " + qs);
          assert(qs.includes("t=metrics"), "pl-e2e: URL has t=metrics", { got: qs });

          setDocTab("spec");
          await wait(200);
          const qs2 = encodeUrlState();
          assert(!qs2.includes("t=") || qs2 === "", "pl-e2e: URL omits t=spec (default)", { got: qs2 });
        })();

        // --- E2E 4: Compare mode toggle persists in URL ---
        await (async function testE2E_comparePersists() {
          const btn = document.getElementById("btnCompareToggle");
          if (!btn) { assert(false, "pl-e2e: btnCompareToggle not found"); return; }
          // Ensure off first.
          if (DOC.compareMode) { btn.click(); await wait(300); }
          assert(!DOC.compareMode, "pl-e2e: compare off before test");

          btn.click();
          await wait(300);
          const qs = encodeUrlState();
          log("After compare on, URL: " + qs);
          assert(qs.includes("cmp=1"), "pl-e2e: URL has cmp=1 after toggle on", { got: qs });
          assert(qs.includes("ca="), "pl-e2e: URL has ca= after toggle on");
          assert(qs.includes("cb="), "pl-e2e: URL has cb= after toggle on");

          btn.click();
          await wait(300);
          const qs2 = encodeUrlState();
          assert(!qs2.includes("cmp="), "pl-e2e: URL omits cmp after toggle off", { got: qs2 });
        })();

        // --- E2E 5: Multiple rapid changes produce stable URL ---
        await (async function testE2E_rapidChangesStable() {
          DOC.compareMode = false; DOC.tab = "spec";
          selectCommitIdx(1);
          selectCommitIdx(2);
          selectCommitIdx(5 < maxIdx ? 5 : maxIdx);
          await wait(300); // Let debounce settle.
          const qs = encodeUrlState();
          const decoded = decodeUrlState(qs);
          if (decoded) {
            applyUrlState(decoded);
            const qs2 = encodeUrlState();
            assert(qs === qs2, "pl-e2e: rapid changes produce stable URL", { qs, qs2 });
          } else {
            assert(qs === "", "pl-e2e: rapid changes at default produce empty URL");
          }
        })();

        // --- E2E 6: copyPermalink function produces valid URL ---
        await (async function testE2E_copyPermalink() {
          if (typeof copyPermalink !== "function") {
            assert(false, "pl-e2e: copyPermalink function not found");
            return;
          }
          DOC.idx = 2; DOC.tab = "diff"; DOC.compareMode = false;
          STATE.q = "test"; STATE.minImpact = 0; STATE.bucketMode = "primary";
          STATE.bucketEnabled = new Set(URL_ALL_BUCKET_IDS);
          // copyPermalink writes to clipboard; we can't easily read it, but
          // we can verify encodeUrlState produces the expected result.
          const qs = encodeUrlState();
          assert(qs.includes("c=2"), "pl-e2e: permalink would have c=2");
          assert(qs.includes("t=diff"), "pl-e2e: permalink would have t=diff");
          assert(qs.includes("q=test"), "pl-e2e: permalink would have q=test");
          log("Permalink URL would be: ?" + qs);
        })();

        // --- E2E 7: Console warnings logged for diagnostic ---
        await (async function testE2E_diagnosticLog() {
          // Verify we can log state summaries without errors.
          try {
            const state = { idx: DOC.idx, tab: DOC.tab, cmp: DOC.compareMode, ca: DOC.compareFromIdx, cb: DOC.compareToIdx, q: STATE.q };
            const url = encodeUrlState();
            log("Diagnostic state: " + JSON.stringify(state));
            log("Diagnostic URL: " + url);
            assert(true, "pl-e2e: diagnostic logging works");
          } catch (e) {
            assert(false, "pl-e2e: diagnostic logging threw", { error: String(e) });
          }
        })();

        // --- Restore original state ---
        DOC.compareMode = origDoc.compareMode;
        DOC.compareFromIdx = origDoc.compareFromIdx;
        DOC.compareToIdx = origDoc.compareToIdx;
        DOC.diffLayout = origDoc.diffLayout;
        DOC.abViewMode = origDoc.abViewMode;
        DOC.rawSpec = origDoc.rawSpec;
        DOC.diffMode = origDoc.diffMode;
        DOC.idx = origDoc.idx;
        STATE.q = origState.q;
        STATE.minImpact = origState.minImpact;
        STATE.bucketMode = origState.bucketMode;
        STATE.bucketEnabled = origState.bucketEnabled;
        setDocTab(origDoc.tab);
        await wait(300);

        const passed = results.filter((r) => r.pass).length;
        const failed = results.filter((r) => !r.pass).length;
        const summary = `Permalink E2E Tests: ${passed} passed, ${failed} failed, ${results.length} total`;
        if (failed > 0) {
          console.warn(summary);
          results.filter((r) => !r.pass).forEach((r) => console.error("  FAIL:", r.msg, r.ctx || ""));
        } else {
          console.log("%c" + summary, "color: green; font-weight: bold");
        }
        return { passed, failed, total: results.length, results };
      };
      // ---- End Permalink E2E Tests ----

      // ---- Playback Unit Tests (bd-24q.7.3) ----
      // Run via console: window.__runPlaybackTests()
      window.__runPlaybackTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };

        // --- playbackTicksForElapsed ---
        (function testTicks_basic() {
          // 1000ms at speed=1 => exactly 1 tick, 0 remainder.
          const r = playbackTicksForElapsed(1000, 1, 0);
          A(r.ticks === 1, "ticks: 1000ms@1x = 1 tick", r);
          A(r.remainder === 0, "ticks: 1000ms@1x = 0 remainder", r);
        })();

        (function testTicks_subTick() {
          // 500ms at speed=1 => 0 ticks, 500 remainder.
          const r = playbackTicksForElapsed(500, 1, 0);
          A(r.ticks === 0, "ticks: 500ms@1x = 0 ticks", r);
          A(Math.abs(r.remainder - 500) < 0.01, "ticks: 500ms remainder", r);
        })();

        (function testTicks_accumulation() {
          // 600ms at speed=1 with 500ms accumulated => 1 tick, 100ms remainder.
          const r = playbackTicksForElapsed(600, 1, 500);
          A(r.ticks === 1, "ticks: 600ms+500ms@1x = 1 tick", r);
          A(Math.abs(r.remainder - 100) < 0.01, "ticks: remainder 100ms", r);
        })();

        (function testTicks_fastSpeed() {
          // 1000ms at speed=4 => 4 ticks.
          const r = playbackTicksForElapsed(1000, 4, 0);
          A(r.ticks === 4, "ticks: 1000ms@4x = 4 ticks", r);
          A(r.remainder === 0, "ticks: 4x remainder = 0", r);
        })();

        (function testTicks_slowSpeed() {
          // 1000ms at speed=0.5 => 0 ticks, 1000 remainder (interval=2000ms).
          const r = playbackTicksForElapsed(1000, 0.5, 0);
          A(r.ticks === 0, "ticks: 1000ms@0.5x = 0 ticks", r);
          A(Math.abs(r.remainder - 1000) < 0.01, "ticks: 0.5x remainder = 1000", r);
        })();

        (function testTicks_slowSpeedCrossThreshold() {
          // 2500ms at speed=0.5 => 1 tick (interval=2000ms), 500ms remainder.
          const r = playbackTicksForElapsed(2500, 0.5, 0);
          A(r.ticks === 1, "ticks: 2500ms@0.5x = 1 tick", r);
          A(Math.abs(r.remainder - 500) < 0.01, "ticks: 0.5x remainder = 500", r);
        })();

        (function testTicks_zeroElapsed() {
          const r = playbackTicksForElapsed(0, 1, 0);
          A(r.ticks === 0, "ticks: 0ms = 0 ticks", r);
          A(r.remainder === 0, "ticks: 0ms remainder = 0", r);
        })();

        (function testTicks_quarterSpeed() {
          // 4000ms at speed=0.25 => 1 tick (interval=4000ms).
          const r = playbackTicksForElapsed(4000, 0.25, 0);
          A(r.ticks === 1, "ticks: 4000ms@0.25x = 1 tick", r);
        })();

        (function testTicks_multipleTicks() {
          // 5500ms at speed=2 => 11 ticks (interval=500ms), 0 remainder.
          const r = playbackTicksForElapsed(5500, 2, 0);
          A(r.ticks === 11, "ticks: 5500ms@2x = 11 ticks", r);
          A(r.remainder === 0, "ticks: 5500ms@2x remainder = 0", r);
        })();

        // --- playbackNextIndex ---
        (function testNext_basic() {
          const r = playbackNextIndex(5, 1, 100, false);
          A(r.idx === 6, "next: 5+1 = 6", r);
          A(r.stopped === false, "next: not stopped", r);
        })();

        (function testNext_clampAtMax() {
          const r = playbackNextIndex(98, 5, 100, false);
          A(r.idx === 100, "next: 98+5 clamped to 100", r);
          A(r.stopped === true, "next: stopped at max", r);
        })();

        (function testNext_loopWrap() {
          const r = playbackNextIndex(98, 5, 100, true);
          A(r.idx === 2, "next: 98+5 loops to 2 (mod 101)", r);
          A(r.stopped === false, "next: loop no stop", r);
        })();

        (function testNext_zeroTicks() {
          const r = playbackNextIndex(50, 0, 100, false);
          A(r.idx === 50, "next: 0 ticks = same idx", r);
          A(r.stopped === false, "next: 0 ticks not stopped", r);
        })();

        (function testNext_exactMax() {
          const r = playbackNextIndex(99, 1, 100, false);
          A(r.idx === 100, "next: 99+1 = 100 (max)", r);
          A(r.stopped === true, "next: stopped at exact max", r);
        })();

        (function testNext_loopFromMax() {
          const r = playbackNextIndex(100, 1, 100, true);
          A(r.idx === 0, "next: 100+1 loops to 0", r);
          A(r.stopped === false, "next: loop from max", r);
        })();

        (function testNext_largeTicks() {
          const r = playbackNextIndex(0, 500, 100, true);
          A(r.idx === 500 % 101, "next: 0+500 loops mod 101 = " + (500 % 101), r);
        })();

        // --- playbackTransition (state machine) ---
        (function testTransition_pausedPlay() {
          A(playbackTransition("paused", "play") === "playing", "trans: paused+play->playing");
        })();

        (function testTransition_pausedSeek() {
          A(playbackTransition("paused", "seek") === "seeking", "trans: paused+seek->seeking");
        })();

        (function testTransition_pausedPause() {
          A(playbackTransition("paused", "pause") === null, "trans: paused+pause->null");
        })();

        (function testTransition_playingPause() {
          A(playbackTransition("playing", "pause") === "paused", "trans: playing+pause->paused");
        })();

        (function testTransition_playingSeek() {
          A(playbackTransition("playing", "seek") === "seeking", "trans: playing+seek->seeking");
        })();

        (function testTransition_playingStop() {
          A(playbackTransition("playing", "stop") === "paused", "trans: playing+stop->paused");
        })();

        (function testTransition_playingEnd() {
          A(playbackTransition("playing", "end") === "paused", "trans: playing+end->paused");
        })();

        (function testTransition_seekingStop() {
          A(playbackTransition("seeking", "stop") === "paused", "trans: seeking+stop->paused");
        })();

        (function testTransition_seekingResume() {
          // Resume depends on PLAYBACK._preSeekState.
          const orig = PLAYBACK._preSeekState;
          PLAYBACK._preSeekState = "playing";
          A(playbackTransition("seeking", "resume") === "playing", "trans: seeking+resume(was playing)->playing");
          PLAYBACK._preSeekState = "paused";
          A(playbackTransition("seeking", "resume") === "paused", "trans: seeking+resume(was paused)->paused");
          PLAYBACK._preSeekState = orig;
        })();

        (function testTransition_invalidAction() {
          A(playbackTransition("paused", "resume") === null, "trans: paused+resume->null");
          A(playbackTransition("playing", "play") === null, "trans: playing+play->null");
          A(playbackTransition("seeking", "play") === null, "trans: seeking+play->null");
        })();

        (function testTransition_invalidState() {
          A(playbackTransition("bogus", "play") === null, "trans: bogus+play->null");
        })();

        // --- Drift correction simulation ---
        (function testDrift_sequence() {
          // Simulate a sequence of frames with jittery timing.
          const speed = 2; // 500ms interval
          let accum = 0;
          let idx = 0;
          const maxIdx = 20;
          const frames = [450, 550, 480, 520, 510, 490, 500, 500, 500]; // ~500ms avg
          const idxHistory = [idx];
          for (const elapsed of frames) {
            const { ticks, remainder } = playbackTicksForElapsed(elapsed, speed, accum);
            accum = remainder;
            if (ticks > 0) {
              const { idx: next } = playbackNextIndex(idx, ticks, maxIdx, false);
              idx = next;
            }
            idxHistory.push(idx);
          }
          console.log("  [Drift] idx history:", idxHistory.join(","), "final accum:", accum.toFixed(1) + "ms");
          const totalElapsed = frames.reduce((a, b) => a + b, 0);
          const expectedTicks = Math.floor(totalElapsed / 500);
          A(idx === expectedTicks, "drift: total advancement matches expected", { idx, expectedTicks, totalElapsed });
          A(accum < 500, "drift: accumulator < interval", { accum });
        })();

        // --- Loop boundary ---
        (function testLoop_boundary() {
          const maxIdx = 10;
          // One tick past max with loop.
          let r = playbackNextIndex(10, 1, maxIdx, true);
          A(r.idx === 0, "loop-boundary: max+1 wraps to 0", r);
          // Exactly at max, no ticks.
          r = playbackNextIndex(10, 0, maxIdx, true);
          A(r.idx === 10, "loop-boundary: max+0 stays", r);
          // Two ticks past max.
          r = playbackNextIndex(10, 2, maxIdx, true);
          A(r.idx === 1, "loop-boundary: max+2 wraps to 1", r);
          // No loop: clamp.
          r = playbackNextIndex(10, 1, maxIdx, false);
          A(r.idx === 10, "loop-boundary: no-loop max+1 clamped", r);
          A(r.stopped === true, "loop-boundary: stopped at clamp", r);
        })();

        // --- PLAYBACK_SPEEDS constant ---
        (function testSpeeds() {
          A(Array.isArray(PLAYBACK_SPEEDS), "speeds: is array");
          A(PLAYBACK_SPEEDS.length >= 3, "speeds: at least 3 options", { len: PLAYBACK_SPEEDS.length });
          A(PLAYBACK_SPEEDS.includes(1), "speeds: includes 1x");
          A(PLAYBACK_SPEEDS[0] < 1, "speeds: first < 1 (slow)");
          A(PLAYBACK_SPEEDS[PLAYBACK_SPEEDS.length - 1] > 1, "speeds: last > 1 (fast)");
        })();

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Playback Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Playback Unit Tests ----
      // ---- Binning Unit Tests (bd-24q.12.3) ----
      // Run via console: window.__runBinningTests()
      window.__runBinningTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };

        // --- wallClockBinMinutes ---
        (function testBinMinutes() {
          A(wallClockBinMinutes("day") === 1440, "binMin: day=1440");
          A(wallClockBinMinutes("hour") === 60, "binMin: hour=60");
          A(wallClockBinMinutes("15m") === 15, "binMin: 15m=15");
          A(wallClockBinMinutes("5m") === 5, "binMin: 5m=5");
          A(wallClockBinMinutes("minute") === 1, "binMin: default=1");
          A(wallClockBinMinutes("commit") === 1, "binMin: commit=1 (default)");
        })();

        // --- wallClockBinKey format ---
        (function testBinKey_day() {
          const t = dayjs("2025-03-09T14:37:00");
          A(wallClockBinKey(t, "day") === "2025-03-09", "binKey: day format", { got: wallClockBinKey(t, "day") });
        })();

        (function testBinKey_hour() {
          const t = dayjs("2025-03-09T14:37:00");
          A(wallClockBinKey(t, "hour") === "2025-03-09 14:00", "binKey: hour format", { got: wallClockBinKey(t, "hour") });
        })();

        (function testBinKey_15m() {
          const t = dayjs("2025-03-09T14:37:00");
          A(wallClockBinKey(t, "15m") === "2025-03-09 14:30", "binKey: 15m floors to :30", { got: wallClockBinKey(t, "15m") });
        })();

        (function testBinKey_15m_exact() {
          const t = dayjs("2025-03-09T14:45:00");
          A(wallClockBinKey(t, "15m") === "2025-03-09 14:45", "binKey: 15m exact :45", { got: wallClockBinKey(t, "15m") });
        })();

        (function testBinKey_5m() {
          const t = dayjs("2025-03-09T14:37:00");
          A(wallClockBinKey(t, "5m") === "2025-03-09 14:35", "binKey: 5m floors to :35", { got: wallClockBinKey(t, "5m") });
        })();

        (function testBinKey_5m_exact() {
          const t = dayjs("2025-03-09T14:00:00");
          A(wallClockBinKey(t, "5m") === "2025-03-09 14:00", "binKey: 5m exact :00", { got: wallClockBinKey(t, "5m") });
        })();

        (function testBinKey_minute() {
          const t = dayjs("2025-03-09T14:37:22");
          A(wallClockBinKey(t, "minute") === "2025-03-09 14:37", "binKey: minute format", { got: wallClockBinKey(t, "minute") });
        })();

        // --- wallClockFloor ---
        (function testFloor_day() {
          const t = dayjs("2025-06-15T23:59:59");
          const f = wallClockFloor(t, "day");
          A(f.hour() === 0 && f.minute() === 0, "floor: day zeros time", { h: f.hour(), m: f.minute() });
          A(f.date() === 15, "floor: day preserves date", { got: f.date() });
        })();

        (function testFloor_hour() {
          const t = dayjs("2025-06-15T14:47:33");
          const f = wallClockFloor(t, "hour");
          A(f.hour() === 14 && f.minute() === 0, "floor: hour zeros minutes", { h: f.hour(), m: f.minute() });
        })();

        (function testFloor_15m() {
          const t = dayjs("2025-06-15T14:47:33");
          const f = wallClockFloor(t, "15m");
          A(f.hour() === 14 && f.minute() === 45, "floor: 15m -> :45", { h: f.hour(), m: f.minute() });
        })();

        (function testFloor_15m_boundary() {
          const t = dayjs("2025-06-15T14:14:59");
          const f = wallClockFloor(t, "15m");
          A(f.minute() === 0, "floor: 15m 14:14->14:00", { m: f.minute() });
        })();

        (function testFloor_5m() {
          const t = dayjs("2025-06-15T14:47:33");
          const f = wallClockFloor(t, "5m");
          A(f.hour() === 14 && f.minute() === 45, "floor: 5m -> :45", { h: f.hour(), m: f.minute() });
        })();

        (function testFloor_5m_exact() {
          const t = dayjs("2025-06-15T14:43:00");
          const f = wallClockFloor(t, "5m");
          A(f.minute() === 40, "floor: 5m 14:43->14:40", { m: f.minute() });
        })();

        // --- buildWallClockBins: commit mode returns null ---
        (function testBuild_commitMode() {
          const result = buildWallClockBins([{ dateIso: "2025-01-01T00:00:00Z" }], "commit", "utc");
          A(result === null, "build: commit mode returns null");
        })();

        // --- buildWallClockBins: empty array returns null ---
        (function testBuild_empty() {
          const result = buildWallClockBins([], "hour", "utc");
          A(result === null, "build: empty array returns null");
        })();

        // --- buildWallClockBins: single commit ---
        (function testBuild_singleCommit() {
          const commits = [{ dateIso: "2025-06-15T14:30:00Z" }];
          const result = buildWallClockBins(commits, "hour", "utc");
          A(result !== null, "build: single commit not null");
          A(result.labels.length === 1, "build: single commit = 1 bin", { got: result.labels.length });
          A(result.bins[0].commits.length === 1, "build: single commit in bin");
        })();

        // --- buildWallClockBins: empty bins between sparse commits ---
        (function testBuild_emptyBinsHour() {
          const commits = [
            { dateIso: "2025-06-15T10:00:00Z" },
            { dateIso: "2025-06-15T13:30:00Z" },
          ];
          const result = buildWallClockBins(commits, "hour", "utc");
          A(result.labels.length === 4, "build: 4 hourly bins for 10-13", { got: result.labels.length, labels: result.labels });
          A(result.bins[0].commits.length === 1, "build: first bin has 1 commit");
          A(result.bins[1].commits.length === 0, "build: 11:00 bin is empty");
          A(result.bins[2].commits.length === 0, "build: 12:00 bin is empty");
          A(result.bins[3].commits.length === 1, "build: 13:00 bin has 1 commit");
        })();

        // --- buildWallClockBins: empty bins between sparse commits (day) ---
        (function testBuild_emptyBinsDay() {
          const commits = [
            { dateIso: "2025-06-10T12:00:00Z" },
            { dateIso: "2025-06-13T12:00:00Z" },
          ];
          const result = buildWallClockBins(commits, "day", "utc");
          A(result.labels.length === 4, "build: 4 daily bins for June 10-13", { got: result.labels.length, labels: result.labels });
          A(result.bins[0].commits.length === 1, "build: June 10 has 1");
          A(result.bins[1].commits.length === 0, "build: June 11 empty");
          A(result.bins[2].commits.length === 0, "build: June 12 empty");
          A(result.bins[3].commits.length === 1, "build: June 13 has 1");
        })();

        // --- buildWallClockBins: multiple commits in same bin ---
        (function testBuild_multiplePerBin() {
          const commits = [
            { dateIso: "2025-06-15T14:05:00Z" },
            { dateIso: "2025-06-15T14:12:00Z" },
            { dateIso: "2025-06-15T14:50:00Z" },
          ];
          const result = buildWallClockBins(commits, "hour", "utc");
          A(result.labels.length === 1, "build: all in same hour bin", { got: result.labels.length });
          A(result.bins[0].commits.length === 3, "build: 3 commits in bin");
        })();

        // --- buildWallClockBins: 5m resolution correct assignment ---
        (function testBuild_5mResolution() {
          const commits = [
            { dateIso: "2025-06-15T14:00:00Z" },
            { dateIso: "2025-06-15T14:03:00Z" },
            { dateIso: "2025-06-15T14:07:00Z" },
            { dateIso: "2025-06-15T14:10:00Z" },
          ];
          const result = buildWallClockBins(commits, "5m", "utc");
          A(result.labels.length === 3, "build: 3 five-min bins", { got: result.labels.length, labels: result.labels });
          A(result.bins[0].commits.length === 2, "build: 14:00 bin has 2 (00 + 03)");
          A(result.bins[1].commits.length === 1, "build: 14:05 bin has 1 (07)");
          A(result.bins[2].commits.length === 1, "build: 14:10 bin has 1");
        })();

        // --- buildWallClockBins: UTC vs local mode ---
        (function testBuild_utcMode() {
          const commits = [{ dateIso: "2025-06-15T23:30:00Z" }];
          const resultUtc = buildWallClockBins(commits, "hour", "utc");
          A(resultUtc !== null && resultUtc.labels[0].includes("23:00"), "build: UTC key shows 23:00", { got: resultUtc?.labels[0] });
        })();

        (function testBuild_localMode() {
          const commits = [{ dateIso: "2025-06-15T23:30:00Z" }];
          const resultLocal = buildWallClockBins(commits, "hour", "local");
          A(resultLocal !== null && resultLocal.labels.length === 1, "build: local mode produces 1 bin");
          A(resultLocal.labels[0].includes(":00"), "build: local key has :00 hour mark", { got: resultLocal.labels[0] });
        })();

        // --- buildWallClockBins: DST spring-forward (UTC unaffected) ---
        (function testBuild_dstSpringForwardUtc() {
          const commits = [
            { dateIso: "2025-03-09T06:00:00Z" },
            { dateIso: "2025-03-09T09:00:00Z" },
          ];
          const result = buildWallClockBins(commits, "hour", "utc");
          A(result.labels.length === 4, "build: DST spring UTC = 4 continuous hour bins", { got: result.labels.length, labels: result.labels });
        })();

        // --- buildWallClockBins: DST fall-back (UTC unaffected) ---
        (function testBuild_dstFallBackUtc() {
          const commits = [
            { dateIso: "2025-11-02T05:00:00Z" },
            { dateIso: "2025-11-02T08:00:00Z" },
          ];
          const result = buildWallClockBins(commits, "hour", "utc");
          A(result.labels.length === 4, "build: DST fall-back UTC = 4 continuous hour bins", { got: result.labels.length, labels: result.labels });
        })();

        // --- buildWallClockBins: day bins across DST transition (UTC) ---
        (function testBuild_dstDayBinsUtc() {
          const commits = [
            { dateIso: "2025-03-08T12:00:00Z" },
            { dateIso: "2025-03-10T12:00:00Z" },
          ];
          const result = buildWallClockBins(commits, "day", "utc");
          A(result.labels.length === 3, "build: DST day bins UTC = 3", { got: result.labels.length, labels: result.labels });
          A(result.labels[0] === "2025-03-08", "build: DST day label 0");
          A(result.labels[1] === "2025-03-09", "build: DST day label 1");
          A(result.labels[2] === "2025-03-10", "build: DST day label 2");
        })();

        // --- buildWallClockBins: label format consistency ---
        (function testBuild_labelConsistency() {
          const commits = [
            { dateIso: "2025-06-15T14:00:00Z" },
            { dateIso: "2025-06-15T14:20:00Z" },
          ];
          const result = buildWallClockBins(commits, "15m", "utc");
          A(result.labels.length === 2, "build: 15m labels count", { got: result.labels.length });
          const pat = /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}$/;
          A(pat.test(result.labels[0]), "build: 15m label 0 format", { got: result.labels[0] });
          A(pat.test(result.labels[1]), "build: 15m label 1 format", { got: result.labels[1] });
        })();

        // --- aggregateBinMetric: sum ---
        (function testAgg_sum() {
          const commits = [{ v: 10 }, { v: 20 }, { v: 30 }];
          const result = aggregateBinMetric(commits, (c) => c.v, "sum");
          A(result === 60, "agg: sum = 60", { got: result });
        })();

        // --- aggregateBinMetric: mean ---
        (function testAgg_mean() {
          const commits = [{ v: 10 }, { v: 20 }, { v: 30 }];
          const result = aggregateBinMetric(commits, (c) => c.v, "mean");
          A(Math.abs(result - 20) < 0.001, "agg: mean = 20", { got: result });
        })();

        // --- aggregateBinMetric: median odd ---
        (function testAgg_medianOdd() {
          const commits = [{ v: 30 }, { v: 10 }, { v: 20 }];
          const result = aggregateBinMetric(commits, (c) => c.v, "median");
          A(result === 20, "agg: median odd = 20", { got: result });
        })();

        // --- aggregateBinMetric: median even ---
        (function testAgg_medianEven() {
          const commits = [{ v: 10 }, { v: 20 }, { v: 30 }, { v: 40 }];
          const result = aggregateBinMetric(commits, (c) => c.v, "median");
          A(result === 25, "agg: median even = 25", { got: result });
        })();

        // --- aggregateBinMetric: empty array ---
        (function testAgg_empty() {
          const result = aggregateBinMetric([], (c) => c.v, "sum");
          A(result === 0, "agg: empty = 0", { got: result });
        })();

        // --- aggregateBinMetric: single element ---
        (function testAgg_single() {
          A(aggregateBinMetric([{ v: 42 }], (c) => c.v, "sum") === 42, "agg: single sum = 42");
          A(aggregateBinMetric([{ v: 42 }], (c) => c.v, "mean") === 42, "agg: single mean = 42");
          A(aggregateBinMetric([{ v: 42 }], (c) => c.v, "median") === 42, "agg: single median = 42");
        })();

        // --- aggregateBinMetric: default mode is sum ---
        (function testAgg_defaultMode() {
          const commits = [{ v: 10 }, { v: 20 }];
          const result = aggregateBinMetric(commits, (c) => c.v, "unknown_mode");
          A(result === 30, "agg: unknown mode defaults to sum = 30", { got: result });
        })();

        // --- aggregateBinMetric: median with duplicate values ---
        (function testAgg_medianDuplicates() {
          const commits = [{ v: 5 }, { v: 5 }, { v: 5 }, { v: 100 }, { v: 100 }];
          const result = aggregateBinMetric(commits, (c) => c.v, "median");
          A(result === 5, "agg: median duplicates = 5", { got: result });
        })();

        // --- Integration: buildWallClockBins + aggregateBinMetric ---
        (function testIntegration_buildThenAggregate() {
          const commits = [
            { dateIso: "2025-06-15T10:05:00Z", lines: 100 },
            { dateIso: "2025-06-15T10:55:00Z", lines: 200 },
            { dateIso: "2025-06-15T11:30:00Z", lines: 50 },
          ];
          const result = buildWallClockBins(commits, "hour", "utc");
          A(result.bins.length === 2, "integ: 2 hourly bins");
          const sum0 = aggregateBinMetric(result.bins[0].commits, (c) => c.lines, "sum");
          const sum1 = aggregateBinMetric(result.bins[1].commits, (c) => c.lines, "sum");
          A(sum0 === 300, "integ: hour 10 sum = 300", { got: sum0 });
          A(sum1 === 50, "integ: hour 11 sum = 50", { got: sum1 });
          const mean0 = aggregateBinMetric(result.bins[0].commits, (c) => c.lines, "mean");
          A(Math.abs(mean0 - 150) < 0.001, "integ: hour 10 mean = 150", { got: mean0 });
        })();

        // --- wallClockBinKey: edge case minute=0 padding ---
        (function testBinKey_zeroPadding() {
          const t = dayjs("2025-01-01T00:00:00");
          A(wallClockBinKey(t, "5m") === "2025-01-01 00:00", "binKey: zero-padded 00:00", { got: wallClockBinKey(t, "5m") });
          A(wallClockBinKey(t, "15m") === "2025-01-01 00:00", "binKey: 15m zero-padded 00:00", { got: wallClockBinKey(t, "15m") });
        })();

        // --- wallClockFloor: minute resolution ---
        (function testFloor_minute() {
          const t = dayjs("2025-06-15T14:37:45");
          const f = wallClockFloor(t, "minute");
          A(f.second() === 0, "floor: minute zeros seconds", { s: f.second() });
          A(f.minute() === 37, "floor: minute preserves minute", { m: f.minute() });
        })();

        // --- buildWallClockBins: maxBins safety (10000 limit) ---
        (function testBuild_maxBinsSafety() {
          const commits = [
            { dateIso: "2025-01-01T00:00:00Z" },
            { dateIso: "2025-12-31T23:59:00Z" },
          ];
          const result = buildWallClockBins(commits, "5m", "utc");
          A(result.bins.length <= 10000, "build: maxBins capped at 10000", { got: result.bins.length });
        })();

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Binning Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Binning Unit Tests ----
      // ---- Binning E2E Tests (bd-24q.12.4) ----
      // Run via console: window.__runBinningE2ETests()
      // Requires dataset to be loaded.
      window.__runBinningE2ETests = async function () {
        const R = [];
        const log = (msg, ctx) => console.log("  [BIN-E2E]", msg, ctx || "");
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("  FAIL:", m, x || ""); else log("PASS: " + m); };
        const wait = (ms) => new Promise((r) => setTimeout(r, ms));

        if (!DATASET.loaded || ALL_COMMITS.length < 5) {
          console.error("BIN-E2E: Need loaded dataset with >= 5 commits.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded or < 5 commits" }] };
        }

        const resSel = document.getElementById("stackResolution");
        const tzSel = document.getElementById("stackTimezone");
        const metSel = document.getElementById("stackMetric");
        if (!resSel || !tzSel || !metSel) {
          console.error("BIN-E2E: Missing select elements (stackResolution, stackTimezone, stackMetric).");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Missing binning select elements" }] };
        }

        // Save original select values.
        const origRes = resSel.value;
        const origTz = tzSel.value;
        const origMet = metSel.value;

        const getChartLabels = () => {
          if (!chartStack) return [];
          const opt = chartStack.getOption();
          return opt?.xAxis?.[0]?.data || [];
        };

        // --- E2E 1: Toggle commit -> day; x-axis labels change + bin count differs ---
        await (async function testE2E_commitToDay() {
          log("Setting resolution to commit...");
          resSel.value = "commit";
          resSel.dispatchEvent(new Event("change"));
          await wait(400);
          const commitLabels = getChartLabels();
          const commitCount = commitLabels.length;
          log("Commit mode: " + commitCount + " bins, first=" + commitLabels[0] + ", last=" + commitLabels[commitLabels.length - 1]);

          log("Switching to day...");
          resSel.value = "day";
          resSel.dispatchEvent(new Event("change"));
          await wait(400);
          const dayLabels = getChartLabels();
          const dayCount = dayLabels.length;
          log("Day mode: " + dayCount + " bins, first=" + dayLabels[0] + ", last=" + dayLabels[dayLabels.length - 1]);

          A(dayCount !== commitCount, "e2e: day bin count differs from commit count", { commitCount, dayCount });
          A(dayLabels[0] !== commitLabels[0], "e2e: day labels differ from commit labels", { dayFirst: dayLabels[0], commitFirst: commitLabels[0] });
          // Day labels should look like YYYY-MM-DD.
          const dayPat = /^\d{4}-\d{2}-\d{2}$/;
          A(dayPat.test(dayLabels[0]), "e2e: day label format is YYYY-MM-DD", { got: dayLabels[0] });
        })();

        // --- E2E 2: Toggle resolution day -> hour; bin count increases ---
        await (async function testE2E_dayToHour() {
          resSel.value = "day";
          resSel.dispatchEvent(new Event("change"));
          await wait(400);
          const dayCount = getChartLabels().length;

          resSel.value = "hour";
          resSel.dispatchEvent(new Event("change"));
          await wait(400);
          const hourLabels = getChartLabels();
          const hourCount = hourLabels.length;
          log("Hour mode: " + hourCount + " bins (day was " + dayCount + ")");

          A(hourCount >= dayCount, "e2e: hour bin count >= day bin count", { hourCount, dayCount });
          // Hour labels should include time component.
          const hourPat = /^\d{4}-\d{2}-\d{2} \d{2}:00$/;
          A(hourPat.test(hourLabels[0]), "e2e: hour label format is YYYY-MM-DD HH:00", { got: hourLabels[0] });
        })();

        // --- E2E 3: Toggle timezone UTC -> local; labels update ---
        await (async function testE2E_tzToggle() {
          resSel.value = "hour";
          resSel.dispatchEvent(new Event("change"));
          await wait(200);

          tzSel.value = "utc";
          tzSel.dispatchEvent(new Event("change"));
          await wait(400);
          const utcLabels = getChartLabels().slice();
          log("UTC hour labels: first=" + utcLabels[0] + ", count=" + utcLabels.length);

          tzSel.value = "local";
          tzSel.dispatchEvent(new Event("change"));
          await wait(400);
          const localLabels = getChartLabels().slice();
          log("Local hour labels: first=" + localLabels[0] + ", count=" + localLabels.length);

          // In non-UTC-0 environments, labels will differ. In UTC-0, they'll match.
          // We can't know the timezone, so just check both produce valid labels.
          A(utcLabels.length > 0, "e2e: UTC mode produces labels");
          A(localLabels.length > 0, "e2e: Local mode produces labels");
          // Both should have time format.
          const pat = /^\d{4}-\d{2}-\d{2} \d{2}:\d{2}$/;
          A(pat.test(utcLabels[0]), "e2e: UTC label is valid datetime", { got: utcLabels[0] });
          A(pat.test(localLabels[0]), "e2e: Local label is valid datetime", { got: localLabels[0] });
          log("UTC vs local labels differ: " + (utcLabels[0] !== localLabels[0]));
        })();

        // --- E2E 4: Metric toggle changes y-axis values ---
        await (async function testE2E_metricToggle() {
          resSel.value = "day";
          resSel.dispatchEvent(new Event("change"));
          await wait(200);

          metSel.value = "groups";
          metSel.dispatchEvent(new Event("change"));
          await wait(400);
          const opt1 = chartStack.getOption();
          const series1 = opt1?.series || [];
          const total1 = series1.reduce((s, sr) => s + (sr.data || []).reduce((a, b) => a + (Number(b) || 0), 0), 0);

          metSel.value = "lines";
          metSel.dispatchEvent(new Event("change"));
          await wait(400);
          const opt2 = chartStack.getOption();
          const series2 = opt2?.series || [];
          const total2 = series2.reduce((s, sr) => s + (sr.data || []).reduce((a, b) => a + (Number(b) || 0), 0), 0);

          log("Metric groups total: " + total1.toFixed(1) + ", lines total: " + total2.toFixed(1));
          A(total1 > 0, "e2e: groups metric has data");
          A(total2 > 0, "e2e: lines metric has data");
          // Groups and lines should differ (groups counts changeGroups, lines counts impact).
          A(Math.abs(total1 - total2) > 0.1, "e2e: groups vs lines totals differ", { groups: total1, lines: total2 });
        })();

        // --- E2E 5: URL round-trip preserves resolution, timezone, metric ---
        await (async function testE2E_urlRoundTrip() {
          resSel.value = "15m";
          tzSel.value = "utc";
          metSel.value = "tokens";
          resSel.dispatchEvent(new Event("change"));
          await wait(200);

          const encoded = encodeUrlState();
          log("Encoded URL: " + encoded);
          A(encoded.includes("res=15m"), "e2e: URL contains res=15m", { got: encoded });
          A(encoded.includes("tz=utc"), "e2e: URL contains tz=utc", { got: encoded });
          A(encoded.includes("met=tokens"), "e2e: URL contains met=tokens", { got: encoded });

          // Reset to defaults.
          resSel.value = "commit";
          tzSel.value = "local";
          metSel.value = "groups";

          // Decode and apply.
          const decoded = decodeUrlState(encoded);
          A(decoded.res === "15m", "e2e: decoded res=15m", { got: decoded.res });
          A(decoded.tz === "utc", "e2e: decoded tz=utc", { got: decoded.tz });
          A(decoded.met === "tokens", "e2e: decoded met=tokens", { got: decoded.met });

          applyUrlState(decoded);
          A(resSel.value === "15m", "e2e: resSel restored to 15m", { got: resSel.value });
          A(tzSel.value === "utc", "e2e: tzSel restored to utc", { got: tzSel.value });
          A(metSel.value === "tokens", "e2e: metSel restored to tokens", { got: metSel.value });
        })();

        // --- E2E 6: Default values omitted from URL ---
        await (async function testE2E_defaultsOmitted() {
          resSel.value = "commit";
          tzSel.value = "local";
          metSel.value = "groups";
          resSel.dispatchEvent(new Event("change"));
          await wait(200);

          const encoded = encodeUrlState();
          log("Default state URL: " + encoded);
          A(!encoded.includes("res="), "e2e: default res omitted from URL", { got: encoded });
          A(!encoded.includes("tz="), "e2e: default tz omitted from URL", { got: encoded });
          A(!encoded.includes("met="), "e2e: default met omitted from URL", { got: encoded });
        })();

        // --- E2E 7: Empty bins visible in chart data ---
        await (async function testE2E_emptyBinsInChart() {
          resSel.value = "hour";
          resSel.dispatchEvent(new Event("change"));
          await wait(400);
          const labels = getChartLabels();
          const opt = chartStack.getOption();
          const firstSeries = (opt?.series || [])[0]?.data || [];

          // Count how many bins have zero across all series.
          let emptyCount = 0;
          for (let i = 0; i < labels.length; i++) {
            const total = (opt?.series || []).reduce((s, sr) => s + (Number(sr.data?.[i]) || 0), 0);
            if (total === 0) emptyCount++;
          }
          log("Hour bins: " + labels.length + " total, " + emptyCount + " empty, first=" + labels[0] + ", last=" + labels[labels.length - 1]);
          // With real data spanning multiple days, there should be empty hour bins.
          A(labels.length > 0, "e2e: hour mode has bins");
          // If the data spans more than a day, we expect some empty bins.
          if (labels.length > 24) {
            A(emptyCount > 0, "e2e: hour mode has empty bins between activity", { emptyCount, total: labels.length });
          } else {
            log("Dataset spans <= 24 hour bins, empty bins not guaranteed");
          }
        })();

        // --- Restore original state ---
        resSel.value = origRes;
        tzSel.value = origTz;
        metSel.value = origMet;
        resSel.dispatchEvent(new Event("change"));
        await wait(200);
        log("Restored original state: res=" + origRes + ", tz=" + origTz + ", met=" + origMet);

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Binning E2E Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Binning E2E Tests ----
      // ---- Side-by-Side Unit Tests (bd-24q.15.4) ----
      // Run via console: window.__runSbsTests()
      window.__runSbsTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };

        // --- normalizeHeadingText ---
        (function testNorm_basic() {
          A(normalizeHeadingText("Hello World") === "hello world", "norm: basic lowercase");
        })();

        (function testNorm_punctuation() {
          A(normalizeHeadingText("Hello, World! (v2.0)") === "hello world v2 0", "norm: strips punctuation", { got: normalizeHeadingText("Hello, World! (v2.0)") });
        })();

        (function testNorm_unicode() {
          const r = normalizeHeadingText("Section 日本語 heading");
          A(r.includes("section"), "norm: preserves unicode letters", { got: r });
          A(r.includes("日本語"), "norm: preserves CJK", { got: r });
        })();

        (function testNorm_empty() {
          A(normalizeHeadingText("") === "", "norm: empty string");
          A(normalizeHeadingText(null) === "", "norm: null");
          A(normalizeHeadingText(undefined) === "", "norm: undefined");
        })();

        (function testNorm_whitespace() {
          A(normalizeHeadingText("  lots   of   spaces  ") === "lots of spaces", "norm: collapses whitespace", { got: normalizeHeadingText("  lots   of   spaces  ") });
        })();

        (function testNorm_codeBackticks() {
          const r = normalizeHeadingText("`code_heading`");
          A(r === "code heading", "norm: backticks become space, underscore becomes space", { got: r });
        })();

        (function testNorm_numbers() {
          A(normalizeHeadingText("Section 5.3.1") === "section 5 3 1", "norm: preserves numbers", { got: normalizeHeadingText("Section 5.3.1") });
        })();

        // --- buildHeadingMatchMap: exact matches ---
        (function testMatch_exactSimple() {
          const oA = [
            { id: "intro", text: "Introduction", level: 2 },
            { id: "methods", text: "Methods", level: 2 },
            { id: "results", text: "Results", level: 2 },
          ];
          const oB = [
            { id: "intro", text: "Introduction", level: 2 },
            { id: "methods", text: "Methods", level: 2 },
            { id: "conclusion", text: "Conclusion", level: 2 },
          ];
          const { matchAtoB, matchBtoA } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          A(matchAtoB.get("a-intro") === "b-intro", "match: intro exact", { got: matchAtoB.get("a-intro") });
          A(matchAtoB.get("a-methods") === "b-methods", "match: methods exact", { got: matchAtoB.get("a-methods") });
          A(!matchAtoB.has("a-results"), "match: results has no match in B");
          A(!matchBtoA.has("b-conclusion"), "match: conclusion has no match in A");
          // Bidirectional consistency.
          A(matchBtoA.get("b-intro") === "a-intro", "match: reverse intro");
          A(matchBtoA.get("b-methods") === "a-methods", "match: reverse methods");
        })();

        // --- buildHeadingMatchMap: level must match ---
        (function testMatch_levelMismatch() {
          const oA = [{ id: "title", text: "Introduction", level: 1 }];
          const oB = [{ id: "title", text: "Introduction", level: 2 }];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          A(!matchAtoB.has("a-title"), "match: level mismatch blocks exact match");
        })();

        // --- buildHeadingMatchMap: duplicate headings (first match wins) ---
        (function testMatch_duplicates() {
          const oA = [
            { id: "sec", text: "Section", level: 2 },
            { id: "sec-1", text: "Section", level: 2 },
          ];
          const oB = [
            { id: "sec", text: "Section", level: 2 },
            { id: "sec-1", text: "Section", level: 2 },
          ];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          A(matchAtoB.get("a-sec") === "b-sec", "match: first dup matches first", { got: matchAtoB.get("a-sec") });
          A(matchAtoB.get("a-sec-1") === "b-sec-1", "match: second dup matches second", { got: matchAtoB.get("a-sec-1") });
        })();

        // --- buildHeadingMatchMap: fuzzy matching (prefix >= 60%) ---
        (function testMatch_fuzzy() {
          const oA = [{ id: "mvcc-page-versioning", text: "MVCC Page-Level Versioning", level: 2 }];
          const oB = [{ id: "mvcc-page-versioning-impl", text: "MVCC Page-Level Versioning Implementation", level: 2 }];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          // "mvcc page level versioning" is a prefix of "mvcc page level versioning implementation"
          // prefix ratio = 27/41 ≈ 0.66 >= 0.6, so should match.
          A(matchAtoB.has("a-mvcc-page-versioning"), "match: fuzzy prefix matches", { got: matchAtoB.get("a-mvcc-page-versioning") });
        })();

        // --- buildHeadingMatchMap: fuzzy too short ---
        (function testMatch_fuzzyTooShort() {
          const oA = [{ id: "ab", text: "AB", level: 2 }];
          const oB = [{ id: "abcdefghijklmnop", text: "ABCDEFGHIJKLMNOP", level: 2 }];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          // "ab" vs "abcdefghijklmnop": prefix ratio = 2/16 = 0.125 < 0.6
          A(!matchAtoB.has("a-ab"), "match: fuzzy below threshold rejected");
        })();

        // --- buildHeadingMatchMap: empty outlines ---
        (function testMatch_emptyOutlines() {
          const { matchAtoB } = buildHeadingMatchMap([], [], "a-", "b-");
          A(matchAtoB.size === 0, "match: empty outlines = empty map");
        })();

        (function testMatch_oneEmpty() {
          const oA = [{ id: "x", text: "Something", level: 2 }];
          const { matchAtoB } = buildHeadingMatchMap(oA, [], "a-", "b-");
          A(matchAtoB.size === 0, "match: one empty outline = no matches");
        })();

        // --- buildHeadingMatchMap: renamed heading (fuzzy catches it) ---
        (function testMatch_renamedHeading() {
          const oA = [
            { id: "sec-a", text: "Section Architecture Overview", level: 2 },
            { id: "sec-b", text: "Testing Strategy", level: 2 },
          ];
          const oB = [
            { id: "sec-a", text: "Section Architecture", level: 2 },
            { id: "sec-b", text: "Testing Strategy", level: 2 },
          ];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          // "section architecture overview" vs "section architecture": prefix = "section architecture" (21 chars)
          // ratio = 21/30 ≈ 0.7 >= 0.6
          A(matchAtoB.has("a-sec-a"), "match: renamed heading fuzzy matched", { got: matchAtoB.get("a-sec-a") });
          A(matchAtoB.get("a-sec-b") === "b-sec-b", "match: unchanged heading exact matched");
        })();

        // --- buildHeadingMatchMap: moved sections (order doesn't matter) ---
        (function testMatch_movedSections() {
          const oA = [
            { id: "first", text: "Alpha", level: 2 },
            { id: "second", text: "Beta", level: 2 },
            { id: "third", text: "Gamma", level: 2 },
          ];
          const oB = [
            { id: "third", text: "Gamma", level: 2 },
            { id: "first", text: "Alpha", level: 2 },
            { id: "second", text: "Beta", level: 2 },
          ];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          A(matchAtoB.size === 3, "match: all 3 reordered headings matched", { got: matchAtoB.size });
          A(matchAtoB.get("a-first") === "b-first", "match: Alpha matched despite reorder");
          A(matchAtoB.get("a-second") === "b-second", "match: Beta matched");
          A(matchAtoB.get("a-third") === "b-third", "match: Gamma matched");
        })();

        // --- buildHeadingMatchMap: deterministic tie-breaking ---
        (function testMatch_tieBreaking() {
          // When two B headings have the same text, first one should win.
          const oA = [{ id: "x", text: "Duplicate", level: 2 }];
          const oB = [
            { id: "dup-first", text: "Duplicate", level: 2 },
            { id: "dup-second", text: "Duplicate", level: 2 },
          ];
          const { matchAtoB } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          A(matchAtoB.get("a-x") === "b-dup-first", "match: tie-break picks first B match", { got: matchAtoB.get("a-x") });
        })();

        // --- buildHeadingMatchMap: mixed levels ---
        (function testMatch_mixedLevels() {
          const oA = [
            { id: "h1", text: "Title", level: 1 },
            { id: "h2a", text: "Section A", level: 2 },
            { id: "h3a", text: "Detail A.1", level: 3 },
          ];
          const oB = [
            { id: "h1", text: "Title", level: 1 },
            { id: "h2a", text: "Section A", level: 2 },
            { id: "h3a", text: "Detail A.1", level: 3 },
            { id: "h3b", text: "Detail A.2", level: 3 },
          ];
          const { matchAtoB, matchBtoA } = buildHeadingMatchMap(oA, oB, "a-", "b-");
          A(matchAtoB.size === 3, "match: all 3 A headings matched", { got: matchAtoB.size });
          A(!matchBtoA.has("b-h3b"), "match: extra B heading unmatched");
        })();

        // --- cachePaneHeadingOffsets: with no pane ---
        (function testCache_noPane() {
          const offsets = cachePaneHeadingOffsets(null, "x-");
          A(Array.isArray(offsets) && offsets.length === 0, "cache: null pane returns empty array");
        })();

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Side-by-Side Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Side-by-Side Unit Tests ----
      // ---- Playback E2E Tests (bd-24q.7.4) ----
      // Run via console: window.__runPlaybackE2ETests()
      // Requires dataset to be loaded.
      window.__runPlaybackE2ETests = async function () {
        const R = [];
        const log = (msg, ctx) => console.log("  [PLAY-E2E]", msg, ctx || "");
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("  FAIL:", m, x || ""); else log("PASS: " + m); };
        const wait = (ms) => new Promise((r) => setTimeout(r, ms));

        if (!DATASET.loaded || ALL_COMMITS.length < 10) {
          console.error("PLAY-E2E: Need loaded dataset with >= 10 commits.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded or < 10 commits" }] };
        }

        const maxIdx = ALL_COMMITS.length - 1;

        // Save original state.
        const origIdx = DOC.idx;
        const origState = PLAYBACK.state;
        const origSpeed = PLAYBACK.speed;
        const origLoop = PLAYBACK.loop;

        // Ensure we start clean.
        playbackStop();
        PLAYBACK.speed = 1;
        PLAYBACK.loop = false;

        // --- E2E 1: Play advances commit index ---
        await (async function testE2E_playAdvances() {
          selectCommitIdx(0);
          await wait(100);
          A(DOC.idx === 0, "play-e2e: start at idx 0", { got: DOC.idx });

          playbackSetSpeed(4); // 4 commits/sec => 1 tick every 250ms
          playbackPlay();
          A(PLAYBACK.state === "playing", "play-e2e: state is playing");
          log("Playing at 4x from idx 0...");

          await wait(1500); // ~6 ticks expected at 4x over 1.5s
          const idxAfter = DOC.idx;
          log("After 1.5s at 4x: idx=" + idxAfter);
          playbackPause();

          A(idxAfter > 0, "play-e2e: idx advanced from 0", { got: idxAfter });
          A(idxAfter >= 2, "play-e2e: advanced at least 2 commits at 4x in 1.5s", { got: idxAfter });
          A(PLAYBACK.state === "paused", "play-e2e: paused after pause()");
        })();

        // --- E2E 2: Pause stops advancement ---
        await (async function testE2E_pauseStops() {
          selectCommitIdx(5);
          await wait(100);
          playbackSetSpeed(4);
          playbackPlay();
          await wait(500);
          playbackPause();
          const idxAtPause = DOC.idx;
          log("Paused at idx=" + idxAtPause);

          await wait(800); // Wait to confirm no further advancement.
          const idxAfterWait = DOC.idx;
          A(idxAfterWait === idxAtPause, "play-e2e: no advancement after pause", { atPause: idxAtPause, afterWait: idxAfterWait });
        })();

        // --- E2E 3: Toggle play/pause ---
        await (async function testE2E_toggle() {
          selectCommitIdx(0);
          await wait(100);
          playbackSetSpeed(4);

          playbackToggle(); // paused -> playing
          A(PLAYBACK.state === "playing", "play-e2e: toggle from paused -> playing");
          await wait(600);

          playbackToggle(); // playing -> paused
          A(PLAYBACK.state === "paused", "play-e2e: toggle from playing -> paused");
          const idx1 = DOC.idx;
          A(idx1 > 0, "play-e2e: advanced during play phase", { got: idx1 });
        })();

        // --- E2E 4: Stop resets accumulator ---
        await (async function testE2E_stopResets() {
          selectCommitIdx(3);
          await wait(100);
          playbackSetSpeed(2);
          playbackPlay();
          await wait(300);
          playbackStop();
          A(PLAYBACK.state === "paused", "play-e2e: stop sets paused");
          A(PLAYBACK._accumMs === 0, "play-e2e: stop resets accumulator", { got: PLAYBACK._accumMs });
        })();

        // --- E2E 5: Speed change takes effect ---
        await (async function testE2E_speedChange() {
          selectCommitIdx(0);
          await wait(100);

          // Play at 0.5x (1 tick per 2s) for 1s => should barely advance.
          playbackSetSpeed(0.5);
          playbackPlay();
          await wait(1000);
          playbackPause();
          const slowIdx = DOC.idx;

          // Reset and play at 4x (1 tick per 250ms) for 1s => should advance more.
          selectCommitIdx(0);
          await wait(100);
          playbackSetSpeed(4);
          playbackPlay();
          await wait(1000);
          playbackPause();
          const fastIdx = DOC.idx;

          log("0.5x for 1s: idx=" + slowIdx + ", 4x for 1s: idx=" + fastIdx);
          A(fastIdx > slowIdx, "play-e2e: faster speed advances more", { slow: slowIdx, fast: fastIdx });
        })();

        // --- E2E 6: Loop wraps around ---
        await (async function testE2E_loopWraps() {
          // Start near end, enable loop, play fast.
          const nearEnd = Math.max(0, maxIdx - 3);
          selectCommitIdx(nearEnd);
          await wait(100);
          playbackSetSpeed(4);
          playbackSetLoop(true);
          playbackPlay();
          await wait(2000); // Should wrap around.
          playbackPause();
          playbackSetLoop(false);

          const loopIdx = DOC.idx;
          log("Loop test: started at " + nearEnd + ", ended at " + loopIdx);
          // With loop, it should have wrapped past maxIdx and ended up at a lower index.
          // Or it could have advanced past and wrapped. Just verify playback didn't stop at maxIdx.
          A(PLAYBACK.state === "paused", "play-e2e: loop paused correctly");
          // If it wrapped, idx should be less than nearEnd (or at least it advanced).
          if (maxIdx - nearEnd < 8) {
            // Started close to end, so wrapping is likely.
            A(loopIdx !== nearEnd, "play-e2e: loop advanced from start position", { start: nearEnd, end: loopIdx });
          }
        })();

        // --- E2E 7: No-loop stops at end ---
        await (async function testE2E_noLoopStopsAtEnd() {
          const nearEnd = Math.max(0, maxIdx - 2);
          selectCommitIdx(nearEnd);
          await wait(100);
          playbackSetSpeed(4);
          playbackSetLoop(false);
          playbackPlay();
          await wait(2000); // Should hit end and stop.

          A(PLAYBACK.state === "paused", "play-e2e: stopped at end (no loop)", { state: PLAYBACK.state });
          A(DOC.idx === maxIdx, "play-e2e: idx at maxIdx after stop", { got: DOC.idx, max: maxIdx });
        })();

        // --- E2E 8: Manual scrub during playback ---
        await (async function testE2E_scrubDuringPlay() {
          selectCommitIdx(0);
          await wait(100);
          playbackSetSpeed(2);
          playbackPlay();
          await wait(500);
          A(PLAYBACK.state === "playing", "play-e2e: playing before scrub");

          playbackOnManualScrub();
          A(PLAYBACK.state === "seeking", "play-e2e: seeking after scrub");

          // Simulate scrub to a specific index.
          selectCommitIdx(10);
          await wait(100);

          playbackOnScrubEnd();
          // Should resume playing (was playing before scrub).
          A(PLAYBACK.state === "playing", "play-e2e: resumed playing after scrub end", { got: PLAYBACK.state });
          await wait(500);
          const afterResume = DOC.idx;
          A(afterResume > 10, "play-e2e: continued advancing after scrub resume", { got: afterResume });

          playbackStop();
        })();

        // --- E2E 9: Scrub while paused stays paused ---
        await (async function testE2E_scrubWhilePaused() {
          selectCommitIdx(5);
          await wait(100);
          playbackStop(); // ensure paused
          playbackOnManualScrub();
          // When paused, scrub is a no-op (state stays paused).
          A(PLAYBACK.state === "paused", "play-e2e: scrub while paused stays paused", { got: PLAYBACK.state });
        })();

        // --- Restore original state ---
        playbackStop();
        PLAYBACK.speed = origSpeed;
        PLAYBACK.loop = origLoop;
        selectCommitIdx(origIdx);
        await wait(200);
        log("Restored: idx=" + origIdx + ", speed=" + origSpeed + ", loop=" + origLoop);

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Playback E2E Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Playback E2E Tests ----
      // ---- Mini-Map Unit Tests (bd-24q.2.5) ----
      // Run via console: window.__runMiniMapTests()
      window.__runMiniMapTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };

        // --- slugifyHeading ---
        (function testSlug_basic() {
          A(slugifyHeading("Hello World") === "hello-world", "slug: basic", { got: slugifyHeading("Hello World") });
        })();

        (function testSlug_punctuation() {
          A(slugifyHeading("Hello, World! (v2.0)") === "hello-world-v2-0", "slug: punctuation", { got: slugifyHeading("Hello, World! (v2.0)") });
        })();

        (function testSlug_empty() {
          A(slugifyHeading("") === "heading", "slug: empty -> fallback 'heading'", { got: slugifyHeading("") });
          A(slugifyHeading(null) === "heading", "slug: null -> fallback");
          A(slugifyHeading(undefined) === "heading", "slug: undefined -> fallback");
        })();

        (function testSlug_unicode() {
          const r = slugifyHeading("日本語の見出し");
          A(r.length > 0 && r !== "heading", "slug: unicode produces non-empty slug", { got: r });
        })();

        (function testSlug_leadingTrailingDash() {
          A(slugifyHeading("  --Hello--  ") === "hello", "slug: strips leading/trailing dashes", { got: slugifyHeading("  --Hello--  ") });
        })();

        (function testSlug_codeBackticks() {
          const r = slugifyHeading("`code_heading`");
          A(r === "code-heading", "slug: backticks+underscore -> dashes", { got: r });
        })();

        // --- extractOutline: stable IDs ---
        (function testOutline_stableIds() {
          const md = "# Title\n\n## Section A\n\n## Section B\n";
          const o1 = extractOutline(md);
          const o2 = extractOutline(md);
          A(o1.length === o2.length, "outline: same length on re-parse");
          for (let i = 0; i < o1.length; i++) {
            A(o1[i].id === o2[i].id, "outline: id stable for heading " + i, { id1: o1[i].id, id2: o2[i].id });
          }
        })();

        // --- extractOutline: duplicate headings get disambiguated IDs ---
        (function testOutline_duplicateIds() {
          const md = "## Intro\n\nText\n\n## Intro\n\nText\n\n## Intro\n";
          const o = extractOutline(md);
          A(o.length === 3, "outline: 3 duplicate headings");
          A(o[0].id === "intro", "outline: first is 'intro'");
          A(o[1].id === "intro-1", "outline: second is 'intro-1'", { got: o[1].id });
          A(o[2].id === "intro-2", "outline: third is 'intro-2'", { got: o[2].id });
          // All IDs must be unique.
          const ids = o.map(h => h.id);
          const unique = new Set(ids);
          A(unique.size === ids.length, "outline: all IDs unique", { ids });
        })();

        // --- extractOutline: heading levels ---
        (function testOutline_levels() {
          const md = "# H1\n## H2\n### H3\n#### H4\n";
          const o = extractOutline(md);
          A(o.length === 4, "outline: 4 levels");
          A(o[0].level === 1, "outline: h1 level=1");
          A(o[1].level === 2, "outline: h2 level=2");
          A(o[2].level === 3, "outline: h3 level=3");
          A(o[3].level === 4, "outline: h4 level=4");
        })();

        // --- extractOutline: empty heading ---
        (function testOutline_emptyHeading() {
          const md = "## \n\n## Real Heading\n";
          const o = extractOutline(md);
          A(o.length === 2, "outline: 2 headings (one empty)");
          A(o[0].id === "heading", "outline: empty heading gets fallback slug", { got: o[0].id });
        })();

        // --- countRoughTokens ---
        (function testTokens_basic() {
          A(countRoughTokens("hello world") === 2, "tokens: 2 words", { got: countRoughTokens("hello world") });
        })();

        (function testTokens_withPunctuation() {
          // "Hello, world!" => "Hello" + "," + "world" + "!" = 4
          const r = countRoughTokens("Hello, world!");
          A(r === 4, "tokens: words + punctuation", { got: r });
        })();

        (function testTokens_empty() {
          A(countRoughTokens("") === 0, "tokens: empty = 0");
          A(countRoughTokens("   ") === 0, "tokens: whitespace only = 0");
        })();

        // --- buildLineToHeadingMap ---
        (function testLineMap_basic() {
          const outline = [
            { id: "intro", text: "Introduction", level: 2, line: 1 },
            { id: "methods", text: "Methods", level: 2, line: 5 },
            { id: "results", text: "Results", level: 2, line: 10 },
          ];
          const map = buildLineToHeadingMap(15, outline);
          A(map[0] === "__preamble__", "lineMap: line 0 is preamble");
          A(map[1] === "intro", "lineMap: line 1 = intro", { got: map[1] });
          A(map[4] === "intro", "lineMap: line 4 = intro (before methods)", { got: map[4] });
          A(map[5] === "methods", "lineMap: line 5 = methods", { got: map[5] });
          A(map[7] === "methods", "lineMap: line 7 = methods", { got: map[7] });
          A(map[10] === "results", "lineMap: line 10 = results", { got: map[10] });
          A(map[15] === "results", "lineMap: line 15 = results (last section)", { got: map[15] });
        })();

        (function testLineMap_emptyOutline() {
          const map = buildLineToHeadingMap(5, []);
          A(map[0] === "__preamble__", "lineMap: empty outline line 0 = preamble");
          A(map[3] === "__preamble__", "lineMap: empty outline all preamble");
          A(map[5] === "__preamble__", "lineMap: empty outline last line = preamble");
        })();

        (function testLineMap_headingOnLine1() {
          const outline = [{ id: "title", text: "Title", level: 1, line: 1 }];
          const map = buildLineToHeadingMap(3, outline);
          A(map[0] === "__preamble__", "lineMap: line 0 always preamble");
          A(map[1] === "title", "lineMap: heading on line 1", { got: map[1] });
        })();

        // --- attributeHunksToHeadings ---
        (function testAttrib_addedLines() {
          const patch = "@@ -0,0 +1,3 @@\n+line one\n+line two\n+line three\n";
          const lineToHeading = ["__preamble__", "intro", "intro", "intro"];
          const metrics = attributeHunksToHeadings(patch, lineToHeading);
          const m = metrics.get("intro");
          A(m != null, "attrib: intro has metrics");
          A(m.addLines === 3, "attrib: 3 added lines", { got: m?.addLines });
          A(m.delLines === 0, "attrib: 0 deleted lines", { got: m?.delLines });
          A(m.tokensAdded > 0, "attrib: tokens added > 0", { got: m?.tokensAdded });
        })();

        (function testAttrib_deletedLines() {
          const patch = "@@ -1,2 +1,0 @@\n-removed line one\n-removed line two\n";
          const lineToHeading = ["__preamble__", "methods"];
          const metrics = attributeHunksToHeadings(patch, lineToHeading);
          const m = metrics.get("methods");
          A(m != null, "attrib: methods has metrics");
          A(m.delLines === 2, "attrib: 2 deleted lines", { got: m?.delLines });
          A(m.addLines === 0, "attrib: 0 added lines", { got: m?.addLines });
        })();

        (function testAttrib_mixedAddDel() {
          // Context line at line 1, delete at line 1 (old), add at line 2 (new).
          const patch = "@@ -1,3 +1,3 @@\n old context\n-old line\n+new line\n old tail\n";
          const lineToHeading = ["__preamble__", "sec-a", "sec-a", "sec-a"];
          const metrics = attributeHunksToHeadings(patch, lineToHeading);
          const m = metrics.get("sec-a");
          A(m != null, "attrib: sec-a has mixed metrics");
          A(m.addLines === 1, "attrib: mixed add=1", { got: m?.addLines });
          A(m.delLines === 1, "attrib: mixed del=1", { got: m?.delLines });
        })();

        (function testAttrib_acrossSections() {
          // Patch spans two sections: lines 1-2 in "intro", lines 3-4 in "methods".
          const patch = "@@ -1,4 +1,4 @@\n+added to intro\n context\n+added to methods\n context\n";
          const lineToHeading = ["__preamble__", "intro", "intro", "methods", "methods"];
          const metrics = attributeHunksToHeadings(patch, lineToHeading);
          A(metrics.has("intro"), "attrib: has intro");
          A(metrics.has("methods"), "attrib: has methods");
          A(metrics.get("intro").addLines >= 1, "attrib: intro got additions", { got: metrics.get("intro").addLines });
          A(metrics.get("methods").addLines >= 1, "attrib: methods got additions", { got: metrics.get("methods").addLines });
        })();

        (function testAttrib_emptyPatch() {
          const metrics = attributeHunksToHeadings("", []);
          A(metrics.size === 0, "attrib: empty patch = no metrics");
        })();

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Mini-Map Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Mini-Map Unit Tests ----







      // ---- Story Mode Unit Tests (bd-24q.4.5) ----
      // Run via console: window.__runStoryModeTests()
      window.__runStoryModeTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };

        if (!DATASET.loaded || !ALL_COMMITS.length) {
          console.error("StoryMode: Need loaded dataset.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded" }] };
        }

        // Save state.
        const origIdx = DOC.idx;
        const origTab = DOC.tab;
        const origStoryActiveIdx = _storyActiveIdx;
        const origStoryMilestones = _storyMilestones.slice();

        // --- 1. MILESTONES const schema validation ---
        (function testSchema_isArray() {
          A(Array.isArray(MILESTONES), "schema: MILESTONES is array");
          A(MILESTONES.length >= 5, "schema: at least 5 milestones", { len: MILESTONES.length });
        })();

        (function testSchema_requiredFields() {
          const required = ["id", "title", "commitHash", "annotationMd", "defaultTab"];
          for (const m of MILESTONES) {
            for (const f of required) {
              A(m[f] !== undefined && m[f] !== null, `schema: ${m.id}.${f} exists`, { milestone: m.id, field: f, value: m[f] });
            }
            A(typeof m.id === "string" && m.id.length > 0, `schema: ${m.id} id is non-empty string`);
            A(typeof m.title === "string" && m.title.length > 0, `schema: ${m.id} title is non-empty string`);
            A(typeof m.commitHash === "string" && m.commitHash.length >= 7, `schema: ${m.id} commitHash >= 7 chars`, { hash: m.commitHash });
            A(typeof m.annotationMd === "string" && m.annotationMd.length > 0, `schema: ${m.id} annotationMd non-empty`);
            A(["spec", "diff", "metrics"].includes(m.defaultTab), `schema: ${m.id} defaultTab valid`, { tab: m.defaultTab });
          }
        })();

        (function testSchema_uniqueIds() {
          const ids = MILESTONES.map(m => m.id);
          const unique = new Set(ids);
          A(unique.size === ids.length, "schema: all ids unique", { ids, dupes: ids.filter((v, i) => ids.indexOf(v) !== i) });
        })();

        (function testSchema_uniqueHashes() {
          const hashes = MILESTONES.map(m => m.commitHash);
          const unique = new Set(hashes);
          A(unique.size === hashes.length, "schema: all commitHashes unique", { dupes: hashes.filter((v, i) => hashes.indexOf(v) !== i) });
        })();

        (function testSchema_optionalFocusHeading() {
          // focusHeading is optional — verify it's a string when present.
          for (const m of MILESTONES) {
            if (m.focusHeading !== undefined) {
              A(typeof m.focusHeading === "string" && m.focusHeading.length > 0, `schema: ${m.id} focusHeading is non-empty string`, { heading: m.focusHeading });
            }
          }
        })();

        // --- 2. getMilestones() resolver ---
        (function testGetMilestones_returnsArray() {
          const resolved = getMilestones();
          A(Array.isArray(resolved), "resolver: returns array");
          A(resolved.length === MILESTONES.length, "resolver: same length as MILESTONES", { got: resolved.length, expected: MILESTONES.length });
        })();

        (function testGetMilestones_hasCommitIdx() {
          const resolved = getMilestones();
          for (const m of resolved) {
            A("commitIdx" in m, `resolver: ${m.id} has commitIdx`);
            A("warning" in m, `resolver: ${m.id} has warning field`);
            if (m.commitIdx !== null) {
              A(typeof m.commitIdx === "number" && m.commitIdx >= 0, `resolver: ${m.id} commitIdx is valid index`, { idx: m.commitIdx });
              A(m.commitIdx < ALL_COMMITS.length, `resolver: ${m.id} commitIdx in range`, { idx: m.commitIdx, max: ALL_COMMITS.length - 1 });
              A(m.warning === null, `resolver: ${m.id} no warning when found`);
            } else {
              A(typeof m.warning === "string", `resolver: ${m.id} has warning string when not found`, { warning: m.warning });
            }
          }
        })();

        (function testGetMilestones_commitHashMatches() {
          const resolved = getMilestones();
          for (const m of resolved) {
            if (m.commitIdx !== null) {
              const commit = ALL_COMMITS[m.commitIdx];
              const hashMatch = (commit.hash && commit.hash.startsWith(m.commitHash)) ||
                                (commit.short && commit.short === m.commitHash) ||
                                (commit.hash === m.commitHash);
              A(hashMatch, `resolver: ${m.id} commit hash matches`, { expected: m.commitHash, gotHash: commit.hash, gotShort: commit.short });
            }
          }
        })();

        (function testGetMilestones_preservesOriginalFields() {
          const resolved = getMilestones();
          for (let i = 0; i < resolved.length; i++) {
            const r = resolved[i];
            const o = MILESTONES[i];
            A(r.id === o.id, `resolver: preserves id at ${i}`);
            A(r.title === o.title, `resolver: preserves title at ${i}`);
            A(r.commitHash === o.commitHash, `resolver: preserves commitHash at ${i}`);
            A(r.annotationMd === o.annotationMd, `resolver: preserves annotationMd at ${i}`);
            A(r.defaultTab === o.defaultTab, `resolver: preserves defaultTab at ${i}`);
          }
        })();

        (function testGetMilestones_orderMatchesMilestones() {
          const resolved = getMilestones();
          // Verify indices are generally ascending (milestones should be chronological).
          let lastIdx = -1;
          let ascending = true;
          for (const m of resolved) {
            if (m.commitIdx !== null) {
              if (m.commitIdx < lastIdx) ascending = false;
              lastIdx = m.commitIdx;
            }
          }
          A(ascending, "resolver: milestones are chronologically ordered by commitIdx");
        })();

        // --- 3. Navigation: storyGoToIdx ---
        (function testNavigation_goToIdx() {
          // Populate _storyMilestones via getMilestones filter.
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (milestones.length < 2) { A(false, "nav: need >= 2 resolved milestones"); return; }

          // Manually set _storyMilestones for testing.
          _storyMilestones = milestones;

          storyGoToIdx(0);
          A(_storyActiveIdx === 0, "nav: goToIdx(0) sets _storyActiveIdx=0", { got: _storyActiveIdx });
          A(DOC.idx === milestones[0].commitIdx, "nav: goToIdx(0) sets DOC.idx", { got: DOC.idx, expected: milestones[0].commitIdx });

          storyGoToIdx(1);
          A(_storyActiveIdx === 1, "nav: goToIdx(1) sets _storyActiveIdx=1", { got: _storyActiveIdx });
          A(DOC.idx === milestones[1].commitIdx, "nav: goToIdx(1) sets DOC.idx", { got: DOC.idx, expected: milestones[1].commitIdx });
        })();

        (function testNavigation_goToIdxLast() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (!milestones.length) { A(false, "nav: no milestones"); return; }
          _storyMilestones = milestones;

          const lastIdx = milestones.length - 1;
          storyGoToIdx(lastIdx);
          A(_storyActiveIdx === lastIdx, "nav: goToIdx(last) sets correct index", { got: _storyActiveIdx, expected: lastIdx });
          A(DOC.idx === milestones[lastIdx].commitIdx, "nav: goToIdx(last) sets DOC.idx", { got: DOC.idx, expected: milestones[lastIdx].commitIdx });
        })();

        (function testNavigation_goToIdxInvalid() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          _storyMilestones = milestones;

          const beforeIdx = _storyActiveIdx;
          const beforeDocIdx = DOC.idx;
          storyGoToIdx(-1); // Invalid index.
          A(_storyActiveIdx === beforeIdx, "nav: goToIdx(-1) no change to _storyActiveIdx");
          storyGoToIdx(999); // Out of range.
          A(_storyActiveIdx === beforeIdx, "nav: goToIdx(999) no change to _storyActiveIdx");
        })();

        (function testNavigation_defaultTab() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (!milestones.length) { A(false, "nav: no milestones for tab test"); return; }
          _storyMilestones = milestones;

          // First milestone has defaultTab.
          storyGoToIdx(0);
          A(DOC.tab === milestones[0].defaultTab, "nav: goToIdx applies defaultTab", { got: DOC.tab, expected: milestones[0].defaultTab });
        })();

        // --- 4. Navigation: storyPrev / storyNext bounds ---
        (function testNavigation_prevNext() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (milestones.length < 3) { A(false, "nav: need >= 3 milestones for prev/next"); return; }
          _storyMilestones = milestones;

          // Start at index 1.
          storyGoToIdx(1);
          A(_storyActiveIdx === 1, "nav: start at 1");

          storyNext();
          A(_storyActiveIdx === 2, "nav: next from 1 → 2", { got: _storyActiveIdx });

          storyPrev();
          A(_storyActiveIdx === 1, "nav: prev from 2 → 1", { got: _storyActiveIdx });
        })();

        (function testNavigation_prevAtZero() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (!milestones.length) { A(false, "nav: no milestones"); return; }
          _storyMilestones = milestones;

          storyGoToIdx(0);
          storyPrev();
          A(_storyActiveIdx === 0, "nav: prev at 0 stays at 0 (lower bound)", { got: _storyActiveIdx });
        })();

        (function testNavigation_nextAtLast() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (!milestones.length) { A(false, "nav: no milestones"); return; }
          _storyMilestones = milestones;

          const lastIdx = milestones.length - 1;
          storyGoToIdx(lastIdx);
          storyNext();
          A(_storyActiveIdx === lastIdx, "nav: next at last stays at last (upper bound)", { got: _storyActiveIdx, expected: lastIdx });
        })();

        (function testNavigation_fullTraversal() {
          const milestones = getMilestones().filter(m => m.commitIdx !== null);
          if (milestones.length < 2) { A(false, "nav: need >= 2 milestones for traversal"); return; }
          _storyMilestones = milestones;

          // Forward traverse: 0 → last.
          storyGoToIdx(0);
          for (let i = 0; i < milestones.length - 1; i++) storyNext();
          A(_storyActiveIdx === milestones.length - 1, "nav: full forward traversal reaches last", { got: _storyActiveIdx });

          // Backward traverse: last → 0.
          for (let i = 0; i < milestones.length - 1; i++) storyPrev();
          A(_storyActiveIdx === 0, "nav: full backward traversal reaches 0", { got: _storyActiveIdx });
        })();

        // --- 5. Diagnostics ---
        (function testDiagnostics() {
          const resolved = getMilestones();
          const diag = resolved.map(m => ({ id: m.id, commitIdx: m.commitIdx, warning: m.warning }));
          console.log("  [StoryMode] Milestone diagnostics:", JSON.stringify(diag));
          const found = resolved.filter(m => m.commitIdx !== null).length;
          const missing = resolved.filter(m => m.commitIdx === null).length;
          console.log(`  [StoryMode] ${found} resolved, ${missing} missing`);
          A(found > 0, "diag: at least 1 milestone resolved", { found, missing });
        })();

        // --- Restore state ---
        DOC.idx = origIdx;
        DOC.tab = origTab;
        _storyActiveIdx = origStoryActiveIdx;
        _storyMilestones = origStoryMilestones;
        // Restore the selected commit display.
        selectCommitIdx(origIdx);

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Story Mode Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Story Mode Unit Tests ----


      // ---- Outlier Unit Tests (bd-24q.10.3) ----
      // Run via console: window.__runOutlierTests()
      window.__runOutlierTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };
        const near = (a, b, eps) => Math.abs(a - b) < (eps || 0.01);

        // --- 1. Basic MAD-Z correctness on known synthetic series ---
        (function testBasic_knownSeries() {
          // Series: [1, 2, 3, 4, 100]. Median=3, MAD=median(|1-3|,|2-3|,|3-3|,|4-3|,|100-3|)=median(2,1,0,1,97)=1.
          const entries = [1, 2, 3, 4, 100].map((v, i) => ({ value: v, idx: i, ts: "2026-01-0" + (i + 1), hash: "h" + i }));
          const r = _inlineOutliersRobust(entries, 3);
          A(near(r.median, 3), "basic: median=3", { got: r.median });
          A(near(r.mad, 1), "basic: MAD=1", { got: r.mad });
          A(r.top.length === 3, "basic: top-3 returned", { got: r.top.length });
          // The outlier (100) should be first.
          A(r.top[0].value === 100, "basic: top[0] is 100", { got: r.top[0].value });
          // z for 100: 0.6745 * (100 - 3) / 1 = 65.4265
          A(near(r.top[0].z, 65.4265, 0.01), "basic: z(100) ~= 65.43", { got: r.top[0].z });
          // z for 1: 0.6745 * (1 - 3) / 1 = -1.349
          const entry1 = r.all.find(e => e.value === 1);
          A(entry1 && near(entry1.z, -1.349, 0.01), "basic: z(1) ~= -1.35", { got: entry1?.z });
        })();

        // --- 2. Even-length series (median is average of two middle values) ---
        (function testEven_median() {
          const entries = [10, 20, 30, 40].map((v, i) => ({ value: v, idx: i }));
          const r = _inlineOutliersRobust(entries, 2);
          A(near(r.median, 25), "even: median=(20+30)/2=25", { got: r.median });
          // MAD: |10-25|=15, |20-25|=5, |30-25|=5, |40-25|=15 → sorted: 5,5,15,15 → median=(5+15)/2=10
          A(near(r.mad, 10), "even: MAD=10", { got: r.mad });
        })();

        // --- 3. MAD=0 (all identical values) ---
        (function testMADZero() {
          const entries = [5, 5, 5, 5, 5].map((v, i) => ({ value: v, idx: i }));
          const r = _inlineOutliersRobust(entries, 3);
          A(near(r.median, 5), "mad0: median=5", { got: r.median });
          A(r.mad === 0 || near(r.mad, 0), "mad0: MAD=0", { got: r.mad });
          // All z-scores should be 0.
          A(r.all.every(e => near(e.z, 0, 0.001)), "mad0: all z=0");
          A(r.top.length >= 1, "mad0: at least 1 in top");
        })();

        // --- 4. Single element ---
        (function testSingle() {
          const r = _inlineOutliersRobust([{ value: 42, idx: 0 }], 5);
          A(near(r.median, 42), "single: median=42", { got: r.median });
          A(r.top.length === 1, "single: top length=1");
          A(r.all.length === 1, "single: all length=1");
        })();

        // --- 5. Empty series ---
        (function testEmpty() {
          const r = _inlineOutliersRobust([], 5);
          A(r.median === 0, "empty: median=0");
          A(r.mad === 0, "empty: MAD=0");
          A(r.top.length === 0, "empty: no top");
          A(r.all.length === 0, "empty: no all");
        })();

        // --- 6. Two elements ---
        (function testTwo() {
          const entries = [{ value: 10, idx: 0 }, { value: 20, idx: 1 }];
          const r = _inlineOutliersRobust(entries, 2);
          A(near(r.median, 15), "two: median=15", { got: r.median });
          // MAD: |10-15|=5, |20-15|=5 → median=(5+5)/2=5
          A(near(r.mad, 5), "two: MAD=5", { got: r.mad });
        })();

        // --- 7. NaN/undefined handling ---
        (function testNaN() {
          const entries = [{ value: NaN, idx: 0 }, { value: undefined, idx: 1 }, { value: 10, idx: 2 }, { value: 20, idx: 3 }];
          const r = _inlineOutliersRobust(entries, 4);
          // NaN/undefined → 0. Series: [0, 0, 10, 20]. Median=5, MAD=5.
          A(near(r.median, 5), "nan: median=5 (NaN→0)", { got: r.median });
          A(r.all.length === 4, "nan: all 4 entries processed");
          A(r.top.length === 4, "nan: top-4 returned");
        })();

        // --- 8. Stable tie-breaking: timestamp then hash ---
        (function testTieBreaking() {
          // All values identical → all |z|=0. Tie-break by timestamp asc, then hash asc.
          const entries = [
            { value: 5, idx: 0, ts: "2026-01-03", hash: "bbb" },
            { value: 5, idx: 1, ts: "2026-01-01", hash: "aaa" },
            { value: 5, idx: 2, ts: "2026-01-01", hash: "zzz" },
            { value: 5, idx: 3, ts: "2026-01-02", hash: "ccc" },
          ];
          const r = _inlineOutliersRobust(entries, 4);
          A(r.top[0].ts === "2026-01-01" && r.top[0].hash === "aaa", "tie: first is earliest ts + smallest hash", { got: r.top[0] });
          A(r.top[1].ts === "2026-01-01" && r.top[1].hash === "zzz", "tie: second is same ts, larger hash", { got: r.top[1] });
          A(r.top[2].ts === "2026-01-02", "tie: third is next timestamp", { got: r.top[2] });
          A(r.top[3].ts === "2026-01-03", "tie: fourth is latest", { got: r.top[3] });
        })();

        // --- 9. Evidence object structure ---
        (function testEvidence() {
          const entries = [
            { value: 1, idx: 0, buckets: [1, 4] },
            { value: 2, idx: 1, buckets: [2] },
            { value: 100, idx: 2, buckets: [3, 6, 8] },
          ];
          const r = _inlineOutliersRobust(entries, 3);
          const top0 = r.top[0];
          A(top0.evidence !== undefined, "evidence: exists on top entry");
          A(top0.evidence.value === top0.value, "evidence: value matches entry value");
          A(near(top0.evidence.median, r.median), "evidence: median matches result median");
          A(near(top0.evidence.mad, r.mad), "evidence: MAD matches result MAD");
          A(near(top0.evidence.z, top0.z), "evidence: z matches entry z");
          A(Array.isArray(top0.evidence.contributingBuckets), "evidence: contributingBuckets is array");
          // The outlier (100) has buckets [3, 6, 8].
          A(top0.value === 100, "evidence: top is 100");
          A(JSON.stringify(top0.evidence.contributingBuckets) === "[3,6,8]", "evidence: buckets=[3,6,8]", { got: top0.evidence.contributingBuckets });
        })();

        // --- 10. topK clamping ---
        (function testTopK() {
          const entries = [1, 2, 3].map((v, i) => ({ value: v, idx: i }));
          const r1 = _inlineOutliersRobust(entries, 100);
          A(r1.top.length === 3, "topK: clamped to series length", { got: r1.top.length });
          const r2 = _inlineOutliersRobust(entries, 0);
          A(r2.top.length === 1, "topK: min 1", { got: r2.top.length });
          const r3 = _inlineOutliersRobust(entries, -5);
          A(r3.top.length === 1, "topK: negative → min 1", { got: r3.top.length });
        })();

        // --- 11. Large outlier has highest |z| ---
        (function testLargestOutlier() {
          const entries = [1, 2, 3, 4, 5, 6, 7, 8, 9, 1000].map((v, i) => ({ value: v, idx: i }));
          const r = _inlineOutliersRobust(entries, 1);
          A(r.top[0].value === 1000, "largest: top-1 is 1000", { got: r.top[0].value });
          A(Math.abs(r.top[0].z) > 10, "largest: |z| > 10", { got: r.top[0].z });
        })();

        // --- 12. Negative values ---
        (function testNegative() {
          const entries = [-100, -5, 0, 5, 10].map((v, i) => ({ value: v, idx: i }));
          const r = _inlineOutliersRobust(entries, 2);
          A(near(r.median, 0), "negative: median=0", { got: r.median });
          A(r.top[0].value === -100, "negative: top[0] is -100 (largest deviation)", { got: r.top[0].value });
          A(r.top[0].z < 0, "negative: z is negative for -100", { got: r.top[0].z });
        })();

        // --- 13. buildOutlierMetricSeries ---
        (function testBuildSeries() {
          if (!DATASET.loaded || !ALL_COMMITS.length) {
            A(false, "buildSeries: need loaded dataset");
            return;
          }
          const series = buildOutlierMetricSeries(ALL_COMMITS);
          A("impact" in series, "buildSeries: has impact");
          A("linesAdded" in series, "buildSeries: has linesAdded");
          A("linesDeleted" in series, "buildSeries: has linesDeleted");
          A(series.impact.length === ALL_COMMITS.length, "buildSeries: impact length matches commits", { got: series.impact.length, expected: ALL_COMMITS.length });
          A(series.linesAdded.length === ALL_COMMITS.length, "buildSeries: linesAdded length matches");
          // Each entry should have value, ts, hash, idx, buckets.
          const e = series.impact[0];
          A("value" in e, "buildSeries: entry has value");
          A("ts" in e, "buildSeries: entry has ts");
          A("hash" in e, "buildSeries: entry has hash");
          A("idx" in e, "buildSeries: entry has idx");
          A("buckets" in e && Array.isArray(e.buckets), "buildSeries: entry has buckets array");
          console.log("  [Outlier] series keys:", Object.keys(series).join(", "), "entries:", series.impact.length);
        })();

        // --- 14. buildTimeBinSeries ---
        (function testTimeBins() {
          if (!DATASET.loaded || !ALL_COMMITS.length) {
            A(false, "timeBins: need loaded dataset");
            return;
          }
          const dayBins = buildTimeBinSeries(ALL_COMMITS, "day", "impact");
          A(Array.isArray(dayBins), "timeBins: day returns array");
          A(dayBins.length > 0, "timeBins: day has bins", { len: dayBins.length });
          A(dayBins.length <= ALL_COMMITS.length, "timeBins: day bins <= commits (aggregated)");
          // Each bin entry has value, ts, hash, idx, buckets.
          const b = dayBins[0];
          A(typeof b.value === "number", "timeBins: bin has numeric value");
          A(typeof b.ts === "string", "timeBins: bin has ts");
          A(Array.isArray(b.buckets), "timeBins: bin has buckets array");

          const weekBins = buildTimeBinSeries(ALL_COMMITS, "week", "impact");
          A(weekBins.length <= dayBins.length, "timeBins: week bins <= day bins", { week: weekBins.length, day: dayBins.length });

          const monthBins = buildTimeBinSeries(ALL_COMMITS, "month", "impact");
          A(monthBins.length <= weekBins.length, "timeBins: month bins <= week bins", { month: monthBins.length, week: weekBins.length });

          // Verify total sum matches.
          const totalDirect = ALL_COMMITS.reduce((s, c) => s + Number(c.impact || 0), 0);
          const totalBins = dayBins.reduce((s, b) => s + b.value, 0);
          A(near(totalDirect, totalBins, 0.1), "timeBins: day sum matches direct sum", { direct: totalDirect, bins: totalBins });
          console.log("  [Outlier] time bins: day=" + dayBins.length + " week=" + weekBins.length + " month=" + monthBins.length);
        })();

        // --- 15. Integration: full pipeline on ALL_COMMITS ---
        (function testFullPipeline() {
          if (!DATASET.loaded || !ALL_COMMITS.length) {
            A(false, "pipeline: need loaded dataset");
            return;
          }
          const series = buildOutlierMetricSeries(ALL_COMMITS);
          const impactResult = _inlineOutliersRobust(series.impact, 5);
          A(impactResult.top.length === Math.min(5, ALL_COMMITS.length), "pipeline: top-5 from impact");
          A(impactResult.median >= 0, "pipeline: median >= 0", { got: impactResult.median });
          A(impactResult.mad >= 0, "pipeline: MAD >= 0", { got: impactResult.mad });
          // Top outlier should have the largest |z|.
          if (impactResult.top.length > 1) {
            A(Math.abs(impactResult.top[0].z) >= Math.abs(impactResult.top[1].z), "pipeline: top[0] |z| >= top[1] |z|");
          }
          // Every top entry has evidence.
          A(impactResult.top.every(e => e.evidence && typeof e.evidence.value === "number"), "pipeline: all top have evidence");
          console.log("  [Outlier] pipeline: median=" + impactResult.median.toFixed(1) + " MAD=" + impactResult.mad.toFixed(1) + " top[0]=" + JSON.stringify(impactResult.top[0]?.evidence || {}));
        })();

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Outlier Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Outlier Unit Tests ----


      // ---- Heat Stripe Unit Tests (bd-24q.13.3) ----
      // Run via console: window.__runHeatStripeTests()
      window.__runHeatStripeTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };
        const near = (a, b, eps) => Math.abs(a - b) < (eps || 0.01);

        if (!DATASET.loaded || !ALL_COMMITS.length) {
          console.error("HeatStripe: Need loaded dataset.");
          return { passed: 0, failed: 1, total: 1, results: [{ pass: false, msg: "Dataset not loaded" }] };
        }

        // Clear cache before tests to ensure fresh computation.
        _heatStripeCache.clear();

        // --- 1. computeHeatStripe returns correct structure ---
        (function testStructure() {
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          A(stripe !== null && stripe !== undefined, "struct: result is not null");
          A(Array.isArray(stripe.bins), "struct: has bins array");
          A(typeof stripe.maxMass === "number", "struct: has numeric maxMass");
          A(typeof stripe.binCount === "number", "struct: has binCount");
          A(stripe.binCount === stripe.bins.length, "struct: binCount matches bins.length", { binCount: stripe.binCount, binsLen: stripe.bins.length });
          A(stripe.bins.length > 0, "struct: at least 1 bin", { len: stripe.bins.length });
        })();

        // --- 2. Bin structure ---
        (function testBinStructure() {
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          const bin = stripe.bins[0];
          A("label" in bin, "bin: has label");
          A(typeof bin.totalMass === "number", "bin: has numeric totalMass");
          A(bin.perBucket instanceof Map, "bin: perBucket is Map");
          A(typeof bin.dominant === "number", "bin: dominant is numeric id");
          A(typeof bin.dominantColor === "string" && bin.dominantColor.startsWith("#"), "bin: dominantColor is hex string", { got: bin.dominantColor });
          A("repCommit" in bin, "bin: has repCommit");
          A(typeof bin.repCommitIdx === "number", "bin: has numeric repCommitIdx");
          A(typeof bin.empty === "boolean", "bin: has boolean empty");
        })();

        // --- 3. Commit resolution: one bin per unique short hash ---
        (function testCommitResolution() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          const uniqueShorts = new Set(ALL_COMMITS.map(c => c.short));
          A(stripe.bins.length === uniqueShorts.size, "commit-res: bins = unique short hashes", { bins: stripe.bins.length, unique: uniqueShorts.size });
        })();

        // --- 4. First and last bins map to first and last commits ---
        (function testFirstLastBins() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          const firstBin = stripe.bins[0];
          const lastBin = stripe.bins[stripe.bins.length - 1];
          A(firstBin.label === ALL_COMMITS[0].short, "first-last: first bin label matches first commit short", { got: firstBin.label, expected: ALL_COMMITS[0].short });
          const lastCommitShort = ALL_COMMITS[ALL_COMMITS.length - 1].short;
          A(lastBin.label === lastCommitShort, "first-last: last bin label matches last commit short", { got: lastBin.label, expected: lastCommitShort });
        })();

        // --- 5. No gaps: bins cover all commits ---
        (function testNoGaps() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          // Sum of all bin masses should equal sum of all commit impacts.
          const totalBinMass = stripe.bins.reduce((s, b) => s + b.totalMass, 0);
          const totalCommitImpact = ALL_COMMITS.reduce((s, c) => s + Number(c.impact || 0), 0);
          A(near(totalBinMass, totalCommitImpact, 1), "no-gaps: total bin mass matches commit impact sum", { binMass: totalBinMass, commitImpact: totalCommitImpact });
        })();

        // --- 6. Dominant bucket: deterministic tie-breaking (highest contribution, then lowest id) ---
        (function testDominantTieBreak() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          for (const bin of stripe.bins) {
            if (bin.empty) continue;
            let maxContrib = 0;
            for (const b of BUCKETS) {
              const contrib = bin.perBucket.get(b.id) || 0;
              if (contrib > maxContrib) maxContrib = contrib;
            }
            // Dominant should have >= maxContrib. If tie, should be lowest id.
            const domContrib = bin.perBucket.get(bin.dominant) || 0;
            A(domContrib === maxContrib, "dominant: has max contribution in bin " + bin.label, { dominant: bin.dominant, domContrib, maxContrib });
            // If there are ties, dominant should be lowest id among them.
            const tiedIds = [];
            for (const b of BUCKETS) {
              if ((bin.perBucket.get(b.id) || 0) === maxContrib) tiedIds.push(b.id);
            }
            if (tiedIds.length > 1) {
              A(bin.dominant === Math.min(...tiedIds), "dominant: tie-break to lowest id in bin " + bin.label, { dominant: bin.dominant, tied: tiedIds });
            }
          }
        })();

        // --- 7. Intensity scaling is monotone: higher mass → higher normalized intensity ---
        (function testIntensityMonotone() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          A(stripe.maxMass >= 0, "intensity: maxMass >= 0", { got: stripe.maxMass });
          // All bins should have totalMass <= maxMass.
          for (const bin of stripe.bins) {
            A(bin.totalMass <= stripe.maxMass + 0.001, "intensity: bin mass <= maxMass", { label: bin.label, mass: bin.totalMass, max: stripe.maxMass });
          }
          // The bin with the highest mass should equal maxMass.
          const maxBin = stripe.bins.reduce((a, b) => a.totalMass > b.totalMass ? a : b);
          A(near(maxBin.totalMass, stripe.maxMass, 0.001), "intensity: max bin equals maxMass", { got: maxBin.totalMass, expected: stripe.maxMass });
        })();

        // --- 8. Representative commit is the one with highest metric value in bin ---
        (function testRepCommit() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          // For commit-resolution, each bin has one commit, so repCommit should match.
          const bin = stripe.bins.find(b => b.repCommit !== null);
          if (bin) {
            A(bin.repCommit !== null, "rep: has representative commit");
            A(bin.repCommitIdx >= 0, "rep: repCommitIdx >= 0", { got: bin.repCommitIdx });
            A(bin.repCommitIdx < ALL_COMMITS.length, "rep: repCommitIdx in range", { got: bin.repCommitIdx, max: ALL_COMMITS.length - 1 });
          }
        })();

        // --- 9. Different metrics produce different results ---
        (function testDifferentMetrics() {
          _heatStripeCache.clear();
          const linesStripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          _heatStripeCache.clear();
          const groupsStripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "groups", bucketMode: "primary" });
          // Groups metric: totalMass counts number of groups, so values are smaller integers.
          const linesMax = linesStripe.maxMass;
          const groupsMax = groupsStripe.maxMass;
          // They should generally differ (unless dataset is degenerate).
          A(linesStripe.bins.length === groupsStripe.bins.length, "metrics: same bin count", { lines: linesStripe.bins.length, groups: groupsStripe.bins.length });
          console.log("  [HeatStripe] lines maxMass=" + linesMax + " groups maxMass=" + groupsMax);
        })();

        // --- 10. Primary vs multi bucket mode ---
        (function testBucketModes() {
          _heatStripeCache.clear();
          const primary = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          _heatStripeCache.clear();
          const multi = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "multi" });
          A(primary.bins.length === multi.bins.length, "modes: same bin count");
          // In multi mode, total mass per bin can be >= primary mode (multi-labeling).
          let primaryTotal = 0, multiTotal = 0;
          for (const b of primary.bins) primaryTotal += b.totalMass;
          for (const b of multi.bins) multiTotal += b.totalMass;
          // Multi should spread same or higher (lines metric distributes by label count).
          A(near(primaryTotal, multiTotal, 1), "modes: total mass roughly equal for lines metric", { primary: primaryTotal, multi: multiTotal });
          console.log("  [HeatStripe] primary total=" + primaryTotal.toFixed(1) + " multi total=" + multiTotal.toFixed(1));
        })();

        // --- 11. Cache hit ---
        (function testCache() {
          _heatStripeCache.clear();
          const stripe1 = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          const stripe2 = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          A(stripe1 === stripe2, "cache: second call returns same reference (cached)");
          A(stripe1.cacheKey === stripe2.cacheKey, "cache: same cacheKey");
        })();

        // --- 12. perBucket covers all BUCKETS ---
        (function testPerBucketCoverage() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          const bin = stripe.bins[0];
          for (const b of BUCKETS) {
            A(bin.perBucket.has(b.id), "perBucket: has bucket id " + b.id);
            A(typeof bin.perBucket.get(b.id) === "number", "perBucket: bucket " + b.id + " is numeric");
          }
        })();

        // --- 13. Empty bins (if any in time-bin mode) ---
        (function testEmptyBins() {
          if (typeof buildWallClockBins !== "function") {
            console.log("  [HeatStripe] Skipping empty bin test (buildWallClockBins not available)");
            return;
          }
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "day", metric: "lines", bucketMode: "primary" });
          if (!stripe || !stripe.bins) {
            console.log("  [HeatStripe] Skipping empty bin test (day resolution returned null)");
            return;
          }
          const emptyBins = stripe.bins.filter(b => b.empty);
          console.log("  [HeatStripe] day bins: " + stripe.bins.length + " (" + emptyBins.length + " empty)");
          for (const b of emptyBins) {
            A(b.totalMass === 0, "empty: empty bin has 0 mass", { label: b.label });
          }
        })();

        // --- 14. Diagnostic output ---
        (function testDiagnostic() {
          _heatStripeCache.clear();
          const stripe = computeHeatStripe(ALL_COMMITS, { resolution: "commit", metric: "lines", bucketMode: "primary" });
          const sample = stripe.bins.slice(0, 3).map(b => ({
            label: b.label, mass: b.totalMass.toFixed(1), dominant: b.dominant, rep: b.repCommit?.short || "none",
          }));
          console.log("  [HeatStripe] sample bins:", JSON.stringify(sample));
          console.log("  [HeatStripe] binCount=" + stripe.binCount + " maxMass=" + stripe.maxMass.toFixed(1));
          A(true, "diagnostic: logged successfully");
        })();

        // --- Summary ---
        _heatStripeCache.clear(); // Clean up test cache pollution.
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Heat Stripe Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Heat Stripe Unit Tests ----


      // ---- Phase Map Unit Tests (bd-24q.11.3) ----
      // Run via console: window.__runPhaseMapTests()
      window.__runPhaseMapTests = function () {
        const R = [];
        const A = (c, m, x) => { R.push(c ? { pass: true, msg: m } : { pass: false, msg: m, ctx: x }); if (!c) console.error("FAIL:", m, x || "") };
        const near = (a, b, eps) => Math.abs(a - b) < (eps || 0.01);

        // Helper: generate synthetic piecewise-stationary series.
        function generatePiecewise(segments) {
          const values = [];
          const metadata = [];
          for (const seg of segments) {
            for (let i = 0; i < seg.n; i++) {
              const noise = (Math.random() - 0.5) * (seg.noise || 0);
              values.push(seg.mean + noise);
              metadata.push({ ts: "2026-01-01", hash: "h" + values.length, idx: values.length - 1, buckets: seg.buckets || [] });
            }
          }
          return { values, metadata };
        }

        // --- 1. Basic two-segment detection ---
        (function testTwoSegment() {
          // Segment 1: mean=1, n=30. Segment 2: mean=10, n=30. Clear shift.
          const { values, metadata } = generatePiecewise([
            { mean: 1, n: 30, noise: 0.5 },
            { mean: 10, n: 30, noise: 0.5 },
          ]);
          const result = _inlinePhaseMapEnhanced(values, 0.05, metadata);
          A(result.p0.length === 60, "2seg: p0 length = 60", { got: result.p0.length });
          A(result.changePoints.length >= 1, "2seg: at least 1 change point detected", { cps: result.changePoints });
          // Change point should be near index 30 (±5).
          const nearCP = result.changePoints.some(cp => Math.abs(cp - 30) <= 5);
          A(nearCP, "2seg: change point near index 30 (±5)", { cps: result.changePoints });
          console.log("  [PhaseMap] 2-segment CPs:", result.changePoints.join(","));
        })();

        // --- 2. Three-segment detection ---
        (function testThreeSegment() {
          const { values, metadata } = generatePiecewise([
            { mean: 0, n: 25, noise: 0.3 },
            { mean: 8, n: 25, noise: 0.3 },
            { mean: 2, n: 25, noise: 0.3 },
          ]);
          const result = _inlinePhaseMapEnhanced(values, 0.05, metadata);
          A(result.changePoints.length >= 2, "3seg: at least 2 change points", { cps: result.changePoints });
          console.log("  [PhaseMap] 3-segment CPs:", result.changePoints.join(","));
        })();

        // --- 3. Constant series: no change points ---
        (function testConstant() {
          const values = new Array(50).fill(5);
          const result = _inlinePhaseMapEnhanced(values, 0.05, []);
          A(result.changePoints.length === 0, "constant: no change points", { cps: result.changePoints });
          A(result.segments.length === 1, "constant: 1 segment", { segs: result.segments.length });
        })();

        // --- 4. Single spike ---
        (function testSingleSpike() {
          const values = new Array(50).fill(1);
          values[25] = 100; // Large spike.
          const result = _inlinePhaseMapEnhanced(values, 0.05, []);
          // A single spike may or may not trigger a CP depending on hazard.
          // The key test is that the algorithm doesn't crash and returns valid structure.
          A(result.p0.length === 50, "spike: p0 length = 50");
          A(Array.isArray(result.segments), "spike: has segments");
          A(Array.isArray(result.evidence), "spike: has evidence");
          console.log("  [PhaseMap] spike CPs:", result.changePoints.join(","), "segs:", result.segments.length);
        })();

        // --- 5. Output structure validation ---
        (function testStructure() {
          const values = [1, 1, 1, 10, 10, 10, 1, 1, 1];
          const meta = values.map((v, i) => ({ ts: "2026-01-0" + (i + 1), hash: "h" + i, idx: i, buckets: [1, 4] }));
          const result = _inlinePhaseMapEnhanced(values, 0.1, meta);
          A("p0" in result, "struct: has p0");
          A("changePoints" in result, "struct: has changePoints");
          A("segments" in result, "struct: has segments");
          A("evidence" in result, "struct: has evidence");
          A("hazard" in result, "struct: has hazard");
          A("seriesLength" in result, "struct: has seriesLength");
          A(result.seriesLength === 9, "struct: seriesLength = 9", { got: result.seriesLength });
          A(near(result.hazard, 0.1), "struct: hazard = 0.1", { got: result.hazard });
        })();

        // --- 6. Segments cover all indices (no gaps/overlaps) ---
        (function testSegmentCoverage() {
          const { values, metadata } = generatePiecewise([
            { mean: 0, n: 20, noise: 0.2 },
            { mean: 5, n: 20, noise: 0.2 },
            { mean: 1, n: 20, noise: 0.2 },
          ]);
          const result = _inlinePhaseMapEnhanced(values, 0.05, metadata);
          // Segments should cover [0, length-1] with no gaps.
          A(result.segments.length >= 1, "coverage: at least 1 segment");
          A(result.segments[0].start === 0, "coverage: first segment starts at 0", { got: result.segments[0].start });
          const lastSeg = result.segments[result.segments.length - 1];
          A(lastSeg.end === values.length - 1, "coverage: last segment ends at length-1", { got: lastSeg.end, expected: values.length - 1 });
          // Check for gaps.
          for (let i = 1; i < result.segments.length; i++) {
            const prevEnd = result.segments[i - 1].end;
            const currStart = result.segments[i].start;
            A(currStart === prevEnd + 1, "coverage: no gap between segments " + (i - 1) + " and " + i, { prevEnd, currStart });
          }
          // Total length should equal series length.
          const totalLen = result.segments.reduce((s, seg) => s + seg.length, 0);
          A(totalLen === values.length, "coverage: total segment length = series length", { total: totalLen, series: values.length });
        })();

        // --- 7. Posterior and confidence in [0, 1] ---
        (function testPosteriorBounds() {
          const values = [1, 2, 1, 2, 10, 11, 10, 11];
          const result = _inlinePhaseMapEnhanced(values, 0.1, []);
          for (let i = 0; i < result.p0.length; i++) {
            A(result.p0[i] >= -0.001 && result.p0[i] <= 1.001, "posterior: p0[" + i + "] in [0,1]", { got: result.p0[i] });
          }
          for (const seg of result.segments) {
            A(seg.confidence >= -0.001 && seg.confidence <= 1.001, "posterior: confidence in [0,1]", { got: seg.confidence });
            A(seg.avgP0 >= -0.001 && seg.avgP0 <= 1.001, "posterior: avgP0 in [0,1]", { got: seg.avgP0 });
          }
        })();

        // --- 8. Evidence ledger structure ---
        (function testEvidence() {
          const { values, metadata } = generatePiecewise([
            { mean: 0, n: 25, noise: 0.1, buckets: [1, 4] },
            { mean: 10, n: 25, noise: 0.1, buckets: [3, 6] },
          ]);
          const result = _inlinePhaseMapEnhanced(values, 0.05, metadata);
          A(result.evidence.length === result.changePoints.length, "evidence: count matches CPs", { evidence: result.evidence.length, cps: result.changePoints.length });
          for (const ev of result.evidence) {
            A(typeof ev.idx === "number", "evidence: has idx");
            A(typeof ev.posteriorP0 === "number", "evidence: has posteriorP0");
            A(ev.posteriorP0 > 0.5, "evidence: posteriorP0 > 0.5 (triggered CP)", { got: ev.posteriorP0 });
            A("before" in ev && "after" in ev, "evidence: has before/after");
            A(typeof ev.before.mean === "number", "evidence: before.mean is number");
            A(typeof ev.before.variance === "number", "evidence: before.variance is number");
            A(typeof ev.before.stddev === "number", "evidence: before.stddev is number");
            A(typeof ev.before.n === "number" && ev.before.n > 0, "evidence: before.n > 0");
            A(typeof ev.after.mean === "number", "evidence: after.mean is number");
            A(typeof ev.after.n === "number" && ev.after.n > 0, "evidence: after.n > 0");
            A(typeof ev.meanShift === "number", "evidence: has meanShift");
            A(typeof ev.varianceRatio === "number", "evidence: has varianceRatio");
          }
          // For a clear mean shift (0 → 10), meanShift should be positive.
          if (result.evidence.length > 0) {
            const ev0 = result.evidence[0];
            A(ev0.meanShift > 3, "evidence: meanShift > 3 for 0→10 shift", { got: ev0.meanShift });
            console.log("  [PhaseMap] evidence[0]: meanShift=" + ev0.meanShift.toFixed(2) + " varRatio=" + ev0.varianceRatio.toFixed(2) + " p0=" + ev0.posteriorP0.toFixed(3));
          }
        })();

        // --- 9. Segment stats are correct ---
        (function testSegmentStats() {
          const values = [5, 5, 5, 5, 5]; // Constant series.
          const result = _inlinePhaseMapEnhanced(values, 0.05, []);
          A(result.segments.length === 1, "segstats: 1 segment for constant series");
          const seg = result.segments[0];
          A(near(seg.mean, 5), "segstats: mean = 5", { got: seg.mean });
          A(near(seg.variance, 0), "segstats: variance = 0", { got: seg.variance });
          A(seg.length === 5, "segstats: length = 5", { got: seg.length });
        })();

        // --- 10. Hazard sensitivity ---
        (function testHazardSensitivity() {
          const { values, metadata } = generatePiecewise([
            { mean: 1, n: 30, noise: 1 },
            { mean: 5, n: 30, noise: 1 },
          ]);
          const highH = _inlinePhaseMapEnhanced(values, 0.3, metadata);
          const lowH = _inlinePhaseMapEnhanced(values, 0.01, metadata);
          // Higher hazard should detect more or equal change points (more sensitive).
          A(highH.changePoints.length >= lowH.changePoints.length, "hazard: high H >= low H CPs", { high: highH.changePoints.length, low: lowH.changePoints.length });
          console.log("  [PhaseMap] hazard sensitivity: H=0.3 CPs=" + highH.changePoints.length + " H=0.01 CPs=" + lowH.changePoints.length);
        })();

        // --- 11. Empty series ---
        (function testEmpty() {
          const result = _inlinePhaseMapEnhanced([], 0.05, []);
          A(result.p0.length === 0, "empty: p0 empty");
          A(result.changePoints.length === 0, "empty: no CPs");
          A(result.segments.length === 0, "empty: no segments");
          A(result.evidence.length === 0, "empty: no evidence");
        })();

        // --- 12. Metadata propagation ---
        (function testMetadata() {
          const values = [0, 0, 0, 10, 10, 10];
          const meta = values.map((v, i) => ({ ts: "2026-01-0" + (i + 1), hash: "hash" + i, idx: i, buckets: [i % 3 + 1] }));
          const result = _inlinePhaseMapEnhanced(values, 0.1, meta);
          // Segments should have startMeta and endMeta.
          for (const seg of result.segments) {
            if (seg.startMeta) A(typeof seg.startMeta.ts === "string", "meta: startMeta has ts");
            if (seg.endMeta) A(typeof seg.endMeta.hash === "string", "meta: endMeta has hash");
          }
          // Evidence should propagate metadata.
          for (const ev of result.evidence) {
            A(typeof ev.ts === "string", "meta: evidence has ts");
            A(typeof ev.hash === "string", "meta: evidence has hash");
            A(Array.isArray(ev.buckets), "meta: evidence has buckets");
          }
        })();

        // --- 13. Gradual drift (challenging case) ---
        (function testGradualDrift() {
          // Linear ramp: 0 to 20 over 50 points. BOCPD may or may not detect this.
          const values = Array.from({ length: 50 }, (_, i) => i * 0.4);
          const result = _inlinePhaseMapEnhanced(values, 0.05, []);
          // The key is that it runs without errors and returns valid structure.
          A(result.p0.length === 50, "drift: p0 length = 50");
          A(result.seriesLength === 50, "drift: seriesLength = 50");
          console.log("  [PhaseMap] gradual drift: CPs=" + result.changePoints.length + " segs=" + result.segments.length);
        })();

        // --- 14. Integration with ALL_COMMITS ---
        (function testIntegration() {
          if (!DATASET.loaded || !ALL_COMMITS.length) {
            A(false, "integration: need loaded dataset");
            return;
          }
          const values = ALL_COMMITS.map(c => Math.log1p(Number(c.impact || 0)));
          const meta = ALL_COMMITS.map(c => ({ ts: c.dateIso || "", hash: c.hash || "", idx: c.idx, buckets: c.labels || [] }));
          const result = _inlinePhaseMapEnhanced(values, 0.03, meta);
          A(result.p0.length === ALL_COMMITS.length, "integration: p0 length matches commits");
          A(result.segments.length >= 1, "integration: at least 1 segment");
          A(result.evidence.length === result.changePoints.length, "integration: evidence count matches CPs");
          // Total segment coverage.
          const totalLen = result.segments.reduce((s, seg) => s + seg.length, 0);
          A(totalLen === ALL_COMMITS.length, "integration: segments cover all commits", { total: totalLen, commits: ALL_COMMITS.length });
          console.log("  [PhaseMap] integration: CPs=" + result.changePoints.length + " segs=" + result.segments.length + " commits=" + ALL_COMMITS.length);
        })();

        // --- Summary ---
        const p = R.filter(x => x.pass).length, f = R.filter(x => !x.pass).length;
        const s = `Phase Map Tests: ${p} passed, ${f} failed, ${R.length} total`;
        if (f > 0) { console.warn(s); R.filter(x => !x.pass).forEach(x => console.error("  FAIL:", x.msg, x.ctx || "")); }
        else console.log("%c" + s, "color:green;font-weight:bold");
        return { passed: p, failed: f, total: R.length, results: R };
      };
      // ---- End Phase Map Unit Tests ----









      async function levenshteinForPatchLocal(patch) {
        const hunks = parseUnifiedHunks(patch);
        const enc = new TextEncoder();
        let sum = 0;
        for (const h of hunks) {
          const oldLines = [];
          const newLines = [];
          for (const hl of h.lines) {
            if (!hl) continue;
            const p = hl[0];
            const content = hl.slice(1);
            if (p === "-") oldLines.push(content);
            if (p === "+") newLines.push(content);
          }
          if (!oldLines.length && !newLines.length) continue;
          const a = enc.encode(oldLines.join("\n"));
          const b = enc.encode(newLines.join("\n"));
          if (a.length > 20000 || b.length > 20000) {
            // Worst-case guard: fallback to a cheap upper bound.
            sum += a.length + b.length;
          } else {
            sum += await levenshteinBytes(a, b);
          }
        }
        return sum;
      }

      async function levenshteinForPatch(patch, opts = {}) {
        if (WORKER_STATE.ready && !opts.localOnly) {
          try {
            const res = await workerRequest("levenshtein_patch", { patch }, { timeoutMs: 30000, signal: opts.signal });
            if (Number.isFinite(Number(res?.lev))) return Number(res.lev);
          } catch (e) {
            if (e?.name === "AbortError") throw e;
            console.error("Worker Levenshtein failed; using local fallback:", e);
          }
        }
        return levenshteinForPatchLocal(patch);
      }

      function selectCommitIdx(idx, opts = {}) {
        const max = Math.max(0, (ALL_COMMITS.length || 1) - 1);
        const next = clamp(Number(idx || 0), 0, max);
        DOC.idx = next;

        const slider = document.getElementById("dockSlider");
        if (slider) slider.value = String(next);

        syncDockAndDoc();
        if (!opts._fromPopstate) syncUrlToState();
        // Update story rail if visible.
        if (!document.getElementById("storyRail")?.classList.contains("hidden")) renderStoryCards();

        if (opts.scrollToCommitList) {
          const c = ALL_COMMITS[next];
          const el = c ? document.getElementById(`commit-${c.hash}`) : null;
          if (el) {
            el.scrollIntoView({ behavior: "smooth", block: "start" });
            el.open = true;
          }
        }
      }

      // -------------------------------------------------------
      // Story Mode: Desktop UI (bd-24q.4.2)
      // -------------------------------------------------------
      let _storyMilestones = [];
      let _storyActiveIdx = -1;

      /** Render milestone cards in the story rail. */
      function renderStoryCards() {
        const rail = document.getElementById("storyRail");
        const container = document.getElementById("storyCards");
        if (!rail || !container || rail.classList.contains("hidden")) return;

        _storyMilestones = getMilestones().filter((m) => m.commitIdx !== null);

        if (!_storyMilestones.length) {
          container.innerHTML = '<div class="text-[11px] text-slate-400 italic">No milestones available</div>';
          _updateStoryProgress();
          return;
        }

        // Find which milestone is closest to (at or before) current DOC.idx.
        _storyActiveIdx = -1;
        for (let i = _storyMilestones.length - 1; i >= 0; i--) {
          if (_storyMilestones[i].commitIdx <= DOC.idx) { _storyActiveIdx = i; break; }
        }
        if (_storyActiveIdx === -1 && _storyMilestones.length) _storyActiveIdx = 0;

        const md = window._mdSingleton || window.markdownit?.();
        container.innerHTML = _storyMilestones.map((m, i) => {
          const isActive = i === _storyActiveIdx;
          const commit = ALL_COMMITS[m.commitIdx];
          const date = commit?.dateIso ? new Date(commit.dateIso).toLocaleDateString() : "";
          const annotationHtml = md ? md.render(m.annotationMd || "") : escapeHtml(m.annotationMd || "");
          const metrics = commit ? `+${fmtInt(commit.add || 0)} -${fmtInt(commit.del || 0)}` : "";
          return `<div class="story-card rounded-xl border p-3 cursor-pointer transition-all ${isActive ? 'border-blue-400 bg-blue-50/80 shadow-sm' : 'border-slate-900/10 bg-white/60 hover:bg-slate-50'}" data-story-idx="${i}">
            <div class="flex items-center gap-2">
              <span class="inline-block w-2 h-2 rounded-full shrink-0 ${isActive ? 'bg-blue-500' : 'bg-slate-300'}"></span>
              <span class="text-[11px] font-semibold ${isActive ? 'text-blue-900' : 'text-slate-700'} truncate">${escapeHtml(m.title)}</span>
            </div>
            <div class="mt-1.5 text-[10px] leading-snug text-slate-600 story-annotation">${annotationHtml}</div>
            <div class="mt-1.5 flex items-center gap-2 text-[10px] text-slate-400">
              ${date ? `<span>${escapeHtml(date)}</span>` : ""}
              ${metrics ? `<span class="mono">${escapeHtml(metrics)}</span>` : ""}
            </div>
          </div>`;
        }).join("");

        // Click handlers.
        container.querySelectorAll(".story-card").forEach((card) => {
          card.addEventListener("click", () => {
            const idx = Number(card.dataset.storyIdx);
            const m = _storyMilestones[idx];
            if (!m) return;
            selectCommitIdx(m.commitIdx);
            if (m.defaultTab) setDocTab(m.defaultTab);
            // Focus heading after render settles.
            if (m.focusHeading) {
              requestAnimationFrame(() => {
                const docEl = document.getElementById("docRendered");
                const target = docEl?.querySelector("#" + CSS.escape(m.focusHeading));
                if (target) target.scrollIntoView({ behavior: "smooth", block: "start" });
              });
            }
            _storyActiveIdx = idx;
            renderStoryCards();
          });
        });

        // Scroll active card into view.
        const activeCard = container.querySelector(`.story-card[data-story-idx="${_storyActiveIdx}"]`);
        if (activeCard) activeCard.scrollIntoView({ block: "nearest", behavior: "smooth" });

        _updateStoryProgress();
      }

      function _updateStoryProgress() {
        const el = document.getElementById("storyProgress");
        if (el) el.textContent = _storyMilestones.length ? `${_storyActiveIdx + 1}/${_storyMilestones.length}` : "0/0";
      }

      function storyGoToIdx(storyIdx) {
        const m = _storyMilestones[storyIdx];
        if (!m) return;
        selectCommitIdx(m.commitIdx);
        if (m.defaultTab) setDocTab(m.defaultTab);
        if (m.focusHeading) {
          requestAnimationFrame(() => {
            const docEl = document.getElementById("docRendered");
            const target = docEl?.querySelector("#" + CSS.escape(m.focusHeading));
            if (target) target.scrollIntoView({ behavior: "smooth", block: "start" });
          });
        }
        _storyActiveIdx = storyIdx;
        renderStoryCards();
      }

      function storyPrev() {
        if (_storyActiveIdx > 0) storyGoToIdx(_storyActiveIdx - 1);
      }

      function storyNext() {
        if (_storyActiveIdx < _storyMilestones.length - 1) storyGoToIdx(_storyActiveIdx + 1);
      }

      // -------------------------------------------------------
      // Playback: Core Scheduler + State Machine (bd-24q.7.1)
      // -------------------------------------------------------
      // States: "paused" | "playing" | "seeking"
      // Transitions:
      //   paused  -> playing  (play)
      //   playing -> paused   (pause / reach end without loop / visibility hidden)
      //   playing -> seeking  (manual scrub during playback)
      //   seeking -> playing  (scrub ends, resume)
      //   seeking -> paused   (scrub ends, was paused before)
      //   any     -> paused   (stop)

      const PLAYBACK = {
        state: "paused",         // "paused" | "playing" | "seeking"
        speed: 1,                // commits per second (0.25, 0.5, 1, 2, 4)
        loop: false,             // loop back to start at end
        _preSeekState: "paused", // state to restore after seeking
        _rafId: 0,               // requestAnimationFrame id
        _lastTickTime: 0,        // performance.now() of last tick
        _accumMs: 0,             // accumulated sub-tick milliseconds (drift correction)
        _visCleanup: null,       // cleanup for visibilitychange listener
      };

      const PLAYBACK_SPEEDS = [0.25, 0.5, 1, 2, 4];

      /** Pure: compute how many commits to advance given elapsed ms and speed. */
      function playbackTicksForElapsed(elapsedMs, speed, accumMs) {
        const totalMs = accumMs + elapsedMs;
        const intervalMs = 1000 / speed;
        const ticks = Math.floor(totalMs / intervalMs);
        const remainder = totalMs - ticks * intervalMs;
        return { ticks, remainder };
      }

      /** Pure: compute next commit index given current, ticks, max, and loop flag. */
      function playbackNextIndex(currentIdx, ticks, maxIdx, loop) {
        if (ticks <= 0) return { idx: currentIdx, stopped: false };
        let next = currentIdx + ticks;
        if (next > maxIdx) {
          if (loop) {
            next = next % (maxIdx + 1);
          } else {
            return { idx: maxIdx, stopped: true };
          }
        }
        return { idx: next, stopped: false };
      }

      /** Pure: validate and return a transition, or null if invalid. */
      function playbackTransition(currentState, action) {
        const transitions = {
          paused:  { play: "playing", seek: "seeking" },
          playing: { pause: "paused", seek: "seeking", stop: "paused", end: "paused" },
          seeking: { resume: null, stop: "paused" }, // resume target computed at runtime
        };
        const t = transitions[currentState];
        if (!t || !(action in t)) return null;
        if (currentState === "seeking" && action === "resume") {
          return PLAYBACK._preSeekState === "playing" ? "playing" : "paused";
        }
        return t[action];
      }

      function playbackPlay() {
        // Respect prefers-reduced-motion (a11y).
        if (window.matchMedia?.("(prefers-reduced-motion: reduce)")?.matches) return;
        const next = playbackTransition(PLAYBACK.state, "play");
        if (!next) return;
        PLAYBACK.state = next;
        PLAYBACK._lastTickTime = performance.now();
        PLAYBACK._accumMs = 0;
        _playbackInstallVisibility();
        _playbackSchedule();
      }

      function playbackPause() {
        const next = playbackTransition(PLAYBACK.state, "pause")
          || playbackTransition(PLAYBACK.state, "stop");
        if (!next) return;
        PLAYBACK.state = next;
        _playbackCancel();
      }

      function playbackStop() {
        PLAYBACK.state = "paused";
        PLAYBACK._accumMs = 0;
        _playbackCancel();
        _playbackRemoveVisibility();
        _syncPlaybackUI();
      }

      function playbackToggle() {
        if (PLAYBACK.state === "playing") playbackPause();
        else playbackPlay();
        _syncPlaybackUI();
      }

      function playbackSetSpeed(speed) {
        PLAYBACK.speed = Math.max(0.1, Number(speed) || 1);
        PLAYBACK._accumMs = 0;
        PLAYBACK._lastTickTime = performance.now();
      }

      function playbackSetLoop(loop) {
        PLAYBACK.loop = Boolean(loop);
      }

      /** Call when user manually scrubs the slider during playback. */
      function playbackOnManualScrub() {
        if (PLAYBACK.state === "paused") return; // no-op
        PLAYBACK._preSeekState = PLAYBACK.state;
        PLAYBACK.state = "seeking";
        _playbackCancel();
      }

      /** Call when manual scrub ends to optionally resume playback. */
      function playbackOnScrubEnd() {
        if (PLAYBACK.state !== "seeking") return;
        const next = playbackTransition("seeking", "resume");
        PLAYBACK.state = next || "paused";
        if (PLAYBACK.state === "playing") {
          PLAYBACK._lastTickTime = performance.now();
          PLAYBACK._accumMs = 0;
          _playbackSchedule();
        }
      }

      function _playbackSchedule() {
        if (PLAYBACK.state !== "playing") return;
        PLAYBACK._rafId = requestAnimationFrame(_playbackFrame);
      }

      function _playbackFrame(now) {
        if (PLAYBACK.state !== "playing") return;
        const elapsed = now - PLAYBACK._lastTickTime;
        PLAYBACK._lastTickTime = now;

        const { ticks, remainder } = playbackTicksForElapsed(elapsed, PLAYBACK.speed, PLAYBACK._accumMs);
        PLAYBACK._accumMs = remainder;

        if (ticks > 0) {
          const maxIdx = Math.max(0, (ALL_COMMITS.length || 1) - 1);
          const { idx, stopped } = playbackNextIndex(DOC.idx, ticks, maxIdx, PLAYBACK.loop);
          selectCommitIdx(idx);
          if (stopped) {
            playbackStop();
            return;
          }
        }
        _playbackSchedule();
      }

      function _playbackCancel() {
        if (PLAYBACK._rafId) {
          cancelAnimationFrame(PLAYBACK._rafId);
          PLAYBACK._rafId = 0;
        }
      }

      /** Update playback UI elements to match PLAYBACK state. */
      function _syncPlaybackUI() {
        const btn = document.getElementById("dockPlayPause");
        if (btn) {
          btn.innerHTML = PLAYBACK.state === "playing" ? "&#9646;&#9646;" : "&#9654;";
          btn.classList.toggle("bg-slate-900", PLAYBACK.state === "playing");
          btn.classList.toggle("text-white", PLAYBACK.state === "playing");
          btn.classList.toggle("bg-white/70", PLAYBACK.state !== "playing");
          btn.classList.toggle("text-slate-900", PLAYBACK.state !== "playing");
          btn.setAttribute("aria-label", PLAYBACK.state === "playing" ? "Pause playback" : "Play timeline");
        }
        const speedSel = document.getElementById("dockSpeed");
        if (speedSel) speedSel.value = String(PLAYBACK.speed);
        const loopBtn = document.getElementById("dockLoop");
        if (loopBtn) {
          loopBtn.classList.toggle("bg-slate-900", PLAYBACK.loop);
          loopBtn.classList.toggle("text-white", PLAYBACK.loop);
          loopBtn.classList.toggle("text-slate-500", !PLAYBACK.loop);
        }
      }

      function _playbackInstallVisibility() {
        if (PLAYBACK._visCleanup) return;
        const handler = () => {
          if (document.hidden && PLAYBACK.state === "playing") {
            PLAYBACK._preSeekState = "playing";
            PLAYBACK.state = "paused";
            _playbackCancel();
          } else if (!document.hidden && PLAYBACK._preSeekState === "playing" && PLAYBACK.state === "paused") {
            playbackPlay();
          }
        };
        document.addEventListener("visibilitychange", handler);
        PLAYBACK._visCleanup = () => document.removeEventListener("visibilitychange", handler);
      }

      function _playbackRemoveVisibility() {
        if (PLAYBACK._visCleanup) {
          PLAYBACK._visCleanup();
          PLAYBACK._visCleanup = null;
        }
      }

      function initDockIfNeeded() {
        if (DOCK_READY) return;
        const slider = document.getElementById("dockSlider");
        if (!slider || !ALL_COMMITS.length) return;
        slider.min = "0";
        slider.max = String(ALL_COMMITS.length - 1);
        slider.step = "1";
        document.getElementById("dockLeftLabel").textContent = ALL_COMMITS[0]?.short || "-";
        document.getElementById("dockRightLabel").textContent = ALL_COMMITS[ALL_COMMITS.length - 1]?.short || "-";
        DOCK_READY = true;
      }

      function drawDock() {
        const canvas = document.getElementById("dockCanvas");
        if (!canvas || !ALL_COMMITS.length) return;
        const dpr = window.devicePixelRatio || 1;
        const w = Math.max(1, Math.floor(canvas.clientWidth * dpr));
        const h = Math.max(1, Math.floor(canvas.clientHeight * dpr));
        if (canvas.width !== w || canvas.height !== h) {
          canvas.width = w;
          canvas.height = h;
        }
        const ctx = canvas.getContext("2d");
        if (!ctx) return;
        ctx.clearRect(0, 0, w, h);

        const maxImpact = Math.max(1, ...ALL_COMMITS.map((c) => Number(c.impact || 0)));
        const barW = w / ALL_COMMITS.length;
        const pad = 2 * dpr;

        for (let i = 0; i < ALL_COMMITS.length; i++) {
          const c = ALL_COMMITS[i];
          const v = Number(c.impact || 0);
          const t = Math.sqrt(v / maxImpact);
          const bh = Math.max(1, (h - pad * 2) * t);
          const x = i * barW;
          const y = h - pad - bh;
          ctx.globalAlpha = 0.9;
          ctx.fillStyle = bucketById(c.primary).color;
          ctx.fillRect(x, y, Math.max(1, barW), bh);
        }

        // Selected marker.
        const sx = DOC.idx * barW;
        ctx.globalAlpha = 1;
        ctx.lineWidth = Math.max(1, dpr);
        ctx.strokeStyle = "rgba(2,6,23,0.85)";
        ctx.strokeRect(sx + 0.5, 0.5, Math.max(1, barW - 1), h - 1);

        // Inset glow
        ctx.globalAlpha = 1;
        ctx.strokeStyle = "rgba(37,99,235,0.35)";
        ctx.strokeRect(sx + 0.5, 1.5, Math.max(1, barW - 1), h - 3);
      }

      async function updateDocUI() {
        const loading = document.getElementById("docLoading");
        const main = document.getElementById("docMain");
        if (!loading || !main) return;

        if (!DATASET.loaded) {
          loading.classList.remove("hidden");
          main.classList.add("hidden");
          loading.textContent = DATASET.error
            ? `Spec evolution dataset unavailable: ${DATASET.error}`
            : "Loading spec evolution dataset... (local gzip JSON; no GitHub API)";
          return;
        }

        loading.classList.add("hidden");
        main.classList.remove("hidden");
        updateDocPanelVisibility();

        const c = ALL_COMMITS[DOC.idx];
        if (!c) return;

        document.getElementById("dockTitle").textContent = `${c.short} · ${c.subject}`;

        const title = document.getElementById("docCommitTitle");
        const meta = document.getElementById("docCommitMeta");
        const link = document.getElementById("docCommitLink");
        if (title) title.textContent = c.subject;
        if (meta) meta.textContent = `${c.short} · ${dayjs(c.dateIso).format("YYYY-MM-DD HH:mm:ss")} · +${fmtInt(c.add)} -${fmtInt(c.del)}`;
        if (link) link.href = c.url;

        // Summary box.
        const sum = document.getElementById("docSummary");
        const tok = METRICS.tokensChanged.get(c.hash);
        const byt = METRICS.bytesChanged.get(c.hash);
        const hn = METRICS.hunks.get(c.hash);
        const lv = METRICS.lev.get(c.hash);
        if (sum) {
          sum.innerHTML = `
            <div class="flex flex-wrap gap-2">
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Impact ${fmtInt(c.impact)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Hunks ${fmtInt(hn ?? 0)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Tokens ${fmtInt(tok ?? 0)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Bytes ${fmtInt(byt ?? 0)}</span>
              <span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">Lev ${(lv === null || lv === undefined) ? "?" : fmtInt(lv)}</span>
            </div>
            <div class="mt-2 text-xs text-slate-600">Bucket: <span class="font-semibold">${escapeHtml(bucketById(c.primary).name)}</span></div>
          `;
        }

        // Metrics cards
        document.getElementById("mTokens").textContent = (tok === null || tok === undefined) ? "-" : fmtInt(tok);
        document.getElementById("mBytes").textContent = (byt === null || byt === undefined) ? "-" : fmtInt(byt);
        document.getElementById("mHunks").textContent = (hn === null || hn === undefined) ? "-" : fmtInt(hn);
        document.getElementById("mLev").textContent = (lv === null || lv === undefined) ? "-" : fmtInt(lv);

        const patch = patchForIdx(DOC.idx);

        if (DOC.tab === "diff") {
          const raw = document.getElementById("diffRaw");
          const pretty = document.getElementById("diffPretty");
          // A/B compare mode: generate diff between two arbitrary commits.
          let diffText = patch || "";
          let abDiffError = false;
          if (DOC.compareMode && DOC.abViewMode !== "rendered") {
            try {
              diffText = await generateABDiff(DOC.compareFromIdx, DOC.compareToIdx);
            } catch (e) {
              abDiffError = true;
              diffText = "";
              if (pretty) pretty.innerHTML = `<div class="p-3 text-xs text-red-600">A/B diff failed: ${escapeHtml(String(e?.message || e))}</div>`;
            }
          }
          if (raw) raw.textContent = diffText;

          if (pretty && !abDiffError) {
            if (DOC.diffMode === "pretty") {
              try {
                const outputFmt = DOC.compareMode ? DOC.diffLayout : "side-by-side";
                pretty.innerHTML = Diff2Html.html(diffText, {
                  drawFileList: false,
                  matching: "lines",
                  outputFormat: outputFmt,
                });
              } catch (e) {
                pretty.innerHTML = `<div class="p-3 text-xs text-slate-700">Diff2Html failed: ${escapeHtml(String(e?.message || e))}</div>`;
              }
            } else {
              pretty.innerHTML = "";
            }
          }

          // Side-by-side rendered markdown panes (bd-24q.15.1).
          const sbsContainer = document.getElementById("sbsContainer");
          const inRenderedMode = DOC.compareMode && DOC.abViewMode === "rendered";
          if (sbsContainer) {
            sbsContainer.classList.toggle("hidden", !inRenderedMode);
            if (inRenderedMode) void renderSbsPanes();
          }
          document.getElementById("diffPretty")?.classList.toggle("hidden", inRenderedMode || DOC.diffMode !== "pretty");
          document.getElementById("diffRaw")?.classList.toggle("hidden", inRenderedMode || DOC.diffMode !== "raw");

          // Update diff label for compare mode.
          const diffLabel = document.getElementById("diffLabel");
          if (diffLabel) {
            if (DOC.compareMode) {
              const cA = ALL_COMMITS[DOC.compareFromIdx];
              const cB = ALL_COMMITS[DOC.compareToIdx];
              diffLabel.textContent = `Diff (${cA?.short || "#" + DOC.compareFromIdx} → ${cB?.short || "#" + DOC.compareToIdx})`;
            } else {
              diffLabel.textContent = "Diff (parent → selected)";
            }
          }

          // A/B Compare metrics: show chips when in compare mode.
          const abMetricsBar = document.getElementById("abMetricsBar");
          if (abMetricsBar) {
            if (DOC.compareMode) {
              void computeAndShowABMetrics(DOC.compareFromIdx, DOC.compareToIdx);
            } else {
              abMetricsBar.classList.add("hidden");
            }
          }
        }

        if (DOC.tab === "spec") {
          const raw = document.getElementById("docRaw");
          const rendered = document.getElementById("docRendered");
          const specView = document.getElementById("docSpecView");
          if (specView) specView.classList.remove("hidden");

          const text = await docTextAt(DOC.idx);
          if (raw) raw.textContent = text;

          if (rendered) {
            // Extract outline and render markdown with anchor IDs injected.
            const outline = extractOutline(text);
            OUTLINE_CACHE.set(DOC.idx, outline);

            if (!window._mdSingleton) {
              window._mdSingleton = markdownit({
                html: false,
                linkify: true,
                typographer: true,
                highlight: (str, lang) => {
                  try {
                    if (lang && hljs.getLanguage(lang)) {
                      return `<pre class="hljs"><code>${hljs.highlight(str, { language: lang }).value}</code></pre>`;
                    }
                    return `<pre class="hljs"><code>${hljs.highlightAuto(str).value}</code></pre>`;
                  } catch {
                    return `<pre class="hljs"><code>${escapeHtml(str)}</code></pre>`;
                  }
                },
              });
            }

            // Install heading_open renderer to inject stable anchor IDs.
            let outlineIdx = 0;
            const origHeadingOpen = window._mdSingleton.renderer.rules.heading_open;
            window._mdSingleton.renderer.rules.heading_open = (tokens, idx, options, env, self) => {
              const entry = outline[outlineIdx++];
              if (entry) {
                tokens[idx].attrSet("id", entry.id);
              }
              return self.renderToken(tokens, idx, options);
            };

            const html = window._mdSingleton.render(text || "");
            rendered.innerHTML = DOMPurify.sanitize(html, { ADD_ATTR: ["id"] });

            // Restore original renderer rule.
            if (origHeadingOpen) {
              window._mdSingleton.renderer.rules.heading_open = origHeadingOpen;
            } else {
              delete window._mdSingleton.renderer.rules.heading_open;
            }
          }

          document.getElementById("docRendered").classList.toggle("hidden", DOC.rawSpec);
          document.getElementById("docRaw").classList.toggle("hidden", !DOC.rawSpec);

          // Refresh mini-map outline (non-blocking).
          void updateMiniMap();
        }

        // Refresh section summary panel (non-blocking).
        if (DOC.tab === "sections") {
          void updateSectionSummary();
        }

        // On-demand Levenshtein for selected commit.
        if (DATASET.loaded && DOC.idx > 0 && !METRICS.lev.has(c.hash)) {
          // Compute async, don't block UI.
          void (async () => {
            try {
              const d = await levenshteinForPatch(patch);
              METRICS.lev.set(c.hash, d);
              // Update only if still selected.
              if (ALL_COMMITS[DOC.idx]?.hash === c.hash) {
                document.getElementById("mLev").textContent = fmtInt(d);
                syncDockAndDoc();
              }
            } catch (e) {
              if (e?.name !== "AbortError") {
                console.error("On-demand Levenshtein failed:", e);
                if (ALL_COMMITS[DOC.idx]?.hash === c.hash) {
                  const levNode = document.getElementById("mLev");
                  if (levNode) {
                    levNode.textContent = "ERR";
                    levNode.title = formatErr(e);
                  }
                }
              }
            }
          })();
        }
      }

      let COMPUTE_RUNNING = false;

      function applyMetricsPayload(payload) {
        if (!payload) return;
        const tokens = payload.tokensChanged || {};
        const bytes = payload.bytesChanged || {};
        const hunks = payload.hunks || {};
        const lev = payload.lev || {};
        for (const [hash, value] of Object.entries(tokens)) {
          METRICS.tokensChanged.set(hash, Number(value || 0));
        }
        for (const [hash, value] of Object.entries(bytes)) {
          METRICS.bytesChanged.set(hash, Number(value || 0));
        }
        for (const [hash, value] of Object.entries(hunks)) {
          METRICS.hunks.set(hash, Number(value || 0));
        }
        for (const [hash, value] of Object.entries(lev)) {
          METRICS.lev.set(hash, Number(value || 0));
        }
      }

      async function computeAllMetricsLocal(progressCb, signal) {
        const total = ALL_COMMITS.length;
        for (let i = 0; i < total; i++) {
          if (signal?.aborted) throw new DOMException("Aborted", "AbortError");
          const c = ALL_COMMITS[i];
          const patch = patchForIdx(i);
          if (!METRICS.tokensChanged.has(c.hash) || !METRICS.bytesChanged.has(c.hash) || !METRICS.hunks.has(c.hash)) {
            const qm = quickMetricsFromPatch(patch);
            METRICS.tokensChanged.set(c.hash, qm.tokensChanged);
            METRICS.bytesChanged.set(c.hash, qm.bytesChanged);
            METRICS.hunks.set(c.hash, qm.hunks);
          }
          if (i > 0 && !METRICS.lev.has(c.hash)) {
            const d = await levenshteinForPatchLocal(patch);
            METRICS.lev.set(c.hash, d);
          }
          progressCb?.({
            stage: "metrics",
            done: i + 1,
            total,
            haveLev: METRICS.lev.size,
            message: "Computing per-commit metrics",
          });
          if (i % 4 === 0) {
            await new Promise((r) => setTimeout(r, 0));
            if (i % 12 === 0) render();
          }
        }
      }

      async function computeAllMetrics() {
        if (COMPUTE_RUNNING) return;
        if (!DATASET.loaded) return;
        if (!ALL_COMMITS.length) return;

        COMPUTE_RUNNING = true;
        COMPUTE_ABORT_CONTROLLER?.abort();
        COMPUTE_ABORT_CONTROLLER = new AbortController();
        const prog = document.getElementById("computeProgress");
        const cancelBtn = document.getElementById("btnCancelCompute");
        if (prog) {
          prog.classList.remove("hidden");
          prog.className = "mt-2 text-xs font-semibold text-slate-700";
          prog.textContent = WORKER_STATE.ready
            ? "Worker compute in progress..."
            : "Computing metrics (main-thread fallback)...";
          prog.title = "";
        }
        if (cancelBtn) {
          cancelBtn.classList.remove("hidden");
          cancelBtn.disabled = false;
        }

        try {
          const updateProgressText = (p) => {
            if (prog) {
              const done = Number(p?.done || 0);
              const total = Number(p?.total || ALL_COMMITS.length);
              const haveLev = Number(p?.haveLev || METRICS.lev.size);
              prog.textContent = `Computed ${done}/${total} commits · Levenshtein ready ${haveLev}/${Math.max(0, total - 1)}`;
            }
          };

          if (WORKER_STATE.ready) {
            const payload = await workerRequest(
              "compute_all_metrics",
              { includeLev: true },
              {
                signal: COMPUTE_ABORT_CONTROLLER.signal,
                timeoutMs: 180000,
                onProgress: updateProgressText,
              },
            );
            applyMetricsPayload(payload);
          } else {
            await computeAllMetricsLocal(updateProgressText, COMPUTE_ABORT_CONTROLLER.signal);
          }
          if (prog) prog.textContent = "Done. Charts updated.";
        } catch (e) {
          if (e?.name === "AbortError") {
            if (prog) {
              prog.textContent = "Compute cancelled.";
              prog.title = "";
            }
          } else {
            if (prog) {
              prog.className = "mt-2 text-xs font-semibold text-rose-700";
              prog.textContent = `Compute failed: ${e?.message || e}`;
              prog.title = formatErr(e);
            }
            console.error("computeAllMetrics failed:", e);
          }
        } finally {
          COMPUTE_RUNNING = false;
          if (cancelBtn) {
            cancelBtn.disabled = true;
            cancelBtn.classList.add("hidden");
          }
          render();
        }
      }

      // -----------------------------------------------------------
      // Heat Stripe: Dock UI Rendering + Tooltip + Click-to-Jump
      // (bd-24q.13.2)
      // -----------------------------------------------------------

      let _heatStripeRafPending = false;

      function renderHeatStripe() {
        const canvas = document.getElementById("dockHeatStripe");
        if (!canvas || !ALL_COMMITS.length) return;

        const stripe = computeHeatStripe(ALL_COMMITS, {
          resolution: "commit",
          tzMode: "local",
          metric: "lines",
          bucketMode: STATE.bucketMode,
        });
        if (!stripe || !stripe.bins.length) return;

        const dpr = window.devicePixelRatio || 1;
        const w = Math.max(1, Math.floor(canvas.clientWidth * dpr));
        const h = Math.max(1, Math.floor(canvas.clientHeight * dpr));
        if (canvas.width !== w || canvas.height !== h) {
          canvas.width = w;
          canvas.height = h;
        }
        const ctx = canvas.getContext("2d");
        if (!ctx) return;
        ctx.clearRect(0, 0, w, h);

        const binW = w / stripe.bins.length;
        const maxM = Math.max(1, stripe.maxMass);

        for (let i = 0; i < stripe.bins.length; i++) {
          const bin = stripe.bins[i];
          if (bin.empty) continue;
          const intensity = Math.sqrt(bin.totalMass / maxM);
          ctx.globalAlpha = 0.15 + 0.85 * intensity;
          ctx.fillStyle = bin.dominantColor;
          ctx.fillRect(i * binW, 0, Math.max(1, binW), h);
        }
        ctx.globalAlpha = 1;

        // Draw selected marker
        if (DOC.idx >= 0 && DOC.idx < stripe.bins.length) {
          const sx = DOC.idx * binW;
          ctx.strokeStyle = "rgba(2,6,23,0.7)";
          ctx.lineWidth = Math.max(1, dpr);
          ctx.strokeRect(sx + 0.5, 0.5, Math.max(1, binW - 1), h - 1);
        }
      }

      function _heatStripeBinFromEvent(e) {
        const canvas = document.getElementById("dockHeatStripe");
        if (!canvas || !ALL_COMMITS.length) return -1;
        const rect = canvas.getBoundingClientRect();
        const x = e.clientX - rect.left;
        const stripe = computeHeatStripe(ALL_COMMITS, {
          resolution: "commit",
          tzMode: "local",
          metric: "lines",
          bucketMode: STATE.bucketMode,
        });
        if (!stripe || !stripe.bins.length) return -1;
        const binW = rect.width / stripe.bins.length;
        return clamp(Math.floor(x / binW), 0, stripe.bins.length - 1);
      }

      function _showHeatTooltip(e) {
        const idx = _heatStripeBinFromEvent(e);
        const tooltip = document.getElementById("dockHeatTooltip");
        if (!tooltip) return;
        if (idx < 0) { tooltip.classList.add("hidden"); return; }

        const stripe = computeHeatStripe(ALL_COMMITS, {
          resolution: "commit",
          tzMode: "local",
          metric: "lines",
          bucketMode: STATE.bucketMode,
        });
        if (!stripe) { tooltip.classList.add("hidden"); return; }
        const bin = stripe.bins[idx];
        if (!bin) { tooltip.classList.add("hidden"); return; }

        // Build tooltip content
        const lines = [];
        if (bin.empty) {
          lines.push("<em>No activity</em>");
        } else {
          const c = bin.repCommit;
          if (c) lines.push(`<strong>${escapeHtml(c.short)}</strong> ${escapeHtml(c.subject || "").slice(0, 50)}`);
          const b = bucketById(bin.dominant);
          lines.push(`<span style="color:${b.color}">\u25CF</span> ${escapeHtml(b.name)} (dominant)`);
          lines.push(`Mass: ${Math.round(bin.totalMass)} lines`);
          // Top 3 buckets
          const sorted = [...bin.perBucket.entries()].filter(([,v]) => v > 0).sort((a,b) => b[1] - a[1]).slice(0, 3);
          if (sorted.length > 1) {
            const details = sorted.map(([id, v]) => `${bucketById(id).name}: ${Math.round(v)}`).join(", ");
            lines.push(`<span style="color:#64748b">${details}</span>`);
          }
        }
        tooltip.innerHTML = lines.join("<br>");
        tooltip.classList.remove("hidden");

        // Position near cursor
        const rect = tooltip.getBoundingClientRect();
        const canvas = document.getElementById("dockHeatStripe");
        const cRect = canvas.getBoundingClientRect();
        let left = e.clientX - rect.width / 2;
        left = Math.max(4, Math.min(left, window.innerWidth - rect.width - 4));
        tooltip.style.left = left + "px";
        tooltip.style.top = (cRect.top - rect.height - 6) + "px";
      }

      function _hideHeatTooltip() {
        const tooltip = document.getElementById("dockHeatTooltip");
        if (tooltip) tooltip.classList.add("hidden");
      }

      function _heatStripeClick(e) {
        const idx = _heatStripeBinFromEvent(e);
        if (idx < 0) return;
        const stripe = computeHeatStripe(ALL_COMMITS, {
          resolution: "commit",
          tzMode: "local",
          metric: "lines",
          bucketMode: STATE.bucketMode,
        });
        if (!stripe) return;
        const bin = stripe.bins[idx];
        if (!bin || bin.repCommitIdx < 0) return;
        selectCommitIdx(bin.repCommitIdx);
      }

      function _wireHeatStripe() {
        const canvas = document.getElementById("dockHeatStripe");
        if (!canvas) return;

        canvas.addEventListener("mousemove", _showHeatTooltip);
        canvas.addEventListener("mouseleave", _hideHeatTooltip);
        canvas.addEventListener("click", _heatStripeClick);

        // Mobile: tap-hold for tooltip, single tap for jump
        let _touchTimer = 0;
        let _touchMoved = false;
        canvas.addEventListener("touchstart", (e) => {
          _touchMoved = false;
          _touchTimer = setTimeout(() => {
            if (!_touchMoved && e.touches.length === 1) {
              const touch = e.touches[0];
              _showHeatTooltip({ clientX: touch.clientX, clientY: touch.clientY });
            }
          }, 400);
        }, { passive: true });
        canvas.addEventListener("touchmove", () => { _touchMoved = true; }, { passive: true });
        canvas.addEventListener("touchend", (e) => {
          clearTimeout(_touchTimer);
          if (!_touchMoved && e.changedTouches.length === 1) {
            const touch = e.changedTouches[0];
            _heatStripeClick({ clientX: touch.clientX, clientY: touch.clientY });
          }
          setTimeout(_hideHeatTooltip, 1500);
        });
      }

      function syncDockAndDoc() {
        if (!ALL_COMMITS.length) return;
        DOC.idx = clamp(DOC.idx, 0, ALL_COMMITS.length - 1);
        initDockIfNeeded();
        drawDock();
        renderHeatStripe();
        void updateDocUI();
      }

      // --- Phase 4: Bucket toggle DOM caching ---
      let BUCKET_TOGGLES_BUILT = false;
      const BUCKET_TOGGLE_INDICATORS = new Map(); // bucketId -> [desktopSpan, mobileSpan]

      function renderBucketToggles() {
        const wrap = document.getElementById("bucketToggles");
        const wrapM = document.getElementById("bucketTogglesMobile");

        if (!BUCKET_TOGGLES_BUILT) {
          wrap.innerHTML = "";
          wrapM.innerHTML = "";
          for (const b of BUCKETS) {
            const item = bucketToggleItem(b);
            const itemM = bucketToggleItem(b, true);
            wrap.appendChild(item);
            wrapM.appendChild(itemM);
            const ind = item.querySelector("[data-toggle-ind]");
            const indM = itemM.querySelector("[data-toggle-ind]");
            BUCKET_TOGGLE_INDICATORS.set(b.id, [ind, indM]);
          }
          BUCKET_TOGGLES_BUILT = true;
        }

        // Update only the toggle indicator styles
        for (const b of BUCKETS) {
          const on = STATE.bucketEnabled.has(b.id);
          const indicators = BUCKET_TOGGLE_INDICATORS.get(b.id);
          if (!indicators) continue;
          for (const ind of indicators) {
            if (!ind) continue;
            ind.style.background = on ? b.color : "#cbd5e1";
            ind.style.transform = on ? "translateX(16px)" : "translateX(0)";
          }
        }
      }

      function bucketToggleItem(bucket, isMobile = false) {
        const id = (isMobile ? "m-" : "") + `b-${bucket.id}`;

        const btn = document.createElement("button");
        btn.type = "button";
        btn.id = id;
        btn.className =
          "focus-ring flex items-start gap-3 rounded-2xl border border-slate-900/10 bg-white/70 px-3 py-2 text-left hover:bg-white";
        btn.innerHTML = `
          <span class="mt-1 inline-block h-2.5 w-2.5 rounded-full" style="background:${bucket.color}"></span>
          <span class="min-w-0">
            <span class="block text-xs font-semibold text-slate-900">${escapeHtml(bucket.name)}</span>
            <span class="mt-0.5 block text-[11px] leading-snug text-slate-500">${escapeHtml(bucket.desc)}</span>
          </span>
          <span class="ml-auto mt-0.5 inline-flex h-6 w-10 items-center rounded-full border border-slate-900/10 bg-white/60 p-0.5">
            <span data-toggle-ind class="h-5 w-5 rounded-full transition"></span>
          </span>
        `;
        btn.addEventListener("click", () => {
          if (STATE.bucketEnabled.has(bucket.id)) {
            STATE.bucketEnabled.delete(bucket.id);
          } else {
            STATE.bucketEnabled.add(bucket.id);
          }
          render();
          syncUrlToState();
        });
        return btn;
      }

      // -----------------------------------------------------------
      // Wall-Clock Series Builder (bd-24q.12.1)
      // Builds a dense bin array with explicit empty bins so quiet
      // periods are visible. Supports UTC and local timezone modes.
      // -----------------------------------------------------------

      function wallClockBinKey(t, resolution) {
        const fmt2 = (n) => String(n).padStart(2, "0");
        if (resolution === "day") return t.format("YYYY-MM-DD");
        if (resolution === "hour") return t.format("YYYY-MM-DD HH:00");
        if (resolution === "15m") {
          const m = Math.floor(t.minute() / 15) * 15;
          return `${t.format("YYYY-MM-DD HH")}:${fmt2(m)}`;
        }
        if (resolution === "5m") {
          const m = Math.floor(t.minute() / 5) * 5;
          return `${t.format("YYYY-MM-DD HH")}:${fmt2(m)}`;
        }
        return t.format("YYYY-MM-DD HH:mm");
      }

      function wallClockBinMinutes(resolution) {
        if (resolution === "day") return 1440;
        if (resolution === "hour") return 60;
        if (resolution === "15m") return 15;
        if (resolution === "5m") return 5;
        return 1;
      }

      function wallClockFloor(t, resolution) {
        if (resolution === "day") return t.startOf("day");
        if (resolution === "hour") return t.startOf("hour");
        if (resolution === "15m") {
          const m = Math.floor(t.minute() / 15) * 15;
          return t.startOf("hour").add(m, "minute");
        }
        if (resolution === "5m") {
          const m = Math.floor(t.minute() / 5) * 5;
          return t.startOf("hour").add(m, "minute");
        }
        return t.startOf("minute");
      }

      function buildWallClockBins(commits, resolution, tzMode) {
        if (!commits.length || resolution === "commit") return null;

        const toT = (c) => (tzMode === "utc" && dayjs.utc) ? dayjs.utc(c.dateIso) : dayjs(c.dateIso);
        // Use calendar-aware units for day/hour to handle DST correctly in local tz.
        const stepUnit = resolution === "day" ? "day" : resolution === "hour" ? "hour" : "minute";
        const stepAmount = (stepUnit === "minute") ? wallClockBinMinutes(resolution) : 1;

        let minT = toT(commits[0]);
        let maxT = toT(commits[0]);
        for (const c of commits) {
          const t = toT(c);
          if (t.isBefore(minT)) minT = t;
          if (t.isAfter(maxT)) maxT = t;
        }

        const startBin = wallClockFloor(minT, resolution);
        const endBin = wallClockFloor(maxT, resolution);

        const labels = [];
        const binsMap = new Map();
        let cursor = startBin;
        const maxBins = 10000;
        let count = 0;
        while (!cursor.isAfter(endBin) && count < maxBins) {
          const key = wallClockBinKey(cursor, resolution);
          labels.push(key);
          binsMap.set(key, { key, label: key, start: cursor, commits: [] });
          cursor = cursor.add(stepAmount, stepUnit);
          count++;
        }

        for (const c of commits) {
          const t = toT(c);
          const key = wallClockBinKey(wallClockFloor(t, resolution), resolution);
          const bin = binsMap.get(key);
          if (bin) bin.commits.push(c);
        }

        return { labels, bins: labels.map((k) => binsMap.get(k)) };
      }

      function aggregateBinMetric(binCommits, metricFn, mode) {
        if (!binCommits.length) return 0;
        const vals = binCommits.map(metricFn);
        const sum = vals.reduce((a, b) => a + b, 0);
        if (mode === "sum") return sum;
        if (mode === "mean") return sum / vals.length;
        if (mode === "median") {
          const sorted = vals.slice().sort((a, b) => a - b);
          const mid = Math.floor(sorted.length / 2);
          return sorted.length % 2 ? sorted[mid] : (sorted[mid - 1] + sorted[mid]) / 2;
        }
        return sum;
      }


      // -----------------------------------------------------------
      // Heat Stripe: Compute Density + Dominant Bucket per Bin
      // (bd-24q.13.1)
      //
      // For each bin, computes:
      //   - totalMass: aggregate change mass (lines/tokens/lev/groups)
      //   - perBucket: Map<bucketId, mass> contributions
      //   - dominant: bucket id with highest contribution
      //     (tie-break: highest mass, then lowest bucket id)
      //   - repCommit: the commit with largest individual delta in bin
      //   - repCommitIdx: its index in ALL_COMMITS
      //
      // Cached by dataset hash + bucketMode + resolution + tzMode + metric.
      // -----------------------------------------------------------

      const _heatStripeCache = new Map();

      function computeHeatStripe(commits, { resolution = "commit", tzMode = "local", metric = "lines", bucketMode = "primary" } = {}) {
        // Cache key
        const cacheKey = `${WORKER_STATE.datasetHash}|${bucketMode}|${resolution}|${tzMode}|${metric}`;
        const cached = _heatStripeCache.get(cacheKey);
        if (cached) return cached;

        // Build bins (reuse wall-clock builder or commit-mode)
        let binLabels = [];
        let binCommitArrays = [];

        if (resolution === "commit") {
          const binIdx = new Map();
          for (const c of commits) {
            const k = c.short;
            let j = binIdx.get(k);
            if (j === undefined) {
              j = binLabels.length;
              binIdx.set(k, j);
              binLabels.push(k);
              binCommitArrays.push([]);
            }
            binCommitArrays[j].push(c);
          }
        } else {
          const wc = buildWallClockBins(commits, resolution, tzMode);
          if (wc) {
            binLabels = wc.labels;
            binCommitArrays = wc.bins.map((b) => b.commits);
          }
        }

        // Metric extractor for a single commit
        const metricVal = (c) => {
          if (metric === "groups") return 1;
          if (metric === "lines") return Number(c.impact || 0);
          if (metric === "tokens") return Number(METRICS.tokensChanged.get(c.hash) || 0);
          if (metric === "lev") return Number(METRICS.lev.get(c.hash) || 0);
          return 0;
        };

        // ALL_COMMITS hash->idx lookup for repCommitIdx
        const hashToIdx = new Map();
        for (let i = 0; i < ALL_COMMITS.length; i++) {
          hashToIdx.set(ALL_COMMITS[i].hash, i);
        }

        const bins = [];

        for (let bi = 0; bi < binLabels.length; bi++) {
          const bc = binCommitArrays[bi];
          const perBucket = new Map();
          for (const b of BUCKETS) perBucket.set(b.id, 0);

          let totalMass = 0;

          for (const c of bc) {
            if (metric === "groups") {
              // Count group contributions per bucket
              if (bucketMode === "primary") {
                for (const g of c.changeGroups) {
                  perBucket.set(g.primary, (perBucket.get(g.primary) || 0) + 1);
                  totalMass += 1;
                }
              } else {
                for (const g of c.changeGroups) {
                  for (const lb of g.labels) {
                    perBucket.set(lb, (perBucket.get(lb) || 0) + 1);
                    totalMass += 1;
                  }
                }
              }
            } else {
              const v = metricVal(c);
              const groups = c.changeGroups.length || 1;
              const perGroup = v / groups;

              if (bucketMode === "primary") {
                for (const g of c.changeGroups) {
                  perBucket.set(g.primary, (perBucket.get(g.primary) || 0) + perGroup);
                }
              } else {
                for (const g of c.changeGroups) {
                  const labels = g.labels?.length ? g.labels : [10];
                  const perLabel = perGroup / labels.length;
                  for (const lb of labels) {
                    perBucket.set(lb, (perBucket.get(lb) || 0) + perLabel);
                  }
                }
              }
              totalMass += v;
            }
          }

          // Dominant bucket: highest contribution, tie-break lowest id
          let dominant = BUCKETS[BUCKETS.length - 1].id; // default: Other
          let maxContrib = 0;
          for (const b of BUCKETS) {
            const contrib = perBucket.get(b.id) || 0;
            if (contrib > maxContrib || (contrib === maxContrib && b.id < dominant)) {
              maxContrib = contrib;
              dominant = b.id;
            }
          }

          // Representative commit: highest individual metric value in bin
          let repCommit = null;
          let repCommitIdx = -1;
          let repVal = -1;
          for (const c of bc) {
            const v = metricVal(c);
            if (v > repVal) {
              repVal = v;
              repCommit = c;
              repCommitIdx = hashToIdx.get(c.hash) ?? -1;
            }
          }

          bins.push({
            label: binLabels[bi],
            totalMass,
            perBucket,
            dominant,
            dominantColor: (bucketById(dominant) || {}).color || "#94a3b8",
            repCommit,
            repCommitIdx,
            empty: bc.length === 0,
          });
        }

        // Compute global max for normalization
        let maxMass = 0;
        for (const b of bins) {
          if (b.totalMass > maxMass) maxMass = b.totalMass;
        }

        const result = { bins, maxMass, binCount: bins.length, cacheKey };
        _heatStripeCache.set(cacheKey, result);
        return result;
      }

      function renderCharts(commits) {
        // Timeline scatter
        if (!chartTimeline) chartTimeline = echarts.init(document.getElementById("timelineChart"));
        if (!chartStack) chartStack = echarts.init(document.getElementById("stackChart"));
        if (!chartDonut) chartDonut = echarts.init(document.getElementById("donutChart"));
        if (!chartBocpd) chartBocpd = echarts.init(document.getElementById("bocpdChart"));

        const timelineData = commits.map((c) => {
          return [
            c.dateIso,
            c.impact,
            c.primary,
            c.short,
            c.subject,
            c.hash,
            c.author,
          ];
        });

        chartTimeline.setOption({
          grid: { left: 44, right: 18, top: 18, bottom: 40 },
          tooltip: {
            trigger: "item",
            borderWidth: 1,
            backgroundColor: "rgba(255,255,255,0.95)",
            textStyle: { color: "#0b1220" },
            extraCssText: "box-shadow: 0 16px 40px rgba(2,6,23,0.18); border-radius: 14px;",
            formatter: (p) => {
              const d = p.data;
              const b = bucketById(d[2]);
              return `
                <div style="min-width: 240px">
                  <div style="display:flex;align-items:center;gap:10px;">
                    <span style="width:10px;height:10px;border-radius:99px;background:${b.color};display:inline-block;"></span>
                    <div style="font-weight:700">${escapeHtml(d[3])}</div>
                    <div style="margin-left:auto;font-size:11px;color:rgba(2,6,23,.62)">${dayjs(d[0]).format(
                      "YYYY-MM-DD HH:mm:ss",
                    )}</div>
                  </div>
                  <div style="margin-top:6px;font-size:12px;color:rgba(2,6,23,.8)">${escapeHtml(d[4])}</div>
                  <div style="margin-top:6px;font-size:11px;color:rgba(2,6,23,.62)">Impact ${fmtInt(
                    d[1],
                  )} lines · Bucket ${escapeHtml(b.name)}</div>
                </div>
              `;
            },
          },
          xAxis: {
            type: "time",
            name: "time",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            axisLine: { lineStyle: { color: "rgba(2,6,23,.12)" } },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          yAxis: {
            type: "value",
            name: "lines changed",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            axisLine: { lineStyle: { color: "rgba(2,6,23,.12)" } },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          series: [
            {
              type: "scatter",
              data: timelineData,
              symbolSize: (d) => clamp(6 + Math.sqrt(d[1] || 0) * 0.7, 6, 40),
              itemStyle: {
                color: (p) => bucketById(p.data[2]).color,
                opacity: 0.9,
              },
              emphasis: { scale: true },
            },
          ],
        });

        chartTimeline.off("click");
        chartTimeline.on("click", (p) => {
          const hash = p.data[5];
          const idx = ALL_COMMITS.findIndex((c) => c.hash === hash);
          if (idx >= 0) selectCommitIdx(idx);
          const el = document.getElementById(`commit-${hash}`);
          if (el) {
            el.scrollIntoView({ behavior: "smooth", block: "start" });
            el.open = true;
          }
        });

        // Stacked buckets by time bin (commit/day/hour/15m/5m)
        // Uses dense wall-clock bins for time-based resolutions so
        // empty periods are visible in the chart (bd-24q.12.1).
        const resSel = document.getElementById("stackResolution");
        const metricSel = document.getElementById("stackMetric");
        const tzSel = document.getElementById("stackTimezone");
        const resolution = resSel?.value || "commit";
        const metric = metricSel?.value || "groups";
        const tzMode = tzSel?.value || "local";

        let binLabels = [];
        let binCommits = [];

        if (resolution === "commit") {
          // Commit mode: one bin per commit (no empty bins).
          const binIdx = new Map();
          for (const c of commits) {
            const k = c.short;
            let j = binIdx.get(k);
            if (j === undefined) {
              j = binLabels.length;
              binIdx.set(k, j);
              binLabels.push(k);
              binCommits.push([]);
            }
            binCommits[j].push(c);
          }
        } else {
          // Wall-clock mode: dense bins with empties filled.
          const wc = buildWallClockBins(commits, resolution, tzMode);
          if (wc) {
            binLabels = wc.labels;
            binCommits = wc.bins.map((b) => b.commits);
          }
        }

        const valuesByBucket = new Map(BUCKETS.map((b) => [b.id, new Array(binLabels.length).fill(0)]));

        const metricForCommit = (c) => {
          if (metric === "groups") return 1; // handled per-group
          if (metric === "lines") return Number(c.impact || 0);
          if (metric === "tokens") return Number(METRICS.tokensChanged.get(c.hash) || 0);
          if (metric === "lev") return Number(METRICS.lev.get(c.hash) || 0);
          return 0;
        };

        for (let bi = 0; bi < binCommits.length; bi++) {
          for (const c of binCommits[bi]) {
            if (metric === "groups") {
              if (STATE.bucketMode === "primary") {
                for (const g of c.changeGroups) {
                  const a = valuesByBucket.get(g.primary);
                  if (a) a[bi] += 1;
                }
              } else {
                for (const g of c.changeGroups) {
                  for (const b of g.labels) {
                    const a = valuesByBucket.get(b);
                    if (a) a[bi] += 1;
                  }
                }
              }
              continue;
            }

            const v = metricForCommit(c);
            const groups = c.changeGroups.length || 1;
            const perGroup = v / groups;

            if (STATE.bucketMode === "primary") {
              for (const g of c.changeGroups) {
                const a = valuesByBucket.get(g.primary);
                if (a) a[bi] += perGroup;
              }
            } else {
              for (const g of c.changeGroups) {
                const labels = g.labels?.length ? g.labels : [10];
                const perLabel = perGroup / labels.length;
                for (const b of labels) {
                  const a = valuesByBucket.get(b);
                  if (a) a[bi] += perLabel;
                }
              }
            }
          }
        }

        chartStack.setOption({
          grid: { left: 44, right: 18, top: 18, bottom: 60 },
          tooltip: {
            trigger: "axis",
            formatter: (params) => {
              if (!params?.length) return "";
              const label = params[0].axisValue + (tzMode === "utc" && resolution !== "commit" ? " UTC" : "");
              const total = params.reduce((s, p) => s + (Number(p.value) || 0), 0);
              const lines = params
                .filter((p) => p.value > 0)
                .map((p) => `${p.marker} ${escapeHtml(p.seriesName)}: ${Number(p.value).toFixed(metric === "groups" ? 0 : 1)}`)
                .join("<br>");
              return `<div style="font-weight:700;margin-bottom:4px">${escapeHtml(label)}</div>${lines || "<span style='color:#94a3b8'>No activity</span>"}${total > 0 ? `<div style="margin-top:4px;font-size:11px;color:rgba(2,6,23,.55)">Total: ${total.toFixed(metric === "groups" ? 0 : 1)}</div>` : ""}`;
            },
          },
          xAxis: {
            type: "category",
            data: binLabels,
            axisLabel: {
              color: "rgba(2,6,23,.55)",
              rotate: resolution === "commit" ? 45 : (resolution === "day" ? 0 : 45),
              interval: "auto",
            },
            axisLine: { lineStyle: { color: "rgba(2,6,23,.12)" } },
          },
          yAxis: {
            type: "value",
            axisLabel: { color: "rgba(2,6,23,.55)" },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          legend: {
            type: "scroll",
            bottom: 0,
            textStyle: { color: "rgba(2,6,23,.62)" },
          },
          series: BUCKETS.map((b) => {
            return {
              name: `${b.id}. ${b.name}`,
              type: "bar",
              stack: "b",
              barWidth: "60%",
              emphasis: { focus: "series" },
              itemStyle: { color: b.color, opacity: 0.9 },
              data: valuesByBucket.get(b.id),
            };
          }),
        });

	        // Donut distribution by (primary or multi)
	        const totals = new Map(BUCKETS.map((b) => [b.id, 0]));
	        if (STATE.bucketMode === "primary") {
	          for (const c of commits) {
	            for (const g of c.changeGroups) {
	              totals.set(g.primary, (totals.get(g.primary) || 0) + 1);
	            }
	          }
	        } else {
	          for (const c of commits) {
	            for (const g of c.changeGroups) {
	              for (const b of g.labels) totals.set(b, (totals.get(b) || 0) + 1);
	            }
	          }
	        }
        const donutData = BUCKETS.map((b) => ({ name: `${b.id}. ${b.name}`, value: totals.get(b.id) || 0, itemStyle: { color: b.color } }));

        chartDonut.setOption({
          tooltip: { trigger: "item" },
          series: [
            {
              type: "pie",
              radius: ["45%", "70%"],
              avoidLabelOverlap: true,
              itemStyle: { borderRadius: 10, borderColor: "rgba(255,255,255,0.8)", borderWidth: 2 },
              label: { show: false },
              emphasis: { label: { show: true, fontWeight: 700, formatter: "{b}\\n{c}" } },
              labelLine: { show: false },
              data: donutData,
            },
          ],
        });

        renderBocpd(commits);
        void maybeRefreshPhaseAndOutliers(commits);
      }

      function renderBocpd(commits) {
        const H = Number(document.getElementById("hazard").value);
        document.getElementById("hazardLabel").textContent = H.toFixed(2);

        const xs = commits.map((c) => c.idx);
        const ys = commits.map((c) => Math.log1p(c.impact));

        const cp = WORKER_DERIVED.phase && WORKER_DERIVED.phaseKey === `${H}|${ys.join(",")}`
          ? WORKER_DERIVED.phase
          : bocpdChangePoints(ys, H);
        const markers = cp.changePoints.map((idx) => ({
          xAxis: xs[idx],
          label: { formatter: "CP", color: "rgba(2,6,23,.75)", fontSize: 10 },
          lineStyle: { color: "rgba(2,6,23,.25)", width: 1, type: "dashed" },
        }));

        chartBocpd.setOption({
          grid: { left: 44, right: 18, top: 18, bottom: 40 },
          tooltip: { trigger: "axis" },
          xAxis: {
            type: "value",
            name: "commit index",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          yAxis: {
            type: "value",
            name: "log(1+impact)",
            nameTextStyle: { color: "rgba(2,6,23,.55)" },
            axisLabel: { color: "rgba(2,6,23,.55)" },
            splitLine: { lineStyle: { color: "rgba(2,6,23,.06)" } },
          },
          series: [
            {
              type: "line",
              data: xs.map((x, i) => [x, ys[i]]),
              showSymbol: false,
              lineStyle: { width: 2, color: "rgba(2,6,23,.78)" },
              markLine: {
                symbol: "none",
                data: markers,
              },
            },
            {
              type: "line",
              data: xs.map((x, i) => [x, cp.p0[i]]),
              yAxisIndex: 0,
              showSymbol: false,
              lineStyle: { width: 2, color: "rgba(37,99,235,.55)" },
            },
          ],
        });
      }

      // Minimal BOCPD over a scalar series with a crude Normal-Gamma model.
      // This is an interpretive visualization only.
      function bocpdChangePoints(y, hazard) {
        // Prior
        let mu0 = 0.0;
        let kappa0 = 0.01;
        let alpha0 = 0.5;
        let beta0 = 0.5;

        // Run-length posterior (log-space)
        let logR = [0.0]; // P(r=0)=1 at t=0
        // Sufficient stats per run length: n, mean, M2
        let stats = [{ n: 0, mean: 0.0, m2: 0.0 }];

        const p0 = [];
        const changePoints = [];

        const logHaz = Math.log(hazard);
        const log1mHaz = Math.log(1.0 - hazard);

        for (let t = 0; t < y.length; t++) {
          const x = y[t];

          // Predictive probabilities for each run length
          const logPred = [];
          for (let r = 0; r < stats.length; r++) {
            const st = stats[r];
            // Conjugate predictive approx: Student-t-ish with parameters from Normal-Gamma.
            const n = st.n;
            const mean = st.mean;
            const kappa = kappa0 + n;
            const alpha = alpha0 + n / 2;
            const beta =
              beta0 +
              0.5 * st.m2 +
              (kappa0 * n * (mean - mu0) * (mean - mu0)) / (2 * (kappa0 + n));

            const dof = 2 * alpha;
            const scale2 = (beta * (kappa + 1)) / (alpha * kappa);
            const logp = studentTLogPdf(x, mean, Math.sqrt(scale2), dof);
            logPred.push(logp);
          }

          // Growth + change point
          const newLogR = new Array(stats.length + 1).fill(-Infinity);

          // r_t = 0
          let logSumCp = -Infinity;
          for (let r = 0; r < logR.length; r++) {
            logSumCp = logAddExp(logSumCp, logR[r] + logPred[r] + logHaz);
          }
          newLogR[0] = logSumCp;

          // r_t = r_{t-1}+1
          for (let r = 0; r < logR.length; r++) {
            newLogR[r + 1] = logR[r] + logPred[r] + log1mHaz;
          }

          // Normalize
          const logZ = newLogR.reduce((a, b) => logAddExp(a, b), -Infinity);
          for (let i = 0; i < newLogR.length; i++) newLogR[i] -= logZ;

          // Record P(r_t=0)
          const p_r0 = Math.exp(newLogR[0]);
          p0.push(p_r0);
          if (p_r0 > 0.5) changePoints.push(t);

          // Update stats for next step
          const newStats = new Array(stats.length + 1);
          // For r=0, reset stats
          newStats[0] = { n: 1, mean: x, m2: 0.0 };
          for (let r = 1; r < newStats.length; r++) {
            newStats[r] = updateWelford(stats[r - 1], x);
          }

          // Prune (keep top K run lengths)
          const K = 120;
          const idxs = newLogR.map((v, i) => [v, i]).sort((a, b) => b[0] - a[0]).slice(0, K).map((x) => x[1]).sort((a,b)=>a-b);
          logR = idxs.map((i) => newLogR[i]);
          stats = idxs.map((i) => newStats[i]);

          // Renormalize after pruning
          const logZ2 = logR.reduce((a, b) => logAddExp(a, b), -Infinity);
          logR = logR.map((v) => v - logZ2);
        }

        return { p0, changePoints };
      }

      function updateWelford(st, x) {
        const n1 = st.n + 1;
        const delta = x - st.mean;
        const mean1 = st.mean + delta / n1;
        const delta2 = x - mean1;
        const m21 = st.m2 + delta * delta2;
        return { n: n1, mean: mean1, m2: m21 };
      }

      function logAddExp(a, b) {
        if (a === -Infinity) return b;
        if (b === -Infinity) return a;
        const m = Math.max(a, b);
        return m + Math.log(Math.exp(a - m) + Math.exp(b - m));
      }

      function studentTLogPdf(x, mu, sigma, nu) {
        // log Γ((ν+1)/2) - log(σ*sqrt(νπ)) - log Γ(ν/2) - (ν+1)/2 log(1 + ((x-μ)/σ)^2 / ν)
        const z = (x - mu) / (sigma || 1e-9);
        return (
          logGamma((nu + 1) / 2) -
          logGamma(nu / 2) -
          Math.log((sigma || 1e-9) * Math.sqrt(nu * Math.PI)) -
          ((nu + 1) / 2) * Math.log(1 + (z * z) / nu)
        );
      }

      // Lanczos approximation for log-gamma
      function logGamma(z) {
        const p = [
          0.99999999999980993, 676.5203681218851, -1259.1392167224028, 771.32342877765313,
          -176.61502916214059, 12.507343278686905, -0.13857109526572012, 9.9843695780195716e-6,
          1.5056327351493116e-7,
        ];
        if (z < 0.5) {
          return Math.log(Math.PI) - Math.log(Math.sin(Math.PI * z)) - logGamma(1 - z);
        }
        z -= 1;
        let x = p[0];
        for (let i = 1; i < p.length; i++) x += p[i] / (z + i);
        const t = z + 7.5;
        return 0.5 * Math.log(2 * Math.PI) + (z + 0.5) * Math.log(t) - t + Math.log(x);
      }

      // --- Phase 5: Virtualized commit list + lazy detail loading ---
      // Only render a window of COMMIT_PAGE_SIZE commits at a time.
      // Change group details are injected on first <details> open (lazy).
      const COMMIT_PAGE_SIZE = 20;
      const COMMIT_LIST_NODES = new Map(); // hash -> details element
      let COMMIT_LIST_MODE = null;
      let _clFilteredCommits = []; // current filtered list for progressive load
      let _clRenderedCount = 0;    // how many we've appended so far
      let _clObserver = null;      // IntersectionObserver for sentinel
      const COMMIT_DETAIL_LOADED = new Set(); // hashes with detail content populated

      function buildCommitNode(c) {
        const details = document.createElement("details");
        details.id = `commit-${c.hash}`;
        details.className = "glass-2 rounded-3xl px-4 py-3 shadow-sm";
        details.dataset.hash = c.hash;

        const tags = (STATE.bucketMode === "primary" ? [c.primary] : c.labels).map(bucketById);

        // Render only the summary; detail content is lazy-loaded on first open
        details.innerHTML = `
          <summary class="cursor-pointer list-none">
            <div class="flex flex-col gap-3 sm:flex-row sm:items-start sm:justify-between">
              <div class="min-w-0">
                <div class="flex flex-wrap items-center gap-2">
                  <span class="mono text-xs font-semibold text-slate-600">${escapeHtml(c.short)}</span>
                  <span class="mono text-xs text-slate-500">${dayjs(c.dateIso).format("HH:mm:ss")}</span>
                  <span class="mono text-xs text-slate-500">+${fmtInt(c.add)} -${fmtInt(c.del)}</span>
                </div>
                <div class="mt-1 truncate text-sm font-semibold text-slate-900">${escapeHtml(c.subject)}</div>
                <div class="mt-1 flex flex-wrap gap-1.5">
                  ${tags
                    .map(
                      (t) => `
                        <span class="chip inline-flex items-center gap-2 rounded-full px-2.5 py-1 text-[11px] font-semibold text-slate-700">
                          <span class="inline-block h-2 w-2 rounded-full" style="background:${t.color}"></span>
                          ${escapeHtml(`${t.id}. ${t.name}`)}
                        </span>`,
                    )
                    .join("")}
                </div>
              </div>
              <div class="shrink-0">
                <a class="focus-ring chip inline-flex items-center gap-2 rounded-2xl px-3 py-2 text-xs font-semibold text-slate-700 hover:bg-white"
                   href="${escapeHtml(c.url)}" target="_blank" rel="noreferrer">View commit</a>
              </div>
            </div>
          </summary>
          <div class="commit-detail-placeholder"></div>
        `;

        details.addEventListener("toggle", () => {
          if (details.open) {
            selectCommitIdx(c.idx);
            // Lazy-load change group detail on first open
            if (!COMMIT_DETAIL_LOADED.has(c.hash)) {
              COMMIT_DETAIL_LOADED.add(c.hash);
              const ph = details.querySelector(".commit-detail-placeholder");
              if (ph) {
                ph.className = "mt-3 border-t border-slate-900/10 pt-3";
                ph.innerHTML =
                  (c.hasClassification ? "" : `<div class="text-xs text-red-700">Missing classification entry for this commit.</div>`) +
                  c.changeGroups.map((g, i) => renderGroup(g, i)).join("");
              }
            }
          }
        });

        return details;
      }

      function ensureCommitNodes() {
        if (COMMIT_LIST_MODE === STATE.bucketMode && COMMIT_LIST_NODES.size === ALL_COMMITS.length) return;
        COMMIT_LIST_NODES.clear();
        COMMIT_LIST_MODE = STATE.bucketMode;
        COMMIT_DETAIL_LOADED.clear();
        for (const c of ALL_COMMITS) {
          COMMIT_LIST_NODES.set(c.hash, buildCommitNode(c));
        }
      }

      // Append the next page of commits to the DOM
      function _clAppendPage() {
        const wrap = document.getElementById("commitList");
        const end = Math.min(_clRenderedCount + COMMIT_PAGE_SIZE, _clFilteredCommits.length);
        if (_clRenderedCount >= end) return;
        const frag = document.createDocumentFragment();
        for (let i = _clRenderedCount; i < end; i++) {
          const c = _clFilteredCommits[i];
          const node = COMMIT_LIST_NODES.get(c.hash);
          if (node) frag.appendChild(node);
        }
        const sentinel = document.getElementById("commitListSentinel");
        if (sentinel) wrap.insertBefore(frag, sentinel);
        else wrap.appendChild(frag);
        _clRenderedCount = end;
        if (sentinel && _clRenderedCount >= _clFilteredCommits.length) {
          sentinel.style.display = "none";
        }
      }

      function _clSetupObserver() {
        if (_clObserver) _clObserver.disconnect();
        const sentinel = document.getElementById("commitListSentinel");
        if (!sentinel) return;
        _clObserver = new IntersectionObserver(
          (entries) => {
            if (entries[0].isIntersecting && _clRenderedCount < _clFilteredCommits.length) {
              _clAppendPage();
            }
          },
          { rootMargin: "400px" }
        );
        _clObserver.observe(sentinel);
      }

      function renderCommitList(filteredCommits) {
        ensureCommitNodes();
        const wrap = document.getElementById("commitList");

        _clFilteredCommits = filteredCommits;
        _clRenderedCount = 0;

        // Clear and rebuild with sentinel
        wrap.innerHTML = "";
        wrap.dataset.mode = STATE.bucketMode;

        let sentinel = document.createElement("div");
        sentinel.id = "commitListSentinel";
        sentinel.style.height = "1px";
        wrap.appendChild(sentinel);

        // Render first page
        _clAppendPage();
        // Set up observer for subsequent pages
        _clSetupObserver();
      }

      function renderGroup(g, i) {
        const chips = g.labels.map((id) => bucketById(id));
        const confPct = Math.round(clamp(g.confidence, 0, 1) * 100);
        const headings = (g.changed_headings || []).slice(0, 8);
        const evidence = (g.evidence || []).slice(0, 3);

        return `
          <div class="mt-3 rounded-3xl border border-slate-900/10 bg-white/60 p-4">
            <div class="flex flex-col gap-2 sm:flex-row sm:items-start sm:justify-between">
              <div class="min-w-0">
                <div class="text-xs font-semibold text-slate-500">Change group ${i + 1}</div>
                <div class="mt-1 text-sm font-semibold text-slate-900">${escapeHtml(g.summary || "")}</div>
                <div class="mt-2 flex flex-wrap gap-1.5">
                  ${chips
                    .map(
                      (c) => `
                        <span class="chip inline-flex items-center gap-2 rounded-full px-2.5 py-1 text-[11px] font-semibold text-slate-700">
                          <span class="inline-block h-2 w-2 rounded-full" style="background:${c.color}"></span>
                          ${escapeHtml(`${c.id}. ${c.name}`)}
                        </span>`,
                    )
                    .join("")}
                  <span class="chip inline-flex items-center rounded-full px-2.5 py-1 text-[11px] font-semibold text-slate-700">
                    Confidence <span class="mono ml-1">${confPct}%</span>
                  </span>
                </div>
              </div>
            </div>

            ${
              headings.length
                ? `
                  <div class="mt-3">
                    <div class="text-[11px] font-semibold text-slate-500">Touched headings</div>
                    <div class="mt-2 flex flex-wrap gap-1.5">
                      ${headings
                        .map(
                          (h) => `<span class="chip mono rounded-full px-2.5 py-1 text-[11px] text-slate-700">${escapeHtml(h)}</span>`,
                        )
                        .join("")}
                    </div>
                  </div>
                `
                : ""
            }

            ${
              evidence.length
                ? `
                  <div class="mt-3">
                    <div class="text-[11px] font-semibold text-slate-500">Diff excerpts</div>
                    <div class="mt-2 grid grid-cols-1 gap-2">
                      ${evidence
                        .map(
                          (e) => `
                            <pre class="codebox overflow-auto rounded-2xl p-3"><code class="language-diff">${escapeHtml(
                              String(e),
                            )}</code></pre>
                          `,
                        )
                        .join("")}
                    </div>
                  </div>
                `
                : ""
            }
          </div>
        `;
      }

      // -----------------------------
      // Navigation helpers
      // -----------------------------

      function scrollToSection(id) {
        const el = document.getElementById(id);
        if (!el) return;
        el.scrollIntoView({ behavior: "smooth", block: "start" });
      }

      // -----------------------------
      // UI wiring
      // -----------------------------

      function wireUI() {
        const q = document.getElementById("q");
        const impact = document.getElementById("impact");
        const impactLabel = document.getElementById("impactLabel");
        const qMobile = document.getElementById("qMobile");
        const impactMobile = document.getElementById("impactMobile");
        const impactLabelMobile = document.getElementById("impactLabelMobile");

        const setImpact = (v, skipRender) => {
          STATE.minImpact = Number(v);
          impact.value = String(v);
          impactMobile.value = String(v);
          impactLabel.textContent = `${fmtInt(v)} lines`;
          impactLabelMobile.textContent = `${fmtInt(v)} lines`;
          if (!skipRender) render();
        };
        setImpact(STATE.minImpact, true);

        const debouncedRenderSearch = debounce(() => { render(); syncUrlToState(); }, 150);
        const debouncedRenderSlider = debounce(() => { render(); syncUrlToState(); }, 50);

        q.addEventListener("input", () => {
          STATE.q = q.value;
          qMobile.value = q.value;
          debouncedRenderSearch();
        });
        qMobile.addEventListener("input", () => {
          STATE.q = qMobile.value;
          q.value = qMobile.value;
          debouncedRenderSearch();
        });

        impact.addEventListener("input", () => {
          STATE.minImpact = Number(impact.value);
          impactMobile.value = impact.value;
          impactLabel.textContent = `${fmtInt(impact.value)} lines`;
          impactLabelMobile.textContent = `${fmtInt(impact.value)} lines`;
          debouncedRenderSlider();
        });
        impactMobile.addEventListener("input", () => {
          STATE.minImpact = Number(impactMobile.value);
          impact.value = impactMobile.value;
          impactLabel.textContent = `${fmtInt(impactMobile.value)} lines`;
          impactLabelMobile.textContent = `${fmtInt(impactMobile.value)} lines`;
          debouncedRenderSlider();
        });

        const setMode = (m) => {
          STATE.bucketMode = m;
          document.getElementById("bucketModeLabel").textContent = m;
          document.getElementById("modePrimary").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "primary" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          document.getElementById("modeMulti").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "multi" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          document.getElementById("modePrimaryMobile").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "primary" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          document.getElementById("modeMultiMobile").className =
            "focus-ring rounded-2xl border border-slate-900/10 px-3 py-2 text-xs font-semibold " +
            (m === "multi" ? "bg-slate-900 text-white" : "bg-white/70 text-slate-900");
          render();
          syncUrlToState();
        };

        document.getElementById("modePrimary").addEventListener("click", () => setMode("primary"));
        document.getElementById("modeMulti").addEventListener("click", () => setMode("multi"));
        document.getElementById("modePrimaryMobile").addEventListener("click", () => setMode("primary"));
        document.getElementById("modeMultiMobile").addEventListener("click", () => setMode("multi"));

        document.getElementById("btnReset").addEventListener("click", () => { resetFilters(); syncUrlToState(); });
        document.getElementById("btnResetMobile").addEventListener("click", () => { resetFilters(); syncUrlToState(); });

        // Section buttons
        document.getElementById("viewTimeline").addEventListener("click", () => scrollToSection("sectionTimeline"));
        document.getElementById("viewCommits").addEventListener("click", () => scrollToSection("sectionCommits"));
        document.getElementById("viewAlien").addEventListener("click", () => scrollToSection("sectionAlien"));

        // BOCPD hazard slider
        document.getElementById("hazard").addEventListener("input", debounce(() => render(), 50));

        // Stack chart controls
        document.getElementById("stackResolution")?.addEventListener("change", () => { render(); syncUrlToState(); });
        document.getElementById("stackMetric")?.addEventListener("change", () => { render(); syncUrlToState(); });
        document.getElementById("stackTimezone")?.addEventListener("change", () => { render(); syncUrlToState(); });

        // Doc tabs + toggles
        document.getElementById("docTabSpec")?.addEventListener("click", () => setDocTab("spec"));
        document.getElementById("docTabDiff")?.addEventListener("click", () => setDocTab("diff"));
        document.getElementById("docTabMetrics")?.addEventListener("click", () => setDocTab("metrics"));
        document.getElementById("docTabSections")?.addEventListener("click", () => setDocTab("sections"));

        document.getElementById("btnCopyLink")?.addEventListener("click", () => copyPermalink());
        document.getElementById("btnShareHelp")?.addEventListener("click", () => toggleShareHelp());
        // Close share help popover on outside click.
        document.addEventListener("click", (e) => {
          const pop = document.getElementById("shareHelpPopover");
          const btn = document.getElementById("btnShareHelp");
          if (pop && !pop.classList.contains("hidden") && !pop.contains(e.target) && e.target !== btn) {
            pop.classList.add("hidden");
          }
        });

        document.getElementById("btnRawToggle")?.addEventListener("click", () => {
          DOC.rawSpec = !DOC.rawSpec;
          syncUrlToState();
          void updateDocUI();
        });

        // Story mode toggle + navigation (bd-24q.4.2).
        document.getElementById("btnStoryToggle")?.addEventListener("click", () => {
          const rail = document.getElementById("storyRail");
          if (rail) {
            const show = rail.classList.toggle("hidden");
            const btn = document.getElementById("btnStoryToggle");
            if (btn) {
              btn.classList.toggle("bg-slate-900", !show);
              btn.classList.toggle("text-white", !show);
              btn.classList.toggle("bg-white/70", show);
              btn.classList.toggle("text-slate-900", show);
            }
            if (!show) renderStoryCards();
          }
        });
        document.getElementById("storyPrev")?.addEventListener("click", () => storyPrev());
        document.getElementById("storyNext")?.addEventListener("click", () => storyNext());

        document.getElementById("btnMiniMapToggle")?.addEventListener("click", () => {
          const mm = document.getElementById("miniMap");
          if (mm) {
            const show = mm.classList.toggle("hidden");
            const btn = document.getElementById("btnMiniMapToggle");
            if (btn) {
              btn.classList.toggle("bg-slate-900", !show);
              btn.classList.toggle("text-white", !show);
              btn.classList.toggle("bg-white/70", show);
              btn.classList.toggle("text-slate-900", show);
            }
            if (!show) void updateMiniMap();
          }
        });

        // Mini-map search filter with debounce (bd-24q.2.2).
        {
          let searchTimer = 0;
          document.getElementById("miniMapSearch")?.addEventListener("input", () => {
            clearTimeout(searchTimer);
            searchTimer = setTimeout(() => void updateMiniMap(), 150);
          });
        }

        document.getElementById("btnPrettyDiff")?.addEventListener("click", () => {
          DOC.diffMode = "pretty";
          syncUrlToState();
          void updateDocUI();
        });
        document.getElementById("btnRawDiff")?.addEventListener("click", () => {
          DOC.diffMode = "raw";
          syncUrlToState();
          void updateDocUI();
        });

        // --- A/B Compare event listeners (bd-24q.1: typeahead pickers) ---
        document.getElementById("btnCompareToggle")?.addEventListener("click", () => {
          DOC.compareMode = !DOC.compareMode;
          const btn = document.getElementById("btnCompareToggle");
          const bar = document.getElementById("abCompareBar");
          const layoutBtn = document.getElementById("btnDiffLayout");
          if (btn) { btn.classList.toggle("bg-slate-900", DOC.compareMode); btn.classList.toggle("text-white", DOC.compareMode); btn.classList.toggle("bg-white/70", !DOC.compareMode); btn.classList.toggle("text-slate-900", !DOC.compareMode); }
          if (bar) bar.classList.toggle("hidden", !DOC.compareMode);
          if (layoutBtn) layoutBtn.classList.toggle("hidden", !DOC.compareMode);
          const sbsBtn = document.getElementById("btnSbsRendered");
          if (sbsBtn) sbsBtn.classList.toggle("hidden", !DOC.compareMode);
          if (!DOC.compareMode) { DOC.abViewMode = "diff"; _sbsRenderedKey = ""; }
          if (DOC.compareMode) { DOC.compareFromIdx = Math.max(0, DOC.idx - 1); DOC.compareToIdx = DOC.idx; populateCompareSelects(); }
          syncUrlToState();
          void updateDocUI();
        });
        document.getElementById("btnDiffLayout")?.addEventListener("click", () => {
          DOC.diffLayout = DOC.diffLayout === "side-by-side" ? "line-by-line" : "side-by-side";
          DOC.abViewMode = "diff"; // switching diff layout exits rendered mode
          const btn = document.getElementById("btnDiffLayout");
          if (btn) btn.textContent = DOC.diffLayout === "side-by-side" ? "Side-by-Side" : "Unified";
          updateSbsButtonStyles();
          syncUrlToState(); void updateDocUI();
        });
        // Side-by-side rendered markdown toggle (bd-24q.15.1).
        document.getElementById("btnSbsRendered")?.addEventListener("click", () => {
          DOC.abViewMode = DOC.abViewMode === "rendered" ? "diff" : "rendered";
          updateSbsButtonStyles();
          syncUrlToState(); void updateDocUI();
        });
        // Sync scroll toggle for side-by-side panes (bd-24q.15.1).
        document.getElementById("btnSbsSyncScroll")?.addEventListener("click", () => {
          DOC.sbsSyncScroll = !DOC.sbsSyncScroll;
          const btn = document.getElementById("btnSbsSyncScroll");
          if (btn) btn.innerHTML = DOC.sbsSyncScroll ? "Sync &#x2714;" : "Sync";
          if (DOC.sbsSyncScroll) setupSbsSyncScroll();
          else if (_sbsScrollCleanup) { _sbsScrollCleanup(); _sbsScrollCleanup = null; }
        });
        // Copy permalink for side-by-side rendered view (bd-24q.15.1).
        document.getElementById("btnSbsCopyLink")?.addEventListener("click", () => {
          const qs = encodeUrlState();
          const url = qs ? `${location.origin}${location.pathname}?${qs}` : `${location.origin}${location.pathname}`;
          const done = () => { const b = document.getElementById("btnSbsCopyLink"); if (b) { b.textContent = "Copied!"; setTimeout(() => { b.textContent = "Copy Link"; }, 1500); } };
          if (navigator.clipboard?.writeText) { navigator.clipboard.writeText(url).then(done, () => { fallbackCopy(url); done(); }); }
          else { fallbackCopy(url); done(); }
        });
        // Mobile pane tabs (bd-24q.15.3).
        document.getElementById("sbsTabA")?.addEventListener("click", () => switchSbsMobilePane("a"));
        document.getElementById("sbsTabB")?.addEventListener("click", () => switchSbsMobilePane("b"));
        document.getElementById("btnSwapAB")?.addEventListener("click", () => {
          const tmp = DOC.compareFromIdx; DOC.compareFromIdx = DOC.compareToIdx; DOC.compareToIdx = tmp;
          populateCompareSelects(); syncUrlToState(); void updateDocUI();
        });
        // Reset A/B to current commit (bd-24q.1).
        document.getElementById("btnResetAB")?.addEventListener("click", () => {
          DOC.compareFromIdx = Math.max(0, DOC.idx - 1);
          DOC.compareToIdx = DOC.idx;
          populateCompareSelects(); syncUrlToState(); void updateDocUI();
        });
        // Typeahead picker buttons open their dropdowns (bd-24q.1).
        document.getElementById("pickerABtn")?.addEventListener("click", (e) => { e.stopPropagation(); openPicker("pickerA"); });
        document.getElementById("pickerBBtn")?.addEventListener("click", (e) => { e.stopPropagation(); openPicker("pickerB"); });
        wirePickerSearch("pickerA");
        wirePickerSearch("pickerB");
        // Close picker dropdowns on outside click.
        document.addEventListener("click", (e) => {
          for (const id of ["pickerA", "pickerB"]) {
            const picker = document.getElementById(id);
            const dropdown = document.getElementById(id + "Dropdown");
            if (picker && dropdown && !dropdown.classList.contains("hidden") && !picker.contains(e.target)) {
              closePicker(id);
            }
          }
        });

        document.getElementById("btnComputeAll")?.addEventListener("click", () => {
          void computeAllMetrics();
        });
        document.getElementById("btnCancelCompute")?.addEventListener("click", () => {
          COMPUTE_ABORT_CONTROLLER?.abort();
        });

        // Galaxy brain button: jump to alien section
        document.getElementById("btnGalaxy").addEventListener("click", () => scrollToSection("sectionAlien"));

        // Dock collapse toggle (mobile)
        const dockBody = document.getElementById("dockBody");
        const dockToggle = document.getElementById("dockCollapseToggle");
        if (dockToggle && dockBody) {
          dockToggle.addEventListener("click", () => {
            const hidden = dockBody.classList.toggle("hidden");
            dockToggle.textContent = hidden ? "\u25BC" : "\u25B2";
            if (!hidden) drawDock(); // redraw canvas after un-collapsing
          });
        }

        // Dock controls
        document.getElementById("dockPrev")?.addEventListener("click", () => selectCommitIdx(DOC.idx - 1));
        document.getElementById("dockNext")?.addEventListener("click", () => selectCommitIdx(DOC.idx + 1));
        document.getElementById("dockSlider")?.addEventListener("input", (e) => {
          playbackOnManualScrub();
          const v = Number(e?.target?.value || 0);
          selectCommitIdx(v);
        });
        document.getElementById("dockSlider")?.addEventListener("change", () => {
          playbackOnScrubEnd();
        });

        // Playback controls (bd-24q.7.2).
        document.getElementById("dockPlayPause")?.addEventListener("click", () => playbackToggle());
        document.getElementById("dockSpeed")?.addEventListener("change", (e) => {
          playbackSetSpeed(Number(e.target.value));
          _syncPlaybackUI();
        });
        document.getElementById("dockLoop")?.addEventListener("click", () => {
          playbackSetLoop(!PLAYBACK.loop);
          _syncPlaybackUI();
        });

        document.addEventListener("keydown", (e) => {
          // Cmd/Ctrl+K: open search palette (works from anywhere, bd-24q.9.2).
          if ((e.metaKey || e.ctrlKey) && e.key === "k") {
            e.preventDefault();
            if (_spOpen) closeSearchPalette(); else openSearchPalette();
            return;
          }

          const t = e.target;
          const isTyping =
            t && (t.tagName === "INPUT" || t.tagName === "TEXTAREA" || t.tagName === "SELECT" || t.isContentEditable);
          if (isTyping) return;

          if (e.key === "ArrowLeft") {
            e.preventDefault();
            selectCommitIdx(DOC.idx - 1);
          }
          if (e.key === "ArrowRight") {
            e.preventDefault();
            selectCommitIdx(DOC.idx + 1);
          }
          // Playback keyboard shortcuts (bd-24q.7.2).
          if (e.key === " " || e.code === "Space") {
            e.preventDefault();
            playbackToggle();
          }
        });

        // Mobile sheet
        const overlay = document.getElementById("overlay");
        const sheet = document.getElementById("sheet");
        const openSheet = () => {
          overlay.classList.remove("hidden");
          sheet.classList.remove("hidden");
          requestAnimationFrame(() => sheet.classList.add("open"));
        };
        const closeSheet = () => {
          sheet.classList.remove("open");
          setTimeout(() => {
            overlay.classList.add("hidden");
            sheet.classList.add("hidden");
          }, 200);
        };

        document.getElementById("btnFilters").addEventListener("click", openSheet);
        overlay.addEventListener("click", closeSheet);
        document.getElementById("btnCloseSheet").addEventListener("click", closeSheet);
        document.getElementById("btnApplyMobile").addEventListener("click", () => {
          // Apply mobile search changes
          STATE.q = qMobile.value;
          q.value = qMobile.value;
          render();
          syncUrlToState();
          closeSheet();
        });

        // --- Search Palette event wiring (bd-24q.9.2) ---
        const spOverlay = document.getElementById("searchPaletteOverlay");
        const spInput = document.getElementById("searchPaletteInput");
        const spResultsEl = document.getElementById("searchPaletteResults");

        if (spOverlay) {
          spOverlay.addEventListener("click", (e) => {
            if (e.target === spOverlay) closeSearchPalette();
          });
        }

        if (spInput) {
          spInput.addEventListener("input", () => {
            clearTimeout(_spDebounce);
            _spDebounce = setTimeout(() => searchPaletteQuery(spInput.value), 180);
          });

          spInput.addEventListener("keydown", (e) => {
            if (e.key === "Escape") { e.preventDefault(); closeSearchPalette(); return; }
            if (e.key === "ArrowDown") { e.preventDefault(); spNavigate(1); return; }
            if (e.key === "ArrowUp") { e.preventDefault(); spNavigate(-1); return; }
            if (e.key === "Enter") { e.preventDefault(); selectSearchResult(_spActiveIdx); return; }
          });
        }

        if (spResultsEl) {
          spResultsEl.addEventListener("click", (e) => {
            const item = e.target.closest(".search-palette-item");
            if (!item) return;
            const idx = parseInt(item.dataset.spIdx, 10);
            if (!isNaN(idx)) selectSearchResult(idx);
          });
        }
      }

      function resetFilters() {
        STATE.q = "";
        STATE.minImpact = 0;
        STATE.bucketMode = "primary";
        STATE.bucketEnabled = new Set(BUCKETS.map((b) => b.id));

        document.getElementById("q").value = "";
        document.getElementById("qMobile").value = "";
        document.getElementById("impact").value = "0";
        document.getElementById("impactMobile").value = "0";
        document.getElementById("impactLabel").textContent = "0 lines";
        document.getElementById("impactLabelMobile").textContent = "0 lines";

        render();
      }

      // -----------------------------
      // Boot
      // -----------------------------

      window.addEventListener("resize", () => {
        chartTimeline?.resize();
        chartStack?.resize();
        chartDonut?.resize();
        chartBocpd?.resize();
        drawDock();
        renderHeatStripe();
      });

      wireUI();
      _wireHeatStripe();
      (async function boot() {
        await loadEvolutionDataset();

        if (DATASET.loaded) {
          const workerReady = await initAnalysisWorker();
          const d = DATASET.data;
          if (workerReady) {
            try {
              const metricsNoLev = await workerRequest(
                "compute_all_metrics",
                { includeLev: false },
                { timeoutMs: 120000 },
              );
              applyMetricsPayload(metricsNoLev);
            } catch (e) {
              console.error("Worker boot metric precompute failed; using local precompute:", e);
              setWorkerStatus("Worker precompute failed; local fallback active.", "error", formatErr(e));
              for (let i = 0; i < d.commits.length; i++) {
                const c = d.commits[i];
                const qm = quickMetricsFromPatch(d.patches[i]);
                METRICS.tokensChanged.set(c.hash, qm.tokensChanged);
                METRICS.bytesChanged.set(c.hash, qm.bytesChanged);
                METRICS.hunks.set(c.hash, qm.hunks);
              }
            }
          } else {
            for (let i = 0; i < d.commits.length; i++) {
              const c = d.commits[i];
              const qm = quickMetricsFromPatch(d.patches[i]);
              METRICS.tokensChanged.set(c.hash, qm.tokensChanged);
              METRICS.bytesChanged.set(c.hash, qm.bytesChanged);
              METRICS.hunks.set(c.hash, qm.hunks);
            }
          }

          // Start at the latest commit (most interesting view).
          DOC.idx = Math.max(0, d.commits.length - 1);
        }

        // Restore state from URL if present; otherwise use defaults.
        const urlState = decodeUrlState(location.search);
        if (urlState) {
          applyUrlState(urlState);
          if (DOC.compareMode) {
            populateCompareSelects();
            const _b = document.getElementById("btnCompareToggle"); if (_b) { _b.classList.add("bg-slate-900","text-white"); _b.classList.remove("bg-white/70","text-slate-900"); }
            const _r = document.getElementById("abCompareBar"); if (_r) _r.classList.remove("hidden");
            const _l = document.getElementById("btnDiffLayout"); if (_l) { _l.classList.remove("hidden"); _l.textContent = DOC.diffLayout === "side-by-side" ? "Side-by-Side" : "Unified"; }
          }
        }

        // Set tab (may have been overridden by URL state).
        setDocTab(DOC.tab);
        render();
        // Record initial URL state (replaceState so back goes to referrer, not blank).
        syncUrlToState({ immediate: true, replace: true });
        void warmDerivedWorkerArtifacts();
      })();

      // Browser back/forward: restore state from URL.
      window.addEventListener("popstate", () => {
        const s = decodeUrlState(location.search);
        if (s) {
          applyUrlState(s);
          // Restore compare UI elements.
          const cmpBtn = document.getElementById("btnCompareToggle");
          const cmpBar = document.getElementById("abCompareBar");
          const layoutBtn = document.getElementById("btnDiffLayout");
          if (cmpBtn) { cmpBtn.classList.toggle("bg-slate-900", DOC.compareMode); cmpBtn.classList.toggle("text-white", DOC.compareMode); cmpBtn.classList.toggle("bg-white/70", !DOC.compareMode); cmpBtn.classList.toggle("text-slate-900", !DOC.compareMode); }
          if (cmpBar) cmpBar.classList.toggle("hidden", !DOC.compareMode);
          if (layoutBtn) { layoutBtn.classList.toggle("hidden", !DOC.compareMode); if (DOC.compareMode) layoutBtn.textContent = DOC.diffLayout === "side-by-side" ? "Side-by-Side" : "Unified"; }
          const sbsRndBtn = document.getElementById("btnSbsRendered");
          if (sbsRndBtn) sbsRndBtn.classList.toggle("hidden", !DOC.compareMode);
          if (DOC.compareMode) { populateCompareSelects(); updateSbsButtonStyles(); }
          setDocTab(DOC.tab);
          selectCommitIdx(DOC.idx);
          render();
        }
      });
    </script>
  </body>
</html>
